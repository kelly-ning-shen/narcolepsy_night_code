cuda:0
Subjects num: 78

2.5min inputs: chc001-nsrr (160)
2.5min inputs: chc004-nsrr (213)
2.5min inputs: chc005-nsrr (190)
2.5min inputs: chc006-nsrr (165)
2.5min inputs: chc008-nsrr (192)
2.5min inputs: chc009-nsrr (178)
2.5min inputs: chc010-nsrr (172)
2.5min inputs: chc012-nsrr (184)
2.5min inputs: chc013-nsrr (188)
2.5min inputs: chc014-nsrr (191)
2.5min inputs: chc015-nsrr (187)
2.5min inputs: chc016-nsrr (191)
2.5min inputs: chc022-nsrr (162)
2.5min inputs: chc025-nsrr (166)
2.5min inputs: chc027-nsrr (180)
2.5min inputs: chc028-nsrr (177)
2.5min inputs: chc033-nsrr (174)
2.5min inputs: chc035-nsrr (180)
2.5min inputs: chc037-nsrr (177)
2.5min inputs: chc040-nsrr (216)
2.5min inputs: chc041-nsrr (171)
2.5min inputs: chc052-nsrr (183)
2.5min inputs: chc056-nsrr (184)
2.5min inputs: chp001-nsrr (232)
2.5min inputs: chp002-nsrr (216)
2.5min inputs: chp003-nsrr (200)
2.5min inputs: chp004-nsrr (197)
2.5min inputs: chp005-nsrr (261)
2.5min inputs: chp006-nsrr (220)
2.5min inputs: chp007-nsrr (231)
2.5min inputs: chp008-nsrr (191)
2.5min inputs: chp009-nsrr (206)
2.5min inputs: chp010-nsrr (194)
2.5min inputs: chp011-nsrr (202)
2.5min inputs: chp012-nsrr (223)
2.5min inputs: chp013-nsrr (200)
2.5min inputs: chp014-nsrr (201)
2.5min inputs: chp015-nsrr (231)
2.5min inputs: chp016-nsrr (254)
2.5min inputs: chp017-nsrr (202)
2.5min inputs: chp018-nsrr (225)
2.5min inputs: chp019-nsrr (188)
2.5min inputs: chp020-nsrr (230)
2.5min inputs: chp022-nsrr (253)
2.5min inputs: chp024-nsrr (225)
2.5min inputs: chp025-nsrr (89)
2.5min inputs: chp026-nsrr (188)
2.5min inputs: chp028-nsrr (206)
2.5min inputs: chp029-nsrr (209)
2.5min inputs: chp030-nsrr (240)
2.5min inputs: chp031-nsrr (222)
2.5min inputs: chp032-nsrr (213)
2.5min inputs: chp033-nsrr (202)
2.5min inputs: chp034-nsrr (208)
2.5min inputs: chp036-nsrr (252)
2.5min inputs: chp037-nsrr (207)
2.5min inputs: chp038-nsrr (205)
2.5min inputs: chp039-nsrr (222)
2.5min inputs: chp040-nsrr (214)
2.5min inputs: chp041-nsrr (221)
2.5min inputs: chp042-nsrr (223)
2.5min inputs: chp043-nsrr (241)
2.5min inputs: chp044-nsrr (210)
2.5min inputs: chp045-nsrr (241)
2.5min inputs: chp046-nsrr (219)
2.5min inputs: chp047-nsrr (178)
2.5min inputs: chp048-nsrr (206)
2.5min inputs: chp049-nsrr (216)
2.5min inputs: chp051-nsrr (218)
2.5min inputs: chp052-nsrr (200)
2.5min inputs: chp053-nsrr (217)
2.5min inputs: chp054-nsrr (224)
2.5min inputs: chp055-nsrr (222)
2.5min inputs: chp056-nsrr (220)
2.5min inputs: chp057-nsrr (239)
2.5min inputs: chp058-nsrr (206)
2.5min inputs: chp059-nsrr (227)
2.5min inputs: chp060-nsrr (252)

=== Test on chc001-nsrr. train_data(15860), test_data(160) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3652859669002448
Starting epoch 2/10.
Epoch finished! Loss: 1.0151778153252526
Starting epoch 3/10.
Epoch finished! Loss: 0.944815000543835
Starting epoch 4/10.
Epoch finished! Loss: 0.8913042225108162
Starting epoch 5/10.
Epoch finished! Loss: 0.8616564607770661
Starting epoch 6/10.
Epoch finished! Loss: 0.8331940838967212
Starting epoch 7/10.
Epoch finished! Loss: 0.8209131977535573
Starting epoch 8/10.
Epoch finished! Loss: 0.8021369146999877
Starting epoch 9/10.
Epoch finished! Loss: 0.8013740132095686
Starting epoch 10/10.
Epoch finished! Loss: 0.7819434289488507
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.845
              precision    recall  f1-score   support

         0.0       0.78      0.96      0.86        78
         1.0       0.67      0.04      0.08        50
         2.0       0.90      0.86      0.88       417
         3.0       0.73      1.00      0.85       143
         4.0       0.90      0.88      0.89       112

    accuracy                           0.84       800
   macro avg       0.80      0.75      0.71       800
weighted avg       0.84      0.84      0.82       800
 


====== chc001-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  97.00   96.15   97.09  78.12     86.21
1  93.88    4.00   99.87  66.67      7.55
2  87.75   85.85   89.82  90.18     87.96
3  93.50  100.00   92.09  73.33     84.62
4  96.88   87.50   98.40  89.91     88.69
Total accuracy: 84.50%
Average sen: 74.70%
Average spec: 95.45%
Macro f1-score: 71.00%
Diagnosis acc on 2.5mins: 1.0
pred: 4.6775928796204123e-05, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc001-nsrr

=== Test on chc004-nsrr. train_data(15807), test_data(213) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3610212955293777
Starting epoch 2/10.
Epoch finished! Loss: 1.0011817256672473
Starting epoch 3/10.
Epoch finished! Loss: 0.9258367219303227
Starting epoch 4/10.
Epoch finished! Loss: 0.8935763625027259
Starting epoch 5/10.
Epoch finished! Loss: 0.8516757230781302
Starting epoch 6/10.
Epoch finished! Loss: 0.8240746611469909
Starting epoch 7/10.
Epoch finished! Loss: 0.8189550788719443
Starting epoch 8/10.
Epoch finished! Loss: 0.791892442880552
Starting epoch 9/10.
Epoch finished! Loss: 0.7828121697412261
Starting epoch 10/10.
Epoch finished! Loss: 0.7820332283837885
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7680751173708921
              precision    recall  f1-score   support

         0.0       0.43      0.97      0.60        75
         1.0       0.33      0.02      0.04        42
         2.0       0.89      0.71      0.79       523
         3.0       0.88      0.82      0.85       243
         4.0       0.70      0.96      0.81       182

    accuracy                           0.77      1065
   macro avg       0.65      0.70      0.62      1065
weighted avg       0.80      0.77      0.76      1065
 


====== chc004-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  90.80  97.33   90.30  43.20     59.84
1  95.96   2.38   99.80  33.33      4.44
2  81.22  70.55   91.51  88.92     78.68
3  93.33  82.30   96.59  87.72     84.93
4  92.30  96.15   91.51  70.00     81.02
Total accuracy: 76.81%
Average sen: 69.75%
Average spec: 93.94%
Macro f1-score: 61.78%
Diagnosis acc on 2.5mins: 1.0
pred: 0.0005556763263272792, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc004-nsrr

=== Test on chc005-nsrr. train_data(15830), test_data(190) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3142865998517397
Starting epoch 2/10.
Epoch finished! Loss: 0.9939514938671279
Starting epoch 3/10.
Epoch finished! Loss: 0.9259024822870187
Starting epoch 4/10.
Epoch finished! Loss: 0.8867206336499466
Starting epoch 5/10.
Epoch finished! Loss: 0.858290785483253
Starting epoch 6/10.
Epoch finished! Loss: 0.8362529447535347
Starting epoch 7/10.
Epoch finished! Loss: 0.8222211439977253
Starting epoch 8/10.
Epoch finished! Loss: 0.7967407401043606
Starting epoch 9/10.
Epoch finished! Loss: 0.7923989746761985
Starting epoch 10/10.
Epoch finished! Loss: 0.7742437303593729
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8463157894736842
              precision    recall  f1-score   support

         0.0       0.81      0.93      0.87        42
         1.0       0.50      0.03      0.06        34
         2.0       0.89      0.88      0.88       548
         3.0       0.91      0.81      0.86       236
         4.0       0.61      1.00      0.76        90

    accuracy                           0.85       950
   macro avg       0.74      0.73      0.69       950
weighted avg       0.85      0.85      0.84       950
 


====== chc005-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  98.74   92.86   99.01  81.25     86.67
1  96.42    2.94   99.89  50.00      5.56
2  86.74   87.96   85.07  88.93     88.44
3  93.37   81.36   97.34  91.00     85.91
4  94.00  100.00   93.37  61.22     75.95
Total accuracy: 84.63%
Average sen: 73.02%
Average spec: 94.94%
Macro f1-score: 68.50%
Diagnosis acc on 2.5mins: 1.0
pred: 0.005701346882677576, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc005-nsrr

=== Test on chc006-nsrr. train_data(15855), test_data(165) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3866661593364993
Starting epoch 2/10.
Epoch finished! Loss: 1.0187338431550876
Starting epoch 3/10.
Epoch finished! Loss: 0.9356001335551686
Starting epoch 4/10.
Epoch finished! Loss: 0.8881719163915712
Starting epoch 5/10.
Epoch finished! Loss: 0.8707407525661239
Starting epoch 6/10.
Epoch finished! Loss: 0.8359035109307864
Starting epoch 7/10.
Epoch finished! Loss: 0.8094701208620794
Starting epoch 8/10.
Epoch finished! Loss: 0.8029876819920465
Starting epoch 9/10.
Epoch finished! Loss: 0.7908735050293926
Starting epoch 10/10.
Epoch finished! Loss: 0.7738189346312725
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7963636363636364
              precision    recall  f1-score   support

         0.0       0.73      0.99      0.84       163
         1.0       1.00      0.03      0.05       113
         2.0       0.93      0.86      0.89       306
         3.0       0.84      1.00      0.91       133
         4.0       0.62      0.89      0.73       110

    accuracy                           0.80       825
   macro avg       0.82      0.75      0.68       825
weighted avg       0.84      0.80      0.75       825
 


====== chc006-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  92.36   98.77   90.79   72.52     83.64
1  86.67    2.65  100.00  100.00      5.17
2  92.12   85.62   95.95   92.58     88.96
3  96.97  100.00   96.39   84.18     91.41
4  91.15   89.09   91.47   61.64     72.86
Total accuracy: 79.64%
Average sen: 75.23%
Average spec: 94.92%
Macro f1-score: 68.41%
Diagnosis acc on 2.5mins: 1.0
pred: 0.00024281139082866978, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc006-nsrr

=== Test on chc008-nsrr. train_data(15828), test_data(192) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3905561865129603
Starting epoch 2/10.
Epoch finished! Loss: 1.0118761330127113
Starting epoch 3/10.
Epoch finished! Loss: 0.9440850315971109
Starting epoch 4/10.
Epoch finished! Loss: 0.8841552334436122
Starting epoch 5/10.
Epoch finished! Loss: 0.8673947312399349
Starting epoch 6/10.
Epoch finished! Loss: 0.8438505465082363
Starting epoch 7/10.
Epoch finished! Loss: 0.8099301092599798
Starting epoch 8/10.
Epoch finished! Loss: 0.7944667829593877
Starting epoch 9/10.
Epoch finished! Loss: 0.7862639231454256
Starting epoch 10/10.
Epoch finished! Loss: 0.765040558354291
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7833333333333333
              precision    recall  f1-score   support

         0.0       0.65      0.90      0.76       144
         1.0       0.42      0.10      0.16        82
         2.0       0.91      0.78      0.84       379
         3.0       0.98      0.93      0.95       227
         4.0       0.53      0.84      0.65       128

    accuracy                           0.78       960
   macro avg       0.70      0.71      0.67       960
weighted avg       0.80      0.78      0.77       960
 


====== chc008-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  91.35  89.58   91.67  65.48     75.66
1  91.15   9.76   98.75  42.11     15.84
2  88.44  78.10   95.18  91.36     84.21
3  97.92  92.95   99.45  98.14     95.48
4  87.81  84.38   88.34  52.68     64.86
Total accuracy: 78.33%
Average sen: 70.95%
Average spec: 94.68%
Macro f1-score: 67.21%
Diagnosis acc on 2.5mins: 1.0
pred: 0.0004022707943361903, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc008-nsrr

=== Test on chc009-nsrr. train_data(15842), test_data(178) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.443655773621015
Starting epoch 2/10.
Epoch finished! Loss: 1.0547688448557047
Starting epoch 3/10.
Epoch finished! Loss: 0.9563985885770032
Starting epoch 4/10.
Epoch finished! Loss: 0.9017605767632374
Starting epoch 5/10.
Epoch finished! Loss: 0.8666057235401388
Starting epoch 6/10.
Epoch finished! Loss: 0.8319938419988812
Starting epoch 7/10.
Epoch finished! Loss: 0.8203733161449281
Starting epoch 8/10.
Epoch finished! Loss: 0.8089112289663818
Starting epoch 9/10.
Epoch finished! Loss: 0.7881768316670199
Starting epoch 10/10.
Epoch finished! Loss: 0.7765925969326436
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7146067415730337
              precision    recall  f1-score   support

         0.0       0.69      1.00      0.81        72
         1.0       0.40      0.04      0.08        46
         2.0       0.94      0.55      0.69       463
         3.0       0.62      0.99      0.77       196
         4.0       0.57      1.00      0.73       113

    accuracy                           0.71       890
   macro avg       0.64      0.72      0.62       890
weighted avg       0.78      0.71      0.69       890
 


====== chc009-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  96.29  100.00   95.97  68.57     81.36
1  94.72    4.35   99.64  40.00      7.84
2  74.83   54.86   96.49  94.42     69.40
3  86.63   99.49   83.00  62.30     76.62
4  90.45  100.00   89.06  57.07     72.67
Total accuracy: 71.46%
Average sen: 71.74%
Average spec: 92.83%
Macro f1-score: 61.58%
Diagnosis acc on 2.5mins: 1.0
pred: 1.0138437620064766e-05, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc009-nsrr

=== Test on chc010-nsrr. train_data(15848), test_data(172) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3780342485718053
Starting epoch 2/10.
Epoch finished! Loss: 1.026250001250042
Starting epoch 3/10.
Epoch finished! Loss: 0.919626243958118
Starting epoch 4/10.
Epoch finished! Loss: 0.8762186989188194
Starting epoch 5/10.
Epoch finished! Loss: 0.8582097870683429
Starting epoch 6/10.
Epoch finished! Loss: 0.8148035346671487
Starting epoch 7/10.
Epoch finished! Loss: 0.804215397554064
Starting epoch 8/10.
Epoch finished! Loss: 0.7967891618797575
Starting epoch 9/10.
Epoch finished! Loss: 0.7647011145253224
Starting epoch 10/10.
Epoch finished! Loss: 0.773438403279417
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8406976744186047
              precision    recall  f1-score   support

         0.0       0.90      0.84      0.87       123
         1.0       1.00      0.07      0.13        43
         2.0       0.81      0.97      0.89       420
         3.0       0.94      0.67      0.79       193
         4.0       0.77      0.96      0.86        81

    accuracy                           0.84       860
   macro avg       0.89      0.70      0.71       860
weighted avg       0.86      0.84      0.82       860
 


====== chc010-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  96.40  83.74   98.51   90.35     86.92
1  95.35   6.98  100.00  100.00     13.04
2  87.67  97.38   78.41   81.15     88.53
3  91.74  67.36   98.80   94.20     78.55
4  96.98  96.30   97.05   77.23     85.71
Total accuracy: 84.07%
Average sen: 70.35%
Average spec: 94.55%
Macro f1-score: 70.55%
Diagnosis acc on 2.5mins: 0.9767441860465116
pred: 0.029799808682836618, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc010-nsrr

=== Test on chc012-nsrr. train_data(15836), test_data(184) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3472537337717043
Starting epoch 2/10.
Epoch finished! Loss: 0.9844480138260281
Starting epoch 3/10.
Epoch finished! Loss: 0.917174954355629
Starting epoch 4/10.
Epoch finished! Loss: 0.876009669303141
Starting epoch 5/10.
Epoch finished! Loss: 0.8310983096092318
Starting epoch 6/10.
Epoch finished! Loss: 0.8196448778341785
Starting epoch 7/10.
Epoch finished! Loss: 0.8000346028345413
Starting epoch 8/10.
Epoch finished! Loss: 0.7801631364503091
Starting epoch 9/10.
Epoch finished! Loss: 0.7795101449938416
Starting epoch 10/10.
Epoch finished! Loss: 0.7598878144464836
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7923913043478261
              precision    recall  f1-score   support

         0.0       0.45      0.97      0.61        64
         1.0       0.00      0.00      0.00        23
         2.0       0.85      0.89      0.87       559
         3.0       1.00      0.62      0.77       204
         4.0       0.61      0.64      0.62        70

    accuracy                           0.79       920
   macro avg       0.58      0.62      0.57       920
weighted avg       0.82      0.79      0.79       920
 


====== chc012-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  91.52  96.88   91.12   44.93     61.39
1  97.50   0.00  100.00    0.00      0.00
2  83.70  88.55   76.18   85.20     86.84
3  91.63  62.25  100.00  100.00     76.74
4  94.13  64.29   96.59   60.81     62.50
Total accuracy: 79.24%
Average sen: 62.39%
Average spec: 92.78%
Macro f1-score: 57.49%
Diagnosis acc on 2.5mins: 1.0
pred: 7.164119064697316e-05, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc012-nsrr

=== Test on chc013-nsrr. train_data(15832), test_data(188) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.447498528285638
Starting epoch 2/10.
Epoch finished! Loss: 1.0707908999633728
Starting epoch 3/10.
Epoch finished! Loss: 0.9839882910891717
Starting epoch 4/10.
Epoch finished! Loss: 0.9342608463515681
Starting epoch 5/10.
Epoch finished! Loss: 0.8928063127223405
Starting epoch 6/10.
Epoch finished! Loss: 0.8711410237691558
Starting epoch 7/10.
Epoch finished! Loss: 0.8361006636297258
Starting epoch 8/10.
Epoch finished! Loss: 0.8431864461225569
Starting epoch 9/10.
Epoch finished! Loss: 0.8217259104200654
Starting epoch 10/10.
Epoch finished! Loss: 0.8014901253481267
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7351063829787234
              precision    recall  f1-score   support

         0.0       0.73      1.00      0.84        69
         1.0       0.00      0.00      0.00        40
         2.0       0.77      0.74      0.75       434
         3.0       1.00      0.59      0.74       228
         4.0       0.57      0.98      0.72       169

    accuracy                           0.74       940
   macro avg       0.61      0.66      0.61       940
weighted avg       0.75      0.74      0.72       940
 


====== chc013-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  97.23  100.00   97.01   72.63     84.15
1  95.74    0.00  100.00    0.00      0.00
2  77.77   73.96   81.03   76.98     75.44
3  90.11   59.21  100.00  100.00     74.38
4  86.17   98.22   83.53   56.66     71.86
Total accuracy: 73.51%
Average sen: 66.28%
Average spec: 92.31%
Macro f1-score: 61.17%
Diagnosis acc on 2.5mins: 1.0
pred: 1.472084125426352e-06, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc013-nsrr

=== Test on chc014-nsrr. train_data(15829), test_data(191) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.353697482086765
Starting epoch 2/10.
Epoch finished! Loss: 1.0260647962955398
Starting epoch 3/10.
Epoch finished! Loss: 0.9377727517210578
Starting epoch 4/10.
Epoch finished! Loss: 0.8879851910807239
Starting epoch 5/10.
Epoch finished! Loss: 0.8532058185934267
Starting epoch 6/10.
Epoch finished! Loss: 0.8399031829517499
Starting epoch 7/10.
Epoch finished! Loss: 0.8193062334386196
Starting epoch 8/10.
Epoch finished! Loss: 0.7933149884741014
Starting epoch 9/10.
Epoch finished! Loss: 0.7919872301229183
Starting epoch 10/10.
Epoch finished! Loss: 0.7783230748569167
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8607329842931937
              precision    recall  f1-score   support

         0.0       0.96      0.98      0.97       240
         1.0       0.00      0.00      0.00         6
         2.0       0.99      0.73      0.84       439
         3.0       0.74      0.99      0.84       195
         4.0       0.60      1.00      0.75        75

    accuracy                           0.86       955
   macro avg       0.66      0.74      0.68       955
weighted avg       0.89      0.86      0.86       955
 


====== chc014-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  98.53   97.92   98.74  96.31     97.11
1  99.27    0.00   99.89   0.00      0.00
2  87.12   72.67   99.42  99.07     83.84
3  92.57   98.97   90.92  73.66     84.46
4  94.66  100.00   94.20  59.52     74.63
Total accuracy: 86.07%
Average sen: 73.91%
Average spec: 96.64%
Macro f1-score: 68.01%
Diagnosis acc on 2.5mins: 0.93717277486911
pred: 0.07659342676965362, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc014-nsrr

=== Test on chc015-nsrr. train_data(15833), test_data(187) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3851595622636212
Starting epoch 2/10.
Epoch finished! Loss: 1.0592320016382317
Starting epoch 3/10.
Epoch finished! Loss: 0.9565563868173526
Starting epoch 4/10.
Epoch finished! Loss: 0.9105079972284622
Starting epoch 5/10.
Epoch finished! Loss: 0.8797179053120423
Starting epoch 6/10.
Epoch finished! Loss: 0.8484955974398575
Starting epoch 7/10.
Epoch finished! Loss: 0.842472935543735
Starting epoch 8/10.
Epoch finished! Loss: 0.8147947599503035
Starting epoch 9/10.
Epoch finished! Loss: 0.797901179563826
Starting epoch 10/10.
Epoch finished! Loss: 0.7895587593768868
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7336898395721925
              precision    recall  f1-score   support

         0.0       0.45      0.82      0.58        38
         1.0       0.67      0.05      0.09        88
         2.0       0.95      0.72      0.82       502
         3.0       0.60      1.00      0.75       166
         4.0       0.61      0.87      0.72       141

    accuracy                           0.73       935
   macro avg       0.66      0.69      0.59       935
weighted avg       0.79      0.73      0.71       935
 


====== chc015-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  95.19   81.58   95.76  44.93     57.94
1  90.80    4.55   99.76  66.67      8.51
2  82.89   72.11   95.38  94.76     81.90
3  88.02  100.00   85.44  59.71     74.77
4  89.84   87.23   90.30  61.50     72.14
Total accuracy: 73.37%
Average sen: 69.09%
Average spec: 93.33%
Macro f1-score: 59.05%
Diagnosis acc on 2.5mins: 1.0
pred: 0.001928777343954623, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc015-nsrr

=== Test on chc016-nsrr. train_data(15829), test_data(191) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3610058050466096
Starting epoch 2/10.
Epoch finished! Loss: 1.0257171182392821
Starting epoch 3/10.
Epoch finished! Loss: 0.9374650179699309
Starting epoch 4/10.
Epoch finished! Loss: 0.8884617294244911
Starting epoch 5/10.
Epoch finished! Loss: 0.8536766009445287
Starting epoch 6/10.
Epoch finished! Loss: 0.8257872932290308
Starting epoch 7/10.
Epoch finished! Loss: 0.8068985361817814
Starting epoch 8/10.
Epoch finished! Loss: 0.792268702141027
Starting epoch 9/10.
Epoch finished! Loss: 0.7815934432724635
Starting epoch 10/10.
Epoch finished! Loss: 0.7636339924334726
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8209424083769633
              precision    recall  f1-score   support

         0.0       0.64      0.99      0.78       226
         1.0       0.00      0.00      0.00        55
         2.0       0.93      0.84      0.88       410
         3.0       1.00      0.82      0.90       108
         4.0       0.88      0.81      0.85       156

    accuracy                           0.82       955
   macro avg       0.69      0.69      0.68       955
weighted avg       0.81      0.82      0.80       955
 


====== chc016-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  86.49  99.12   82.58   63.82     77.64
1  94.24   0.00  100.00    0.00      0.00
2  90.26  83.90   95.05   92.72     88.09
3  98.01  82.41  100.00  100.00     90.36
4  95.18  81.41   97.87   88.19     84.67
Total accuracy: 82.09%
Average sen: 69.37%
Average spec: 95.10%
Macro f1-score: 68.15%
Diagnosis acc on 2.5mins: 1.0
pred: 0.00019471220601294757, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc016-nsrr

=== Test on chc022-nsrr. train_data(15858), test_data(162) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3975715812824503
Starting epoch 2/10.
Epoch finished! Loss: 1.0296262127743911
Starting epoch 3/10.
Epoch finished! Loss: 0.94494995465414
Starting epoch 4/10.
Epoch finished! Loss: 0.8997553450640068
Starting epoch 5/10.
Epoch finished! Loss: 0.8700254721784442
Starting epoch 6/10.
Epoch finished! Loss: 0.8504644918893038
Starting epoch 7/10.
Epoch finished! Loss: 0.8162324052221768
Starting epoch 8/10.
Epoch finished! Loss: 0.8037431156221625
Starting epoch 9/10.
Epoch finished! Loss: 0.7909262577441964
Starting epoch 10/10.
Epoch finished! Loss: 0.7791756694343188
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7901234567901234
              precision    recall  f1-score   support

         0.0       0.96      0.99      0.98       102
         1.0       0.00      0.00      0.00        15
         2.0       0.91      0.66      0.77       397
         3.0       0.61      1.00      0.76       187
         4.0       0.82      0.83      0.82       109

    accuracy                           0.79       810
   macro avg       0.66      0.70      0.66       810
weighted avg       0.82      0.79      0.78       810
 


====== chc022-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  99.38   99.02   99.44  96.19     97.58
1  98.15    0.00  100.00   0.00      0.00
2  80.25   65.99   93.95  91.29     76.61
3  85.06  100.00   80.58  60.71     75.56
4  95.19   82.57   97.15  81.82     82.19
Total accuracy: 79.01%
Average sen: 69.52%
Average spec: 94.22%
Macro f1-score: 66.39%
Diagnosis acc on 2.5mins: 1.0
pred: 5.112832437638557e-07, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc022-nsrr

=== Test on chc025-nsrr. train_data(15854), test_data(166) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3643031904750065
Starting epoch 2/10.
Epoch finished! Loss: 1.0215232033646822
Starting epoch 3/10.
Epoch finished! Loss: 0.9337266266157951
Starting epoch 4/10.
Epoch finished! Loss: 0.8774490949295297
Starting epoch 5/10.
Epoch finished! Loss: 0.844005319278699
Starting epoch 6/10.
Epoch finished! Loss: 0.8189170610359414
Starting epoch 7/10.
Epoch finished! Loss: 0.8103860921288139
Starting epoch 8/10.
Epoch finished! Loss: 0.7839382777266698
Starting epoch 9/10.
Epoch finished! Loss: 0.7738982368436897
Starting epoch 10/10.
Epoch finished! Loss: 0.7632995277361163
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6903614457831325
              precision    recall  f1-score   support

         0.0       0.50      0.24      0.32        38
         1.0       0.17      0.01      0.02        79
         2.0       0.87      0.69      0.77       427
         3.0       0.90      0.92      0.91       114
         4.0       0.46      0.94      0.62       172

    accuracy                           0.69       830
   macro avg       0.58      0.56      0.53       830
weighted avg       0.71      0.69      0.67       830
 


====== chc025-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  95.42  23.68   98.86  50.00     32.14
1  90.00   1.27   99.33  16.67      2.35
2  78.92  69.32   89.08  87.06     77.18
3  97.47  92.11   98.32  89.74     90.91
4  76.27  94.19   71.58  46.42     62.19
Total accuracy: 69.04%
Average sen: 56.11%
Average spec: 91.44%
Macro f1-score: 52.96%
Diagnosis acc on 2.5mins: 1.0
pred: 4.273377731421663e-05, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc025-nsrr

=== Test on chc027-nsrr. train_data(15840), test_data(180) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3715864987743858
Starting epoch 2/10.
Epoch finished! Loss: 1.0414305383919615
Starting epoch 3/10.
Epoch finished! Loss: 0.9572604701666612
Starting epoch 4/10.
Epoch finished! Loss: 0.8961847137403277
Starting epoch 5/10.
Epoch finished! Loss: 0.8714466206423481
Starting epoch 6/10.
Epoch finished! Loss: 0.8461962834668928
Starting epoch 7/10.
Epoch finished! Loss: 0.823791581179549
Starting epoch 8/10.
Epoch finished! Loss: 0.8115249091567529
Starting epoch 9/10.
Epoch finished! Loss: 0.7967118944311473
Starting epoch 10/10.
Epoch finished! Loss: 0.7951229748681461
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8166666666666667
              precision    recall  f1-score   support

         0.0       0.78      1.00      0.87       277
         1.0       0.75      0.05      0.09        66
         2.0       0.83      0.80      0.82       293
         3.0       1.00      0.78      0.88       189
         4.0       0.66      0.97      0.79        75

    accuracy                           0.82       900
   macro avg       0.80      0.72      0.69       900
weighted avg       0.83      0.82      0.79       900
 


====== chc027-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  91.11  100.00   87.16   77.59     87.38
1  92.89    4.55   99.88   75.00      8.57
2  88.22   79.86   92.26   83.27     81.53
3  95.44   78.31  100.00  100.00     87.83
4  95.67   97.33   95.52   66.36     78.92
Total accuracy: 81.67%
Average sen: 72.01%
Average spec: 94.96%
Macro f1-score: 68.85%
Diagnosis acc on 2.5mins: 1.0
pred: 0.0060808029404126685, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc027-nsrr

=== Test on chc028-nsrr. train_data(15843), test_data(177) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.412287580432615
Starting epoch 2/10.
Epoch finished! Loss: 1.0497737703938979
Starting epoch 3/10.
Epoch finished! Loss: 0.9433424788329637
Starting epoch 4/10.
Epoch finished! Loss: 0.8888985662335398
Starting epoch 5/10.
Epoch finished! Loss: 0.8541617382581186
Starting epoch 6/10.
Epoch finished! Loss: 0.8238676107780198
Starting epoch 7/10.
Epoch finished! Loss: 0.7990895593350734
Starting epoch 8/10.
Epoch finished! Loss: 0.7921095776625655
Starting epoch 9/10.
Epoch finished! Loss: 0.7837161092614435
Starting epoch 10/10.
Epoch finished! Loss: 0.7698421952493414
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.752542372881356
              precision    recall  f1-score   support

         0.0       0.50      1.00      0.67       134
         1.0       0.00      0.00      0.00        53
         2.0       0.96      0.67      0.79       460
         3.0       0.93      0.96      0.95       164
         4.0       0.56      0.92      0.70        74

    accuracy                           0.75       885
   macro avg       0.59      0.71      0.62       885
weighted avg       0.80      0.75      0.74       885
 


====== chc028-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  84.75  100.00   82.02  49.81     66.50
1  93.11    0.00   99.04   0.00      0.00
2  81.24   66.52   97.18  96.23     78.66
3  98.08   96.34   98.47  93.49     94.89
4  93.33   91.89   93.46  56.20     69.74
Total accuracy: 75.25%
Average sen: 70.95%
Average spec: 94.04%
Macro f1-score: 61.96%
Diagnosis acc on 2.5mins: 1.0
pred: 0.002235776143694279, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc028-nsrr

=== Test on chc033-nsrr. train_data(15846), test_data(174) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4848667256759875
Starting epoch 2/10.
Epoch finished! Loss: 1.0343240193947396
Starting epoch 3/10.
Epoch finished! Loss: 0.929654549017097
Starting epoch 4/10.
Epoch finished! Loss: 0.884686857292598
Starting epoch 5/10.
Epoch finished! Loss: 0.8546685249817492
Starting epoch 6/10.
Epoch finished! Loss: 0.8323772894877075
Starting epoch 7/10.
Epoch finished! Loss: 0.8150924358215897
Starting epoch 8/10.
Epoch finished! Loss: 0.7868438148400699
Starting epoch 9/10.
Epoch finished! Loss: 0.7898410381843345
Starting epoch 10/10.
Epoch finished! Loss: 0.7704602438072213
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8333333333333334
              precision    recall  f1-score   support

         0.0       0.73      0.93      0.82        59
         1.0       0.00      0.00      0.00        60
         2.0       0.97      0.80      0.88       389
         3.0       0.80      1.00      0.89       151
         4.0       0.73      0.98      0.84       211

    accuracy                           0.83       870
   macro avg       0.65      0.74      0.69       870
weighted avg       0.80      0.83      0.81       870
 


====== chc033-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  97.24   93.22   97.53  73.33     82.09
1  92.87    0.00   99.75   0.00      0.00
2  90.23   80.46   98.13  97.20     88.05
3  95.63  100.00   94.71  79.89     88.82
4  90.69   97.63   88.47  73.05     83.57
Total accuracy: 83.33%
Average sen: 74.26%
Average spec: 95.72%
Macro f1-score: 68.51%
Diagnosis acc on 2.5mins: 1.0
pred: 5.9180531253017625e-06, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc033-nsrr

=== Test on chc035-nsrr. train_data(15840), test_data(180) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4133610525842113
Starting epoch 2/10.
Epoch finished! Loss: 1.081938638953717
Starting epoch 3/10.
Epoch finished! Loss: 0.9964836867113167
Starting epoch 4/10.
Epoch finished! Loss: 0.9541599762002954
Starting epoch 5/10.
Epoch finished! Loss: 0.915672634985352
Starting epoch 6/10.
Epoch finished! Loss: 0.907263295697925
Starting epoch 7/10.
Epoch finished! Loss: 0.8770412728519885
Starting epoch 8/10.
Epoch finished! Loss: 0.8650906310003164
Starting epoch 9/10.
Epoch finished! Loss: 0.8448147959748327
Starting epoch 10/10.
Epoch finished! Loss: 0.8389636342539037
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8311111111111111
              precision    recall  f1-score   support

         0.0       0.73      0.93      0.82        29
         1.0       0.62      0.14      0.23        57
         2.0       0.92      0.79      0.85       391
         3.0       0.88      0.95      0.92       250
         4.0       0.67      0.96      0.79       173

    accuracy                           0.83       900
   macro avg       0.77      0.75      0.72       900
weighted avg       0.84      0.83      0.82       900
 


====== chc035-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  98.67  93.10   98.85  72.97     81.82
1  94.00  14.04   99.41  61.54     22.86
2  88.11  79.28   94.89  92.26     85.28
3  95.11  94.80   95.23  88.43     91.51
4  90.33  95.95   89.00  67.48     79.24
Total accuracy: 83.11%
Average sen: 75.44%
Average spec: 95.48%
Macro f1-score: 72.14%
Diagnosis acc on 2.5mins: 1.0
pred: 0.00017634209024811732, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc035-nsrr

=== Test on chc037-nsrr. train_data(15843), test_data(177) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.40245288347054
Starting epoch 2/10.
Epoch finished! Loss: 1.0417010651129965
Starting epoch 3/10.
Epoch finished! Loss: 0.9591406111539614
Starting epoch 4/10.
Epoch finished! Loss: 0.9009977362372659
Starting epoch 5/10.
Epoch finished! Loss: 0.8846290513327477
Starting epoch 6/10.
Epoch finished! Loss: 0.8487185992752061
Starting epoch 7/10.
Epoch finished! Loss: 0.8239226937294006
Starting epoch 8/10.
Epoch finished! Loss: 0.8222669501215069
Starting epoch 9/10.
Epoch finished! Loss: 0.7952919280100049
Starting epoch 10/10.
Epoch finished! Loss: 0.7793257832339014
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.9084745762711864
              precision    recall  f1-score   support

         0.0       0.83      1.00      0.91       154
         1.0       0.50      0.06      0.11        34
         2.0       0.99      0.86      0.92       322
         3.0       0.87      1.00      0.93       168
         4.0       0.92      0.99      0.95       207

    accuracy                           0.91       885
   macro avg       0.82      0.78      0.76       885
weighted avg       0.90      0.91      0.89       885
 


====== chc037-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  96.38  100.00   95.62  82.80     90.59
1  96.16    5.88   99.76  50.00     10.53
2  94.46   85.71   99.47  98.92     91.85
3  97.06  100.00   96.37  86.60     92.82
4  97.63   98.55   97.35  91.89     95.10
Total accuracy: 90.85%
Average sen: 78.03%
Average spec: 97.71%
Macro f1-score: 76.18%
Diagnosis acc on 2.5mins: 0.9152542372881356
pred: 0.09136930095284634, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc037-nsrr

=== Test on chc040-nsrr. train_data(15804), test_data(216) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4072609768260884
Starting epoch 2/10.
Epoch finished! Loss: 1.0038822481149359
Starting epoch 3/10.
Epoch finished! Loss: 0.9291020994510831
Starting epoch 4/10.
Epoch finished! Loss: 0.8829959153563162
Starting epoch 5/10.
Epoch finished! Loss: 0.8755946450218369
Starting epoch 6/10.
Epoch finished! Loss: 0.8190771866448318
Starting epoch 7/10.
Epoch finished! Loss: 0.8203415282542192
Starting epoch 8/10.
Epoch finished! Loss: 0.7963462671995918
Starting epoch 9/10.
Epoch finished! Loss: 0.7922310675435429
Starting epoch 10/10.
Epoch finished! Loss: 0.7759885710817349
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7851851851851852
              precision    recall  f1-score   support

         0.0       0.91      0.60      0.72       185
         1.0       0.62      0.16      0.25        50
         2.0       0.86      0.89      0.88       483
         3.0       0.97      0.72      0.83       216
         4.0       0.50      0.98      0.66       146

    accuracy                           0.79      1080
   macro avg       0.77      0.67      0.67      1080
weighted avg       0.83      0.79      0.78      1080
 


====== chc040-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  92.13  60.00   98.77  90.98     72.31
1  95.65  16.00   99.51  61.54     25.40
2  88.80  89.03   88.61  86.35     87.67
3  93.98  72.22   99.42  96.89     82.76
4  86.48  97.95   84.69  50.00     66.20
Total accuracy: 78.52%
Average sen: 67.04%
Average spec: 94.20%
Macro f1-score: 66.87%
Diagnosis acc on 2.5mins: 1.0
pred: 0.0002279833308610027, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc040-nsrr

=== Test on chc041-nsrr. train_data(15849), test_data(171) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3839455424911447
Starting epoch 2/10.
Epoch finished! Loss: 0.995580208591289
Starting epoch 3/10.
Epoch finished! Loss: 0.912098853387917
Starting epoch 4/10.
Epoch finished! Loss: 0.8683388424717416
Starting epoch 5/10.
Epoch finished! Loss: 0.8412390432762679
Starting epoch 6/10.
Epoch finished! Loss: 0.8243816166532912
Starting epoch 7/10.
Epoch finished! Loss: 0.7985636607621505
Starting epoch 8/10.
Epoch finished! Loss: 0.7936281533347387
Starting epoch 9/10.
Epoch finished! Loss: 0.7793369769974791
Starting epoch 10/10.
Epoch finished! Loss: 0.7648289541836188
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8573099415204678
              precision    recall  f1-score   support

         0.0       0.66      0.88      0.75        56
         1.0       0.14      0.03      0.04        38
         2.0       0.85      0.96      0.90       416
         3.0       1.00      0.78      0.87       188
         4.0       0.88      0.87      0.87       157

    accuracy                           0.86       855
   macro avg       0.71      0.70      0.69       855
weighted avg       0.84      0.86      0.84       855
 


====== chc041-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  96.26  87.50   96.87   66.22     75.38
1  94.97   2.63   99.27   14.29      4.44
2  89.71  96.39   83.37   84.60     90.11
3  95.09  77.66  100.00  100.00     87.43
4  95.44  86.62   97.42   88.31     87.46
Total accuracy: 85.73%
Average sen: 70.16%
Average spec: 95.39%
Macro f1-score: 68.97%
Diagnosis acc on 2.5mins: 1.0
pred: 0.006605172739150329, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc041-nsrr

=== Test on chc052-nsrr. train_data(15837), test_data(183) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3235496458040334
Starting epoch 2/10.
Epoch finished! Loss: 1.0079331603030652
Starting epoch 3/10.
Epoch finished! Loss: 0.9172837567419774
Starting epoch 4/10.
Epoch finished! Loss: 0.8877589149295869
Starting epoch 5/10.
Epoch finished! Loss: 0.8604993698006556
Starting epoch 6/10.
Epoch finished! Loss: 0.8319773241943449
Starting epoch 7/10.
Epoch finished! Loss: 0.814959008540824
Starting epoch 8/10.
Epoch finished! Loss: 0.8119646729413121
Starting epoch 9/10.
Epoch finished! Loss: 0.7905325254570135
Starting epoch 10/10.
Epoch finished! Loss: 0.7701087642698746
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7387978142076502
              precision    recall  f1-score   support

         0.0       0.88      0.92      0.90       142
         1.0       0.00      0.00      0.00        23
         2.0       0.94      0.59      0.72       468
         3.0       0.57      1.00      0.72       180
         4.0       0.58      0.89      0.70       102

    accuracy                           0.74       915
   macro avg       0.59      0.68      0.61       915
weighted avg       0.79      0.74      0.73       915
 


====== chc052-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  96.72   91.55   97.67  87.84     89.66
1  97.38    0.00   99.89   0.00      0.00
2  77.05   58.76   96.20  94.18     72.37
3  85.03  100.00   81.36  56.78     72.43
4  91.58   89.22   91.88  57.96     70.27
Total accuracy: 73.88%
Average sen: 67.91%
Average spec: 93.40%
Macro f1-score: 60.95%
Diagnosis acc on 2.5mins: 1.0
pred: 0.00010834136195712695, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc052-nsrr

=== Test on chc056-nsrr. train_data(15836), test_data(184) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.378644578003537
Starting epoch 2/10.
Epoch finished! Loss: 1.0169484069922718
Starting epoch 3/10.
Epoch finished! Loss: 0.9375583091380094
Starting epoch 4/10.
Epoch finished! Loss: 0.8762290990021284
Starting epoch 5/10.
Epoch finished! Loss: 0.834672491289134
Starting epoch 6/10.
Epoch finished! Loss: 0.8283411208316637
Starting epoch 7/10.
Epoch finished! Loss: 0.8121624085169687
Starting epoch 8/10.
Epoch finished! Loss: 0.7915004227011548
Starting epoch 9/10.
Epoch finished! Loss: 0.792794627361635
Starting epoch 10/10.
Epoch finished! Loss: 0.7596705374805067
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7717391304347826
              precision    recall  f1-score   support

         0.0       0.88      0.84      0.86       191
         1.0       0.16      0.07      0.10        89
         2.0       0.73      0.95      0.82       397
         3.0       1.00      0.73      0.85       153
         4.0       0.79      0.58      0.67        90

    accuracy                           0.77       920
   macro avg       0.71      0.63      0.66       920
weighted avg       0.76      0.77      0.75       920
 


====== chc056-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  94.35  84.29   96.98   87.98     86.10
1  87.61   6.74   96.27   16.22      9.52
2  82.50  95.47   72.66   72.61     82.48
3  95.54  73.20  100.00  100.00     84.53
4  94.35  57.78   98.31   78.79     66.67
Total accuracy: 77.17%
Average sen: 63.50%
Average spec: 92.84%
Macro f1-score: 65.86%
Diagnosis acc on 2.5mins: 1.0
pred: 0.0007052076090527913, label: 0
Right! Diagnosis: Other
Save 2.5mins of subject chc056-nsrr

=== Test on chp001-nsrr. train_data(15788), test_data(232) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3522897893409462
Starting epoch 2/10.
Epoch finished! Loss: 1.0334602280488032
Starting epoch 3/10.
Epoch finished! Loss: 0.9562826109778594
Starting epoch 4/10.
Epoch finished! Loss: 0.9080309492591367
Starting epoch 5/10.
Epoch finished! Loss: 0.8749177973948806
Starting epoch 6/10.
Epoch finished! Loss: 0.8382824179828545
Starting epoch 7/10.
Epoch finished! Loss: 0.8296621239570611
Starting epoch 8/10.
Epoch finished! Loss: 0.8070005558535023
Starting epoch 9/10.
Epoch finished! Loss: 0.8014701316074122
Starting epoch 10/10.
Epoch finished! Loss: 0.783681872717479
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7267241379310345
              precision    recall  f1-score   support

         0.0       0.24      0.93      0.38        55
         1.0       0.16      0.22      0.18        79
         2.0       0.91      0.82      0.87       553
         3.0       1.00      0.59      0.75        69
         4.0       0.94      0.69      0.79       404

    accuracy                           0.73      1160
   macro avg       0.65      0.65      0.59      1160
weighted avg       0.84      0.73      0.76      1160
 


====== chp001-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  85.78  92.73   85.43   24.06     38.20
1  86.72  21.52   91.49   15.60     18.09
2  87.76  82.46   92.59   91.02     86.53
3  97.59  59.42  100.00  100.00     74.55
4  87.50  68.81   97.49   93.60     79.32
Total accuracy: 72.67%
Average sen: 64.99%
Average spec: 93.40%
Macro f1-score: 59.34%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9918013988383885, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp001-nsrr

=== Test on chp002-nsrr. train_data(15804), test_data(216) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3812236725152294
Starting epoch 2/10.
Epoch finished! Loss: 1.0084959128800828
Starting epoch 3/10.
Epoch finished! Loss: 0.923583750822876
Starting epoch 4/10.
Epoch finished! Loss: 0.8682072265238702
Starting epoch 5/10.
Epoch finished! Loss: 0.8469659366751019
Starting epoch 6/10.
Epoch finished! Loss: 0.828879041875465
Starting epoch 7/10.
Epoch finished! Loss: 0.8049885973240001
Starting epoch 8/10.
Epoch finished! Loss: 0.7905120850175242
Starting epoch 9/10.
Epoch finished! Loss: 0.76940991696489
Starting epoch 10/10.
Epoch finished! Loss: 0.7650620348940167
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6777777777777778
              precision    recall  f1-score   support

         0.0       0.74      0.66      0.70       260
         1.0       0.78      0.07      0.13       248
         2.0       0.87      0.97      0.92       375
         3.0       1.00      0.92      0.96       169
         4.0       0.09      0.79      0.16        28

    accuracy                           0.68      1080
   macro avg       0.70      0.68      0.57      1080
weighted avg       0.82      0.68      0.67      1080
 


====== chp002-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  86.30  65.77   92.80   74.35     69.80
1  78.24   7.26   99.40   78.26     13.28
2  93.89  97.33   92.06   86.70     91.71
3  98.80  92.31  100.00  100.00     96.00
4  78.33  78.57   78.33    8.80     15.83
Total accuracy: 67.78%
Average sen: 68.25%
Average spec: 92.52%
Macro f1-score: 57.32%
Diagnosis acc on 2.5mins: 0.8101851851851852
pred: 0.7915229941028412, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp002-nsrr

=== Test on chp003-nsrr. train_data(15820), test_data(200) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3780124499253423
Starting epoch 2/10.
Epoch finished! Loss: 1.0171841948677813
Starting epoch 3/10.
Epoch finished! Loss: 0.930038823329671
Starting epoch 4/10.
Epoch finished! Loss: 0.8993554139800799
Starting epoch 5/10.
Epoch finished! Loss: 0.8534594550116164
Starting epoch 6/10.
Epoch finished! Loss: 0.8161841314439152
Starting epoch 7/10.
Epoch finished! Loss: 0.8146477886048545
Starting epoch 8/10.
Epoch finished! Loss: 0.7967879144754084
Starting epoch 9/10.
Epoch finished! Loss: 0.7851463301999142
Starting epoch 10/10.
Epoch finished! Loss: 0.767017511741637
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.677
              precision    recall  f1-score   support

         0.0       0.34      0.54      0.42        90
         1.0       0.02      0.03      0.02        38
         2.0       0.91      0.67      0.77       478
         3.0       0.88      0.91      0.90       196
         4.0       0.54      0.66      0.59       198

    accuracy                           0.68      1000
   macro avg       0.54      0.56      0.54      1000
weighted avg       0.75      0.68      0.70      1000
 


====== chp003-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0   86.5  54.44   89.67  34.27     42.06
1   89.9   2.63   93.35   1.54      1.94
2   81.0  66.53   94.25  91.38     77.00
3   95.8  91.33   96.89  87.75     89.50
4   82.2  65.66   86.28  54.17     59.36
Total accuracy: 67.70%
Average sen: 56.12%
Average spec: 92.09%
Macro f1-score: 53.97%
Diagnosis acc on 2.5mins: 0.325
pred: 0.3332904951839009, label: 1
Wrong!!! Real Diagnosis: NT1
Save 2.5mins of subject chp003-nsrr

=== Test on chp004-nsrr. train_data(15823), test_data(197) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3543251368550373
Starting epoch 2/10.
Epoch finished! Loss: 0.9799997433172315
Starting epoch 3/10.
Epoch finished! Loss: 0.9077181783322287
Starting epoch 4/10.
Epoch finished! Loss: 0.8644517583657155
Starting epoch 5/10.
Epoch finished! Loss: 0.8400989586084742
Starting epoch 6/10.
Epoch finished! Loss: 0.8219779215837851
Starting epoch 7/10.
Epoch finished! Loss: 0.8150512590420381
Starting epoch 8/10.
Epoch finished! Loss: 0.7843941578408409
Starting epoch 9/10.
Epoch finished! Loss: 0.7828379942836563
Starting epoch 10/10.
Epoch finished! Loss: 0.7678141720998001
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6243654822335025
              precision    recall  f1-score   support

         0.0       0.39      0.64      0.48       135
         1.0       0.14      0.04      0.06       141
         2.0       0.78      0.70      0.74       354
         3.0       0.90      0.71      0.79       197
         4.0       0.54      0.87      0.66       158

    accuracy                           0.62       985
   macro avg       0.55      0.59      0.55       985
weighted avg       0.62      0.62      0.60       985
 


====== chp004-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  81.42  63.70   84.24  39.09     48.45
1  83.05   3.55   96.33  13.89      5.65
2  82.03  70.06   88.75  77.74     73.70
3  92.49  70.56   97.97  89.68     78.98
4  85.89  86.71   85.73  53.73     66.34
Total accuracy: 62.44%
Average sen: 58.91%
Average spec: 90.60%
Macro f1-score: 54.62%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9973224328859204, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp004-nsrr

=== Test on chp005-nsrr. train_data(15759), test_data(261) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.36124096113538
Starting epoch 2/10.
Epoch finished! Loss: 0.9991385701724461
Starting epoch 3/10.
Epoch finished! Loss: 0.9186327541252923
Starting epoch 4/10.
Epoch finished! Loss: 0.8760324524319361
Starting epoch 5/10.
Epoch finished! Loss: 0.8512659314700536
Starting epoch 6/10.
Epoch finished! Loss: 0.8133623356762386
Starting epoch 7/10.
Epoch finished! Loss: 0.8028297192047513
Starting epoch 8/10.
Epoch finished! Loss: 0.7849071829186546
Starting epoch 9/10.
Epoch finished! Loss: 0.775208972238359
Starting epoch 10/10.
Epoch finished! Loss: 0.7669551737157125
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.5938697318007663
              precision    recall  f1-score   support

         0.0       0.21      0.83      0.34        84
         1.0       0.29      0.16      0.20       238
         2.0       0.80      0.88      0.84       565
         3.0       0.71      0.98      0.82       136
         4.0       0.93      0.13      0.24       282

    accuracy                           0.59      1305
   macro avg       0.59      0.60      0.49      1305
weighted avg       0.69      0.59      0.56      1305
 


====== chp005-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  79.23  83.33   78.95  21.41     34.06
1  77.62  15.55   91.47  28.91     20.22
2  85.21  87.96   83.11  79.90     83.74
3  95.63  97.79   95.38  71.12     82.35
4  81.07  13.48   99.71  92.68     23.53
Total accuracy: 59.39%
Average sen: 59.62%
Average spec: 89.72%
Macro f1-score: 48.78%
Diagnosis acc on 2.5mins: 0.9118773946360154
pred: 0.8893315728710985, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp005-nsrr

=== Test on chp006-nsrr. train_data(15800), test_data(220) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3552875844189607
Starting epoch 2/10.
Epoch finished! Loss: 1.0128096004050318
Starting epoch 3/10.
Epoch finished! Loss: 0.9268456696142797
Starting epoch 4/10.
Epoch finished! Loss: 0.8754257683968378
Starting epoch 5/10.
Epoch finished! Loss: 0.8429465328424017
Starting epoch 6/10.
Epoch finished! Loss: 0.8171988285327728
Starting epoch 7/10.
Epoch finished! Loss: 0.8043840621622247
Starting epoch 8/10.
Epoch finished! Loss: 0.7934616846872932
Starting epoch 9/10.
Epoch finished! Loss: 0.764547931819569
Starting epoch 10/10.
Epoch finished! Loss: 0.7668033640848224
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.5163636363636364
              precision    recall  f1-score   support

         0.0       0.26      0.78      0.39       120
         1.0       0.67      0.01      0.02       329
         2.0       0.77      0.74      0.76       287
         3.0       0.99      0.82      0.90       224
         4.0       0.27      0.52      0.36       140

    accuracy                           0.52      1100
   macro avg       0.59      0.58      0.49      1100
weighted avg       0.67      0.52      0.48      1100
 


====== chp006-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  73.27  78.33   72.65  25.97     39.00
1  70.27   1.22   99.74  66.67      2.39
2  87.45  74.22   92.13  76.90     75.53
3  96.27  82.14   99.89  99.46     89.98
4  76.00  52.14   79.48  27.04     35.61
Total accuracy: 51.64%
Average sen: 57.61%
Average spec: 88.78%
Macro f1-score: 48.50%
Diagnosis acc on 2.5mins: 0.7909090909090909
pred: 0.7891816694289446, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp006-nsrr

=== Test on chp007-nsrr. train_data(15789), test_data(231) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.34638096156078
Starting epoch 2/10.
Epoch finished! Loss: 1.0012851406186252
Starting epoch 3/10.
Epoch finished! Loss: 0.9273059029882852
Starting epoch 4/10.
Epoch finished! Loss: 0.8840179753847448
Starting epoch 5/10.
Epoch finished! Loss: 0.8586847335289035
Starting epoch 6/10.
Epoch finished! Loss: 0.843648584000058
Starting epoch 7/10.
Epoch finished! Loss: 0.8275360570056659
Starting epoch 8/10.
Epoch finished! Loss: 0.8159130318196555
Starting epoch 9/10.
Epoch finished! Loss: 0.793778198347421
Starting epoch 10/10.
Epoch finished! Loss: 0.7861789589693489
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6926406926406926
              precision    recall  f1-score   support

         0.0       0.83      0.30      0.44       166
         1.0       0.18      0.12      0.15        58
         2.0       0.65      0.83      0.73       397
         3.0       0.80      0.97      0.88       180
         4.0       0.73      0.68      0.70       354

    accuracy                           0.69      1155
   macro avg       0.64      0.58      0.58      1155
weighted avg       0.70      0.69      0.67      1155
 


====== chp007-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  89.00  29.52   98.99  83.05     43.56
1  92.90  12.07   97.17  18.42     14.58
2  78.61  82.87   76.39  64.76     72.71
3  95.67  97.22   95.38  79.55     87.50
4  82.34  67.80   88.76  72.73     70.18
Total accuracy: 69.26%
Average sen: 57.90%
Average spec: 91.34%
Macro f1-score: 57.70%
Diagnosis acc on 2.5mins: 0.6493506493506493
pred: 0.6432572769722297, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp007-nsrr

=== Test on chp008-nsrr. train_data(15829), test_data(191) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3519039042906273
Starting epoch 2/10.
Epoch finished! Loss: 1.0132852342314123
Starting epoch 3/10.
Epoch finished! Loss: 0.9271781140686438
Starting epoch 4/10.
Epoch finished! Loss: 0.8851655945276039
Starting epoch 5/10.
Epoch finished! Loss: 0.8497444247513746
Starting epoch 6/10.
Epoch finished! Loss: 0.829730698360806
Starting epoch 7/10.
Epoch finished! Loss: 0.8166030045179591
Starting epoch 8/10.
Epoch finished! Loss: 0.8107571254676271
Starting epoch 9/10.
Epoch finished! Loss: 0.7776501734756338
Starting epoch 10/10.
Epoch finished! Loss: 0.7754231498738005
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6554973821989529
              precision    recall  f1-score   support

         0.0       0.87      0.40      0.55       129
         1.0       0.09      0.16      0.12        37
         2.0       0.69      0.57      0.62       387
         3.0       0.78      0.90      0.84       263
         4.0       0.54      0.79      0.64       139

    accuracy                           0.66       955
   macro avg       0.59      0.57      0.55       955
weighted avg       0.69      0.66      0.66       955
 


====== chp008-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  91.10  40.31   99.03  86.67     55.03
1  90.37  16.22   93.36   8.96     11.54
2  72.15  56.85   82.57  68.97     62.32
3  90.26  90.49   90.17  77.78     83.66
4  87.23  79.14   88.60  54.19     64.33
Total accuracy: 65.55%
Average sen: 56.60%
Average spec: 90.75%
Macro f1-score: 55.37%
Diagnosis acc on 2.5mins: 0.6073298429319371
pred: 0.62733114622192, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp008-nsrr

=== Test on chp009-nsrr. train_data(15814), test_data(206) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3543886462394985
Starting epoch 2/10.
Epoch finished! Loss: 1.0022240654152454
Starting epoch 3/10.
Epoch finished! Loss: 0.9321412442795164
Starting epoch 4/10.
Epoch finished! Loss: 0.8792358143166754
Starting epoch 5/10.
Epoch finished! Loss: 0.8574604449356605
Starting epoch 6/10.
Epoch finished! Loss: 0.8272296490170095
Starting epoch 7/10.
Epoch finished! Loss: 0.819810959902238
Starting epoch 8/10.
Epoch finished! Loss: 0.79581617079039
Starting epoch 9/10.
Epoch finished! Loss: 0.7903561674289353
Starting epoch 10/10.
Epoch finished! Loss: 0.7753252660187644
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.612621359223301
              precision    recall  f1-score   support

         0.0       0.93      0.26      0.41        96
         1.0       0.38      0.02      0.05       123
         2.0       0.85      0.49      0.62       355
         3.0       0.99      0.88      0.93       219
         4.0       0.40      1.00      0.57       237

    accuracy                           0.61      1030
   macro avg       0.71      0.53      0.51      1030
weighted avg       0.73      0.61      0.59      1030
 


====== chp009-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  92.91   26.04   99.79  92.59     40.65
1  87.86    2.44   99.45  37.50      4.58
2  79.42   48.73   95.56  85.22     62.01
3  97.28   88.13   99.75  98.97     93.24
4  65.05  100.00   54.60  39.70     56.83
Total accuracy: 61.26%
Average sen: 53.07%
Average spec: 89.83%
Macro f1-score: 51.46%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9972881802077432, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp009-nsrr

=== Test on chp010-nsrr. train_data(15826), test_data(194) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.436615121462553
Starting epoch 2/10.
Epoch finished! Loss: 1.0428266835348343
Starting epoch 3/10.
Epoch finished! Loss: 0.9716324551706821
Starting epoch 4/10.
Epoch finished! Loss: 0.9163796270428657
Starting epoch 5/10.
Epoch finished! Loss: 0.8800651873785686
Starting epoch 6/10.
Epoch finished! Loss: 0.8518304912333392
Starting epoch 7/10.
Epoch finished! Loss: 0.832124787405152
Starting epoch 8/10.
Epoch finished! Loss: 0.8139723156368085
Starting epoch 9/10.
Epoch finished! Loss: 0.8017947397815292
Starting epoch 10/10.
Epoch finished! Loss: 0.7886041811421306
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8381443298969072
              precision    recall  f1-score   support

         0.0       0.80      0.70      0.75        57
         1.0       0.30      0.17      0.22        60
         2.0       0.91      0.91      0.91       506
         3.0       0.97      0.78      0.86        90
         4.0       0.76      0.91      0.83       257

    accuracy                           0.84       970
   macro avg       0.75      0.69      0.71       970
weighted avg       0.83      0.84      0.83       970
 


====== chp010-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  97.22  70.18   98.90  80.00     74.77
1  92.47  16.67   97.47  30.30     21.51
2  90.21  90.71   89.66  90.53     90.62
3  97.73  77.78   99.77  97.22     86.42
4  90.00  91.05   89.62  75.97     82.83
Total accuracy: 83.81%
Average sen: 69.28%
Average spec: 95.09%
Macro f1-score: 71.23%
Diagnosis acc on 2.5mins: 0.9948453608247423
pred: 0.990378295945138, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp010-nsrr

=== Test on chp011-nsrr. train_data(15818), test_data(202) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3841800522306613
Starting epoch 2/10.
Epoch finished! Loss: 1.0749603623381754
Starting epoch 3/10.
Epoch finished! Loss: 0.9712791127694098
Starting epoch 4/10.
Epoch finished! Loss: 0.9273123994686421
Starting epoch 5/10.
Epoch finished! Loss: 0.8888256799036155
Starting epoch 6/10.
Epoch finished! Loss: 0.8739427250258007
Starting epoch 7/10.
Epoch finished! Loss: 0.8471678467885668
Starting epoch 8/10.
Epoch finished! Loss: 0.8393512014759107
Starting epoch 9/10.
Epoch finished! Loss: 0.8181627841028966
Starting epoch 10/10.
Epoch finished! Loss: 0.8142355406005348
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.5673267326732673
              precision    recall  f1-score   support

         0.0       0.46      0.37      0.41       234
         1.0       0.33      0.04      0.07       148
         2.0       0.62      0.48      0.54       221
         3.0       0.96      0.90      0.93       271
         4.0       0.35      0.96      0.51       136

    accuracy                           0.57      1010
   macro avg       0.54      0.55      0.49      1010
weighted avg       0.59      0.57      0.54      1010
 


====== chp011-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  75.15  36.75   86.73  45.50     40.66
1  84.75   4.05   98.61  33.33      7.23
2  82.28  48.42   91.76  62.21     54.45
3  96.24  89.67   98.65  96.05     92.75
4  75.05  96.32   71.74  34.66     50.97
Total accuracy: 56.73%
Average sen: 55.04%
Average spec: 89.50%
Macro f1-score: 49.21%
Diagnosis acc on 2.5mins: 1.0
pred: 0.999919220657632, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp011-nsrr

=== Test on chp012-nsrr. train_data(15797), test_data(223) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3746842731019226
Starting epoch 2/10.
Epoch finished! Loss: 1.0179054097822755
Starting epoch 3/10.
Epoch finished! Loss: 0.9334283782153887
Starting epoch 4/10.
Epoch finished! Loss: 0.8903345593627002
Starting epoch 5/10.
Epoch finished! Loss: 0.8433963225528059
Starting epoch 6/10.
Epoch finished! Loss: 0.8286443284374766
Starting epoch 7/10.
Epoch finished! Loss: 0.8113135372803436
Starting epoch 8/10.
Epoch finished! Loss: 0.7804665659767227
Starting epoch 9/10.
Epoch finished! Loss: 0.7773737197740687
Starting epoch 10/10.
Epoch finished! Loss: 0.7728804109064819
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.726457399103139
              precision    recall  f1-score   support

         0.0       0.25      0.70      0.36        23
         1.0       0.10      0.01      0.01       182
         2.0       0.86      0.86      0.86       379
         3.0       0.99      0.76      0.86       203
         4.0       0.62      0.95      0.75       328

    accuracy                           0.73      1115
   macro avg       0.56      0.66      0.57      1115
weighted avg       0.68      0.73      0.68      1115
 


====== chp012-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  94.98  69.57   95.51  24.62     36.36
1  82.96   0.55   99.04  10.00      1.04
2  90.31  86.02   92.53  85.56     85.79
3  95.61  76.35   99.89  99.36     86.35
4  81.43  95.12   75.73  62.03     75.09
Total accuracy: 72.65%
Average sen: 65.52%
Average spec: 92.54%
Macro f1-score: 56.93%
Diagnosis acc on 2.5mins: 0.6053811659192825
pred: 0.5526537026239913, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp012-nsrr

=== Test on chp013-nsrr. train_data(15820), test_data(200) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.424162487320927
Starting epoch 2/10.
Epoch finished! Loss: 1.0198355899024507
Starting epoch 3/10.
Epoch finished! Loss: 0.9248551293349885
Starting epoch 4/10.
Epoch finished! Loss: 0.8839664923511374
Starting epoch 5/10.
Epoch finished! Loss: 0.8463468043808693
Starting epoch 6/10.
Epoch finished! Loss: 0.8231181715916109
Starting epoch 7/10.
Epoch finished! Loss: 0.8096034643131295
Starting epoch 8/10.
Epoch finished! Loss: 0.7928145496736667
Starting epoch 9/10.
Epoch finished! Loss: 0.7793547582072144
Starting epoch 10/10.
Epoch finished! Loss: 0.7674355138750637
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.688
              precision    recall  f1-score   support

         0.0       0.44      0.73      0.55        33
         1.0       0.60      0.02      0.04       142
         2.0       0.84      0.70      0.76       433
         3.0       0.64      0.89      0.74       189
         4.0       0.60      0.93      0.73       203

    accuracy                           0.69      1000
   macro avg       0.62      0.65      0.57      1000
weighted avg       0.71      0.69      0.64      1000
 


====== chp013-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0   96.1  72.73   96.90  44.44     55.17
1   85.9   2.11   99.77  60.00      4.08
2   81.3  69.98   89.95  84.17     76.42
3   88.3  89.42   88.04  63.53     74.29
4   86.0  93.10   84.19  60.00     72.97
Total accuracy: 68.80%
Average sen: 65.47%
Average spec: 91.77%
Macro f1-score: 56.59%
Diagnosis acc on 2.5mins: 0.575
pred: 0.6041857240814715, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp013-nsrr

=== Test on chp014-nsrr. train_data(15819), test_data(201) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3724769574415072
Starting epoch 2/10.
Epoch finished! Loss: 1.0285609550185026
Starting epoch 3/10.
Epoch finished! Loss: 0.9243023590544671
Starting epoch 4/10.
Epoch finished! Loss: 0.8961046107542205
Starting epoch 5/10.
Epoch finished! Loss: 0.8579811649296873
Starting epoch 6/10.
Epoch finished! Loss: 0.8350686400676361
Starting epoch 7/10.
Epoch finished! Loss: 0.8224431502147991
Starting epoch 8/10.
Epoch finished! Loss: 0.7921207090350814
Starting epoch 9/10.
Epoch finished! Loss: 0.7812740309452573
Starting epoch 10/10.
Epoch finished! Loss: 0.7678164139173214
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8407960199004975
              precision    recall  f1-score   support

         0.0       0.92      0.87      0.89       203
         1.0       0.39      0.13      0.20        68
         2.0       0.86      0.90      0.88       397
         3.0       1.00      0.82      0.90       146
         4.0       0.71      0.95      0.82       191

    accuracy                           0.84      1005
   macro avg       0.78      0.74      0.74      1005
weighted avg       0.83      0.84      0.83      1005
 


====== chp014-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  95.82  87.19   98.00   91.71     89.39
1  92.74  13.24   98.51   39.13     19.78
2  90.35  89.92   90.62   86.23     88.04
3  97.41  82.19  100.00  100.00     90.23
4  91.84  95.29   91.03   71.37     81.61
Total accuracy: 84.08%
Average sen: 73.57%
Average spec: 95.63%
Macro f1-score: 73.81%
Diagnosis acc on 2.5mins: 0.9850746268656716
pred: 0.9761428642318357, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp014-nsrr

=== Test on chp015-nsrr. train_data(15789), test_data(231) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4168541392521563
Starting epoch 2/10.
Epoch finished! Loss: 1.0331232471460021
Starting epoch 3/10.
Epoch finished! Loss: 0.9398823152514616
Starting epoch 4/10.
Epoch finished! Loss: 0.8898077445678385
Starting epoch 5/10.
Epoch finished! Loss: 0.8627855516734081
Starting epoch 6/10.
Epoch finished! Loss: 0.8328944964497261
Starting epoch 7/10.
Epoch finished! Loss: 0.8369817962475754
Starting epoch 8/10.
Epoch finished! Loss: 0.8007444986561254
Starting epoch 9/10.
Epoch finished! Loss: 0.7900211997094112
Starting epoch 10/10.
Epoch finished! Loss: 0.7775368455736054
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6735930735930736
              precision    recall  f1-score   support

         0.0       0.26      0.85      0.40        67
         1.0       0.74      0.05      0.09       281
         2.0       0.81      0.83      0.82       335
         3.0       0.98      0.88      0.93       279
         4.0       0.57      0.95      0.71       193

    accuracy                           0.67      1155
   macro avg       0.67      0.71      0.59      1155
weighted avg       0.76      0.67      0.63      1155
 


====== chp015-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  85.02  85.07   85.02  25.91     39.72
1  76.45   4.98   99.43  73.68      9.33
2  89.44  82.99   92.07  81.05     82.01
3  96.62  88.17   99.32  97.62     92.66
4  87.19  94.82   85.65  57.01     71.21
Total accuracy: 67.36%
Average sen: 71.21%
Average spec: 92.30%
Macro f1-score: 58.98%
Diagnosis acc on 2.5mins: 0.8658008658008658
pred: 0.8110263122898804, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp015-nsrr

=== Test on chp016-nsrr. train_data(15766), test_data(254) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4343182284971179
Starting epoch 2/10.
Epoch finished! Loss: 0.9948296460895066
Starting epoch 3/10.
Epoch finished! Loss: 0.9170898264321277
Starting epoch 4/10.
Epoch finished! Loss: 0.8749771079398351
Starting epoch 5/10.
Epoch finished! Loss: 0.8519009944372976
Starting epoch 6/10.
Epoch finished! Loss: 0.8301338685042967
Starting epoch 7/10.
Epoch finished! Loss: 0.8026035793201269
Starting epoch 8/10.
Epoch finished! Loss: 0.7965197542181173
Starting epoch 9/10.
Epoch finished! Loss: 0.7875843115793872
Starting epoch 10/10.
Epoch finished! Loss: 0.7768762910710222
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6826771653543308
              precision    recall  f1-score   support

         0.0       0.60      0.99      0.75       305
         1.0       0.57      0.16      0.25       291
         2.0       0.76      0.75      0.75       330
         3.0       0.71      0.99      0.83       133
         4.0       0.80      0.66      0.73       211

    accuracy                           0.68      1270
   macro avg       0.69      0.71      0.66      1270
weighted avg       0.68      0.68      0.64      1270
 


====== chp016-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  83.86  98.69   79.17  59.96     74.60
1  77.95  16.15   96.32  56.63     25.13
2  87.32  74.85   91.70  76.00     75.42
3  95.75  99.25   95.34  71.35     83.02
4  91.65  66.35   96.69  80.00     72.54
Total accuracy: 68.27%
Average sen: 71.06%
Average spec: 91.85%
Macro f1-score: 66.14%
Diagnosis acc on 2.5mins: 0.9881889763779528
pred: 0.9674697359363864, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp016-nsrr

=== Test on chp017-nsrr. train_data(15818), test_data(202) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3656223206336102
Starting epoch 2/10.
Epoch finished! Loss: 1.0102683821296028
Starting epoch 3/10.
Epoch finished! Loss: 0.9255558453844289
Starting epoch 4/10.
Epoch finished! Loss: 0.8861875253942177
Starting epoch 5/10.
Epoch finished! Loss: 0.8517379137362806
Starting epoch 6/10.
Epoch finished! Loss: 0.8149711987042563
Starting epoch 7/10.
Epoch finished! Loss: 0.8052981144016412
Starting epoch 8/10.
Epoch finished! Loss: 0.789288466976535
Starting epoch 9/10.
Epoch finished! Loss: 0.7811881206142683
Starting epoch 10/10.
Epoch finished! Loss: 0.764551889398745
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.46633663366336636
              precision    recall  f1-score   support

         0.0       0.61      0.59      0.60       237
         1.0       0.25      0.01      0.02       249
         2.0       0.43      0.59      0.49       210
         3.0       0.93      0.59      0.72       265
         4.0       0.16      1.00      0.27        49

    accuracy                           0.47      1010
   macro avg       0.47      0.56      0.42      1010
weighted avg       0.54      0.47      0.45      1010
 


====== chp017-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  81.49   58.65   88.49  60.96     59.78
1  74.75    1.20   98.82  25.00      2.30
2  74.95   58.57   79.25  42.56     49.30
3  88.12   59.25   98.39  92.90     72.35
4  73.96  100.00   72.63  15.71     27.15
Total accuracy: 46.63%
Average sen: 55.53%
Average spec: 87.52%
Macro f1-score: 42.18%
Diagnosis acc on 2.5mins: 0.9405940594059405
pred: 0.8874316151728762, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp017-nsrr

=== Test on chp018-nsrr. train_data(15795), test_data(225) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.393399081289051
Starting epoch 2/10.
Epoch finished! Loss: 1.0476589288758356
Starting epoch 3/10.
Epoch finished! Loss: 0.9518203721573415
Starting epoch 4/10.
Epoch finished! Loss: 0.9031339404777758
Starting epoch 5/10.
Epoch finished! Loss: 0.8769181764072976
Starting epoch 6/10.
Epoch finished! Loss: 0.840689972854627
Starting epoch 7/10.
Epoch finished! Loss: 0.8235730149838048
Starting epoch 8/10.
Epoch finished! Loss: 0.8020862046301251
Starting epoch 9/10.
Epoch finished! Loss: 0.7951556779939665
Starting epoch 10/10.
Epoch finished! Loss: 0.7746822637440359
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7413333333333333
              precision    recall  f1-score   support

         0.0       0.92      0.52      0.67       138
         1.0       0.50      0.04      0.08       123
         2.0       0.59      0.72      0.65       135
         3.0       0.97      0.85      0.91       363
         4.0       0.63      0.96      0.76       366

    accuracy                           0.74      1125
   macro avg       0.72      0.62      0.61      1125
weighted avg       0.76      0.74      0.71      1125
 


====== chp018-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  93.60  52.17   99.39  92.31     66.67
1  89.07   4.07   99.50  50.00      7.52
2  90.67  71.85   93.23  59.15     64.88
3  94.40  84.85   98.95  97.47     90.72
4  80.53  96.17   72.99  63.20     76.27
Total accuracy: 74.13%
Average sen: 61.82%
Average spec: 92.81%
Macro f1-score: 61.21%
Diagnosis acc on 2.5mins: 0.9377777777777778
pred: 0.9216596022413837, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp018-nsrr

=== Test on chp019-nsrr. train_data(15832), test_data(188) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4309324322813157
Starting epoch 2/10.
Epoch finished! Loss: 1.0372619685385698
Starting epoch 3/10.
Epoch finished! Loss: 0.945251343469415
Starting epoch 4/10.
Epoch finished! Loss: 0.8962144309481863
Starting epoch 5/10.
Epoch finished! Loss: 0.8664508977233045
Starting epoch 6/10.
Epoch finished! Loss: 0.8411247956172921
Starting epoch 7/10.
Epoch finished! Loss: 0.8166004666612635
Starting epoch 8/10.
Epoch finished! Loss: 0.7981958946451987
Starting epoch 9/10.
Epoch finished! Loss: 0.7859329398267267
Starting epoch 10/10.
Epoch finished! Loss: 0.7674667772825805
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7138297872340426
              precision    recall  f1-score   support

         0.0       1.00      0.31      0.47        36
         1.0       0.40      0.02      0.03       112
         2.0       0.79      0.47      0.59       224
         3.0       0.81      0.98      0.89       236
         4.0       0.64      0.97      0.77       332

    accuracy                           0.71       940
   macro avg       0.73      0.55      0.55       940
weighted avg       0.70      0.71      0.66       940
 


====== chp019-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  97.34  30.56  100.00  100.00     46.81
1  87.98   1.79   99.64   40.00      3.42
2  84.47  47.32   96.09   79.10     59.22
3  93.62  97.88   92.19   80.77     88.51
4  79.36  96.69   69.90   63.69     76.79
Total accuracy: 71.38%
Average sen: 54.85%
Average spec: 91.56%
Macro f1-score: 54.95%
Diagnosis acc on 2.5mins: 0.9893617021276596
pred: 0.9289459950746374, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp019-nsrr

=== Test on chp020-nsrr. train_data(15790), test_data(230) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4506417514026846
Starting epoch 2/10.
Epoch finished! Loss: 1.0473943282442855
Starting epoch 3/10.
Epoch finished! Loss: 0.9532515630031568
Starting epoch 4/10.
Epoch finished! Loss: 0.8986696734438983
Starting epoch 5/10.
Epoch finished! Loss: 0.8845904508017769
Starting epoch 6/10.
Epoch finished! Loss: 0.8440631459194444
Starting epoch 7/10.
Epoch finished! Loss: 0.8169420836316316
Starting epoch 8/10.
Epoch finished! Loss: 0.8038906937769611
Starting epoch 9/10.
Epoch finished! Loss: 0.7899381525635115
Starting epoch 10/10.
Epoch finished! Loss: 0.7812977511109961
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6947826086956522
              precision    recall  f1-score   support

         0.0       0.87      0.69      0.77       307
         1.0       0.31      0.09      0.14       200
         2.0       0.82      0.92      0.87       354
         3.0       0.95      0.77      0.85       159
         4.0       0.38      0.93      0.54       130

    accuracy                           0.69      1150
   macro avg       0.66      0.68      0.63      1150
weighted avg       0.71      0.69      0.67      1150
 


====== chp020-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  88.96  69.06   96.20  86.89     76.95
1  80.61   9.00   95.68  30.51     13.90
2  91.30  92.09   90.95  81.91     86.70
3  96.26  76.73   99.39  95.31     85.02
4  81.83  93.08   80.39  37.69     53.66
Total accuracy: 69.48%
Average sen: 67.99%
Average spec: 92.53%
Macro f1-score: 63.25%
Diagnosis acc on 2.5mins: 0.7956521739130434
pred: 0.7809592229314148, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp020-nsrr

=== Test on chp022-nsrr. train_data(15767), test_data(253) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3553886222582179
Starting epoch 2/10.
Epoch finished! Loss: 0.9869857702952654
Starting epoch 3/10.
Epoch finished! Loss: 0.9156593586020361
Starting epoch 4/10.
Epoch finished! Loss: 0.8675982382356515
Starting epoch 5/10.
Epoch finished! Loss: 0.8504783078498647
Starting epoch 6/10.
Epoch finished! Loss: 0.833774165529285
Starting epoch 7/10.
Epoch finished! Loss: 0.8072036431563384
Starting epoch 8/10.
Epoch finished! Loss: 0.7993824500590563
Starting epoch 9/10.
Epoch finished! Loss: 0.7790572112757088
Starting epoch 10/10.
Epoch finished! Loss: 0.7606729502000179
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6197628458498023
              precision    recall  f1-score   support

         0.0       0.51      0.83      0.63       258
         1.0       0.48      0.04      0.07       293
         2.0       0.80      0.86      0.83       468
         3.0       0.65      0.79      0.71       107
         4.0       0.38      0.52      0.44       139

    accuracy                           0.62      1265
   macro avg       0.56      0.61      0.54      1265
weighted avg       0.61      0.62      0.56      1265
 


====== chp022-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  80.16  82.56   79.54  50.84     62.92
1  76.76   3.75   98.77  47.83      6.96
2  86.88  86.11   87.33  79.96     82.92
3  94.62  79.44   96.03  64.89     71.43
4  85.53  51.80   89.70  38.30     44.04
Total accuracy: 61.98%
Average sen: 60.73%
Average spec: 90.27%
Macro f1-score: 53.65%
Diagnosis acc on 2.5mins: 0.9683794466403162
pred: 0.9634671774067044, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp022-nsrr

=== Test on chp024-nsrr. train_data(15795), test_data(225) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3706607991868442
Starting epoch 2/10.
Epoch finished! Loss: 1.011819870412312
Starting epoch 3/10.
Epoch finished! Loss: 0.924757625990234
Starting epoch 4/10.
Epoch finished! Loss: 0.892367024694235
Starting epoch 5/10.
Epoch finished! Loss: 0.8553375072725368
Starting epoch 6/10.
Epoch finished! Loss: 0.8315479845242685
Starting epoch 7/10.
Epoch finished! Loss: 0.8068765886151541
Starting epoch 8/10.
Epoch finished! Loss: 0.7933006831896011
Starting epoch 9/10.
Epoch finished! Loss: 0.7809972988607915
Starting epoch 10/10.
Epoch finished! Loss: 0.7705681581354503
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.576
              precision    recall  f1-score   support

         0.0       0.72      0.50      0.59       232
         1.0       0.29      0.06      0.09       179
         2.0       0.58      0.72      0.64       261
         3.0       1.00      0.69      0.82       339
         4.0       0.27      0.86      0.41       114

    accuracy                           0.58      1125
   macro avg       0.57      0.57      0.51      1125
weighted avg       0.66      0.58      0.57      1125
 


====== chp024-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  85.60  50.00   94.85  71.60     58.88
1  82.84   5.59   97.46  29.41      9.39
2  81.24  72.41   83.91  57.62     64.18
3  90.67  69.32   99.87  99.58     81.74
4  74.84  85.96   73.59  26.85     40.92
Total accuracy: 57.60%
Average sen: 56.66%
Average spec: 89.94%
Macro f1-score: 51.02%
Diagnosis acc on 2.5mins: 0.5822222222222222
pred: 0.5764796359247217, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp024-nsrr

=== Test on chp025-nsrr. train_data(15931), test_data(89) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3741624206772258
Starting epoch 2/10.
Epoch finished! Loss: 1.014652468521342
Starting epoch 3/10.
Epoch finished! Loss: 0.9161468968029226
Starting epoch 4/10.
Epoch finished! Loss: 0.8899784143979041
Starting epoch 5/10.
Epoch finished! Loss: 0.84547968157342
Starting epoch 6/10.
Epoch finished! Loss: 0.8259168085779548
Starting epoch 7/10.
Epoch finished! Loss: 0.8048349808520366
Starting epoch 8/10.
Epoch finished! Loss: 0.7845625404060373
Starting epoch 9/10.
Epoch finished! Loss: 0.7693230930414128
Starting epoch 10/10.
Epoch finished! Loss: 0.755412780632407
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.5707865168539326
              precision    recall  f1-score   support

         0.0       0.97      0.48      0.64       304
         1.0       0.28      0.23      0.25        31
         2.0       0.68      0.93      0.78        29
         3.0       1.00      0.97      0.98        62
         4.0       0.08      0.74      0.15        19

    accuracy                           0.57       445
   macro avg       0.60      0.67      0.56       445
weighted avg       0.87      0.57      0.65       445
 


====== chp025-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  63.37  48.03   96.45   96.69     64.18
1  90.56  22.58   95.65   28.00     25.00
2  96.63  93.10   96.88   67.50     78.26
3  99.55  96.77  100.00  100.00     98.36
4  64.04  73.68   63.62    8.28     14.89
Total accuracy: 57.08%
Average sen: 66.83%
Average spec: 90.52%
Macro f1-score: 56.14%
Diagnosis acc on 2.5mins: 0.9438202247191011
pred: 0.9459738458684656, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp025-nsrr

=== Test on chp026-nsrr. train_data(15832), test_data(188) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3700336135796785
Starting epoch 2/10.
Epoch finished! Loss: 1.023468668296679
Starting epoch 3/10.
Epoch finished! Loss: 0.9446607334698143
Starting epoch 4/10.
Epoch finished! Loss: 0.8797527416288589
Starting epoch 5/10.
Epoch finished! Loss: 0.8605250262585307
Starting epoch 6/10.
Epoch finished! Loss: 0.8169008552350353
Starting epoch 7/10.
Epoch finished! Loss: 0.7996947973665375
Starting epoch 8/10.
Epoch finished! Loss: 0.7843116377436203
Starting epoch 9/10.
Epoch finished! Loss: 0.7735032130195156
Starting epoch 10/10.
Epoch finished! Loss: 0.773334988031068
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8382978723404255
              precision    recall  f1-score   support

         0.0       0.91      0.71      0.80        58
         1.0       1.00      0.02      0.04        55
         2.0       0.75      0.98      0.85       422
         3.0       0.95      0.84      0.89       182
         4.0       0.98      0.81      0.88       223

    accuracy                           0.84       940
   macro avg       0.92      0.67      0.69       940
weighted avg       0.87      0.84      0.82       940
 


====== chp026-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  97.77  70.69   99.55   91.11     79.61
1  94.26   1.82  100.00  100.00      3.57
2  84.68  98.10   73.75   75.27     85.19
3  95.96  83.52   98.94   95.00     88.89
4  95.00  80.72   99.44   97.83     88.45
Total accuracy: 83.83%
Average sen: 66.97%
Average spec: 94.34%
Macro f1-score: 69.14%
Diagnosis acc on 2.5mins: 0.8031914893617021
pred: 0.8047235456364665, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp026-nsrr

=== Test on chp028-nsrr. train_data(15814), test_data(206) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3601707621211874
Starting epoch 2/10.
Epoch finished! Loss: 1.0098036537624326
Starting epoch 3/10.
Epoch finished! Loss: 0.9373214146632473
Starting epoch 4/10.
Epoch finished! Loss: 0.8917609161964177
Starting epoch 5/10.
Epoch finished! Loss: 0.8733028205115158
Starting epoch 6/10.
Epoch finished! Loss: 0.8423408525775008
Starting epoch 7/10.
Epoch finished! Loss: 0.8380078522843096
Starting epoch 8/10.
Epoch finished! Loss: 0.7974470297344721
Starting epoch 9/10.
Epoch finished! Loss: 0.7890227133341035
Starting epoch 10/10.
Epoch finished! Loss: 0.7732276762025707
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.8036929057337221
              precision    recall  f1-score   support

         0.0       0.88      0.93      0.90       111
         1.0       0.22      0.18      0.20        55
         2.0       0.81      0.80      0.80       382
         3.0       0.72      0.79      0.75       191
         4.0       0.92      0.90      0.91       290

    accuracy                           0.80      1029
   macro avg       0.71      0.72      0.71      1029
weighted avg       0.80      0.80      0.80      1029
 


====== chp028-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  97.86  92.79   98.47  88.03     90.35
1  92.13  18.18   96.30  21.74     19.80
2  85.62  79.58   89.18  81.28     80.42
3  90.28  78.53   92.96  71.77     75.00
4  94.85  89.66   96.89  91.87     90.75
Total accuracy: 80.37%
Average sen: 71.75%
Average spec: 94.76%
Macro f1-score: 71.27%
Diagnosis acc on 2.5mins: 0.8980582524271845
pred: 0.8573455696392045, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp028-nsrr

=== Test on chp029-nsrr. train_data(15811), test_data(209) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3260426827618625
Starting epoch 2/10.
Epoch finished! Loss: 0.986971605133211
Starting epoch 3/10.
Epoch finished! Loss: 0.9004862066087355
Starting epoch 4/10.
Epoch finished! Loss: 0.8568901112945226
Starting epoch 5/10.
Epoch finished! Loss: 0.8344659677869831
Starting epoch 6/10.
Epoch finished! Loss: 0.823047685055775
Starting epoch 7/10.
Epoch finished! Loss: 0.8039753732709173
Starting epoch 8/10.
Epoch finished! Loss: 0.7869489352436174
Starting epoch 9/10.
Epoch finished! Loss: 0.7853261498919324
Starting epoch 10/10.
Epoch finished! Loss: 0.7658604613630776
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6688995215311004
              precision    recall  f1-score   support

         0.0       0.32      0.62      0.42        66
         1.0       0.00      0.00      0.00        51
         2.0       0.71      0.61      0.66       424
         3.0       0.94      0.70      0.80       334
         4.0       0.56      0.96      0.71       170

    accuracy                           0.67      1045
   macro avg       0.51      0.58      0.52      1045
weighted avg       0.70      0.67      0.67      1045
 


====== chp029-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  89.19  62.12   91.01  31.78     42.05
1  94.16   0.00   98.99   0.00      0.00
2  74.26  61.32   83.09  71.23     65.91
3  89.09  70.36   97.89  94.00     80.48
4  87.08  95.88   85.37  56.01     70.72
Total accuracy: 66.89%
Average sen: 57.94%
Average spec: 91.27%
Macro f1-score: 51.83%
Diagnosis acc on 2.5mins: 0.9425837320574163
pred: 0.8995883237374457, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp029-nsrr

=== Test on chp030-nsrr. train_data(15780), test_data(240) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3724614938150574
Starting epoch 2/10.
Epoch finished! Loss: 1.0259355423037735
Starting epoch 3/10.
Epoch finished! Loss: 0.9430275168234439
Starting epoch 4/10.
Epoch finished! Loss: 0.8921872358119556
Starting epoch 5/10.
Epoch finished! Loss: 0.8522751144993963
Starting epoch 6/10.
Epoch finished! Loss: 0.8280574357161887
Starting epoch 7/10.
Epoch finished! Loss: 0.80792386380078
Starting epoch 8/10.
Epoch finished! Loss: 0.7976889346283905
Starting epoch 9/10.
Epoch finished! Loss: 0.7855862085964382
Starting epoch 10/10.
Epoch finished! Loss: 0.7865102796064727
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7105921601334445
              precision    recall  f1-score   support

         0.0       0.76      0.89      0.82       350
         1.0       0.35      0.21      0.26       204
         2.0       0.81      0.76      0.79       346
         3.0       0.97      0.85      0.91       179
         4.0       0.44      0.68      0.54       120

    accuracy                           0.71      1199
   macro avg       0.67      0.68      0.66      1199
weighted avg       0.70      0.71      0.70      1199
 


====== chp030-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  88.49  88.86   88.34  75.85     81.84
1  80.07  20.59   92.26  35.29     26.01
2  87.99  76.30   92.73  80.98     78.57
3  97.41  85.47   99.51  96.84     90.80
4  88.16  68.33   90.36  44.09     53.59
Total accuracy: 71.06%
Average sen: 67.91%
Average spec: 92.64%
Macro f1-score: 66.16%
Diagnosis acc on 2.5mins: 0.49583333333333335
pred: 0.5302464209729806, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp030-nsrr

=== Test on chp031-nsrr. train_data(15798), test_data(222) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.39046711118407
Starting epoch 2/10.
Epoch finished! Loss: 1.0316774358358316
Starting epoch 3/10.
Epoch finished! Loss: 0.9401935235354778
Starting epoch 4/10.
Epoch finished! Loss: 0.9055970308711213
Starting epoch 5/10.
Epoch finished! Loss: 0.8645881478774389
Starting epoch 6/10.
Epoch finished! Loss: 0.8424241678898964
Starting epoch 7/10.
Epoch finished! Loss: 0.8241888128971283
Starting epoch 8/10.
Epoch finished! Loss: 0.8116304978794354
Starting epoch 9/10.
Epoch finished! Loss: 0.7999864200706946
Starting epoch 10/10.
Epoch finished! Loss: 0.783465293491468
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7189189189189189
              precision    recall  f1-score   support

         0.0       0.28      0.59      0.38        51
         1.0       0.08      0.08      0.08        48
         2.0       0.67      0.86      0.75       309
         3.0       1.00      0.65      0.79       229
         4.0       0.86      0.74      0.80       473

    accuracy                           0.72      1110
   macro avg       0.58      0.58      0.56      1110
weighted avg       0.77      0.72      0.73      1110
 


====== chp031-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  91.17  58.82   92.73   28.04     37.97
1  92.07   8.33   95.86    8.33      8.33
2  84.05  85.76   83.40   66.58     74.96
3  92.70  64.63  100.00  100.00     78.51
4  83.78  74.21   90.89   85.82     79.59
Total accuracy: 71.89%
Average sen: 58.35%
Average spec: 92.58%
Macro f1-score: 55.88%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9996287626726134, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp031-nsrr

=== Test on chp032-nsrr. train_data(15807), test_data(213) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3718438302037081
Starting epoch 2/10.
Epoch finished! Loss: 1.0211698660744897
Starting epoch 3/10.
Epoch finished! Loss: 0.9582120204085036
Starting epoch 4/10.
Epoch finished! Loss: 0.899595618757266
Starting epoch 5/10.
Epoch finished! Loss: 0.8681537952604174
Starting epoch 6/10.
Epoch finished! Loss: 0.8349608826674992
Starting epoch 7/10.
Epoch finished! Loss: 0.8247276246547699
Starting epoch 8/10.
Epoch finished! Loss: 0.797184630483389
Starting epoch 9/10.
Epoch finished! Loss: 0.7942069501722161
Starting epoch 10/10.
Epoch finished! Loss: 0.7725557981223999
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7427230046948357
              precision    recall  f1-score   support

         0.0       0.28      0.94      0.44        47
         1.0       0.15      0.06      0.08       108
         2.0       0.88      0.89      0.88       530
         3.0       0.98      0.83      0.90       151
         4.0       0.70      0.63      0.67       229

    accuracy                           0.74      1065
   macro avg       0.60      0.67      0.59      1065
weighted avg       0.75      0.74      0.74      1065
 


====== chp032-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  89.30  93.62   89.10  28.39     43.56
1  87.23   5.56   96.45  15.00      8.11
2  88.36  88.87   87.85  87.87     88.37
3  97.28  82.78   99.67  97.66     89.61
4  86.38  63.32   92.70  70.39     66.67
Total accuracy: 74.27%
Average sen: 66.83%
Average spec: 93.15%
Macro f1-score: 59.26%
Diagnosis acc on 2.5mins: 0.3333333333333333
pred: 0.38225905378439307, label: 1
Wrong!!! Real Diagnosis: NT1
Save 2.5mins of subject chp032-nsrr

=== Test on chp033-nsrr. train_data(15818), test_data(202) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3084908569258726
Starting epoch 2/10.
Epoch finished! Loss: 0.9784468296846961
Starting epoch 3/10.
Epoch finished! Loss: 0.9020146634252971
Starting epoch 4/10.
Epoch finished! Loss: 0.8680324925322989
Starting epoch 5/10.
Epoch finished! Loss: 0.8468377810068178
Starting epoch 6/10.
Epoch finished! Loss: 0.8158514073459051
Starting epoch 7/10.
Epoch finished! Loss: 0.8016263882922342
Starting epoch 8/10.
Epoch finished! Loss: 0.7903624141917509
Starting epoch 9/10.
Epoch finished! Loss: 0.7803174118257489
Starting epoch 10/10.
Epoch finished! Loss: 0.7630987271129294
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6376237623762376
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        32
         1.0       0.00      0.00      0.00       252
         2.0       0.65      0.87      0.74       208
         3.0       1.00      0.79      0.88       254
         4.0       0.50      1.00      0.66       264

    accuracy                           0.64      1010
   macro avg       0.43      0.53      0.46      1010
weighted avg       0.51      0.64      0.55      1010
 


====== chp033-nsrr ======

The ppr of  0  has ZeroDivisionError.

The f1-score of  0  has ZeroDivisionError.

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  96.83    0.00  100.00   0.00      0.00
1  75.05    0.00  100.00   0.00      0.00
2  87.72   86.54   88.03  65.22     74.38
3  94.55   78.74   99.87  99.50     87.91
4  73.37  100.00   63.94  49.53     66.25
Total accuracy: 63.76%
Average sen: 53.06%
Average spec: 90.37%
Macro f1-score: 45.71%
Diagnosis acc on 2.5mins: 0.8613861386138614
pred: 0.8275150573342154, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp033-nsrr

=== Test on chp034-nsrr. train_data(15812), test_data(208) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3574367666983438
Starting epoch 2/10.
Epoch finished! Loss: 0.9822055181508423
Starting epoch 3/10.
Epoch finished! Loss: 0.91826269220959
Starting epoch 4/10.
Epoch finished! Loss: 0.8566823654315051
Starting epoch 5/10.
Epoch finished! Loss: 0.8281019745673808
Starting epoch 6/10.
Epoch finished! Loss: 0.8139763626209322
Starting epoch 7/10.
Epoch finished! Loss: 0.7913325118027029
Starting epoch 8/10.
Epoch finished! Loss: 0.7781894982125018
Starting epoch 9/10.
Epoch finished! Loss: 0.7791633943565882
Starting epoch 10/10.
Epoch finished! Loss: 0.7585853418355347
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7076923076923077
              precision    recall  f1-score   support

         0.0       0.28      0.85      0.42        20
         1.0       0.00      0.00      0.00        68
         2.0       0.70      0.56      0.63       375
         3.0       0.78      0.89      0.83       345
         4.0       0.72      0.87      0.79       232

    accuracy                           0.71      1040
   macro avg       0.50      0.63      0.53      1040
weighted avg       0.68      0.71      0.68      1040
 


====== chp034-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.58  85.00   95.78  28.33     42.50
1  93.08   0.00   99.59   0.00      0.00
2  75.67  56.27   86.62  70.33     62.52
3  87.79  88.99   87.19  77.53     82.86
4  89.42  86.64   90.22  71.79     78.52
Total accuracy: 70.77%
Average sen: 63.38%
Average spec: 91.88%
Macro f1-score: 53.28%
Diagnosis acc on 2.5mins: 0.08653846153846154
pred: 0.11860847176720969, label: 1
Wrong!!! Real Diagnosis: NT1
Save 2.5mins of subject chp034-nsrr

=== Test on chp036-nsrr. train_data(15768), test_data(252) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3688339295650496
Starting epoch 2/10.
Epoch finished! Loss: 1.0318619040819594
Starting epoch 3/10.
Epoch finished! Loss: 0.9243150054462973
Starting epoch 4/10.
Epoch finished! Loss: 0.889037848256415
Starting epoch 5/10.
Epoch finished! Loss: 0.8484134805308381
Starting epoch 6/10.
Epoch finished! Loss: 0.8235508846449973
Starting epoch 7/10.
Epoch finished! Loss: 0.7981701786937144
Starting epoch 8/10.
Epoch finished! Loss: 0.7822280307560403
Starting epoch 9/10.
Epoch finished! Loss: 0.7791436511531548
Starting epoch 10/10.
Epoch finished! Loss: 0.7677399729317064
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7126984126984127
              precision    recall  f1-score   support

         0.0       0.59      0.97      0.73       237
         1.0       0.60      0.16      0.25       167
         2.0       0.88      0.67      0.76       563
         3.0       0.08      1.00      0.14         8
         4.0       0.88      0.90      0.89       285

    accuracy                           0.71      1260
   macro avg       0.61      0.74      0.55      1260
weighted avg       0.78      0.71      0.71      1260
 


====== chp036-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  86.83   96.62   84.56  59.17     73.40
1  87.46   15.57   98.44  60.47     24.76
2  81.11   67.14   92.40  87.70     76.06
3  92.22  100.00   92.17   7.55     14.04
4  94.92   90.18   96.31  87.71     88.93
Total accuracy: 71.27%
Average sen: 73.90%
Average spec: 92.78%
Macro f1-score: 55.44%
Diagnosis acc on 2.5mins: 0.9920634920634921
pred: 0.9892065562307835, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp036-nsrr

=== Test on chp037-nsrr. train_data(15813), test_data(207) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.381881822595711
Starting epoch 2/10.
Epoch finished! Loss: 1.0003253346866328
Starting epoch 3/10.
Epoch finished! Loss: 0.9224235944586566
Starting epoch 4/10.
Epoch finished! Loss: 0.8787708447787823
Starting epoch 5/10.
Epoch finished! Loss: 0.8429307645630942
Starting epoch 6/10.
Epoch finished! Loss: 0.8263454641027589
Starting epoch 7/10.
Epoch finished! Loss: 0.8145775522030584
Starting epoch 8/10.
Epoch finished! Loss: 0.786269743096821
Starting epoch 9/10.
Epoch finished! Loss: 0.7717308394898349
Starting epoch 10/10.
Epoch finished! Loss: 0.7616187381092164
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6418199419167473
              precision    recall  f1-score   support

         0.0       0.79      0.71      0.74       202
         1.0       1.00      0.02      0.03       171
         2.0       0.86      0.66      0.75       348
         3.0       1.00      0.88      0.94       208
         4.0       0.26      0.99      0.41       104

    accuracy                           0.64      1033
   macro avg       0.78      0.65      0.58      1033
weighted avg       0.84      0.64      0.63      1033
 


====== chp037-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  90.51  70.79   95.31   78.57     74.48
1  83.74   1.75  100.00  100.00      3.45
2  84.90  66.38   94.31   85.56     74.76
3  97.58  87.98  100.00  100.00     93.61
4  71.64  99.04   68.57   26.08     41.28
Total accuracy: 64.18%
Average sen: 65.19%
Average spec: 91.64%
Macro f1-score: 57.51%
Diagnosis acc on 2.5mins: 0.5555555555555556
pred: 0.5717765968439525, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp037-nsrr

=== Test on chp038-nsrr. train_data(15815), test_data(205) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3633943675138918
Starting epoch 2/10.
Epoch finished! Loss: 1.036602761061564
Starting epoch 3/10.
Epoch finished! Loss: 0.9358080341271552
Starting epoch 4/10.
Epoch finished! Loss: 0.8793135845608383
Starting epoch 5/10.
Epoch finished! Loss: 0.8679927728132384
Starting epoch 6/10.
Epoch finished! Loss: 0.8308772332848513
Starting epoch 7/10.
Epoch finished! Loss: 0.7996567149542314
Starting epoch 8/10.
Epoch finished! Loss: 0.7959498433769692
Starting epoch 9/10.
Epoch finished! Loss: 0.7803165874739073
Starting epoch 10/10.
Epoch finished! Loss: 0.7724901214289107
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.735609756097561
              precision    recall  f1-score   support

         0.0       0.44      0.89      0.59        62
         1.0       0.27      0.02      0.04       178
         2.0       0.80      0.98      0.88       437
         3.0       0.98      0.91      0.94       102
         4.0       0.69      0.71      0.70       246

    accuracy                           0.74      1025
   macro avg       0.63      0.70      0.63      1025
weighted avg       0.68      0.74      0.68      1025
 


====== chp038-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  92.39  88.71   92.63  43.65     58.51
1  81.95   2.25   98.70  26.67      4.15
2  88.68  97.94   81.80  80.00     88.07
3  98.93  91.18   99.78  97.89     94.42
4  85.17  70.73   89.73  68.50     69.60
Total accuracy: 73.56%
Average sen: 70.16%
Average spec: 92.53%
Macro f1-score: 62.95%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9987753661667428, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp038-nsrr

=== Test on chp039-nsrr. train_data(15798), test_data(222) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3803755915980311
Starting epoch 2/10.
Epoch finished! Loss: 1.0268336145125891
Starting epoch 3/10.
Epoch finished! Loss: 0.9439492480259594
Starting epoch 4/10.
Epoch finished! Loss: 0.8892682723941646
Starting epoch 5/10.
Epoch finished! Loss: 0.86649945516085
Starting epoch 6/10.
Epoch finished! Loss: 0.8391310538273208
Starting epoch 7/10.
Epoch finished! Loss: 0.817791707252233
Starting epoch 8/10.
Epoch finished! Loss: 0.7950647521936267
Starting epoch 9/10.
Epoch finished! Loss: 0.7885591243927504
Starting epoch 10/10.
Epoch finished! Loss: 0.7756171859635667
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.4990990990990991
              precision    recall  f1-score   support

         0.0       0.07      0.89      0.12        19
         1.0       0.40      0.03      0.06       355
         2.0       0.87      0.60      0.71       376
         3.0       0.98      0.87      0.92       199
         4.0       0.33      0.79      0.46       161

    accuracy                           0.50      1110
   macro avg       0.53      0.64      0.46      1110
weighted avg       0.65      0.50      0.49      1110
 


====== chp039-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  78.47  89.47   78.28   6.69     12.45
1  67.48   3.38   97.62  40.00      6.23
2  83.24  59.57   95.37  86.82     70.66
3  97.39  87.44   99.56  97.75     92.31
4  73.24  78.88   72.29  32.56     46.10
Total accuracy: 49.91%
Average sen: 63.75%
Average spec: 88.62%
Macro f1-score: 45.55%
Diagnosis acc on 2.5mins: 0.9864864864864865
pred: 0.9586849683845365, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp039-nsrr

=== Test on chp040-nsrr. train_data(15806), test_data(214) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3749939490722705
Starting epoch 2/10.
Epoch finished! Loss: 1.0327423912437657
Starting epoch 3/10.
Epoch finished! Loss: 0.9375055130146727
Starting epoch 4/10.
Epoch finished! Loss: 0.8999625863530968
Starting epoch 5/10.
Epoch finished! Loss: 0.8503242909908295
Starting epoch 6/10.
Epoch finished! Loss: 0.8282778843105594
Starting epoch 7/10.
Epoch finished! Loss: 0.8214771958563146
Starting epoch 8/10.
Epoch finished! Loss: 0.7836675007226347
Starting epoch 9/10.
Epoch finished! Loss: 0.7821213428732715
Starting epoch 10/10.
Epoch finished! Loss: 0.7787377664371382
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.611214953271028
              precision    recall  f1-score   support

         0.0       0.41      0.92      0.56       181
         1.0       0.59      0.30      0.40       142
         2.0       0.70      0.93      0.80       330
         3.0       0.98      0.66      0.79       201
         4.0       0.43      0.03      0.05       216

    accuracy                           0.61      1070
   macro avg       0.62      0.57      0.52      1070
weighted avg       0.63      0.61      0.55      1070
 


====== chp040-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  75.98  91.71   72.78  40.69     56.37
1  87.94  30.28   96.77  58.90     40.00
2  85.33  92.73   82.03  69.70     79.58
3  93.36  66.17   99.65  97.79     78.93
4  79.63   2.78   99.06  42.86      5.22
Total accuracy: 61.12%
Average sen: 56.73%
Average spec: 90.06%
Macro f1-score: 52.02%
Diagnosis acc on 2.5mins: 0.4672897196261682
pred: 0.4647089296083671, label: 1
Wrong!!! Real Diagnosis: NT1
Save 2.5mins of subject chp040-nsrr

=== Test on chp041-nsrr. train_data(15799), test_data(221) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.371892832101637
Starting epoch 2/10.
Epoch finished! Loss: 1.034433311152262
Starting epoch 3/10.
Epoch finished! Loss: 0.9483257680093283
Starting epoch 4/10.
Epoch finished! Loss: 0.8848597722162244
Starting epoch 5/10.
Epoch finished! Loss: 0.8509377604651255
Starting epoch 6/10.
Epoch finished! Loss: 0.8391123534268107
Starting epoch 7/10.
Epoch finished! Loss: 0.8195163008342293
Starting epoch 8/10.
Epoch finished! Loss: 0.7924187284356964
Starting epoch 9/10.
Epoch finished! Loss: 0.7844646417166026
Starting epoch 10/10.
Epoch finished! Loss: 0.7734619554667778
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7647058823529411
              precision    recall  f1-score   support

         0.0       0.88      0.59      0.70       221
         1.0       0.08      0.03      0.05        58
         2.0       0.95      0.83      0.89       527
         3.0       0.79      0.91      0.85        33
         4.0       0.57      0.91      0.70       266

    accuracy                           0.76      1105
   macro avg       0.65      0.66      0.64      1105
weighted avg       0.79      0.76      0.76      1105
 


====== chp041-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  90.14  58.82   97.96  87.84     70.46
1  92.76   3.45   97.71   7.69      4.76
2  89.86  83.49   95.67  94.62     88.71
3  99.00  90.91   99.25  78.95     84.51
4  81.18  91.35   77.95  56.78     70.03
Total accuracy: 76.47%
Average sen: 65.61%
Average spec: 93.71%
Macro f1-score: 63.69%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9980730800067678, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp041-nsrr

=== Test on chp042-nsrr. train_data(15797), test_data(223) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3739607528352225
Starting epoch 2/10.
Epoch finished! Loss: 0.9940580275143303
Starting epoch 3/10.
Epoch finished! Loss: 0.9350059862715145
Starting epoch 4/10.
Epoch finished! Loss: 0.8874518384542399
Starting epoch 5/10.
Epoch finished! Loss: 0.8495774315723216
Starting epoch 6/10.
Epoch finished! Loss: 0.8292184516721469
Starting epoch 7/10.
Epoch finished! Loss: 0.81468841252333
Starting epoch 8/10.
Epoch finished! Loss: 0.7976524989540023
Starting epoch 9/10.
Epoch finished! Loss: 0.7781142867804328
Starting epoch 10/10.
Epoch finished! Loss: 0.773796926936143
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7524663677130045
              precision    recall  f1-score   support

         0.0       0.59      0.82      0.69       153
         1.0       0.59      0.44      0.50       237
         2.0       0.93      0.83      0.88       441
         3.0       0.97      0.91      0.94        93
         4.0       0.64      0.82      0.72       191

    accuracy                           0.75      1115
   macro avg       0.74      0.77      0.75      1115
weighted avg       0.77      0.75      0.75      1115
 


====== chp042-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  89.87  82.35   91.06  59.43     69.04
1  81.70  43.88   91.91  59.43     50.49
2  90.94  83.45   95.85  92.93     87.93
3  99.01  91.40   99.71  96.59     93.92
4  88.97  81.68   90.48  63.93     71.72
Total accuracy: 75.25%
Average sen: 76.55%
Average spec: 93.80%
Macro f1-score: 74.62%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9936250253108585, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp042-nsrr

=== Test on chp043-nsrr. train_data(15779), test_data(241) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3790030030412015
Starting epoch 2/10.
Epoch finished! Loss: 1.0390889689033365
Starting epoch 3/10.
Epoch finished! Loss: 0.9614090073615142
Starting epoch 4/10.
Epoch finished! Loss: 0.9111339556467858
Starting epoch 5/10.
Epoch finished! Loss: 0.8754212550332294
Starting epoch 6/10.
Epoch finished! Loss: 0.8407452746554879
Starting epoch 7/10.
Epoch finished! Loss: 0.8258909728607197
Starting epoch 8/10.
Epoch finished! Loss: 0.8212513821689706
Starting epoch 9/10.
Epoch finished! Loss: 0.7923033795518518
Starting epoch 10/10.
Epoch finished! Loss: 0.7787804062051266
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6730290456431536
              precision    recall  f1-score   support

         0.0       0.34      0.99      0.51       148
         1.0       0.33      0.02      0.04       197
         2.0       0.91      0.84      0.87       506
         3.0       0.77      0.92      0.84        64
         4.0       0.81      0.61      0.70       290

    accuracy                           0.67      1205
   macro avg       0.63      0.68      0.59      1205
weighted avg       0.71      0.67      0.65      1205
 


====== chp043-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  76.51  99.32   73.32  34.27     50.95
1  83.32   2.03   99.21  33.33      3.83
2  89.54  83.79   93.71  90.60     87.06
3  98.09  92.19   98.42  76.62     83.69
4  87.14  61.03   95.41  80.82     69.55
Total accuracy: 67.30%
Average sen: 67.67%
Average spec: 92.01%
Macro f1-score: 59.02%
Diagnosis acc on 2.5mins: 0.9336099585062241
pred: 0.906388393774688, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp043-nsrr

=== Test on chp044-nsrr. train_data(15810), test_data(210) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3916435283950612
Starting epoch 2/10.
Epoch finished! Loss: 1.0525778577674794
Starting epoch 3/10.
Epoch finished! Loss: 0.9626069230369375
Starting epoch 4/10.
Epoch finished! Loss: 0.9113134638983992
Starting epoch 5/10.
Epoch finished! Loss: 0.8695577716148353
Starting epoch 6/10.
Epoch finished! Loss: 0.852856522609916
Starting epoch 7/10.
Epoch finished! Loss: 0.8297633634337896
Starting epoch 8/10.
Epoch finished! Loss: 0.8222987553741359
Starting epoch 9/10.
Epoch finished! Loss: 0.7973642968584465
Starting epoch 10/10.
Epoch finished! Loss: 0.785781119829869
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6933333333333334
              precision    recall  f1-score   support

         0.0       0.83      0.40      0.54        25
         1.0       0.10      0.01      0.02        93
         2.0       0.68      0.60      0.64       324
         3.0       0.93      0.84      0.88       484
         4.0       0.38      0.92      0.54       124

    accuracy                           0.69      1050
   macro avg       0.58      0.56      0.52      1050
weighted avg       0.71      0.69      0.68      1050
 


====== chp044-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  98.38  40.00   99.80  83.33     54.05
1  90.38   1.08   99.06  10.00      1.94
2  78.86  60.49   87.05  67.59     63.84
3  89.81  84.09   94.70  93.14     88.38
4  81.24  91.94   79.81  37.87     53.65
Total accuracy: 69.33%
Average sen: 55.52%
Average spec: 92.08%
Macro f1-score: 52.37%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9908675815377916, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp044-nsrr

=== Test on chp045-nsrr. train_data(15779), test_data(241) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4103598908752146
Starting epoch 2/10.
Epoch finished! Loss: 1.0276188141723637
Starting epoch 3/10.
Epoch finished! Loss: 0.9448567723162051
Starting epoch 4/10.
Epoch finished! Loss: 0.8813916514890437
Starting epoch 5/10.
Epoch finished! Loss: 0.8455123837869531
Starting epoch 6/10.
Epoch finished! Loss: 0.811217632024214
Starting epoch 7/10.
Epoch finished! Loss: 0.8039519754140984
Starting epoch 8/10.
Epoch finished! Loss: 0.7796298892118543
Starting epoch 9/10.
Epoch finished! Loss: 0.7638123099117545
Starting epoch 10/10.
Epoch finished! Loss: 0.7546970075871571
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6478405315614618
              precision    recall  f1-score   support

         0.0       0.42      0.74      0.53       156
         1.0       0.19      0.07      0.10       135
         2.0       0.74      0.85      0.79       442
         3.0       0.93      0.62      0.75       221
         4.0       0.64      0.58      0.61       250

    accuracy                           0.65      1204
   macro avg       0.58      0.57      0.55      1204
weighted avg       0.65      0.65      0.63      1204
 


====== chp045-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  83.22  73.72   84.64  41.67     53.24
1  86.30   6.67   96.35  18.75      9.84
2  83.31  84.62   82.55  73.77     78.82
3  92.19  62.44   98.88  92.62     74.59
4  84.55  57.60   91.61  64.29     60.76
Total accuracy: 64.78%
Average sen: 57.01%
Average spec: 90.81%
Macro f1-score: 55.45%
Diagnosis acc on 2.5mins: 0.9128630705394191
pred: 0.8854803055161572, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp045-nsrr

=== Test on chp046-nsrr. train_data(15801), test_data(219) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3351837102182305
Starting epoch 2/10.
Epoch finished! Loss: 0.9901893762093557
Starting epoch 3/10.
Epoch finished! Loss: 0.9129668928211249
Starting epoch 4/10.
Epoch finished! Loss: 0.8656277270445341
Starting epoch 5/10.
Epoch finished! Loss: 0.8342316720870476
Starting epoch 6/10.
Epoch finished! Loss: 0.8251264048999624
Starting epoch 7/10.
Epoch finished! Loss: 0.8171349589771862
Starting epoch 8/10.
Epoch finished! Loss: 0.7843273612800278
Starting epoch 9/10.
Epoch finished! Loss: 0.7704169906487194
Starting epoch 10/10.
Epoch finished! Loss: 0.7556032377330563
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.5041095890410959
              precision    recall  f1-score   support

         0.0       0.59      0.97      0.73       229
         1.0       0.54      0.04      0.07       364
         2.0       0.46      0.46      0.46       192
         3.0       0.03      1.00      0.05         2
         4.0       0.53      0.73      0.61       308

    accuracy                           0.50      1095
   macro avg       0.43      0.64      0.39      1095
weighted avg       0.53      0.50      0.43      1095
 


====== chp046-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  85.21   97.38   81.99  58.84     73.36
1  66.94    3.85   98.36  53.85      7.18
2  81.10   46.35   88.48  46.11     46.23
3  93.52  100.00   93.50   2.74      5.33
4  74.06   72.73   74.59  52.83     61.20
Total accuracy: 50.41%
Average sen: 64.06%
Average spec: 87.38%
Macro f1-score: 38.66%
Diagnosis acc on 2.5mins: 0.8310502283105022
pred: 0.8157267330589675, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp046-nsrr

=== Test on chp047-nsrr. train_data(15842), test_data(178) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3835870753032993
Starting epoch 2/10.
Epoch finished! Loss: 1.0625427536139584
Starting epoch 3/10.
Epoch finished! Loss: 0.951607382150762
Starting epoch 4/10.
Epoch finished! Loss: 0.9052873231997394
Starting epoch 5/10.
Epoch finished! Loss: 0.8641720143795917
Starting epoch 6/10.
Epoch finished! Loss: 0.8423795207507081
Starting epoch 7/10.
Epoch finished! Loss: 0.8155221413218915
Starting epoch 8/10.
Epoch finished! Loss: 0.8004981803171562
Starting epoch 9/10.
Epoch finished! Loss: 0.7901880371224399
Starting epoch 10/10.
Epoch finished! Loss: 0.7801883359806556
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.5370786516853933
              precision    recall  f1-score   support

         0.0       0.52      0.95      0.67       311
         1.0       0.32      0.17      0.22       231
         2.0       0.74      0.59      0.66       233
         3.0       0.00      0.00      0.00        25
         4.0       0.46      0.07      0.12        90

    accuracy                           0.54       890
   macro avg       0.41      0.36      0.33       890
weighted avg       0.51      0.54      0.48       890
 


====== chp047-nsrr ======

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  67.64  95.18   52.85  52.02     67.27
1  69.10  16.88   87.41  31.97     22.10
2  83.82  58.80   92.69  74.05     65.55
3  97.08   0.00   99.88   0.00      0.00
4  89.78   6.67   99.12  46.15     11.65
Total accuracy: 53.71%
Average sen: 35.50%
Average spec: 86.39%
Macro f1-score: 33.31%
Diagnosis acc on 2.5mins: 0.7191011235955056
pred: 0.711153179802147, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp047-nsrr

=== Test on chp048-nsrr. train_data(15814), test_data(206) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3662733164186496
Starting epoch 2/10.
Epoch finished! Loss: 1.0251371704423677
Starting epoch 3/10.
Epoch finished! Loss: 0.930840607254208
Starting epoch 4/10.
Epoch finished! Loss: 0.8940453315784025
Starting epoch 5/10.
Epoch finished! Loss: 0.8517650356215816
Starting epoch 6/10.
Epoch finished! Loss: 0.8297696087007504
Starting epoch 7/10.
Epoch finished! Loss: 0.8267297541921762
Starting epoch 8/10.
Epoch finished! Loss: 0.8011368267487906
Starting epoch 9/10.
Epoch finished! Loss: 0.7863691435216124
Starting epoch 10/10.
Epoch finished! Loss: 0.7911385751596212
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7339805825242719
              precision    recall  f1-score   support

         0.0       0.47      0.97      0.63        38
         1.0       0.39      0.11      0.17       144
         2.0       0.78      0.92      0.84       505
         3.0       0.77      0.46      0.57       107
         4.0       0.77      0.81      0.79       236

    accuracy                           0.73      1030
   macro avg       0.63      0.65      0.60      1030
weighted avg       0.71      0.73      0.70      1030
 


====== chp048-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  95.83  97.37   95.77  46.84     63.25
1  85.15  11.11   97.18  39.02     17.30
2  83.01  91.88   74.48  77.59     84.13
3  92.91  45.79   98.37  76.56     57.31
4  89.90  80.51   92.70  76.61     78.51
Total accuracy: 73.40%
Average sen: 65.33%
Average spec: 91.70%
Macro f1-score: 60.10%
Diagnosis acc on 2.5mins: 0.5242718446601942
pred: 0.481128111626338, label: 1
Wrong!!! Real Diagnosis: NT1
Save 2.5mins of subject chp048-nsrr

=== Test on chp049-nsrr. train_data(15804), test_data(216) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3461913082041317
Starting epoch 2/10.
Epoch finished! Loss: 1.003801452227031
Starting epoch 3/10.
Epoch finished! Loss: 0.9382682497365565
Starting epoch 4/10.
Epoch finished! Loss: 0.8865876505646525
Starting epoch 5/10.
Epoch finished! Loss: 0.8471667306709894
Starting epoch 6/10.
Epoch finished! Loss: 0.8220573984558069
Starting epoch 7/10.
Epoch finished! Loss: 0.7960864162992073
Starting epoch 8/10.
Epoch finished! Loss: 0.7977583436554746
Starting epoch 9/10.
Epoch finished! Loss: 0.7736324381130406
Starting epoch 10/10.
Epoch finished! Loss: 0.7627432919189899
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.4111111111111111
              precision    recall  f1-score   support

         0.0       0.23      0.64      0.34       108
         1.0       0.29      0.03      0.06       387
         2.0       0.90      0.41      0.56       360
         3.0       0.94      0.97      0.95        95
         4.0       0.26      0.95      0.41       130

    accuracy                           0.41      1080
   macro avg       0.52      0.60      0.46      1080
weighted avg       0.54      0.41      0.38      1080
 


====== chp049-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  75.09  63.89   76.34  23.08     33.91
1  62.41   3.36   95.38  28.89      6.02
2  78.70  40.83   97.64  89.63     56.11
3  99.17  96.84   99.39  93.88     95.34
4  66.85  94.62   63.05  25.95     40.73
Total accuracy: 41.11%
Average sen: 59.91%
Average spec: 86.36%
Macro f1-score: 46.42%
Diagnosis acc on 2.5mins: 1.0
pred: 0.9992295175238892, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp049-nsrr

=== Test on chp051-nsrr. train_data(15802), test_data(218) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3974132573680034
Starting epoch 2/10.
Epoch finished! Loss: 1.0315994371530375
Starting epoch 3/10.
Epoch finished! Loss: 0.9103952149612994
Starting epoch 4/10.
Epoch finished! Loss: 0.8800864594835269
Starting epoch 5/10.
Epoch finished! Loss: 0.8610994148857986
Starting epoch 6/10.
Epoch finished! Loss: 0.8196885834577717
Starting epoch 7/10.
Epoch finished! Loss: 0.8044506437416318
Starting epoch 8/10.
Epoch finished! Loss: 0.8019261872089362
Starting epoch 9/10.
Epoch finished! Loss: 0.780973618232374
Starting epoch 10/10.
Epoch finished! Loss: 0.7698355653806578
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6770642201834862
              precision    recall  f1-score   support

         0.0       0.67      0.40      0.50        30
         1.0       0.17      0.01      0.03       136
         2.0       0.77      0.61      0.68       414
         3.0       0.79      0.87      0.83       239
         4.0       0.56      0.97      0.71       271

    accuracy                           0.68      1090
   macro avg       0.59      0.57      0.55      1090
weighted avg       0.65      0.68      0.63      1090
 


====== chp051-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  97.80  40.00   99.43  66.67     50.00
1  86.79   1.47   98.95  16.67      2.70
2  78.35  60.63   89.20  77.47     68.02
3  92.29  87.45   93.65  79.47     83.27
4  80.18  97.42   74.48  55.81     70.97
Total accuracy: 67.71%
Average sen: 57.39%
Average spec: 91.14%
Macro f1-score: 54.99%
Diagnosis acc on 2.5mins: 0.8302752293577982
pred: 0.7814249974256808, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp051-nsrr

=== Test on chp052-nsrr. train_data(15820), test_data(200) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3467573649064413
Starting epoch 2/10.
Epoch finished! Loss: 1.0609283095142044
Starting epoch 3/10.
Epoch finished! Loss: 0.9753479450696032
Starting epoch 4/10.
Epoch finished! Loss: 0.9289952674144284
Starting epoch 5/10.
Epoch finished! Loss: 0.8910116156130784
Starting epoch 6/10.
Epoch finished! Loss: 0.869050036514959
Starting epoch 7/10.
Epoch finished! Loss: 0.8534979656630871
Starting epoch 8/10.
Epoch finished! Loss: 0.8274086584666347
Starting epoch 9/10.
Epoch finished! Loss: 0.8256634074362827
Starting epoch 10/10.
Epoch finished! Loss: 0.805440838807448
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.838
              precision    recall  f1-score   support

         0.0       0.79      0.86      0.82       159
         1.0       0.38      0.03      0.06        87
         2.0       0.90      0.91      0.90       439
         3.0       0.87      0.95      0.91       109
         4.0       0.77      0.95      0.85       206

    accuracy                           0.84      1000
   macro avg       0.74      0.74      0.71      1000
weighted avg       0.80      0.84      0.81      1000
 


====== chp052-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0   94.1  85.53   95.72  79.07     82.18
1   91.1   3.45   99.45  37.50      6.32
2   91.4  90.89   91.80  89.66     90.27
3   97.9  95.41   98.20  86.67     90.83
4   93.1  95.15   92.57  76.86     85.03
Total accuracy: 83.80%
Average sen: 74.09%
Average spec: 95.55%
Macro f1-score: 70.92%
Diagnosis acc on 2.5mins: 0.76
pred: 0.7151889764983207, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp052-nsrr

=== Test on chp053-nsrr. train_data(15803), test_data(217) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4116892140500152
Starting epoch 2/10.
Epoch finished! Loss: 1.0338427131500425
Starting epoch 3/10.
Epoch finished! Loss: 0.9376852486706987
Starting epoch 4/10.
Epoch finished! Loss: 0.8906364116676246
Starting epoch 5/10.
Epoch finished! Loss: 0.8708265647858004
Starting epoch 6/10.
Epoch finished! Loss: 0.843313073829005
Starting epoch 7/10.
Epoch finished! Loss: 0.8157697052140779
Starting epoch 8/10.
Epoch finished! Loss: 0.811393077850719
Starting epoch 9/10.
Epoch finished! Loss: 0.7901188074410717
Starting epoch 10/10.
Epoch finished! Loss: 0.7858607326693172
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6682027649769585
              precision    recall  f1-score   support

         0.0       0.89      0.53      0.66       251
         1.0       0.11      0.01      0.01       147
         2.0       0.81      0.85      0.83       310
         3.0       0.98      0.88      0.93       250
         4.0       0.29      0.86      0.43       127

    accuracy                           0.67      1085
   macro avg       0.62      0.62      0.57      1085
weighted avg       0.71      0.67      0.66      1085
 


====== chp053-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  87.56  52.59   98.08  89.19     66.17
1  85.81   0.68   99.15  11.11      1.28
2  89.95  84.84   92.00  80.92     82.83
3  96.77  88.00   99.40  97.78     92.63
4  73.55  85.83   71.92  28.84     43.17
Total accuracy: 66.82%
Average sen: 62.39%
Average spec: 92.11%
Macro f1-score: 57.22%
Diagnosis acc on 2.5mins: 0.6267281105990783
pred: 0.602086564421349, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp053-nsrr

=== Test on chp054-nsrr. train_data(15796), test_data(224) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3970835449727297
Starting epoch 2/10.
Epoch finished! Loss: 1.0458380328921897
Starting epoch 3/10.
Epoch finished! Loss: 0.9573514276172935
Starting epoch 4/10.
Epoch finished! Loss: 0.901216477646414
Starting epoch 5/10.
Epoch finished! Loss: 0.8606292767340508
Starting epoch 6/10.
Epoch finished! Loss: 0.8308292518430604
Starting epoch 7/10.
Epoch finished! Loss: 0.8213600771592492
Starting epoch 8/10.
Epoch finished! Loss: 0.8001730362586842
Starting epoch 9/10.
Epoch finished! Loss: 0.7790893729047129
Starting epoch 10/10.
Epoch finished! Loss: 0.7766923667642419
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7142857142857143
              precision    recall  f1-score   support

         0.0       0.71      0.75      0.73       232
         1.0       0.22      0.06      0.10        98
         2.0       0.87      0.68      0.76       475
         3.0       0.85      0.95      0.90        99
         4.0       0.55      0.95      0.70       216

    accuracy                           0.71      1120
   macro avg       0.64      0.68      0.64      1120
weighted avg       0.72      0.71      0.70      1120
 


====== chp054-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  88.48  74.57   92.12  71.19     72.84
1  89.91   6.12   97.95  22.22      9.60
2  82.14  67.79   92.71  87.26     76.30
3  98.12  94.95   98.43  85.45     89.95
4  84.20  94.91   81.64  55.26     69.85
Total accuracy: 71.43%
Average sen: 67.67%
Average spec: 92.57%
Macro f1-score: 63.71%
Diagnosis acc on 2.5mins: 0.5625
pred: 0.5656026454442846, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp054-nsrr

=== Test on chp055-nsrr. train_data(15798), test_data(222) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3776852091405118
Starting epoch 2/10.
Epoch finished! Loss: 1.0163224469150751
Starting epoch 3/10.
Epoch finished! Loss: 0.9363883167524139
Starting epoch 4/10.
Epoch finished! Loss: 0.8961698613527683
Starting epoch 5/10.
Epoch finished! Loss: 0.8615192948563933
Starting epoch 6/10.
Epoch finished! Loss: 0.8318577094724315
Starting epoch 7/10.
Epoch finished! Loss: 0.8127243940478416
Starting epoch 8/10.
Epoch finished! Loss: 0.7942286824560981
Starting epoch 9/10.
Epoch finished! Loss: 0.8012661622003183
Starting epoch 10/10.
Epoch finished! Loss: 0.7839654355750497
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6432432432432432
              precision    recall  f1-score   support

         0.0       0.46      0.91      0.62       211
         1.0       0.48      0.07      0.11       184
         2.0       0.89      0.63      0.74       408
         3.0       0.74      0.96      0.83       130
         4.0       0.61      0.71      0.65       177

    accuracy                           0.64      1110
   macro avg       0.63      0.66      0.59      1110
weighted avg       0.68      0.64      0.61      1110
 


====== chp055-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  78.29  91.47   75.19  46.39     61.56
1  83.33   6.52   98.60  48.00     11.48
2  83.51  63.24   95.30  88.66     73.82
3  95.50  96.15   95.41  73.53     83.33
4  88.02  71.19   91.21  60.58     65.45
Total accuracy: 64.32%
Average sen: 65.71%
Average spec: 91.14%
Macro f1-score: 59.13%
Diagnosis acc on 2.5mins: 0.26126126126126126
pred: 0.3129765359235944, label: 1
Wrong!!! Real Diagnosis: NT1
Save 2.5mins of subject chp055-nsrr

=== Test on chp056-nsrr. train_data(15800), test_data(220) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3826898286205216
Starting epoch 2/10.
Epoch finished! Loss: 1.0315034375151477
Starting epoch 3/10.
Epoch finished! Loss: 0.9487530709709677
Starting epoch 4/10.
Epoch finished! Loss: 0.9105912837104906
Starting epoch 5/10.
Epoch finished! Loss: 0.8843373675524546
Starting epoch 6/10.
Epoch finished! Loss: 0.8505181071028217
Starting epoch 7/10.
Epoch finished! Loss: 0.8307584264068532
Starting epoch 8/10.
Epoch finished! Loss: 0.8302814927921784
Starting epoch 9/10.
Epoch finished! Loss: 0.8060296310832638
Starting epoch 10/10.
Epoch finished! Loss: 0.7975055782043006
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.4027272727272727
              precision    recall  f1-score   support

         0.0       0.15      0.91      0.26        78
         1.0       0.14      0.00      0.01       284
         2.0       0.65      0.33      0.43       258
         3.0       0.56      0.99      0.72       185
         4.0       0.60      0.35      0.44       295

    accuracy                           0.40      1100
   macro avg       0.42      0.52      0.37      1100
weighted avg       0.45      0.40      0.36      1100
 


====== chp056-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  63.73  91.03   61.64  15.33     26.25
1  73.73   0.35   99.26  14.29      0.69
2  80.00  32.56   94.54  64.62     43.30
3  86.73  99.46   84.15  55.93     71.60
4  76.36  34.92   91.55  60.23     44.21
Total accuracy: 40.27%
Average sen: 51.66%
Average spec: 86.23%
Macro f1-score: 37.21%
Diagnosis acc on 2.5mins: 0.509090909090909
pred: 0.5326132734306157, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp056-nsrr

=== Test on chp057-nsrr. train_data(15781), test_data(239) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3584441514296224
Starting epoch 2/10.
Epoch finished! Loss: 1.0035030315281925
Starting epoch 3/10.
Epoch finished! Loss: 0.9407799553093046
Starting epoch 4/10.
Epoch finished! Loss: 0.8816326261133296
Starting epoch 5/10.
Epoch finished! Loss: 0.8627228209954251
Starting epoch 6/10.
Epoch finished! Loss: 0.8400404214934554
Starting epoch 7/10.
Epoch finished! Loss: 0.8186620436467146
Starting epoch 8/10.
Epoch finished! Loss: 0.8141831918625475
Starting epoch 9/10.
Epoch finished! Loss: 0.7880308885689169
Starting epoch 10/10.
Epoch finished! Loss: 0.7836862605900818
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.6742043551088778
              precision    recall  f1-score   support

         0.0       0.76      0.66      0.71       279
         1.0       0.16      0.04      0.06       162
         2.0       0.85      0.76      0.80       499
         3.0       0.71      0.77      0.74        74
         4.0       0.46      0.99      0.62       180

    accuracy                           0.67      1194
   macro avg       0.59      0.64      0.59      1194
weighted avg       0.67      0.67      0.65      1194
 


====== chp057-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  87.27  66.31   93.66  76.13     70.88
1  84.34   3.70   97.00  16.22      6.03
2  84.51  75.95   90.65  85.36     80.38
3  96.65  77.03   97.95  71.25     74.03
4  82.08  98.89   79.09  45.64     62.46
Total accuracy: 67.42%
Average sen: 64.38%
Average spec: 91.67%
Macro f1-score: 58.76%
Diagnosis acc on 2.5mins: 0.7322175732217573
pred: 0.7281112187869491, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp057-nsrr

=== Test on chp058-nsrr. train_data(15814), test_data(206) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.356134860105412
Starting epoch 2/10.
Epoch finished! Loss: 1.0153587666174644
Starting epoch 3/10.
Epoch finished! Loss: 0.93498109623196
Starting epoch 4/10.
Epoch finished! Loss: 0.893759206342667
Starting epoch 5/10.
Epoch finished! Loss: 0.8463768768845895
Starting epoch 6/10.
Epoch finished! Loss: 0.8298791053926997
Starting epoch 7/10.
Epoch finished! Loss: 0.8071101023606452
Starting epoch 8/10.
Epoch finished! Loss: 0.7927918456763425
Starting epoch 9/10.
Epoch finished! Loss: 0.7704578732799534
Starting epoch 10/10.
Epoch finished! Loss: 0.7657325857523346
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7650485436893204
              precision    recall  f1-score   support

         0.0       0.62      0.70      0.66       105
         1.0       0.04      0.02      0.03        44
         2.0       0.71      0.87      0.78       317
         3.0       0.98      0.79      0.88       268
         4.0       0.80      0.76      0.78       296

    accuracy                           0.77      1030
   macro avg       0.63      0.63      0.63      1030
weighted avg       0.77      0.77      0.76      1030
 


====== chp058-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  92.62  69.52   95.24  62.39     65.77
1  93.50   2.27   97.57   4.00      2.90
2  84.95  87.07   84.01  70.77     78.08
3  94.17  79.48   99.34  97.71     87.65
4  87.77  76.01   92.51  80.36     78.12
Total accuracy: 76.50%
Average sen: 62.87%
Average spec: 93.73%
Macro f1-score: 62.50%
Diagnosis acc on 2.5mins: 1.0
pred: 0.998275384740922, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp058-nsrr

=== Test on chp059-nsrr. train_data(15793), test_data(227) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.4083080452178536
Starting epoch 2/10.
Epoch finished! Loss: 1.0280910402517518
Starting epoch 3/10.
Epoch finished! Loss: 0.9491185533275628
Starting epoch 4/10.
Epoch finished! Loss: 0.9134785694514294
Starting epoch 5/10.
Epoch finished! Loss: 0.8666036738067431
Starting epoch 6/10.
Epoch finished! Loss: 0.8467494019267678
Starting epoch 7/10.
Epoch finished! Loss: 0.8263249968032885
Starting epoch 8/10.
Epoch finished! Loss: 0.8229803560352386
Starting epoch 9/10.
Epoch finished! Loss: 0.7965543398172361
Starting epoch 10/10.
Epoch finished! Loss: 0.7964885857114314
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.5524229074889868
              precision    recall  f1-score   support

         0.0       0.91      0.62      0.74       272
         1.0       0.25      0.19      0.21       254
         2.0       0.70      0.68      0.69       355
         3.0       1.00      0.10      0.19        87
         4.0       0.40      0.96      0.56       167

    accuracy                           0.55      1135
   macro avg       0.65      0.51      0.48      1135
weighted avg       0.63      0.55      0.54      1135
 


====== chp059-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  89.43  62.13   98.03   90.86     73.80
1  69.16  18.50   83.77   24.74     21.17
2  80.97  67.89   86.92   70.26     69.05
3  93.13  10.34  100.00  100.00     18.75
4  77.80  96.41   74.59   39.56     56.10
Total accuracy: 55.24%
Average sen: 51.06%
Average spec: 88.66%
Macro f1-score: 47.77%
Diagnosis acc on 2.5mins: 0.9955947136563876
pred: 0.9915447340137633, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp059-nsrr

=== Test on chp060-nsrr. train_data(15768), test_data(252) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
Epoch finished! Loss: 1.3436418742622216
Starting epoch 2/10.
Epoch finished! Loss: 1.0050026931171188
Starting epoch 3/10.
Epoch finished! Loss: 0.9266560746139378
Starting epoch 4/10.
Epoch finished! Loss: 0.8755785747795238
Starting epoch 5/10.
Epoch finished! Loss: 0.8416851259162886
Starting epoch 6/10.
Epoch finished! Loss: 0.8214471167530203
Starting epoch 7/10.
Epoch finished! Loss: 0.7982269723422183
Starting epoch 8/10.
Epoch finished! Loss: 0.7883449067470386
Starting epoch 9/10.
Epoch finished! Loss: 0.7713673805846327
Starting epoch 10/10.
Epoch finished! Loss: 0.7613954950823699
Model saved !

==== START TESTING ====
Sleep stage: acc = 0.7071428571428572
              precision    recall  f1-score   support

         0.0       0.68      0.96      0.80       519
         1.0       0.38      0.06      0.10       201
         2.0       0.69      0.91      0.78       228
         3.0       0.96      0.68      0.80       158
         4.0       0.78      0.42      0.54       154

    accuracy                           0.71      1260
   macro avg       0.70      0.61      0.61      1260
weighted avg       0.68      0.71      0.65      1260
 


====== chp060-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  80.08  96.34   68.69  68.31     79.94
1  83.41   5.97   98.11  37.50     10.30
2  90.79  90.79   90.79  68.54     78.11
3  95.71  68.35   99.64  96.43     80.00
4  91.43  41.56   98.37  78.05     54.24
Total accuracy: 70.71%
Average sen: 60.60%
Average spec: 91.12%
Macro f1-score: 60.52%
Diagnosis acc on 2.5mins: 0.6111111111111112
pred: 0.5993724412747681, label: 1
Right! Diagnosis: NT1
Save 2.5mins of subject chp060-nsrr

====== all ======
   acc %  sen %  spec %  ppr %  f1-score
0  88.87  77.75   90.68  57.64     66.20
1  86.34   7.31   97.79  32.39     11.93
2  84.86  76.84   89.70  81.83     79.26
3  94.46  83.23   96.84  84.84     84.02
4  85.31  80.28   86.42  56.74     66.48
Total accuracy: 69.92%
Average sen: 65.08%
Average spec: 92.29%
Macro f1-score: 61.58%
Diagnosis acc on patients: 0.9230769230769231

====== all ======
   acc %   sen %  spec %   ppr %  f1-score
0  92.31  100.00   89.09   79.31     88.46
1  92.31   89.09  100.00  100.00     94.23
Total accuracy: 92.31%
Average sen: 94.55%
Average spec: 94.55%
Macro f1-score: 91.35%
fpr: 0.0, tpr: 0.0, threshold: 1.999919220657632, 
fpr: 0.0, tpr: 0.01818181818181818, threshold: 0.999919220657632, 
fpr: 0.0, tpr: 1.0, threshold: 0.11860847176720969, 
fpr: 1.0, tpr: 1.0, threshold: 5.112832437638557e-07, 

=== best_threshold: 0.11860847176720969, best_fpr: 0.0, best_tpr: 1.0 ===
fpr: 0.0, tpr: 0.0, threshold: 2.0, 
fpr: 0.0, tpr: 0.05515668553087254, threshold: 1.0, 
fpr: 0.0, tpr: 0.06698200861559253, threshold: 0.9999998807907104, 
fpr: 0.0, tpr: 0.07255680378410338, threshold: 0.9999997615814209, 
fpr: 0.0, tpr: 0.07770926598530281, threshold: 0.9999996423721313, 
fpr: 0.0, tpr: 0.08091899653686967, threshold: 0.9999995231628418, 
fpr: 0.0, tpr: 0.08548019258383309, threshold: 0.9999994039535522, 
fpr: 0.0, tpr: 0.08750739082692795, threshold: 0.9999992847442627, 
fpr: 0.0, tpr: 0.09004138863079653, threshold: 0.9999991655349731, 
fpr: 0.0, tpr: 0.09198412028042909, threshold: 0.9999990463256836, 
fpr: 0.0, tpr: 0.09375791874313709, threshold: 0.999998927116394, 
fpr: 0.0, tpr: 0.09536278401892051, threshold: 0.9999988079071045, 
fpr: 0.0, tpr: 0.09629191654700565, threshold: 0.9999986886978149, 
fpr: 0.0, tpr: 0.0978123152293268, threshold: 0.9999985694885254, 
fpr: 0.0, tpr: 0.0989948475377988, threshold: 0.9999984502792358, 
fpr: 0.0, tpr: 0.10068417940704451, threshold: 0.9999983310699463, 
fpr: 0.0, tpr: 0.10144437874820508, threshold: 0.9999982118606567, 
fpr: 0.0, tpr: 0.10304924402398852, threshold: 0.9999980926513672, 
fpr: 0.0, tpr: 0.10389390995861136, threshold: 0.9999979734420776, 
fpr: 0.0, tpr: 0.10532984204747023, threshold: 0.9999978542327881, 
fpr: 0.0, tpr: 0.10609004138863079, threshold: 0.9999977350234985, 
fpr: 0.0, tpr: 0.10676577413632908, threshold: 0.999997615814209, 
fpr: 0.0, tpr: 0.10794830644480108, threshold: 0.9999974966049194, 
fpr: 0.0, tpr: 0.10887743897288622, threshold: 0.9999973773956299, 
fpr: 0.0, tpr: 0.10997550468789594, threshold: 0.9999972581863403, 
fpr: 0.0, tpr: 0.11073570402905651, threshold: 0.9999971389770508, 
fpr: 0.0, tpr: 0.11098910380944337, threshold: 0.9999970197677612, 
fpr: 0.0, tpr: 0.11352310161331193, threshold: 0.9999966621398926, 
fpr: 0.0, tpr: 0.11555029985640679, threshold: 0.9999964237213135, 
fpr: 0.0, tpr: 0.11571923304333136, threshold: 0.9999963045120239, 
fpr: 0.0, tpr: 0.11673283216487879, threshold: 0.9999961853027344, 
fpr: 0.0, tpr: 0.11799983106681308, threshold: 0.9999960660934448, 
fpr: 0.0, tpr: 0.11867556381451136, threshold: 0.9999959468841553, 
fpr: 0.0, tpr: 0.11968916293605879, threshold: 0.9999957084655762, 
fpr: 0.0, tpr: 0.11994256271644564, threshold: 0.9999955892562866, 
fpr: 0.0, tpr: 0.12087169524453079, threshold: 0.9999954700469971, 
fpr: 0.0, tpr: 0.1219697609595405, threshold: 0.9999953508377075, 
fpr: 0.0, tpr: 0.12247656052031422, threshold: 0.999995231628418, 
fpr: 0.0, tpr: 0.1231522932680125, threshold: 0.9999951124191284, 
fpr: 0.0, tpr: 0.12340569304839936, threshold: 0.9999949932098389, 
fpr: 0.0, tpr: 0.12391249260917307, threshold: 0.9999948740005493, 
fpr: 0.0, tpr: 0.1254328912914942, threshold: 0.9999946355819702, 
fpr: 0.0, tpr: 0.12593969085226792, threshold: 0.9999945163726807, 
fpr: 0.0, tpr: 0.1261086240391925, threshold: 0.9999943971633911, 
fpr: 0.0, tpr: 0.1261930906326548, threshold: 0.9999942779541016, 
fpr: 0.0, tpr: 0.12737562294112678, threshold: 0.9999940395355225, 
fpr: 0.0, tpr: 0.1278824225019005, threshold: 0.9999939203262329, 
fpr: 0.0, tpr: 0.1284736886561365, threshold: 0.9999938011169434, 
fpr: 0.0, tpr: 0.12914942140383479, threshold: 0.9999935626983643, 
fpr: 0.0, tpr: 0.13033195371230677, threshold: 0.9999933242797852, 
fpr: 0.0, tpr: 0.13100768646000507, threshold: 0.999993085861206, 
fpr: 0.0, tpr: 0.13151448602077878, threshold: 0.9999929666519165, 
fpr: 0.0, tpr: 0.1320212855815525, threshold: 0.9999927282333374, 
fpr: 0.0, tpr: 0.13219021876847706, threshold: 0.9999926090240479, 
fpr: 0.0, tpr: 0.1324436185488639, threshold: 0.9999924898147583, 
fpr: 0.0, tpr: 0.13328828448348679, threshold: 0.9999923706054688, 
fpr: 0.0, tpr: 0.1337106174507982, threshold: 0.9999922513961792, 
fpr: 0.0, tpr: 0.13396401723118506, threshold: 0.9999921321868896, 
fpr: 0.0, tpr: 0.13463974997888334, threshold: 0.9999918937683105, 
fpr: 0.0, tpr: 0.13523101613311936, threshold: 0.999991774559021, 
fpr: 0.0, tpr: 0.13599121547427992, threshold: 0.9999914169311523, 
fpr: 0.0, tpr: 0.1365824816285159, threshold: 0.9999912977218628, 
fpr: 0.0, tpr: 0.13725821437621422, threshold: 0.9999910593032837, 
fpr: 0.0, tpr: 0.13751161415660107, threshold: 0.9999909400939941, 
fpr: 0.0, tpr: 0.13768054734352564, threshold: 0.9999908208847046, 
fpr: 0.0, tpr: 0.1379339471239125, threshold: 0.999990701675415, 
fpr: 0.0, tpr: 0.13827181349776163, threshold: 0.9999905824661255, 
fpr: 0.0, tpr: 0.1384407466846862, threshold: 0.9999904632568359, 
fpr: 0.0, tpr: 0.13869414646507305, threshold: 0.9999903440475464, 
fpr: 0.0, tpr: 0.13903201283892222, threshold: 0.9999902248382568, 
fpr: 0.0, tpr: 0.13936987921277136, threshold: 0.9999899864196777, 
fpr: 0.0, tpr: 0.1397077455866205, threshold: 0.9999898672103882, 
fpr: 0.0, tpr: 0.13996114536700735, threshold: 0.9999897480010986, 
fpr: 0.0, tpr: 0.1402990117408565, threshold: 0.9999896287918091, 
fpr: 0.0, tpr: 0.14046794492778106, threshold: 0.9999895095825195, 
fpr: 0.0, tpr: 0.14055241152124334, threshold: 0.99998939037323, 
fpr: 0.0, tpr: 0.14089027789509248, threshold: 0.9999892711639404, 
fpr: 0.0, tpr: 0.14097474448855477, threshold: 0.9999891519546509, 
fpr: 0.0, tpr: 0.14122814426894165, threshold: 0.9999889135360718, 
fpr: 0.0, tpr: 0.14156601064279078, threshold: 0.9999887943267822, 
fpr: 0.0, tpr: 0.1425796097643382, threshold: 0.9999885559082031, 
fpr: 0.0, tpr: 0.14291747613818734, threshold: 0.9999884366989136, 
fpr: 0.0, tpr: 0.1431708759185742, threshold: 0.999988317489624, 
fpr: 0.0, tpr: 0.14325534251203648, threshold: 0.9999881982803345, 
fpr: 0.0, tpr: 0.14342427569896107, threshold: 0.9999880790710449, 
fpr: 0.0, tpr: 0.14367767547934793, threshold: 0.9999879598617554, 
fpr: 0.0, tpr: 0.14410000844665935, threshold: 0.9999878406524658, 
fpr: 0.0, tpr: 0.1444378748205085, threshold: 0.9999877214431763, 
fpr: 0.0, tpr: 0.1449446743812822, threshold: 0.9999874830245972, 
fpr: 0.0, tpr: 0.14528254075513133, threshold: 0.9999873638153076, 
fpr: 0.0, tpr: 0.14578934031590507, threshold: 0.9999872446060181, 
fpr: 0.0, tpr: 0.1461272066897542, threshold: 0.9999871253967285, 
fpr: 0.0, tpr: 0.1462116732832165, threshold: 0.999987006187439, 
fpr: 0.0, tpr: 0.14663400625052792, threshold: 0.9999868869781494, 
fpr: 0.0, tpr: 0.14688740603091477, threshold: 0.9999867677688599, 
fpr: 0.0, tpr: 0.1472252724047639, threshold: 0.9999866485595703, 
fpr: 0.0, tpr: 0.14747867218515076, threshold: 0.9999865293502808, 
fpr: 0.0, tpr: 0.14781653855899993, threshold: 0.9999864101409912, 
fpr: 0.0, tpr: 0.14832333811977363, threshold: 0.9999861717224121, 
fpr: 0.0, tpr: 0.14840780471323592, threshold: 0.9999860525131226, 
fpr: 0.0, tpr: 0.14925247064785876, threshold: 0.9999858140945435, 
fpr: 0.0, tpr: 0.14942140383478333, threshold: 0.9999856948852539, 
fpr: 0.0, tpr: 0.1495903370217079, threshold: 0.9999854564666748, 
fpr: 0.0, tpr: 0.14992820339555707, threshold: 0.9999853372573853, 
fpr: 0.0, tpr: 0.15009713658248164, threshold: 0.9999852180480957, 
fpr: 0.0, tpr: 0.15018160317594392, threshold: 0.9999850988388062, 
fpr: 0.0, tpr: 0.1503505363628685, threshold: 0.9999849796295166, 
fpr: 0.0, tpr: 0.15060393614325535, threshold: 0.999984860420227, 
fpr: 0.0, tpr: 0.15094180251710448, threshold: 0.9999842643737793, 
fpr: 0.0, tpr: 0.15119520229749134, threshold: 0.9999841451644897, 
fpr: 0.0, tpr: 0.1514486020778782, threshold: 0.9999836683273315, 
fpr: 0.0, tpr: 0.15170200185826505, threshold: 0.9999834299087524, 
fpr: 0.0, tpr: 0.15178646845172733, threshold: 0.9999833106994629, 
fpr: 0.0, tpr: 0.1521243348255765, threshold: 0.9999831914901733, 
fpr: 0.0, tpr: 0.15229326801250107, threshold: 0.9999830722808838, 
fpr: 0.0, tpr: 0.1527156009798125, threshold: 0.9999829530715942, 
fpr: 0.0, tpr: 0.15288453416673706, threshold: 0.9999828338623047, 
fpr: 0.0, tpr: 0.15330686713404848, threshold: 0.9999827146530151, 
fpr: 0.0, tpr: 0.15356026691443533, threshold: 0.9999825954437256, 
fpr: 0.0, tpr: 0.15389813328828447, threshold: 0.9999823570251465, 
fpr: 0.0, tpr: 0.15423599966213364, threshold: 0.9999822378158569, 
fpr: 0.0, tpr: 0.1544893994425205, threshold: 0.9999821186065674, 
fpr: 0.0, tpr: 0.1549961990032942, threshold: 0.9999817609786987, 
fpr: 0.0, tpr: 0.15541853197060562, threshold: 0.9999816417694092, 
fpr: 0.0, tpr: 0.15567193175099248, threshold: 0.9999814033508301, 
fpr: 0.0, tpr: 0.1560942647183039, threshold: 0.9999812841415405, 
fpr: 0.0, tpr: 0.15660106427907763, threshold: 0.9999809265136719, 
fpr: 0.0, tpr: 0.15668553087253992, threshold: 0.9999808073043823, 
fpr: 0.0, tpr: 0.15710786383985134, threshold: 0.9999806880950928, 
fpr: 0.0, tpr: 0.1572767970267759, threshold: 0.9999805688858032, 
fpr: 0.0, tpr: 0.1573612636202382, threshold: 0.9999803304672241, 
fpr: 0.0, tpr: 0.15778359658754962, threshold: 0.9999802112579346, 
fpr: 0.0, tpr: 0.15803699636793647, threshold: 0.999980092048645, 
fpr: 0.0, tpr: 0.1583748627417856, threshold: 0.9999799728393555, 
fpr: 0.0, tpr: 0.15845932933524792, threshold: 0.9999798536300659, 
fpr: 0.0, tpr: 0.15871272911563478, threshold: 0.9999796152114868, 
fpr: 0.0, tpr: 0.15879719570909706, threshold: 0.9999794960021973, 
fpr: 0.0, tpr: 0.15896612889602163, threshold: 0.9999793767929077, 
fpr: 0.0, tpr: 0.15947292845679534, threshold: 0.9999788999557495, 
fpr: 0.0, tpr: 0.1596418616437199, threshold: 0.9999785423278809, 
fpr: 0.0, tpr: 0.15989526142410676, threshold: 0.9999784231185913, 
fpr: 0.0, tpr: 0.16040206098488047, threshold: 0.9999783039093018, 
fpr: 0.0, tpr: 0.16116226032604106, threshold: 0.9999779462814331, 
fpr: 0.0, tpr: 0.16124672691950334, threshold: 0.999977707862854, 
fpr: 0.0, tpr: 0.16158459329335248, threshold: 0.9999774694442749, 
fpr: 0.0, tpr: 0.16166905988681476, threshold: 0.9999773502349854, 
fpr: 0.0, tpr: 0.16192245966720162, threshold: 0.9999772310256958, 
fpr: 0.0, tpr: 0.16242925922797533, threshold: 0.9999771118164062, 
fpr: 0.0, tpr: 0.1625137258214376, threshold: 0.9999769926071167, 
fpr: 0.0, tpr: 0.16268265900836218, threshold: 0.9999768733978271, 
fpr: 0.0, tpr: 0.16302052538221135, threshold: 0.9999767541885376, 
fpr: 0.0, tpr: 0.16352732494298505, threshold: 0.999976396560669, 
fpr: 0.0, tpr: 0.16369625812990962, threshold: 0.9999761581420898, 
fpr: 0.0, tpr: 0.1638651913168342, threshold: 0.9999760389328003, 
fpr: 0.0, tpr: 0.16411859109722104, threshold: 0.9999759197235107, 
fpr: 0.0, tpr: 0.16420305769068333, threshold: 0.9999756813049316, 
fpr: 0.0, tpr: 0.16487879043838163, threshold: 0.9999752044677734, 
fpr: 0.0, tpr: 0.16521665681223077, threshold: 0.9999749660491943, 
fpr: 0.0, tpr: 0.16530112340569306, threshold: 0.9999748468399048, 
fpr: 0.0, tpr: 0.1655545231860799, threshold: 0.9999747276306152, 
fpr: 0.0, tpr: 0.16572345637300448, threshold: 0.9999746084213257, 
fpr: 0.0, tpr: 0.16589238955992905, threshold: 0.9999743700027466, 
fpr: 0.0, tpr: 0.16639918912070276, threshold: 0.9999740123748779, 
fpr: 0.0, tpr: 0.1667370554945519, threshold: 0.9999738931655884, 
fpr: 0.0, tpr: 0.16699045527493875, threshold: 0.9999737739562988, 
fpr: 0.0, tpr: 0.16715938846186335, threshold: 0.9999734163284302, 
fpr: 0.0, tpr: 0.16758172142917477, threshold: 0.9999732971191406, 
fpr: 0.0, tpr: 0.16783512120956162, threshold: 0.9999731779098511, 
fpr: 0.0, tpr: 0.1680040543964862, threshold: 0.9999730587005615, 
fpr: 0.0, tpr: 0.16825745417687304, threshold: 0.999972939491272, 
fpr: 0.0, tpr: 0.16842638736379761, threshold: 0.9999727010726929, 
fpr: 0.0, tpr: 0.16867978714418447, threshold: 0.9999725818634033, 
fpr: 0.0, tpr: 0.16876425373764675, threshold: 0.9999724626541138, 
fpr: 0.0, tpr: 0.1690176535180336, threshold: 0.9999723434448242, 
fpr: 0.0, tpr: 0.1691021201114959, threshold: 0.9999722242355347, 
fpr: 0.0, tpr: 0.16935551989188277, threshold: 0.9999721050262451, 
fpr: 0.0, tpr: 0.16952445307880734, threshold: 0.999971866607666, 
fpr: 0.0, tpr: 0.16960891967226963, threshold: 0.9999716281890869, 
fpr: 0.0, tpr: 0.17011571923304333, threshold: 0.9999712705612183, 
fpr: 0.0, tpr: 0.17070698538727933, threshold: 0.9999711513519287, 
fpr: 0.0, tpr: 0.1707914519807416, threshold: 0.9999710321426392, 
fpr: 0.0, tpr: 0.17121378494805303, threshold: 0.9999706745147705, 
fpr: 0.0, tpr: 0.17138271813497763, threshold: 0.999970555305481, 
fpr: 0.0, tpr: 0.17146718472843991, threshold: 0.9999701976776123, 
fpr: 0.0, tpr: 0.17172058450882677, threshold: 0.9999700784683228, 
fpr: 0.0, tpr: 0.17197398428921362, threshold: 0.9999697208404541, 
fpr: 0.0, tpr: 0.1721429174761382, threshold: 0.9999696016311646, 
fpr: 0.0, tpr: 0.17298758341076104, threshold: 0.9999682903289795, 
fpr: 0.0, tpr: 0.1732409831911479, threshold: 0.9999680519104004, 
fpr: 0.0, tpr: 0.17340991637807246, threshold: 0.9999679327011108, 
fpr: 0.0, tpr: 0.17366331615845934, threshold: 0.9999678134918213, 
fpr: 0.0, tpr: 0.1738322493453839, threshold: 0.9999676942825317, 
fpr: 0.0, tpr: 0.17408564912577076, threshold: 0.9999673366546631, 
fpr: 0.0, tpr: 0.17425458231269533, threshold: 0.9999669790267944, 
fpr: 0.0, tpr: 0.1745079820930822, threshold: 0.9999668598175049, 
fpr: 0.0, tpr: 0.17467691528000676, threshold: 0.9999661445617676, 
fpr: 0.0, tpr: 0.1750147816538559, threshold: 0.9999657869338989, 
fpr: 0.0, tpr: 0.17509924824731818, threshold: 0.9999655485153198, 
fpr: 0.0, tpr: 0.17526818143424275, threshold: 0.9999654293060303, 
fpr: 0.0, tpr: 0.1755215812146296, threshold: 0.9999651908874512, 
fpr: 0.0, tpr: 0.17585944758847877, threshold: 0.9999649524688721, 
fpr: 0.0, tpr: 0.17602838077540334, threshold: 0.9999645948410034, 
fpr: 0.0, tpr: 0.17636624714925248, threshold: 0.9999644756317139, 
fpr: 0.0, tpr: 0.17704197989695075, threshold: 0.999963641166687, 
fpr: 0.0, tpr: 0.17746431286426217, threshold: 0.9999626874923706, 
fpr: 0.0, tpr: 0.17763324605118674, threshold: 0.999962568283081, 
fpr: 0.0, tpr: 0.17780217923811134, threshold: 0.999962329864502, 
fpr: 0.0, tpr: 0.17822451220542276, threshold: 0.9999620914459229, 
fpr: 0.0, tpr: 0.17830897879888505, threshold: 0.9999619722366333, 
fpr: 0.0, tpr: 0.17847791198580962, threshold: 0.9999618530273438, 
fpr: 0.0, tpr: 0.1785623785792719, threshold: 0.9999617338180542, 
fpr: 0.0, tpr: 0.17873131176619647, threshold: 0.9999614953994751, 
fpr: 0.0, tpr: 0.17898471154658332, threshold: 0.9999610185623169, 
fpr: 0.0, tpr: 0.17923811132697018, threshold: 0.9999607801437378, 
fpr: 0.0, tpr: 0.17940704451389475, threshold: 0.9999605417251587, 
fpr: 0.0, tpr: 0.1796604442942816, threshold: 0.9999604225158691, 
fpr: 0.0, tpr: 0.17982937748120617, threshold: 0.9999603033065796, 
fpr: 0.0, tpr: 0.17991384407466846, threshold: 0.9999600648880005, 
fpr: 0.0, tpr: 0.18008277726159305, threshold: 0.9999599456787109, 
fpr: 0.0, tpr: 0.1804206436354422, threshold: 0.9999587535858154, 
fpr: 0.0, tpr: 0.18058957682236676, threshold: 0.9999586343765259, 
fpr: 0.0, tpr: 0.1809274431962159, threshold: 0.9999585151672363, 
fpr: 0.0, tpr: 0.18101190978967818, threshold: 0.9999583959579468, 
fpr: 0.0, tpr: 0.1815187093504519, threshold: 0.999957799911499, 
fpr: 0.0, tpr: 0.18177210913083874, threshold: 0.9999576807022095, 
fpr: 0.0, tpr: 0.1820255089112256, threshold: 0.9999569654464722, 
fpr: 0.0, tpr: 0.1821944420981502, threshold: 0.9999568462371826, 
fpr: 0.0, tpr: 0.18244784187853705, threshold: 0.9999567270278931, 
fpr: 0.0, tpr: 0.18261677506546162, threshold: 0.999956488609314, 
fpr: 0.0, tpr: 0.1827012416589239, threshold: 0.9999563694000244, 
fpr: 0.0, tpr: 0.18287017484584847, threshold: 0.9999562501907349, 
fpr: 0.0, tpr: 0.18312357462623532, threshold: 0.9999560117721558, 
fpr: 0.0, tpr: 0.1832925078131599, threshold: 0.9999557733535767, 
fpr: 0.0, tpr: 0.18363037418700903, threshold: 0.9999548196792603, 
fpr: 0.0, tpr: 0.18388377396739589, threshold: 0.9999547004699707, 
fpr: 0.0, tpr: 0.18396824056085817, threshold: 0.9999544620513916, 
fpr: 0.0, tpr: 0.18430610693470734, threshold: 0.999954104423523, 
fpr: 0.0, tpr: 0.18439057352816962, threshold: 0.9999538660049438, 
fpr: 0.0, tpr: 0.18472843990201876, threshold: 0.9999537467956543, 
fpr: 0.0, tpr: 0.18481290649548104, threshold: 0.9999536275863647, 
fpr: 0.0, tpr: 0.1850663062758679, threshold: 0.9999533891677856, 
fpr: 0.0, tpr: 0.18515077286933018, threshold: 0.999953031539917, 
fpr: 0.0, tpr: 0.18540417264971704, threshold: 0.9999529123306274, 
fpr: 0.0, tpr: 0.1855731058366416, threshold: 0.9999520778656006, 
fpr: 0.0, tpr: 0.18582650561702846, threshold: 0.999951958656311, 
fpr: 0.0, tpr: 0.18599543880395303, threshold: 0.9999517202377319, 
fpr: 0.0, tpr: 0.18633330517780217, threshold: 0.9999514818191528, 
fpr: 0.0, tpr: 0.18650223836472676, threshold: 0.9999511241912842, 
fpr: 0.0, tpr: 0.1868401047385759, threshold: 0.9999501705169678, 
fpr: 0.0, tpr: 0.18717797111242504, threshold: 0.9999499320983887, 
fpr: 0.0, tpr: 0.18726243770588732, threshold: 0.9999498128890991, 
fpr: 0.0, tpr: 0.18751583748627418, threshold: 0.9999496936798096, 
fpr: 0.0, tpr: 0.18768477067319875, threshold: 0.99994957447052, 
fpr: 0.0, tpr: 0.18776923726666103, threshold: 0.9999493360519409, 
fpr: 0.0, tpr: 0.1879381704535856, threshold: 0.9999490976333618, 
fpr: 0.0, tpr: 0.18802263704704789, threshold: 0.9999489784240723, 
fpr: 0.0, tpr: 0.18819157023397245, threshold: 0.9999487400054932, 
fpr: 0.0, tpr: 0.18827603682743474, threshold: 0.9999481439590454, 
fpr: 0.0, tpr: 0.1884449700143593, threshold: 0.9999476671218872, 
fpr: 0.0, tpr: 0.18878283638820847, threshold: 0.9999469518661499, 
fpr: 0.0, tpr: 0.18903623616859533, threshold: 0.9999467134475708, 
fpr: 0.0, tpr: 0.18928963594898218, threshold: 0.9999462366104126, 
fpr: 0.0, tpr: 0.18954303572936904, threshold: 0.9999459981918335, 
fpr: 0.0, tpr: 0.1897964355097559, threshold: 0.9999454021453857, 
fpr: 0.0, tpr: 0.18996536869668046, threshold: 0.9999452829360962, 
fpr: 0.0, tpr: 0.19004983529014274, threshold: 0.9999451637268066, 
fpr: 0.0, tpr: 0.1902187684770673, threshold: 0.9999450445175171, 
fpr: 0.0, tpr: 0.1903032350705296, threshold: 0.9999449253082275, 
fpr: 0.0, tpr: 0.19064110144437874, threshold: 0.9999445676803589, 
fpr: 0.0, tpr: 0.19072556803784102, threshold: 0.9999444484710693, 
fpr: 0.0, tpr: 0.19089450122476562, threshold: 0.9999443292617798, 
fpr: 0.0, tpr: 0.1909789678182279, threshold: 0.9999442100524902, 
fpr: 0.0, tpr: 0.19114790100515247, threshold: 0.999943733215332, 
fpr: 0.0, tpr: 0.19123236759861476, threshold: 0.9999436140060425, 
fpr: 0.0, tpr: 0.1914857673790016, threshold: 0.9999434947967529, 
fpr: 0.0, tpr: 0.19165470056592618, threshold: 0.9999432563781738, 
fpr: 0.0, tpr: 0.19199256693977532, threshold: 0.9999431371688843, 
fpr: 0.0, tpr: 0.19216150012669989, threshold: 0.9999430179595947, 
fpr: 0.0, tpr: 0.19224596672016217, threshold: 0.9999426603317261, 
fpr: 0.0, tpr: 0.19241489990708674, threshold: 0.9999425411224365, 
fpr: 0.0, tpr: 0.19249936650054902, threshold: 0.9999423027038574, 
fpr: 0.0, tpr: 0.19283723287439816, threshold: 0.9999418258666992, 
fpr: 0.0, tpr: 0.19317509924824733, threshold: 0.9999411106109619, 
fpr: 0.0, tpr: 0.1933440324351719, threshold: 0.9999409914016724, 
fpr: 0.0, tpr: 0.19351296562209647, threshold: 0.9999405145645142, 
fpr: 0.0, tpr: 0.19376636540248332, threshold: 0.999940037727356, 
fpr: 0.0, tpr: 0.1939352985894079, threshold: 0.9999397993087769, 
fpr: 0.0, tpr: 0.19418869836979474, threshold: 0.9999393224716187, 
fpr: 0.0, tpr: 0.1943576315567193, threshold: 0.9999387264251709, 
fpr: 0.0, tpr: 0.1944420981501816, threshold: 0.9999386072158813, 
fpr: 0.0, tpr: 0.1949488977109553, threshold: 0.9999383687973022, 
fpr: 0.0, tpr: 0.1951178308978799, threshold: 0.9999382495880127, 
fpr: 0.0, tpr: 0.19520229749134219, threshold: 0.9999381303787231, 
fpr: 0.0, tpr: 0.19537123067826676, threshold: 0.9999377727508545, 
fpr: 0.0, tpr: 0.19545569727172904, threshold: 0.9999374151229858, 
fpr: 0.0, tpr: 0.1956246304586536, threshold: 0.999936580657959, 
fpr: 0.0, tpr: 0.19604696342596503, threshold: 0.9999358654022217, 
fpr: 0.0, tpr: 0.19638482979981417, threshold: 0.9999357461929321, 
fpr: 0.0, tpr: 0.19655376298673874, threshold: 0.9999356269836426, 
fpr: 0.0, tpr: 0.19663822958020102, threshold: 0.999935507774353, 
fpr: 0.0, tpr: 0.1968071627671256, threshold: 0.9999353885650635, 
fpr: 0.0, tpr: 0.19689162936058788, threshold: 0.9999351501464844, 
fpr: 0.0, tpr: 0.19706056254751245, threshold: 0.9999349117279053, 
fpr: 0.0, tpr: 0.1974828955148239, threshold: 0.9999339580535889, 
fpr: 0.0, tpr: 0.19765182870174847, threshold: 0.9999334812164307, 
fpr: 0.0, tpr: 0.19790522848213532, threshold: 0.9999330043792725, 
fpr: 0.0, tpr: 0.1980741616690599, threshold: 0.9999328851699829, 
fpr: 0.0, tpr: 0.19815862826252217, threshold: 0.9999327659606934, 
fpr: 0.0, tpr: 0.19883436101022045, threshold: 0.9999319314956665, 
fpr: 0.0, tpr: 0.19900329419714502, threshold: 0.9999313354492188, 
fpr: 0.0, tpr: 0.19934116057099416, threshold: 0.9999310970306396, 
fpr: 0.0, tpr: 0.19942562716445647, threshold: 0.9999306201934814, 
fpr: 0.0, tpr: 0.19967902694484332, threshold: 0.9999303817749023, 
fpr: 0.0, tpr: 0.1998479601317679, threshold: 0.9999300241470337, 
fpr: 0.0, tpr: 0.20027029309907932, threshold: 0.9999288320541382, 
fpr: 0.0, tpr: 0.20043922628600389, threshold: 0.99992835521698, 
fpr: 0.0, tpr: 0.20069262606639074, threshold: 0.9999274015426636, 
fpr: 0.0, tpr: 0.2008615592533153, threshold: 0.9999271631240845, 
fpr: 0.0, tpr: 0.20119942562716445, threshold: 0.9999252557754517, 
fpr: 0.0, tpr: 0.2015372920010136, threshold: 0.9999245405197144, 
fpr: 0.0, tpr: 0.2022130247487119, threshold: 0.9999231100082397, 
fpr: 0.0, tpr: 0.20238195793563646, threshold: 0.9999226331710815, 
fpr: 0.0, tpr: 0.2026353577160233, threshold: 0.9999217987060547, 
fpr: 0.0, tpr: 0.20314215727679702, threshold: 0.9999208450317383, 
fpr: 0.0, tpr: 0.2032266238702593, threshold: 0.9999207258224487, 
fpr: 0.0, tpr: 0.2039023566179576, threshold: 0.9999194145202637, 
fpr: 0.0, tpr: 0.2039868232114199, threshold: 0.9999192953109741, 
fpr: 0.0, tpr: 0.20415575639834446, threshold: 0.9999191761016846, 
fpr: 0.0, tpr: 0.20424022299180675, threshold: 0.999919056892395, 
fpr: 0.0, tpr: 0.20440915617873132, threshold: 0.9999188184738159, 
fpr: 0.0, tpr: 0.20466255595911817, threshold: 0.9999185800552368, 
fpr: 0.0, tpr: 0.20525382211335416, threshold: 0.9999164342880249, 
fpr: 0.0, tpr: 0.20542275530027873, threshold: 0.9999159574508667, 
fpr: 0.0, tpr: 0.20567615508066558, threshold: 0.999915361404419, 
fpr: 0.0, tpr: 0.20601402145451475, threshold: 0.9999151229858398, 
fpr: 0.0, tpr: 0.2068586873891376, threshold: 0.9999122619628906, 
fpr: 0.0, tpr: 0.20702762057606217, threshold: 0.9999120235443115, 
fpr: 0.0, tpr: 0.20719655376298673, threshold: 0.9999117851257324, 
fpr: 0.0, tpr: 0.2073654869499113, threshold: 0.9999115467071533, 
fpr: 0.0, tpr: 0.207872286510685, threshold: 0.9999090433120728, 
fpr: 0.0, tpr: 0.2080412196976096, threshold: 0.9999088048934937, 
fpr: 0.0, tpr: 0.20829461947799646, threshold: 0.999907374382019, 
fpr: 0.0, tpr: 0.20854801925838332, threshold: 0.9999072551727295, 
fpr: 0.0, tpr: 0.20871695244530789, threshold: 0.9999068975448608, 
fpr: 0.0, tpr: 0.20888588563223245, threshold: 0.9999067783355713, 
fpr: 0.0, tpr: 0.20897035222569474, threshold: 0.9999059438705444, 
fpr: 0.0, tpr: 0.2091392854126193, threshold: 0.9999057054519653, 
fpr: 0.0, tpr: 0.2092237520060816, threshold: 0.9999054670333862, 
fpr: 0.0, tpr: 0.20939268519300616, threshold: 0.9999053478240967, 
fpr: 0.0, tpr: 0.20964608497339302, threshold: 0.999904990196228, 
fpr: 0.0, tpr: 0.20981501816031758, threshold: 0.9999047517776489, 
fpr: 0.0, tpr: 0.21015288453416675, threshold: 0.9999032020568848, 
fpr: 0.0, tpr: 0.21032181772109132, threshold: 0.9999029636383057, 
fpr: 0.0, tpr: 0.21065968409494046, threshold: 0.9999023675918579, 
fpr: 0.0, tpr: 0.21082861728186503, threshold: 0.9999022483825684, 
fpr: 0.0, tpr: 0.2109130838753273, threshold: 0.9999020099639893, 
fpr: 0.0, tpr: 0.21108201706225188, threshold: 0.9999018907546997, 
fpr: 0.0, tpr: 0.21116648365571417, threshold: 0.9999017715454102, 
fpr: 0.0, tpr: 0.21133541684263873, threshold: 0.9999016523361206, 
fpr: 0.0, tpr: 0.2120956161837993, threshold: 0.9998983144760132, 
fpr: 0.0, tpr: 0.21260241574457303, threshold: 0.9998979568481445, 
fpr: 0.0, tpr: 0.21344708167919588, threshold: 0.999895453453064, 
fpr: 0.0, tpr: 0.21361601486612045, threshold: 0.9998948574066162, 
fpr: 0.0, tpr: 0.21403834783343187, threshold: 0.9998924732208252, 
fpr: 0.0, tpr: 0.21420728102035644, threshold: 0.9998923540115356, 
fpr: 0.0, tpr: 0.21479854717459246, threshold: 0.999889612197876, 
fpr: 0.0, tpr: 0.2150519469549793, threshold: 0.99988853931427, 
fpr: 0.0, tpr: 0.21538981332882845, threshold: 0.9998878240585327, 
fpr: 0.0, tpr: 0.21555874651575302, threshold: 0.9998875856399536, 
fpr: 0.0, tpr: 0.2157276797026776, threshold: 0.9998871088027954, 
fpr: 0.0, tpr: 0.21640341245037586, threshold: 0.9998852014541626, 
fpr: 0.0, tpr: 0.21657234563730043, threshold: 0.9998849630355835, 
fpr: 0.0, tpr: 0.21674127882422503, threshold: 0.9998843669891357, 
fpr: 0.0, tpr: 0.2169102120111496, threshold: 0.9998838901519775, 
fpr: 0.0, tpr: 0.21707914519807417, threshold: 0.9998831748962402, 
fpr: 0.0, tpr: 0.21724807838499874, threshold: 0.9998829364776611, 
fpr: 0.0, tpr: 0.21758594475884788, threshold: 0.9998818635940552, 
fpr: 0.0, tpr: 0.21775487794577245, threshold: 0.9998817443847656, 
fpr: 0.0, tpr: 0.2192752766280936, threshold: 0.9998757839202881, 
fpr: 0.0, tpr: 0.21944420981501817, threshold: 0.9998756647109985, 
fpr: 0.0, tpr: 0.2198665427823296, threshold: 0.9998733997344971, 
fpr: 0.0, tpr: 0.22003547596925416, threshold: 0.999873161315918, 
fpr: 0.0, tpr: 0.22020440915617873, threshold: 0.9998729228973389, 
fpr: 0.0, tpr: 0.2203733423431033, threshold: 0.9998726844787598, 
fpr: 0.0, tpr: 0.22071120871695243, threshold: 0.9998717308044434, 
fpr: 0.0, tpr: 0.220880141903877, threshold: 0.9998714923858643, 
fpr: 0.0, tpr: 0.22206267421234901, threshold: 0.9998666048049927, 
fpr: 0.0, tpr: 0.2227384069600473, threshold: 0.9998657703399658, 
fpr: 0.0, tpr: 0.22324520652082103, threshold: 0.9998637437820435, 
fpr: 0.0, tpr: 0.2234141397077456, threshold: 0.9998635053634644, 
fpr: 0.0, tpr: 0.22349860630120788, threshold: 0.9998633861541748, 
fpr: 0.0, tpr: 0.22366753948813245, threshold: 0.9998632669448853, 
fpr: 0.0, tpr: 0.22425880564236844, threshold: 0.9998613595962524, 
fpr: 0.0, tpr: 0.2245122054227553, threshold: 0.9998602867126465, 
fpr: 0.0, tpr: 0.22468113860967986, threshold: 0.9998595714569092, 
fpr: 0.0, tpr: 0.22485007179660443, threshold: 0.9998584985733032, 
fpr: 0.0, tpr: 0.22586367091815188, threshold: 0.9998551607131958, 
fpr: 0.0, tpr: 0.22611707069853873, threshold: 0.9998548030853271, 
fpr: 0.0, tpr: 0.22620153729200101, threshold: 0.9998546838760376, 
fpr: 0.0, tpr: 0.22637047047892558, threshold: 0.999854326248169, 
fpr: 0.0, tpr: 0.226792803446237, threshold: 0.9998522996902466, 
fpr: 0.0, tpr: 0.22704620322662386, threshold: 0.9998519420623779, 
fpr: 0.0, tpr: 0.2275530027873976, threshold: 0.9998500347137451, 
fpr: 0.0, tpr: 0.22789086916124673, threshold: 0.999849796295166, 
fpr: 0.0, tpr: 0.2286510685024073, threshold: 0.999846339225769, 
fpr: 0.0, tpr: 0.22882000168933186, threshold: 0.9998457431793213, 
fpr: 0.0, tpr: 0.229157868063181, threshold: 0.9998446702957153, 
fpr: 0.0, tpr: 0.22932680125010557, threshold: 0.9998445510864258, 
fpr: 0.0, tpr: 0.23000253399780388, threshold: 0.9998413324356079, 
fpr: 0.0, tpr: 0.23034040037165301, threshold: 0.999840497970581, 
fpr: 0.0, tpr: 0.2304248669651153, threshold: 0.9998400211334229, 
fpr: 0.0, tpr: 0.23059380015203987, threshold: 0.9998395442962646, 
fpr: 0.0, tpr: 0.2321986654278233, threshold: 0.999832034111023, 
fpr: 0.0, tpr: 0.23236759861474787, threshold: 0.9998303651809692, 
fpr: 0.0, tpr: 0.23245206520821016, threshold: 0.9998302459716797, 
fpr: 0.0, tpr: 0.23262099839513473, threshold: 0.999829888343811, 
fpr: 0.0, tpr: 0.23321226454937072, threshold: 0.9998272061347961, 
fpr: 0.0, tpr: 0.2333811977362953, threshold: 0.9998266100883484, 
fpr: 0.0, tpr: 0.23355013092321986, threshold: 0.9998260140419006, 
fpr: 0.0, tpr: 0.2338035307036067, threshold: 0.9998254179954529, 
fpr: 0.0, tpr: 0.23464819663822958, threshold: 0.9998226761817932, 
fpr: 0.0, tpr: 0.23481712982515415, threshold: 0.9998223185539246, 
fpr: 0.0, tpr: 0.23557732916631471, threshold: 0.9998183846473694, 
fpr: 0.0, tpr: 0.23591519554016385, threshold: 0.9998171925544739, 
fpr: 0.0, tpr: 0.23616859532055073, threshold: 0.9998146891593933, 
fpr: 0.0, tpr: 0.23650646169439987, threshold: 0.9998133778572083, 
fpr: 0.0, tpr: 0.23667539488132444, threshold: 0.99981290102005, 
fpr: 0.0, tpr: 0.236844328068249, threshold: 0.9998123049736023, 
fpr: 0.0, tpr: 0.2369287946617113, threshold: 0.9998120665550232, 
fpr: 0.0, tpr: 0.23726666103556043, threshold: 0.9998099207878113, 
fpr: 0.0, tpr: 0.23768899400287186, threshold: 0.999808132648468, 
fpr: 0.0, tpr: 0.2379423937832587, threshold: 0.9998080134391785, 
fpr: 0.0, tpr: 0.238026860376721, threshold: 0.9998075366020203, 
fpr: 0.0, tpr: 0.2381957935636456, threshold: 0.9998074173927307, 
fpr: 0.0, tpr: 0.23904045949826844, threshold: 0.999800980091095, 
fpr: 0.0, tpr: 0.239209392685193, threshold: 0.9998006224632263, 
fpr: 0.0, tpr: 0.23946279246557986, threshold: 0.9997979998588562, 
fpr: 0.0, tpr: 0.23963172565250443, threshold: 0.9997969269752502, 
fpr: 0.0, tpr: 0.239800658839429, threshold: 0.9997960925102234, 
fpr: 0.0, tpr: 0.23996959202635357, threshold: 0.9997949004173279, 
fpr: 0.0, tpr: 0.24039192499366502, threshold: 0.999792754650116, 
fpr: 0.0, tpr: 0.2405608581805896, threshold: 0.9997926354408264, 
fpr: 0.0, tpr: 0.240983191147901, threshold: 0.9997907280921936, 
fpr: 0.0, tpr: 0.24115212433482558, threshold: 0.9997895359992981, 
fpr: 0.0, tpr: 0.2416589238955993, threshold: 0.9997870326042175, 
fpr: 0.0, tpr: 0.24199679026944843, threshold: 0.9997860789299011, 
fpr: 0.0, tpr: 0.24225019004983528, threshold: 0.9997853636741638, 
fpr: 0.0, tpr: 0.24241912323675985, threshold: 0.9997850060462952, 
fpr: 0.0, tpr: 0.24275698961060901, threshold: 0.9997840523719788, 
fpr: 0.0, tpr: 0.24292592279753358, threshold: 0.9997836947441101, 
fpr: 0.0, tpr: 0.24309485598445815, threshold: 0.9997828602790833, 
fpr: 0.0, tpr: 0.24326378917138272, threshold: 0.9997826218605042, 
fpr: 0.0, tpr: 0.24545992060140215, threshold: 0.9997679591178894, 
fpr: 0.0, tpr: 0.24562885378832672, threshold: 0.9997667670249939, 
fpr: 0.0, tpr: 0.2457977869752513, threshold: 0.9997656941413879, 
fpr: 0.0, tpr: 0.24596672016217586, threshold: 0.9997655749320984, 
fpr: 0.0, tpr: 0.24638905312948728, threshold: 0.9997637867927551, 
fpr: 0.0, tpr: 0.24655798631641185, threshold: 0.9997634291648865, 
fpr: 0.0, tpr: 0.2469803192837233, threshold: 0.9997619986534119, 
fpr: 0.0, tpr: 0.24714925247064787, threshold: 0.9997615218162537, 
fpr: 0.0, tpr: 0.2475715854379593, threshold: 0.9997596144676208, 
fpr: 0.0, tpr: 0.24774051862488386, threshold: 0.9997592568397522, 
fpr: 0.0, tpr: 0.24816285159219528, threshold: 0.9997559189796448, 
fpr: 0.0, tpr: 0.24833178477911985, threshold: 0.9997555613517761, 
fpr: 0.0, tpr: 0.24841625137258214, threshold: 0.999755322933197, 
fpr: 0.0, tpr: 0.2485851845595067, threshold: 0.9997548460960388, 
fpr: 0.0, tpr: 0.24917645071374273, threshold: 0.9997515082359314, 
fpr: 0.0, tpr: 0.24951431708759186, threshold: 0.9997511506080627, 
fpr: 0.0, tpr: 0.24959878368105415, threshold: 0.9997503161430359, 
fpr: 0.0, tpr: 0.24976771686797872, threshold: 0.9997497200965881, 
fpr: 0.0, tpr: 0.249852183461441, threshold: 0.9997493624687195, 
fpr: 0.0, tpr: 0.25002111664836557, threshold: 0.9997488856315613, 
fpr: 0.0, tpr: 0.25111918236337527, threshold: 0.9997420907020569, 
fpr: 0.0, tpr: 0.25128811555029984, threshold: 0.9997416138648987, 
fpr: 0.0, tpr: 0.2514570487372244, threshold: 0.9997404217720032, 
fpr: 0.0, tpr: 0.251625981924149, threshold: 0.9997401833534241, 
fpr: 0.0, tpr: 0.25263958104569645, threshold: 0.999729573726654, 
fpr: 0.0, tpr: 0.252808514232621, threshold: 0.9997277855873108, 
fpr: 0.0, tpr: 0.25314638060647016, threshold: 0.9997263550758362, 
fpr: 0.0, tpr: 0.2533153137933947, threshold: 0.9997250437736511, 
fpr: 0.0, tpr: 0.25382211335416843, threshold: 0.9997221827507019, 
fpr: 0.0, tpr: 0.253991046541093, threshold: 0.9997217059135437, 
fpr: 0.0, tpr: 0.2555959118168764, threshold: 0.9997093081474304, 
fpr: 0.0, tpr: 0.255764845003801, threshold: 0.9997090697288513, 
fpr: 0.0, tpr: 0.257538643466509, threshold: 0.9996991157531738, 
fpr: 0.0, tpr: 0.2577075766534336, threshold: 0.9996989965438843, 
fpr: 0.0, tpr: 0.2585522425880564, threshold: 0.9996956586837769, 
fpr: 0.0, tpr: 0.258721175774981, threshold: 0.9996953010559082, 
fpr: 0.0, tpr: 0.2592279753357547, threshold: 0.9996929168701172, 
fpr: 0.0, tpr: 0.25939690852267927, threshold: 0.9996927976608276, 
fpr: 0.0, tpr: 0.25998817467691526, threshold: 0.9996882677078247, 
fpr: 0.0, tpr: 0.26015710786383983, threshold: 0.9996880292892456, 
fpr: 0.0, tpr: 0.2611707069853873, threshold: 0.9996808767318726, 
fpr: 0.0, tpr: 0.26142410676577416, threshold: 0.9996802806854248, 
fpr: 0.0, tpr: 0.2615930399526987, threshold: 0.9996784925460815, 
fpr: 0.0, tpr: 0.2617619731396233, threshold: 0.9996769428253174, 
fpr: 0.0, tpr: 0.2650561702846524, threshold: 0.999650239944458, 
fpr: 0.0, tpr: 0.265225103471577, threshold: 0.9996490478515625, 
fpr: 0.0, tpr: 0.26606976940619986, threshold: 0.9996423721313477, 
fpr: 0.0, tpr: 0.26623870259312443, threshold: 0.999642014503479, 
fpr: 0.0, tpr: 0.2664921023735113, threshold: 0.9996402263641357, 
fpr: 0.0, tpr: 0.26666103556043586, threshold: 0.9996392726898193, 
fpr: 0.0, tpr: 0.26733676830813413, threshold: 0.9996341466903687, 
fpr: 0.0, tpr: 0.2675057014950587, threshold: 0.9996340274810791, 
fpr: 0.0, tpr: 0.26936396655122896, threshold: 0.9996067881584167, 
fpr: 0.0, tpr: 0.2695328997381536, threshold: 0.9996064305305481, 
fpr: 0.0, tpr: 0.26961736633161587, threshold: 0.9996055960655212, 
fpr: 0.0, tpr: 0.26978629951854044, threshold: 0.9996035695075989, 
fpr: 0.0, tpr: 0.270546498859701, threshold: 0.9995906949043274, 
fpr: 0.0, tpr: 0.27071543204662557, threshold: 0.9995899796485901, 
fpr: 0.0, tpr: 0.27147563138778613, threshold: 0.9995853304862976, 
fpr: 0.0, tpr: 0.2716445645747107, threshold: 0.9995840191841125, 
fpr: 0.0, tpr: 0.27198243094855984, threshold: 0.999581515789032, 
fpr: 0.0, tpr: 0.272320297322409, threshold: 0.9995806813240051, 
fpr: 0.0, tpr: 0.2731649632570318, threshold: 0.9995735287666321, 
fpr: 0.0, tpr: 0.2733338964439564, threshold: 0.9995717406272888, 
fpr: 0.0, tpr: 0.27493876171973985, threshold: 0.9995580315589905, 
fpr: 0.0, tpr: 0.2751076949066644, threshold: 0.9995560050010681, 
fpr: 0.0, tpr: 0.27544556128051356, threshold: 0.9995532631874084, 
fpr: 0.0, tpr: 0.27561449446743813, threshold: 0.9995511174201965, 
fpr: 0.0, tpr: 0.2756989610609004, threshold: 0.9995495676994324, 
fpr: 0.0, tpr: 0.275867894247825, threshold: 0.9995488524436951, 
fpr: 0.0, tpr: 0.27721935974322154, threshold: 0.9995349645614624, 
fpr: 0.0, tpr: 0.2773882929301461, threshold: 0.9995348453521729, 
fpr: 0.0, tpr: 0.2779795590843821, threshold: 0.9995293617248535, 
fpr: 0.0, tpr: 0.2781484922713067, threshold: 0.9995291233062744, 
fpr: 0.0, tpr: 0.2784018920516936, threshold: 0.9995260238647461, 
fpr: 0.0, tpr: 0.27857082523861815, threshold: 0.9995255470275879, 
fpr: 0.0, tpr: 0.2793310245797787, threshold: 0.9995124340057373, 
fpr: 0.0, tpr: 0.2794999577667033, threshold: 0.9995115995407104, 
fpr: 0.0, tpr: 0.2798378241405524, threshold: 0.9995088577270508, 
fpr: 0.00023917723032767282, tpr: 0.2798378241405524, threshold: 0.9995085000991821, 
fpr: 0.00023917723032767282, tpr: 0.2799222907340147, threshold: 0.9995081424713135, 
fpr: 0.00023917723032767282, tpr: 0.28009122392093927, threshold: 0.9995080232620239, 
fpr: 0.00023917723032767282, tpr: 0.2822028887574964, threshold: 0.9994888305664062, 
fpr: 0.00023917723032767282, tpr: 0.282371821944421, threshold: 0.9994884729385376, 
fpr: 0.00023917723032767282, tpr: 0.2828786215051947, threshold: 0.9994825124740601, 
fpr: 0.00023917723032767282, tpr: 0.2830475546921193, threshold: 0.9994823932647705, 
fpr: 0.00023917723032767282, tpr: 0.283554354252893, threshold: 0.999476969242096, 
fpr: 0.00023917723032767282, tpr: 0.28372328743981756, threshold: 0.9994767308235168, 
fpr: 0.00023917723032767282, tpr: 0.28549708590252554, threshold: 0.999459445476532, 
fpr: 0.00023917723032767282, tpr: 0.2856660190894501, threshold: 0.9994588494300842, 
fpr: 0.00023917723032767282, tpr: 0.2858349522763747, threshold: 0.9994582533836365, 
fpr: 0.00023917723032767282, tpr: 0.28600388546329925, threshold: 0.999457061290741, 
fpr: 0.00023917723032767282, tpr: 0.2863417518371484, threshold: 0.99945467710495, 
fpr: 0.00023917723032767282, tpr: 0.28651068502407295, threshold: 0.9994527697563171, 
fpr: 0.00023917723032767282, tpr: 0.28676408480445986, threshold: 0.9994509816169739, 
fpr: 0.00023917723032767282, tpr: 0.28693301799138443, threshold: 0.9994493126869202, 
fpr: 0.00023917723032767282, tpr: 0.28946701579525297, threshold: 0.999416708946228, 
fpr: 0.00023917723032767282, tpr: 0.28963594898217754, threshold: 0.9994164705276489, 
fpr: 0.00023917723032767282, tpr: 0.2898048821691021, threshold: 0.9994150400161743, 
fpr: 0.00023917723032767282, tpr: 0.2899738153560267, threshold: 0.9994144439697266, 
fpr: 0.00023917723032767282, tpr: 0.29005828194948896, threshold: 0.9994128942489624, 
fpr: 0.00023917723032767282, tpr: 0.29022721513641353, threshold: 0.9994122982025146, 
fpr: 0.00023917723032767282, tpr: 0.29470394458991467, threshold: 0.9993597865104675, 
fpr: 0.00023917723032767282, tpr: 0.29487287777683924, threshold: 0.9993588328361511, 
fpr: 0.00023917723032767282, tpr: 0.2976602753610947, threshold: 0.9993226528167725, 
fpr: 0.00023917723032767282, tpr: 0.29782920854801925, threshold: 0.9993222951889038, 
fpr: 0.00023917723032767282, tpr: 0.29791367514148154, threshold: 0.9993207454681396, 
fpr: 0.00023917723032767282, tpr: 0.2980826083284061, threshold: 0.9993197917938232, 
fpr: 0.00023917723032767282, tpr: 0.3022214714080581, threshold: 0.9992683529853821, 
fpr: 0.00023917723032767282, tpr: 0.3023904045949827, threshold: 0.9992677569389343, 
fpr: 0.00023917723032767282, tpr: 0.30298167074921867, threshold: 0.9992572665214539, 
fpr: 0.00023917723032767282, tpr: 0.30315060393614324, threshold: 0.9992571473121643, 
fpr: 0.00023917723032767282, tpr: 0.30399526987076614, threshold: 0.9992426633834839, 
fpr: 0.00023917723032767282, tpr: 0.3041642030576907, threshold: 0.9992419481277466, 
fpr: 0.00023917723032767282, tpr: 0.3051778021792381, threshold: 0.9992222785949707, 
fpr: 0.00023917723032767282, tpr: 0.3053467353661627, threshold: 0.9992218017578125, 
fpr: 0.00023917723032767282, tpr: 0.3057690683334741, threshold: 0.9992189407348633, 
fpr: 0.00023917723032767282, tpr: 0.3059380015203987, threshold: 0.9992183446884155, 
fpr: 0.00023917723032767282, tpr: 0.30720500042233295, threshold: 0.9992031455039978, 
fpr: 0.00023917723032767282, tpr: 0.3073739336092575, threshold: 0.99920254945755, 
fpr: 0.00023917723032767282, tpr: 0.3075428667961821, threshold: 0.9992019534111023, 
fpr: 0.00023917723032767282, tpr: 0.30771179998310666, threshold: 0.9992009997367859, 
fpr: 0.00023917723032767282, tpr: 0.3082185995438804, threshold: 0.9991959929466248, 
fpr: 0.00023917723032767282, tpr: 0.308387532730805, threshold: 0.9991932511329651, 
fpr: 0.00023917723032767282, tpr: 0.31024579778697525, threshold: 0.9991660118103027, 
fpr: 0.00023917723032767282, tpr: 0.3104147309738998, threshold: 0.9991655349731445, 
fpr: 0.00023917723032767282, tpr: 0.3129487287777684, threshold: 0.9991399049758911, 
fpr: 0.00023917723032767282, tpr: 0.313117661964693, threshold: 0.9991340041160583, 
fpr: 0.00023917723032767282, tpr: 0.31328659515161755, threshold: 0.9991325736045837, 
fpr: 0.00023917723032767282, tpr: 0.3134555283385421, threshold: 0.999131977558136, 
fpr: 0.00023917723032767282, tpr: 0.3177633246051187, threshold: 0.9990481734275818, 
fpr: 0.00023917723032767282, tpr: 0.31793225779204326, threshold: 0.9990468621253967, 
fpr: 0.00023917723032767282, tpr: 0.3183545907593547, threshold: 0.999038815498352, 
fpr: 0.00023917723032767282, tpr: 0.31852352394627925, threshold: 0.9990377426147461, 
fpr: 0.00023917723032767282, tpr: 0.3203817890024495, threshold: 0.9990191459655762, 
fpr: 0.00023917723032767282, tpr: 0.3205507221893741, threshold: 0.9990171194076538, 
fpr: 0.00023917723032767282, tpr: 0.32063518878283637, threshold: 0.9990129470825195, 
fpr: 0.00023917723032767282, tpr: 0.32080412196976094, threshold: 0.9990127086639404, 
fpr: 0.00023917723032767282, tpr: 0.32114198834361013, threshold: 0.9990056157112122, 
fpr: 0.00023917723032767282, tpr: 0.3213109215305347, threshold: 0.9990041851997375, 
fpr: 0.00023917723032767282, tpr: 0.3230847199932427, threshold: 0.9989663362503052, 
fpr: 0.00023917723032767282, tpr: 0.3234225863670918, threshold: 0.9989657402038574, 
fpr: 0.00023917723032767282, tpr: 0.32789931582059295, threshold: 0.9988985061645508, 
fpr: 0.00023917723032767282, tpr: 0.3280682490075175, threshold: 0.9988976716995239, 
fpr: 0.00023917723032767282, tpr: 0.3306867134048484, threshold: 0.9988443851470947, 
fpr: 0.00023917723032767282, tpr: 0.33085564659177297, threshold: 0.9988430738449097, 
fpr: 0.00023917723032767282, tpr: 0.3312779795590844, threshold: 0.9988366961479187, 
fpr: 0.00023917723032767282, tpr: 0.33144691274600896, threshold: 0.9988343119621277, 
fpr: 0.00023917723032767282, tpr: 0.33465664329757583, threshold: 0.9987753033638, 
fpr: 0.00023917723032767282, tpr: 0.3348255764845004, threshold: 0.9987749457359314, 
fpr: 0.00023917723032767282, tpr: 0.3358391756060478, threshold: 0.9987552165985107, 
fpr: 0.00023917723032767282, tpr: 0.3360081087929724, threshold: 0.9987537860870361, 
fpr: 0.00023917723032767282, tpr: 0.33786637384914264, threshold: 0.9987149238586426, 
fpr: 0.00023917723032767282, tpr: 0.3380353070360672, threshold: 0.998713493347168, 
fpr: 0.00023917723032767282, tpr: 0.3476644986907678, threshold: 0.9984904527664185, 
fpr: 0.00023917723032767282, tpr: 0.3478334318776924, threshold: 0.9984879493713379, 
fpr: 0.00023917723032767282, tpr: 0.3572936903454684, threshold: 0.9982321858406067, 
fpr: 0.00023917723032767282, tpr: 0.35746262353239294, threshold: 0.9982267022132874, 
fpr: 0.00023917723032767282, tpr: 0.35999662133626154, threshold: 0.9981415271759033, 
fpr: 0.00023917723032767282, tpr: 0.3601655545231861, threshold: 0.9981397390365601, 
fpr: 0.00023917723032767282, tpr: 0.3605878874904975, threshold: 0.9981352090835571, 
fpr: 0.00023917723032767282, tpr: 0.3607568206774221, threshold: 0.9981241822242737, 
fpr: 0.00023917723032767282, tpr: 0.3618548863924318, threshold: 0.9980996251106262, 
fpr: 0.00023917723032767282, tpr: 0.36202381957935637, threshold: 0.9980974793434143, 
fpr: 0.00023917723032767282, tpr: 0.36421995100937576, threshold: 0.9980364441871643, 
fpr: 0.00023917723032767282, tpr: 0.3643888841963004, threshold: 0.9980352520942688, 
fpr: 0.00023917723032767282, tpr: 0.3710617450798209, threshold: 0.9977720379829407, 
fpr: 0.00023917723032767282, tpr: 0.3712306782667455, threshold: 0.9977713823318481, 
fpr: 0.00023917723032767282, tpr: 0.3724132105752175, threshold: 0.9977173805236816, 
fpr: 0.00023917723032767282, tpr: 0.37258214376214205, threshold: 0.9977152347564697, 
fpr: 0.00023917723032767282, tpr: 0.3736802094771518, threshold: 0.9976775050163269, 
fpr: 0.00023917723032767282, tpr: 0.3738491426640764, threshold: 0.9976759552955627, 
fpr: 0.00023917723032767282, tpr: 0.37452487541177465, threshold: 0.9976581335067749, 
fpr: 0.00023917723032767282, tpr: 0.3746938085986992, threshold: 0.9976574182510376, 
fpr: 0.00023917723032767282, tpr: 0.3747782751921615, threshold: 0.997651994228363, 
fpr: 0.00023917723032767282, tpr: 0.37494720837908607, threshold: 0.9976516366004944, 
fpr: 0.00023917723032767282, tpr: 0.37857927189796436, threshold: 0.9975294470787048, 
fpr: 0.00023917723032767282, tpr: 0.37874820508488893, threshold: 0.997528612613678, 
fpr: 0.00023917723032767282, tpr: 0.38863079651997634, threshold: 0.9971315860748291, 
fpr: 0.00023917723032767282, tpr: 0.3887997297069009, threshold: 0.9971293807029724, 
fpr: 0.00023917723032767282, tpr: 0.3907424613565335, threshold: 0.9970243573188782, 
fpr: 0.00023917723032767282, tpr: 0.3909113945434581, threshold: 0.9970236420631409, 
fpr: 0.00023917723032767282, tpr: 0.3913337275107695, threshold: 0.9970018267631531, 
fpr: 0.00023917723032767282, tpr: 0.39150266069769407, threshold: 0.9970002770423889, 
fpr: 0.00023917723032767282, tpr: 0.40214545147394204, threshold: 0.9964610934257507, 
fpr: 0.00023917723032767282, tpr: 0.4023143846608666, threshold: 0.9964487552642822, 
fpr: 0.00023917723032767282, tpr: 0.4112678435678689, threshold: 0.9960134029388428, 
fpr: 0.00023917723032767282, tpr: 0.41143677675479345, threshold: 0.9960120916366577, 
fpr: 0.00023917723032767282, tpr: 0.42697862995185404, threshold: 0.9950931072235107, 
fpr: 0.00023917723032767282, tpr: 0.4271475631387786, threshold: 0.9950768351554871, 
fpr: 0.00023917723032767282, tpr: 0.43162429259227975, threshold: 0.994672954082489, 
fpr: 0.00023917723032767282, tpr: 0.4317932257792043, threshold: 0.9946632385253906, 
fpr: 0.00023917723032767282, tpr: 0.43779035391502663, threshold: 0.9941547513008118, 
fpr: 0.00023917723032767282, tpr: 0.4379592871019512, threshold: 0.9941532015800476, 
fpr: 0.00023917723032767282, tpr: 0.4448010811723963, threshold: 0.993645191192627, 
fpr: 0.00047835446065534564, tpr: 0.4448010811723963, threshold: 0.9936323761940002, 
fpr: 0.00047835446065534564, tpr: 0.46211673283216487, threshold: 0.9919155240058899, 
fpr: 0.00047835446065534564, tpr: 0.46228566601908944, threshold: 0.9919074773788452, 
fpr: 0.00047835446065534564, tpr: 0.4679449277810626, threshold: 0.9912500381469727, 
fpr: 0.00047835446065534564, tpr: 0.4681138609679872, threshold: 0.9912421703338623, 
fpr: 0.00047835446065534564, tpr: 0.4744488554776586, threshold: 0.9904464483261108, 
fpr: 0.00047835446065534564, tpr: 0.47461778866458315, threshold: 0.9904422163963318, 
fpr: 0.00047835446065534564, tpr: 0.4822197820761889, threshold: 0.9893864393234253, 
fpr: 0.0007175316909830184, tpr: 0.4822197820761889, threshold: 0.9893833994865417, 
fpr: 0.0007175316909830184, tpr: 0.4930315060393614, threshold: 0.9877310395240784, 
fpr: 0.0007175316909830184, tpr: 0.493200439226286, threshold: 0.9877287149429321, 
fpr: 0.0007175316909830184, tpr: 0.4954810372497677, threshold: 0.9874051213264465, 
fpr: 0.0007175316909830184, tpr: 0.4956499704366923, threshold: 0.9873952865600586, 
fpr: 0.0007175316909830184, tpr: 0.517442351549962, threshold: 0.9829416871070862, 
fpr: 0.0007175316909830184, tpr: 0.5176112847368866, threshold: 0.9829278588294983, 
fpr: 0.0007175316909830184, tpr: 0.5942224850071797, threshold: 0.9524129033088684, 
fpr: 0.0007175316909830184, tpr: 0.5943914181941042, threshold: 0.9523231387138367, 
fpr: 0.0007175316909830184, tpr: 0.6089196722696174, threshold: 0.9431297183036804, 
fpr: 0.0009567089213106913, tpr: 0.6089196722696174, threshold: 0.9430645108222961, 
fpr: 0.0009567089213106913, tpr: 0.6112002702930991, threshold: 0.941534161567688, 
fpr: 0.001195886151638364, tpr: 0.6112002702930991, threshold: 0.9415218830108643, 
fpr: 0.001195886151638364, tpr: 0.6122983360081088, threshold: 0.940685510635376, 
fpr: 0.001195886151638364, tpr: 0.6124672691950334, threshold: 0.9406578540802002, 
fpr: 0.001195886151638364, tpr: 0.6152546667792888, threshold: 0.9386249780654907, 
fpr: 0.001195886151638364, tpr: 0.6154235999662133, threshold: 0.9386154413223267, 
fpr: 0.001195886151638364, tpr: 0.6194779964524031, threshold: 0.9352520704269409, 
fpr: 0.0014350633819660368, tpr: 0.6194779964524031, threshold: 0.9352090358734131, 
fpr: 0.0014350633819660368, tpr: 0.6261508573359237, threshold: 0.9291287064552307, 
fpr: 0.0016742406122937097, tpr: 0.6261508573359237, threshold: 0.9289942383766174, 
fpr: 0.0016742406122937097, tpr: 0.6350198496494637, threshold: 0.9214112162590027, 
fpr: 0.0019134178426213825, tpr: 0.6350198496494637, threshold: 0.9213100075721741, 
fpr: 0.0019134178426213825, tpr: 0.6432131092153054, threshold: 0.9137587547302246, 
fpr: 0.0021525950729490554, tpr: 0.6432131092153054, threshold: 0.9134456515312195, 
fpr: 0.0021525950729490554, tpr: 0.6462539065799476, threshold: 0.9094600081443787, 
fpr: 0.002391772303276728, tpr: 0.6462539065799476, threshold: 0.9092371463775635, 
fpr: 0.002391772303276728, tpr: 0.647858771855731, threshold: 0.9073914289474487, 
fpr: 0.002391772303276728, tpr: 0.6480277050426556, threshold: 0.9072774052619934, 
fpr: 0.002391772303276728, tpr: 0.6631472252724048, threshold: 0.887610137462616, 
fpr: 0.0026309495336044007, tpr: 0.6631472252724048, threshold: 0.8875515460968018, 
fpr: 0.0026309495336044007, tpr: 0.6735366162682659, threshold: 0.8707890510559082, 
fpr: 0.0028701267639320736, tpr: 0.6735366162682659, threshold: 0.8706945180892944, 
fpr: 0.0028701267639320736, tpr: 0.6816454092406453, threshold: 0.859639585018158, 
fpr: 0.0031093039942597465, tpr: 0.6816454092406453, threshold: 0.859326183795929, 
fpr: 0.0031093039942597465, tpr: 0.6847706731987498, threshold: 0.8539786338806152, 
fpr: 0.0033484812245874193, tpr: 0.6847706731987498, threshold: 0.8537852168083191, 
fpr: 0.0033484812245874193, tpr: 0.6883182701241659, threshold: 0.8467268943786621, 
fpr: 0.0035876584549150922, tpr: 0.6883182701241659, threshold: 0.8465834856033325, 
fpr: 0.0035876584549150922, tpr: 0.6987921277134893, threshold: 0.8248447179794312, 
fpr: 0.003826835685242765, tpr: 0.6987921277134893, threshold: 0.824796199798584, 
fpr: 0.003826835685242765, tpr: 0.7136582481628516, threshold: 0.7895352840423584, 
fpr: 0.004066012915570438, tpr: 0.7136582481628516, threshold: 0.788957953453064, 
fpr: 0.004066012915570438, tpr: 0.7189796435509755, threshold: 0.7746384143829346, 
fpr: 0.004305190145898111, tpr: 0.7189796435509755, threshold: 0.7745147347450256, 
fpr: 0.004305190145898111, tpr: 0.7258214376214207, threshold: 0.7540601491928101, 
fpr: 0.004544367376225784, tpr: 0.7258214376214207, threshold: 0.7540518641471863, 
fpr: 0.004544367376225784, tpr: 0.7303826336683842, threshold: 0.7413352131843567, 
fpr: 0.004783544606553456, tpr: 0.7303826336683842, threshold: 0.74025958776474, 
fpr: 0.004783544606553456, tpr: 0.7327476982853282, threshold: 0.7340076565742493, 
fpr: 0.005022721836881129, tpr: 0.7327476982853282, threshold: 0.733778178691864, 
fpr: 0.005022721836881129, tpr: 0.7449953543373595, threshold: 0.6918724179267883, 
fpr: 0.0052618990672088015, tpr: 0.7449953543373595, threshold: 0.6917458176612854, 
fpr: 0.0052618990672088015, tpr: 0.7494720837908607, threshold: 0.677352249622345, 
fpr: 0.005501076297536474, tpr: 0.7494720837908607, threshold: 0.6763662099838257, 
fpr: 0.005501076297536474, tpr: 0.7549624123659093, threshold: 0.6594694256782532, 
fpr: 0.005740253527864147, tpr: 0.7549624123659093, threshold: 0.659235954284668, 
fpr: 0.005740253527864147, tpr: 0.7563138778613059, threshold: 0.6534338593482971, 
fpr: 0.00597943075819182, tpr: 0.7563138778613059, threshold: 0.6523820161819458, 
fpr: 0.00597943075819182, tpr: 0.7576653433567024, threshold: 0.646210789680481, 
fpr: 0.006218607988519493, tpr: 0.7576653433567024, threshold: 0.6461232900619507, 
fpr: 0.006218607988519493, tpr: 0.7746431286426219, threshold: 0.5768746733665466, 
fpr: 0.006457785218847166, tpr: 0.7746431286426219, threshold: 0.576633870601654, 
fpr: 0.006457785218847166, tpr: 0.7806402567784442, threshold: 0.551893413066864, 
fpr: 0.006696962449174839, tpr: 0.7806402567784442, threshold: 0.5518672466278076, 
fpr: 0.006696962449174839, tpr: 0.7841033871103978, threshold: 0.5331085324287415, 
fpr: 0.006936139679502512, tpr: 0.7841033871103978, threshold: 0.533025860786438, 
fpr: 0.006936139679502512, tpr: 0.7842723202973224, threshold: 0.5325719118118286, 
fpr: 0.0071753169098301844, tpr: 0.7842723202973224, threshold: 0.5325695276260376, 
fpr: 0.0071753169098301844, tpr: 0.7887490497508235, threshold: 0.5134063363075256, 
fpr: 0.007414494140157857, tpr: 0.7887490497508235, threshold: 0.513328492641449, 
fpr: 0.007414494140157857, tpr: 0.8009122392093927, threshold: 0.4533902704715729, 
fpr: 0.00765367137048553, tpr: 0.8009122392093927, threshold: 0.45221567153930664, 
fpr: 0.00765367137048553, tpr: 0.8097812315229327, threshold: 0.4086576998233795, 
fpr: 0.007892848600813202, tpr: 0.8097812315229327, threshold: 0.40705209970474243, 
fpr: 0.007892848600813202, tpr: 0.8113860967987161, threshold: 0.4011595845222473, 
fpr: 0.008132025831140876, tpr: 0.8113860967987161, threshold: 0.401021271944046, 
fpr: 0.008132025831140876, tpr: 0.811639496579103, threshold: 0.40027323365211487, 
fpr: 0.008371203061468548, tpr: 0.811639496579103, threshold: 0.40018564462661743, 
fpr: 0.008371203061468548, tpr: 0.8117239631725652, threshold: 0.39904749393463135, 
fpr: 0.008610380291796222, tpr: 0.8117239631725652, threshold: 0.3990391790866852, 
fpr: 0.008610380291796222, tpr: 0.8160317594391419, threshold: 0.3785346746444702, 
fpr: 0.008849557522123894, tpr: 0.8160317594391419, threshold: 0.37851080298423767, 
fpr: 0.008849557522123894, tpr: 0.8192414899907087, threshold: 0.36853232979774475, 
fpr: 0.009088734752451567, tpr: 0.8192414899907087, threshold: 0.36723649501800537, 
fpr: 0.009088734752451567, tpr: 0.8228735535095869, threshold: 0.35170862078666687, 
fpr: 0.00932791198277924, tpr: 0.8228735535095869, threshold: 0.35169270634651184, 
fpr: 0.00932791198277924, tpr: 0.8231269532899738, threshold: 0.3509868383407593, 
fpr: 0.009567089213106911, tpr: 0.8231269532899738, threshold: 0.35056376457214355, 
fpr: 0.009567089213106911, tpr: 0.8255764845003801, threshold: 0.3408939838409424, 
fpr: 0.009806266443434585, tpr: 0.8255764845003801, threshold: 0.34086230397224426, 
fpr: 0.009806266443434585, tpr: 0.8276881493369372, threshold: 0.33360451459884644, 
fpr: 0.010045443673762257, tpr: 0.8276881493369372, threshold: 0.33355993032455444, 
fpr: 0.010045443673762257, tpr: 0.8372328743981755, threshold: 0.29499948024749756, 
fpr: 0.010284620904089931, tpr: 0.8372328743981755, threshold: 0.29482439160346985, 
fpr: 0.010284620904089931, tpr: 0.8390066728608835, threshold: 0.28767821192741394, 
fpr: 0.010523798134417603, tpr: 0.8390066728608835, threshold: 0.28745582699775696, 
fpr: 0.010523798134417603, tpr: 0.8395979390151195, threshold: 0.2864654064178467, 
fpr: 0.010762975364745277, tpr: 0.8395979390151195, threshold: 0.28645285964012146, 
fpr: 0.010762975364745277, tpr: 0.8404426049497423, threshold: 0.2814769148826599, 
fpr: 0.011002152595072949, tpr: 0.8404426049497423, threshold: 0.28147104382514954, 
fpr: 0.011002152595072949, tpr: 0.8413717374778276, threshold: 0.2773463726043701, 
fpr: 0.011241329825400622, tpr: 0.8413717374778276, threshold: 0.2770199775695801, 
fpr: 0.011241329825400622, tpr: 0.8433989357209224, threshold: 0.26987770199775696, 
fpr: 0.011480507055728294, tpr: 0.8433989357209224, threshold: 0.26956814527511597, 
fpr: 0.011480507055728294, tpr: 0.8436523355013092, threshold: 0.26765507459640503, 
fpr: 0.011719684286055968, tpr: 0.8436523355013092, threshold: 0.2669453024864197, 
fpr: 0.011719684286055968, tpr: 0.8442436016555452, threshold: 0.2637042999267578, 
fpr: 0.01195886151638364, tpr: 0.8442436016555452, threshold: 0.26355859637260437, 
fpr: 0.01195886151638364, tpr: 0.8449193344032435, threshold: 0.26273778080940247, 
fpr: 0.012198038746711314, tpr: 0.8449193344032435, threshold: 0.26251813769340515, 
fpr: 0.012198038746711314, tpr: 0.8470309992398006, threshold: 0.2558571994304657, 
fpr: 0.012437215977038986, tpr: 0.8470309992398006, threshold: 0.255826860666275, 
fpr: 0.012437215977038986, tpr: 0.851254328912915, threshold: 0.2442270815372467, 
fpr: 0.012676393207366658, tpr: 0.851254328912915, threshold: 0.243607759475708, 
fpr: 0.012676393207366658, tpr: 0.8525213278148492, threshold: 0.23813413083553314, 
fpr: 0.012915570437694332, tpr: 0.8525213278148492, threshold: 0.2379949986934662, 
fpr: 0.012915570437694332, tpr: 0.8532815271560098, threshold: 0.23544402420520782, 
fpr: 0.013154747668022004, tpr: 0.8532815271560098, threshold: 0.23544056713581085, 
fpr: 0.013154747668022004, tpr: 0.8621505194695498, threshold: 0.20827902853488922, 
fpr: 0.013393924898349677, tpr: 0.8621505194695498, threshold: 0.20800115168094635, 
fpr: 0.013393924898349677, tpr: 0.8628262522172481, threshold: 0.2052852064371109, 
fpr: 0.01363310212867735, tpr: 0.8628262522172481, threshold: 0.20502051711082458, 
fpr: 0.01363310212867735, tpr: 0.8658670495818903, threshold: 0.19267773628234863, 
fpr: 0.013872279359005023, tpr: 0.8658670495818903, threshold: 0.1914403885602951, 
fpr: 0.013872279359005023, tpr: 0.8683165807922967, threshold: 0.18314909934997559, 
fpr: 0.014111456589332695, tpr: 0.8683165807922967, threshold: 0.18269413709640503, 
fpr: 0.014111456589332695, tpr: 0.8691612467269195, threshold: 0.17995092272758484, 
fpr: 0.014350633819660369, tpr: 0.8691612467269195, threshold: 0.17968317866325378, 
fpr: 0.014350633819660369, tpr: 0.8702593124419292, threshold: 0.1773921549320221, 
fpr: 0.014589811049988041, tpr: 0.8702593124419292, threshold: 0.1772676408290863, 
fpr: 0.014589811049988041, tpr: 0.8748205084888926, threshold: 0.1624305099248886, 
fpr: 0.014589811049988041, tpr: 0.8754117746431287, threshold: 0.16219092905521393, 
fpr: 0.014589811049988041, tpr: 0.8759185742039024, threshold: 0.16057246923446655, 
fpr: 0.014828988280315715, tpr: 0.8759185742039024, threshold: 0.15998223423957825, 
fpr: 0.014828988280315715, tpr: 0.8770166399189121, threshold: 0.15654632449150085, 
fpr: 0.015068165510643387, tpr: 0.8770166399189121, threshold: 0.15636005997657776, 
fpr: 0.015068165510643387, tpr: 0.8781147056339218, threshold: 0.1542314887046814, 
fpr: 0.01530734274097106, tpr: 0.8781147056339218, threshold: 0.15268924832344055, 
fpr: 0.01530734274097106, tpr: 0.8788749049750824, threshold: 0.15071521699428558, 
fpr: 0.015546519971298732, tpr: 0.8788749049750824, threshold: 0.15001703798770905, 
fpr: 0.015546519971298732, tpr: 0.89061576146634, threshold: 0.12072757631540298, 
fpr: 0.015785697201626404, tpr: 0.89061576146634, threshold: 0.12071031332015991, 
fpr: 0.015785697201626404, tpr: 0.8958526902610018, threshold: 0.10945917665958405, 
fpr: 0.016024874431954078, tpr: 0.8958526902610018, threshold: 0.1093580573797226, 
fpr: 0.016024874431954078, tpr: 0.8967818227890869, threshold: 0.1066150888800621, 
fpr: 0.016264051662281752, tpr: 0.8967818227890869, threshold: 0.10649499297142029, 
fpr: 0.016264051662281752, tpr: 0.8968662893825492, threshold: 0.10645627230405807, 
fpr: 0.016503228892609422, tpr: 0.8968662893825492, threshold: 0.1062254086136818, 
fpr: 0.016503228892609422, tpr: 0.9008362192752766, threshold: 0.09780163317918777, 
fpr: 0.016742406122937096, tpr: 0.9008362192752766, threshold: 0.09739865362644196, 
fpr: 0.016742406122937096, tpr: 0.9048906157614663, threshold: 0.08971849828958511, 
fpr: 0.01698158335326477, tpr: 0.9048906157614663, threshold: 0.0897153988480568, 
fpr: 0.01698158335326477, tpr: 0.9049750823549286, threshold: 0.08953402936458588, 
fpr: 0.017220760583592443, tpr: 0.9049750823549286, threshold: 0.0887530967593193, 
fpr: 0.017220760583592443, tpr: 0.9059042148830138, threshold: 0.08662616461515427, 
fpr: 0.017459937813920114, tpr: 0.9059042148830138, threshold: 0.08651577681303024, 
fpr: 0.017459937813920114, tpr: 0.9062420812568629, threshold: 0.08606529980897903, 
fpr: 0.017699115044247787, tpr: 0.9062420812568629, threshold: 0.08602596819400787, 
fpr: 0.017699115044247787, tpr: 0.906579947630712, threshold: 0.0855473056435585, 
fpr: 0.01793829227457546, tpr: 0.906579947630712, threshold: 0.0852125808596611, 
fpr: 0.01793829227457546, tpr: 0.9075090801587972, threshold: 0.08339942991733551, 
fpr: 0.018177469504903135, tpr: 0.9075090801587972, threshold: 0.08316700905561447, 
fpr: 0.018177469504903135, tpr: 0.9075935467522595, threshold: 0.08311620354652405, 
fpr: 0.018416646735230805, tpr: 0.9075935467522595, threshold: 0.08261963725090027, 
fpr: 0.018416646735230805, tpr: 0.9078469465326463, threshold: 0.08229935169219971, 
fpr: 0.01865582396555848, tpr: 0.9078469465326463, threshold: 0.08220880478620529, 
fpr: 0.01865582396555848, tpr: 0.9080158797195709, threshold: 0.08218270540237427, 
fpr: 0.018895001195886153, tpr: 0.9080158797195709, threshold: 0.08218058198690414, 
fpr: 0.018895001195886153, tpr: 0.9117324098319115, threshold: 0.07514046877622604, 
fpr: 0.019134178426213823, tpr: 0.9117324098319115, threshold: 0.07488401234149933, 
fpr: 0.019134178426213823, tpr: 0.9140130078553932, threshold: 0.07084891945123672, 
fpr: 0.019373355656541497, tpr: 0.9140130078553932, threshold: 0.07082782685756683, 
fpr: 0.019373355656541497, tpr: 0.9143508742292423, threshold: 0.07024924457073212, 
fpr: 0.01961253288686917, tpr: 0.9143508742292423, threshold: 0.07020691782236099, 
fpr: 0.01961253288686917, tpr: 0.9144353408227046, threshold: 0.0698610320687294, 
fpr: 0.019851710117196844, tpr: 0.9144353408227046, threshold: 0.0698288157582283, 
fpr: 0.019851710117196844, tpr: 0.914857673790016, threshold: 0.06924248486757278, 
fpr: 0.020090887347524514, tpr: 0.914857673790016, threshold: 0.06915158033370972, 
fpr: 0.020090887347524514, tpr: 0.9177295379677337, threshold: 0.06483316421508789, 
fpr: 0.020330064577852188, tpr: 0.9177295379677337, threshold: 0.06455132365226746, 
fpr: 0.020330064577852188, tpr: 0.9178984711546583, threshold: 0.06427254527807236, 
fpr: 0.020569241808179862, tpr: 0.9178984711546583, threshold: 0.06414473056793213, 
fpr: 0.020569241808179862, tpr: 0.9196722696173664, threshold: 0.06178964674472809, 
fpr: 0.020808419038507536, tpr: 0.9196722696173664, threshold: 0.06170812249183655, 
fpr: 0.020808419038507536, tpr: 0.9202635357716024, threshold: 0.06114794686436653, 
fpr: 0.021047596268835206, tpr: 0.9202635357716024, threshold: 0.06086307018995285, 
fpr: 0.021047596268835206, tpr: 0.9215305346735366, threshold: 0.059418171644210815, 
fpr: 0.02128677349916288, tpr: 0.9215305346735366, threshold: 0.0593855082988739, 
fpr: 0.02128677349916288, tpr: 0.9223752006081595, threshold: 0.05835326761007309, 
fpr: 0.021525950729490553, tpr: 0.9223752006081595, threshold: 0.05827408656477928, 
fpr: 0.021525950729490553, tpr: 0.9224596672016218, threshold: 0.05812836065888405, 
fpr: 0.021765127959818224, tpr: 0.9224596672016218, threshold: 0.05768463760614395, 
fpr: 0.021765127959818224, tpr: 0.9233887997297069, threshold: 0.05618998780846596, 
fpr: 0.022004305190145897, tpr: 0.9233887997297069, threshold: 0.05615590140223503, 
fpr: 0.022004305190145897, tpr: 0.925500464566264, threshold: 0.05317915230989456, 
fpr: 0.02224348242047357, tpr: 0.925500464566264, threshold: 0.05306724086403847, 
fpr: 0.02224348242047357, tpr: 0.9260072641270377, threshold: 0.052522920072078705, 
fpr: 0.022482659650801245, tpr: 0.9260072641270377, threshold: 0.05236425623297691, 
fpr: 0.022482659650801245, tpr: 0.9273587296224344, threshold: 0.05096594989299774, 
fpr: 0.022721836881128915, tpr: 0.9273587296224344, threshold: 0.05077282711863518, 
fpr: 0.022721836881128915, tpr: 0.9276121294028212, threshold: 0.05043305456638336, 
fpr: 0.02296101411145659, tpr: 0.9276121294028212, threshold: 0.050412651151418686, 
fpr: 0.02296101411145659, tpr: 0.9293859278655292, threshold: 0.04842136427760124, 
fpr: 0.023200191341784263, tpr: 0.9293859278655292, threshold: 0.04840964823961258, 
fpr: 0.023200191341784263, tpr: 0.9299771940197652, threshold: 0.047464825212955475, 
fpr: 0.023439368572111936, tpr: 0.9299771940197652, threshold: 0.04731984809041023, 
fpr: 0.023439368572111936, tpr: 0.9317509924824732, threshold: 0.044373929500579834, 
fpr: 0.023678545802439607, tpr: 0.9317509924824732, threshold: 0.04434209316968918, 
fpr: 0.023678545802439607, tpr: 0.9319199256693977, threshold: 0.044108010828495026, 
fpr: 0.02391772303276728, tpr: 0.9319199256693977, threshold: 0.044061459600925446, 
fpr: 0.02391772303276728, tpr: 0.9321733254497846, threshold: 0.04383741319179535, 
fpr: 0.024156900263094954, tpr: 0.9321733254497846, threshold: 0.04382029548287392, 
fpr: 0.024156900263094954, tpr: 0.9326801250105583, threshold: 0.043424054980278015, 
fpr: 0.024396077493422628, tpr: 0.9326801250105583, threshold: 0.04340836778283119, 
fpr: 0.024396077493422628, tpr: 0.9334403243517189, threshold: 0.042693521827459335, 
fpr: 0.024635254723750298, tpr: 0.9334403243517189, threshold: 0.04265987500548363, 
fpr: 0.024635254723750298, tpr: 0.9366500549032858, threshold: 0.038320936262607574, 
fpr: 0.024874431954077972, tpr: 0.9366500549032858, threshold: 0.038204509764909744, 
fpr: 0.024874431954077972, tpr: 0.9373257876509841, threshold: 0.03691792115569115, 
fpr: 0.025113609184405646, tpr: 0.9373257876509841, threshold: 0.03681762143969536, 
fpr: 0.025113609184405646, tpr: 0.9375791874313709, threshold: 0.03666146472096443, 
fpr: 0.02559196364506099, tpr: 0.9375791874313709, threshold: 0.0365944541990757, 
fpr: 0.02559196364506099, tpr: 0.9388461863333052, threshold: 0.035108935087919235, 
fpr: 0.025831140875388663, tpr: 0.9388461863333052, threshold: 0.03499564155936241, 
fpr: 0.025831140875388663, tpr: 0.9391840527071543, threshold: 0.03481360152363777, 
fpr: 0.02654867256637168, tpr: 0.9391840527071543, threshold: 0.03470102697610855, 
fpr: 0.02654867256637168, tpr: 0.9401131852352395, threshold: 0.034005649387836456, 
fpr: 0.026787849796699355, tpr: 0.9401131852352395, threshold: 0.033935531973838806, 
fpr: 0.026787849796699355, tpr: 0.9401976518287017, threshold: 0.03381606563925743, 
fpr: 0.02702702702702703, tpr: 0.9401976518287017, threshold: 0.0337836816906929, 
fpr: 0.02702702702702703, tpr: 0.9407889179829377, threshold: 0.03308963030576706, 
fpr: 0.027505381487682373, tpr: 0.9407889179829377, threshold: 0.032749272882938385, 
fpr: 0.027505381487682373, tpr: 0.9415491173240983, threshold: 0.03207377344369888, 
fpr: 0.027744558718010046, tpr: 0.9415491173240983, threshold: 0.03179675340652466, 
fpr: 0.027744558718010046, tpr: 0.9416335839175606, threshold: 0.03176254779100418, 
fpr: 0.027983735948337717, tpr: 0.9416335839175606, threshold: 0.03173882141709328, 
fpr: 0.027983735948337717, tpr: 0.9423937832587211, threshold: 0.031221620738506317, 
fpr: 0.02822291317866539, tpr: 0.9423937832587211, threshold: 0.031119506806135178, 
fpr: 0.02822291317866539, tpr: 0.9428161162260326, threshold: 0.030407747253775597, 
fpr: 0.028701267639320738, tpr: 0.9428161162260326, threshold: 0.030177541077136993, 
fpr: 0.028701267639320738, tpr: 0.9429005828194948, threshold: 0.030091838911175728, 
fpr: 0.028940444869648408, tpr: 0.9429005828194948, threshold: 0.030001385137438774, 
fpr: 0.028940444869648408, tpr: 0.9429850494129571, threshold: 0.029910800978541374, 
fpr: 0.029179622099976082, tpr: 0.9429850494129571, threshold: 0.02982921525835991, 
fpr: 0.029179622099976082, tpr: 0.9431539825998817, threshold: 0.02970711700618267, 
fpr: 0.029418799330303756, tpr: 0.9431539825998817, threshold: 0.029636207967996597, 
fpr: 0.029418799330303756, tpr: 0.9440831151279669, threshold: 0.02882366254925728, 
fpr: 0.02965797656063143, tpr: 0.9440831151279669, threshold: 0.02874072641134262, 
fpr: 0.02965797656063143, tpr: 0.9441675817214292, threshold: 0.02872154675424099, 
fpr: 0.030375508251614447, tpr: 0.9441675817214292, threshold: 0.028572041541337967, 
fpr: 0.030375508251614447, tpr: 0.9449277810625898, threshold: 0.02786886878311634, 
fpr: 0.03061468548194212, tpr: 0.9449277810625898, threshold: 0.027803845703601837, 
fpr: 0.03061468548194212, tpr: 0.9450122476560521, threshold: 0.027749599888920784, 
fpr: 0.031093039942597465, tpr: 0.9450122476560521, threshold: 0.027559518814086914, 
fpr: 0.031093039942597465, tpr: 0.9452656474364389, threshold: 0.027294043451547623, 
fpr: 0.031332217172925135, tpr: 0.9452656474364389, threshold: 0.02721587009727955, 
fpr: 0.031332217172925135, tpr: 0.9460258467775995, threshold: 0.026747681200504303, 
fpr: 0.03157139440325281, tpr: 0.9460258467775995, threshold: 0.02669285610318184, 
fpr: 0.03157139440325281, tpr: 0.9462792465579863, threshold: 0.026588937267661095, 
fpr: 0.03181057163358048, tpr: 0.9462792465579863, threshold: 0.026504840701818466, 
fpr: 0.03181057163358048, tpr: 0.9469549793056846, threshold: 0.025915345177054405, 
fpr: 0.03228892609423583, tpr: 0.9469549793056846, threshold: 0.025888418778777122, 
fpr: 0.03228892609423583, tpr: 0.9474617788664583, threshold: 0.025379618629813194, 
fpr: 0.032528103324563504, tpr: 0.9474617788664583, threshold: 0.025372250005602837, 
fpr: 0.032528103324563504, tpr: 0.9475462454599206, threshold: 0.025334255769848824, 
fpr: 0.03348481224587419, tpr: 0.9475462454599206, threshold: 0.02513033337891102, 
fpr: 0.03348481224587419, tpr: 0.9483064448010812, threshold: 0.024519074708223343, 
fpr: 0.033723989476201865, tpr: 0.9483064448010812, threshold: 0.02440696209669113, 
fpr: 0.033723989476201865, tpr: 0.9484753779880057, threshold: 0.024305112659931183, 
fpr: 0.03396316670652954, tpr: 0.9484753779880057, threshold: 0.02428819052875042, 
fpr: 0.03396316670652954, tpr: 0.948559844581468, threshold: 0.024268683046102524, 
fpr: 0.03420234393685721, tpr: 0.948559844581468, threshold: 0.024264086037874222, 
fpr: 0.03420234393685721, tpr: 0.9486443111749303, threshold: 0.02422385849058628, 
fpr: 0.0351590528581679, tpr: 0.9486443111749303, threshold: 0.024026015773415565, 
fpr: 0.0351590528581679, tpr: 0.9488977109553172, threshold: 0.02374929189682007, 
fpr: 0.035398230088495575, tpr: 0.9488977109553172, threshold: 0.023678643628954887, 
fpr: 0.035398230088495575, tpr: 0.9489821775487794, threshold: 0.023647652938961983, 
fpr: 0.03563740731882325, tpr: 0.9489821775487794, threshold: 0.02364278770983219, 
fpr: 0.03563740731882325, tpr: 0.9494045105160909, threshold: 0.02342602051794529, 
fpr: 0.03587658454915092, tpr: 0.9494045105160909, threshold: 0.023393064737319946, 
fpr: 0.03587658454915092, tpr: 0.9501647098572514, threshold: 0.022690828889608383, 
fpr: 0.036115761779478596, tpr: 0.9501647098572514, threshold: 0.022674931213259697, 
fpr: 0.036115761779478596, tpr: 0.950333643044176, threshold: 0.02239990048110485, 
fpr: 0.03635493900980627, tpr: 0.950333643044176, threshold: 0.02234007976949215, 
fpr: 0.03635493900980627, tpr: 0.9506715094180251, threshold: 0.021940357983112335, 
fpr: 0.036594116240133936, tpr: 0.9506715094180251, threshold: 0.021926680579781532, 
fpr: 0.036594116240133936, tpr: 0.9507559760114874, threshold: 0.02187533862888813, 
fpr: 0.03683329347046161, tpr: 0.9507559760114874, threshold: 0.021813346073031425, 
fpr: 0.03683329347046161, tpr: 0.9508404426049497, threshold: 0.02177881821990013, 
fpr: 0.037072470700789284, tpr: 0.9508404426049497, threshold: 0.02172202803194523, 
fpr: 0.037072470700789284, tpr: 0.951516175352648, threshold: 0.02121899090707302, 
fpr: 0.03731164793111696, tpr: 0.951516175352648, threshold: 0.02120964229106903, 
fpr: 0.03731164793111696, tpr: 0.9516006419461103, threshold: 0.02115960232913494, 
fpr: 0.03755082516144463, tpr: 0.9516006419461103, threshold: 0.02114701271057129, 
fpr: 0.03755082516144463, tpr: 0.9519385083199594, threshold: 0.020997077226638794, 
fpr: 0.037790002391772305, tpr: 0.9519385083199594, threshold: 0.020931489765644073, 
fpr: 0.037790002391772305, tpr: 0.9522763746938085, threshold: 0.02070184051990509, 
fpr: 0.03802917962209998, tpr: 0.9522763746938085, threshold: 0.0206387247890234, 
fpr: 0.03802917962209998, tpr: 0.9525297744741954, threshold: 0.020427031442523003, 
fpr: 0.038268356852427646, tpr: 0.9525297744741954, threshold: 0.020338760688900948, 
fpr: 0.038268356852427646, tpr: 0.9527831742545824, threshold: 0.02025691047310829, 
fpr: 0.03850753408275532, tpr: 0.9527831742545824, threshold: 0.020243268460035324, 
fpr: 0.03850753408275532, tpr: 0.9529521074415069, threshold: 0.020210903137922287, 
fpr: 0.03922506577373834, tpr: 0.9529521074415069, threshold: 0.019969476386904716, 
fpr: 0.03922506577373834, tpr: 0.9533744404088184, threshold: 0.01976252906024456, 
fpr: 0.039464243004066014, tpr: 0.9533744404088184, threshold: 0.01976070925593376, 
fpr: 0.039464243004066014, tpr: 0.9541346397499789, threshold: 0.019231120124459267, 
fpr: 0.03970342023439369, tpr: 0.9541346397499789, threshold: 0.019220523536205292, 
fpr: 0.03970342023439369, tpr: 0.9548948390911395, threshold: 0.018844958394765854, 
fpr: 0.03994259746472136, tpr: 0.9548948390911395, threshold: 0.01880890130996704, 
fpr: 0.03994259746472136, tpr: 0.9555705718388378, threshold: 0.018517738208174706, 
fpr: 0.04018177469504903, tpr: 0.9555705718388378, threshold: 0.018291650339961052, 
fpr: 0.04018177469504903, tpr: 0.9560773713996115, threshold: 0.01807396486401558, 
fpr: 0.0404209519253767, tpr: 0.9560773713996115, threshold: 0.018036892637610435, 
fpr: 0.0404209519253767, tpr: 0.9565841709603852, threshold: 0.01774454116821289, 
fpr: 0.040660129155704376, tpr: 0.9565841709603852, threshold: 0.01773831807076931, 
fpr: 0.040660129155704376, tpr: 0.9570065039276966, threshold: 0.01750529184937477, 
fpr: 0.04089930638603205, tpr: 0.9570065039276966, threshold: 0.017464464530348778, 
fpr: 0.04089930638603205, tpr: 0.9575133034884703, threshold: 0.017025763168931007, 
fpr: 0.041138483616359724, tpr: 0.9575133034884703, threshold: 0.017025277018547058, 
fpr: 0.041138483616359724, tpr: 0.9575977700819326, threshold: 0.016961948946118355, 
fpr: 0.0413776608466874, tpr: 0.9575977700819326, threshold: 0.016941307112574577, 
fpr: 0.0413776608466874, tpr: 0.9578511698623194, threshold: 0.016845300793647766, 
fpr: 0.04161683807701507, tpr: 0.9578511698623194, threshold: 0.016733424738049507, 
fpr: 0.04161683807701507, tpr: 0.9579356364557817, threshold: 0.016619287431240082, 
fpr: 0.04185601530734274, tpr: 0.9579356364557817, threshold: 0.01661556214094162, 
fpr: 0.04185601530734274, tpr: 0.9586958357969423, threshold: 0.016369907185435295, 
fpr: 0.04209519253767041, tpr: 0.9586958357969423, threshold: 0.016315100714564323, 
fpr: 0.04209519253767041, tpr: 0.9589492355773291, threshold: 0.016265682876110077, 
fpr: 0.04257354699832576, tpr: 0.9589492355773291, threshold: 0.016134113073349, 
fpr: 0.04257354699832576, tpr: 0.959202635357716, threshold: 0.016071069985628128, 
fpr: 0.04305190145898111, tpr: 0.959202635357716, threshold: 0.01598336547613144, 
fpr: 0.04305190145898111, tpr: 0.9594560351381028, threshold: 0.015715084969997406, 
fpr: 0.04329107868930878, tpr: 0.9594560351381028, threshold: 0.015571458265185356, 
fpr: 0.04329107868930878, tpr: 0.9595405017315651, threshold: 0.01550237461924553, 
fpr: 0.04376943314996412, tpr: 0.9595405017315651, threshold: 0.01545580942183733, 
fpr: 0.04376943314996412, tpr: 0.959793901511952, threshold: 0.015366285108029842, 
fpr: 0.044008610380291795, tpr: 0.959793901511952, threshold: 0.015363847836852074, 
fpr: 0.044008610380291795, tpr: 0.9601317678858011, threshold: 0.015162752009928226, 
fpr: 0.04424778761061947, tpr: 0.9601317678858011, threshold: 0.015038800425827503, 
fpr: 0.04424778761061947, tpr: 0.9603007010727257, threshold: 0.01480376347899437, 
fpr: 0.04448696484094714, tpr: 0.9603007010727257, threshold: 0.014723410829901695, 
fpr: 0.04448696484094714, tpr: 0.960385167666188, threshold: 0.014718728139996529, 
fpr: 0.044726142071274816, tpr: 0.960385167666188, threshold: 0.014718189835548401, 
fpr: 0.044726142071274816, tpr: 0.9604696342596503, threshold: 0.014702916145324707, 
fpr: 0.04496531930160249, tpr: 0.9604696342596503, threshold: 0.014701099134981632, 
fpr: 0.04496531930160249, tpr: 0.9606385674465748, threshold: 0.014589445665478706, 
fpr: 0.04520449653193016, tpr: 0.9606385674465748, threshold: 0.014569619670510292, 
fpr: 0.04520449653193016, tpr: 0.960976433820424, threshold: 0.01436529215425253, 
fpr: 0.045682850992585504, tpr: 0.960976433820424, threshold: 0.014168421737849712, 
fpr: 0.045682850992585504, tpr: 0.9616521665681224, threshold: 0.013847190886735916, 
fpr: 0.04616120545324085, tpr: 0.9616521665681224, threshold: 0.0138399051502347, 
fpr: 0.04616120545324085, tpr: 0.9618210997550469, threshold: 0.013814491219818592, 
fpr: 0.0466395599138962, tpr: 0.9618210997550469, threshold: 0.013728096149861813, 
fpr: 0.0466395599138962, tpr: 0.9619055663485092, threshold: 0.013715273700654507, 
fpr: 0.04687873714422387, tpr: 0.9619055663485092, threshold: 0.013687564991414547, 
fpr: 0.04687873714422387, tpr: 0.9620744995354338, threshold: 0.013623603619635105, 
fpr: 0.04711791437455154, tpr: 0.9620744995354338, threshold: 0.013614936731755733, 
fpr: 0.04711791437455154, tpr: 0.9622434327223583, threshold: 0.01361059583723545, 
fpr: 0.04735709160487921, tpr: 0.9622434327223583, threshold: 0.013607120141386986, 
fpr: 0.04735709160487921, tpr: 0.9623278993158206, threshold: 0.013594658114016056, 
fpr: 0.04759626883520689, tpr: 0.9623278993158206, threshold: 0.013594095595180988, 
fpr: 0.04759626883520689, tpr: 0.9626657656896698, threshold: 0.013369141146540642, 
fpr: 0.048074623295862234, tpr: 0.9626657656896698, threshold: 0.013337980024516582, 
fpr: 0.048074623295862234, tpr: 0.9628346988765943, threshold: 0.013270621187984943, 
fpr: 0.04831380052618991, tpr: 0.9628346988765943, threshold: 0.01326060388237238, 
fpr: 0.04831380052618991, tpr: 0.9629191654700566, threshold: 0.013260123319923878, 
fpr: 0.04855297775651758, tpr: 0.9629191654700566, threshold: 0.01324120070785284, 
fpr: 0.04855297775651758, tpr: 0.9630036320635189, threshold: 0.01316722109913826, 
fpr: 0.048792154986845256, tpr: 0.9630036320635189, threshold: 0.013163944706320763, 
fpr: 0.048792154986845256, tpr: 0.9636793648112172, threshold: 0.012923270463943481, 
fpr: 0.04903133221717292, tpr: 0.9636793648112172, threshold: 0.012877050787210464, 
fpr: 0.04903133221717292, tpr: 0.963932764591604, threshold: 0.012812592089176178, 
fpr: 0.049270509447500596, tpr: 0.963932764591604, threshold: 0.012779547832906246, 
fpr: 0.049270509447500596, tpr: 0.9640172311850663, threshold: 0.012770671397447586, 
fpr: 0.04998804113848362, tpr: 0.9640172311850663, threshold: 0.012704554945230484, 
fpr: 0.04998804113848362, tpr: 0.9641016977785286, threshold: 0.012671957723796368, 
fpr: 0.05022721836881129, tpr: 0.9641016977785286, threshold: 0.012662439607083797, 
fpr: 0.05022721836881129, tpr: 0.9642706309654532, threshold: 0.012634528800845146, 
fpr: 0.050466395599138965, tpr: 0.9642706309654532, threshold: 0.01263272576034069, 
fpr: 0.050466395599138965, tpr: 0.9644395641523777, threshold: 0.01256292499601841, 
fpr: 0.05118392729012198, tpr: 0.9644395641523777, threshold: 0.012484649196267128, 
fpr: 0.05118392729012198, tpr: 0.96452403074584, threshold: 0.012480493634939194, 
fpr: 0.05142310452044965, tpr: 0.96452403074584, threshold: 0.012436112388968468, 
fpr: 0.05142310452044965, tpr: 0.9647774305262269, threshold: 0.012328462675213814, 
fpr: 0.05166228175077733, tpr: 0.9647774305262269, threshold: 0.01232356857508421, 
fpr: 0.05166228175077733, tpr: 0.9651997634935383, threshold: 0.012206941843032837, 
fpr: 0.052140636211432674, tpr: 0.9651997634935383, threshold: 0.012149984948337078, 
fpr: 0.052140636211432674, tpr: 0.9652842300870006, threshold: 0.012133982963860035, 
fpr: 0.052618990672088015, tpr: 0.9652842300870006, threshold: 0.012103190645575523, 
fpr: 0.052618990672088015, tpr: 0.9653686966804629, threshold: 0.012095632962882519, 
fpr: 0.053336522363071036, tpr: 0.9653686966804629, threshold: 0.011918233707547188, 
fpr: 0.053336522363071036, tpr: 0.9654531632739252, threshold: 0.011915224604308605, 
fpr: 0.05357569959339871, tpr: 0.9654531632739252, threshold: 0.011867811903357506, 
fpr: 0.05357569959339871, tpr: 0.965706563054312, threshold: 0.011760998517274857, 
fpr: 0.05381487682372638, tpr: 0.965706563054312, threshold: 0.01161650288850069, 
fpr: 0.05381487682372638, tpr: 0.9659599628346989, threshold: 0.011457406915724277, 
fpr: 0.05477158574503707, tpr: 0.9659599628346989, threshold: 0.011224607937037945, 
fpr: 0.05477158574503707, tpr: 0.9662133626150857, threshold: 0.011074536480009556, 
fpr: 0.055010762975364745, tpr: 0.9662133626150857, threshold: 0.01106260996311903, 
fpr: 0.055010762975364745, tpr: 0.9664667623954726, threshold: 0.010867017321288586, 
fpr: 0.05524994020569242, tpr: 0.9664667623954726, threshold: 0.010779257863759995, 
fpr: 0.05524994020569242, tpr: 0.9669735619562463, threshold: 0.01060550007969141, 
fpr: 0.05548911743602009, tpr: 0.9669735619562463, threshold: 0.010595183819532394, 
fpr: 0.05548911743602009, tpr: 0.9679026944843314, threshold: 0.01005357876420021, 
fpr: 0.055728294666347766, tpr: 0.9679026944843314, threshold: 0.01001537125557661, 
fpr: 0.055728294666347766, tpr: 0.9681560942647183, threshold: 0.009974492713809013, 
fpr: 0.05596747189667543, tpr: 0.9681560942647183, threshold: 0.009906797669827938, 
fpr: 0.05596747189667543, tpr: 0.9684094940451051, threshold: 0.009762118570506573, 
fpr: 0.056685003587658454, tpr: 0.9684094940451051, threshold: 0.00967883225530386, 
fpr: 0.056685003587658454, tpr: 0.9685784272320297, threshold: 0.009645296260714531, 
fpr: 0.05764171250896915, tpr: 0.9685784272320297, threshold: 0.009541654959321022, 
fpr: 0.05764171250896915, tpr: 0.9687473604189543, threshold: 0.009440925903618336, 
fpr: 0.057880889739296816, tpr: 0.9687473604189543, threshold: 0.009413260966539383, 
fpr: 0.057880889739296816, tpr: 0.9690007601993411, threshold: 0.009321929886937141, 
fpr: 0.058359244199952164, tpr: 0.9690007601993411, threshold: 0.009283262304961681, 
fpr: 0.058359244199952164, tpr: 0.9690852267928034, threshold: 0.009273864328861237, 
fpr: 0.05859842143027984, tpr: 0.9690852267928034, threshold: 0.009257107973098755, 
fpr: 0.05859842143027984, tpr: 0.9696764929470394, threshold: 0.009128492325544357, 
fpr: 0.05931595312126286, tpr: 0.9696764929470394, threshold: 0.009095495566725731, 
fpr: 0.05931595312126286, tpr: 0.9700143593208886, threshold: 0.008983301930129528, 
fpr: 0.059555130351590525, tpr: 0.9700143593208886, threshold: 0.008965612389147282, 
fpr: 0.059555130351590525, tpr: 0.9702677591012755, threshold: 0.008845757693052292, 
fpr: 0.0597943075819182, tpr: 0.9702677591012755, threshold: 0.008751939050853252, 
fpr: 0.0597943075819182, tpr: 0.9704366922882001, threshold: 0.008706094697117805, 
fpr: 0.06003348481224587, tpr: 0.9704366922882001, threshold: 0.00868069939315319, 
fpr: 0.06003348481224587, tpr: 0.9707745586620492, threshold: 0.008604736998677254, 
fpr: 0.06027266204257355, tpr: 0.9707745586620492, threshold: 0.008600828237831593, 
fpr: 0.06027266204257355, tpr: 0.9711968916293606, threshold: 0.00841129943728447, 
fpr: 0.060751016503228894, tpr: 0.9711968916293606, threshold: 0.00837196595966816, 
fpr: 0.060751016503228894, tpr: 0.9715347580032098, threshold: 0.00823351088911295, 
fpr: 0.06122937096388424, tpr: 0.9715347580032098, threshold: 0.008228622376918793, 
fpr: 0.06122937096388424, tpr: 0.9725483571247572, threshold: 0.008000885136425495, 
fpr: 0.06146854819421191, tpr: 0.9725483571247572, threshold: 0.007996886968612671, 
fpr: 0.06146854819421191, tpr: 0.9726328237182195, threshold: 0.007889856584370136, 
fpr: 0.06170772542453958, tpr: 0.9726328237182195, threshold: 0.007868430577218533, 
fpr: 0.06170772542453958, tpr: 0.9730551566855309, threshold: 0.0076982504688203335, 
fpr: 0.06266443434585027, tpr: 0.9730551566855309, threshold: 0.007572667673230171, 
fpr: 0.06266443434585027, tpr: 0.97339302305938, threshold: 0.007390644401311874, 
fpr: 0.06362114326716097, tpr: 0.97339302305938, threshold: 0.007312525529414415, 
fpr: 0.06362114326716097, tpr: 0.9736464228397669, threshold: 0.007287901360541582, 
fpr: 0.06386032049748865, tpr: 0.9736464228397669, threshold: 0.007275818847119808, 
fpr: 0.06386032049748865, tpr: 0.9737308894332292, threshold: 0.007266605272889137, 
fpr: 0.06409949772781631, tpr: 0.9737308894332292, threshold: 0.0072534941136837006, 
fpr: 0.06409949772781631, tpr: 0.973984289213616, threshold: 0.007146347314119339, 
fpr: 0.06505620664912701, tpr: 0.973984289213616, threshold: 0.0070711602456867695, 
fpr: 0.06505620664912701, tpr: 0.9740687558070783, threshold: 0.007061193697154522, 
fpr: 0.06577373834011002, tpr: 0.9740687558070783, threshold: 0.006971931084990501, 
fpr: 0.06577373834011002, tpr: 0.9741532224005406, threshold: 0.006958666257560253, 
fpr: 0.06601291557043769, tpr: 0.9741532224005406, threshold: 0.006942940875887871, 
fpr: 0.06601291557043769, tpr: 0.9743221555874652, threshold: 0.006910401862114668, 
fpr: 0.06625209280076537, tpr: 0.9743221555874652, threshold: 0.006899762433022261, 
fpr: 0.06625209280076537, tpr: 0.9746600219613143, threshold: 0.006794567219913006, 
fpr: 0.06673044726142072, tpr: 0.9746600219613143, threshold: 0.006753741763532162, 
fpr: 0.06673044726142072, tpr: 0.9747444885547766, threshold: 0.006736225914210081, 
fpr: 0.06792633341305908, tpr: 0.9747444885547766, threshold: 0.006601803936064243, 
fpr: 0.06792633341305908, tpr: 0.9748289551482389, threshold: 0.006578571628779173, 
fpr: 0.06816551064338675, tpr: 0.9748289551482389, threshold: 0.0065746186301112175, 
fpr: 0.06816551064338675, tpr: 0.9750823549286257, threshold: 0.006498726084828377, 
fpr: 0.06840468787371443, tpr: 0.9750823549286257, threshold: 0.006480822805315256, 
fpr: 0.06840468787371443, tpr: 0.975166821522088, threshold: 0.00646659592166543, 
fpr: 0.06912221956469744, tpr: 0.975166821522088, threshold: 0.006393028888851404, 
fpr: 0.06912221956469744, tpr: 0.9752512881155503, threshold: 0.006347334012389183, 
fpr: 0.06936139679502511, tpr: 0.9752512881155503, threshold: 0.0063321348279714584, 
fpr: 0.06936139679502511, tpr: 0.9756736210828617, threshold: 0.006286056246608496, 
fpr: 0.06960057402535279, tpr: 0.9756736210828617, threshold: 0.006259966176003218, 
fpr: 0.06960057402535279, tpr: 0.9760114874567108, threshold: 0.006208493374288082, 
fpr: 0.06983975125568045, tpr: 0.9760114874567108, threshold: 0.006186099722981453, 
fpr: 0.06983975125568045, tpr: 0.9762648872370977, threshold: 0.0061065130867064, 
fpr: 0.0703181057163358, tpr: 0.9762648872370977, threshold: 0.0060197170823812485, 
fpr: 0.0703181057163358, tpr: 0.97634935383056, threshold: 0.0060150655917823315, 
fpr: 0.07079646017699115, tpr: 0.97634935383056, threshold: 0.005980891175568104, 
fpr: 0.07079646017699115, tpr: 0.9770250865782583, threshold: 0.0058140829205513, 
fpr: 0.0712748146376465, tpr: 0.9770250865782583, threshold: 0.005767031107097864, 
fpr: 0.0712748146376465, tpr: 0.9771095531717205, threshold: 0.005762239918112755, 
fpr: 0.07175316909830184, tpr: 0.9771095531717205, threshold: 0.005744497291743755, 
fpr: 0.07175316909830184, tpr: 0.9772784863586451, threshold: 0.005683262832462788, 
fpr: 0.07223152355895719, tpr: 0.9772784863586451, threshold: 0.005670053418725729, 
fpr: 0.07223152355895719, tpr: 0.977531886139032, threshold: 0.005531409755349159, 
fpr: 0.07247070078928486, tpr: 0.977531886139032, threshold: 0.005491083953529596, 
fpr: 0.07247070078928486, tpr: 0.9777008193259565, threshold: 0.00545576261356473, 
fpr: 0.07270987801961254, tpr: 0.9777008193259565, threshold: 0.005447367671877146, 
fpr: 0.07270987801961254, tpr: 0.978123152293268, threshold: 0.0053596217185258865, 
fpr: 0.0729490552499402, tpr: 0.978123152293268, threshold: 0.0053435396403074265, 
fpr: 0.0729490552499402, tpr: 0.9782076188867302, threshold: 0.005330652464181185, 
fpr: 0.07318823248026787, tpr: 0.9782076188867302, threshold: 0.005327197723090649, 
fpr: 0.07318823248026787, tpr: 0.9782920854801925, threshold: 0.005313890986144543, 
fpr: 0.07342740971059555, tpr: 0.9782920854801925, threshold: 0.005312908440828323, 
fpr: 0.07342740971059555, tpr: 0.9783765520736548, threshold: 0.005275803152471781, 
fpr: 0.07366658694092322, tpr: 0.9783765520736548, threshold: 0.00526398466899991, 
fpr: 0.07366658694092322, tpr: 0.9787144184475041, threshold: 0.005127057898789644, 
fpr: 0.07438411863190625, tpr: 0.9787144184475041, threshold: 0.005108874756842852, 
fpr: 0.07438411863190625, tpr: 0.9788833516344286, threshold: 0.005080272909253836, 
fpr: 0.07486247309256158, tpr: 0.9788833516344286, threshold: 0.0050593046471476555, 
fpr: 0.07486247309256158, tpr: 0.9789678182278909, threshold: 0.005033500026911497, 
fpr: 0.07510165032288926, tpr: 0.9789678182278909, threshold: 0.004932458512485027, 
fpr: 0.07510165032288926, tpr: 0.9790522848213532, threshold: 0.004917442332953215, 
fpr: 0.07581918201387228, tpr: 0.9790522848213532, threshold: 0.004905484616756439, 
fpr: 0.07581918201387228, tpr: 0.9791367514148155, threshold: 0.00488798413425684, 
fpr: 0.07605835924419996, tpr: 0.9791367514148155, threshold: 0.004868207033723593, 
fpr: 0.07605835924419996, tpr: 0.9793056846017401, threshold: 0.0048485444858670235, 
fpr: 0.07677589093518297, tpr: 0.9793056846017401, threshold: 0.004742641933262348, 
fpr: 0.07677589093518297, tpr: 0.9793901511952023, threshold: 0.004736213944852352, 
fpr: 0.07701506816551064, tpr: 0.9793901511952023, threshold: 0.004709253087639809, 
fpr: 0.07701506816551064, tpr: 0.9795590843821269, threshold: 0.004669195972383022, 
fpr: 0.07725424539583832, tpr: 0.9795590843821269, threshold: 0.004665775690227747, 
fpr: 0.07725424539583832, tpr: 0.979896950755976, threshold: 0.004658564459532499, 
fpr: 0.07749342262616599, tpr: 0.979896950755976, threshold: 0.004639154300093651, 
fpr: 0.07749342262616599, tpr: 0.9800658839429006, threshold: 0.004607153125107288, 
fpr: 0.07797177708682133, tpr: 0.9800658839429006, threshold: 0.004561848472803831, 
fpr: 0.07797177708682133, tpr: 0.9801503505363629, threshold: 0.004528375808149576, 
fpr: 0.0791676632384597, tpr: 0.9801503505363629, threshold: 0.004440941847860813, 
fpr: 0.0791676632384597, tpr: 0.9802348171298252, threshold: 0.0044311960227787495, 
fpr: 0.07940684046878738, tpr: 0.9802348171298252, threshold: 0.004386526998132467, 
fpr: 0.07940684046878738, tpr: 0.9809105498775235, threshold: 0.004155569244176149, 
fpr: 0.07964601769911504, tpr: 0.9809105498775235, threshold: 0.004155239090323448, 
fpr: 0.07964601769911504, tpr: 0.9809950164709857, threshold: 0.004120718687772751, 
fpr: 0.07988519492944272, tpr: 0.9809950164709857, threshold: 0.004096949938684702, 
fpr: 0.07988519492944272, tpr: 0.9813328828448349, threshold: 0.004024863243103027, 
fpr: 0.08012437215977039, tpr: 0.9813328828448349, threshold: 0.004007072187960148, 
fpr: 0.08012437215977039, tpr: 0.9817552158121463, threshold: 0.003944318275898695, 
fpr: 0.0808419038507534, tpr: 0.9817552158121463, threshold: 0.003914725035429001, 
fpr: 0.0808419038507534, tpr: 0.9818396824056086, threshold: 0.003911550156772137, 
fpr: 0.08155943554173643, tpr: 0.9818396824056086, threshold: 0.0038952073082327843, 
fpr: 0.08155943554173643, tpr: 0.9823464819663823, threshold: 0.003823072649538517, 
fpr: 0.0817986127720641, tpr: 0.9823464819663823, threshold: 0.003796637523919344, 
fpr: 0.0817986127720641, tpr: 0.9825154151533069, threshold: 0.003782103303819895, 
fpr: 0.08203779000239177, tpr: 0.9825154151533069, threshold: 0.003781059989705682, 
fpr: 0.08203779000239177, tpr: 0.982853281527156, threshold: 0.0037526246160268784, 
fpr: 0.08227696723271945, tpr: 0.982853281527156, threshold: 0.003749661147594452, 
fpr: 0.08227696723271945, tpr: 0.9830222147140806, threshold: 0.0037308696191757917, 
fpr: 0.08251614446304711, tpr: 0.9830222147140806, threshold: 0.0037273704074323177, 
fpr: 0.08251614446304711, tpr: 0.9832756144944674, threshold: 0.0037169749848544598, 
fpr: 0.08323367615403014, tpr: 0.9832756144944674, threshold: 0.0036435555666685104, 
fpr: 0.08323367615403014, tpr: 0.983444547681392, threshold: 0.0035996276419609785, 
fpr: 0.08347285338435781, tpr: 0.983444547681392, threshold: 0.003598736831918359, 
fpr: 0.08347285338435781, tpr: 0.9835290142748543, threshold: 0.003588659455999732, 
fpr: 0.08419038507534082, tpr: 0.9835290142748543, threshold: 0.003533043200150132, 
fpr: 0.08419038507534082, tpr: 0.9838668806487034, threshold: 0.0035073128528892994, 
fpr: 0.0844295623056685, tpr: 0.9838668806487034, threshold: 0.0034927192609757185, 
fpr: 0.0844295623056685, tpr: 0.9841202804290903, threshold: 0.003403209149837494, 
fpr: 0.08490791676632385, tpr: 0.9841202804290903, threshold: 0.003387036267668009, 
fpr: 0.08490791676632385, tpr: 0.9842047470225526, threshold: 0.0033143297769129276, 
fpr: 0.08562544845730687, tpr: 0.9842047470225526, threshold: 0.003258064156398177, 
fpr: 0.08562544845730687, tpr: 0.9842892136160148, threshold: 0.003255853895097971, 
fpr: 0.08586462568763453, tpr: 0.9842892136160148, threshold: 0.0032549379393458366, 
fpr: 0.08586462568763453, tpr: 0.9845426133964017, threshold: 0.0032236287370324135, 
fpr: 0.08610380291796221, tpr: 0.9845426133964017, threshold: 0.003218752332031727, 
fpr: 0.08610380291796221, tpr: 0.9847115465833263, threshold: 0.003139003412798047, 
fpr: 0.08634298014828988, tpr: 0.9847115465833263, threshold: 0.003128768177703023, 
fpr: 0.08634298014828988, tpr: 0.9848804797702508, threshold: 0.00310987769626081, 
fpr: 0.0870605118392729, tpr: 0.9848804797702508, threshold: 0.0030942042358219624, 
fpr: 0.0870605118392729, tpr: 0.9850494129571754, threshold: 0.0030612857080996037, 
fpr: 0.08753886629992824, tpr: 0.9850494129571754, threshold: 0.00303875794634223, 
fpr: 0.08753886629992824, tpr: 0.9851338795506377, threshold: 0.003033324144780636, 
fpr: 0.08825639799091127, tpr: 0.9851338795506377, threshold: 0.0029966598376631737, 
fpr: 0.08825639799091127, tpr: 0.9852183461441, threshold: 0.0029793735593557358, 
fpr: 0.08849557522123894, tpr: 0.9852183461441, threshold: 0.00297458004206419, 
fpr: 0.08849557522123894, tpr: 0.9853872793310245, threshold: 0.0029710535891354084, 
fpr: 0.08873475245156662, tpr: 0.9853872793310245, threshold: 0.002968525281175971, 
fpr: 0.08873475245156662, tpr: 0.9854717459244868, threshold: 0.002964309649541974, 
fpr: 0.08921310691222195, tpr: 0.9854717459244868, threshold: 0.002939017955213785, 
fpr: 0.08921310691222195, tpr: 0.9855562125179491, threshold: 0.002926247427240014, 
fpr: 0.09136570198517101, tpr: 0.9855562125179491, threshold: 0.0028373729437589645, 
fpr: 0.09136570198517101, tpr: 0.9856406791114114, threshold: 0.002831416204571724, 
fpr: 0.09256158813680937, tpr: 0.9856406791114114, threshold: 0.002800657879561186, 
fpr: 0.09256158813680937, tpr: 0.9857251457048737, threshold: 0.002792823826894164, 
fpr: 0.09280076536713705, tpr: 0.9857251457048737, threshold: 0.0027912810910493135, 
fpr: 0.09280076536713705, tpr: 0.985809612298336, threshold: 0.002777978777885437, 
fpr: 0.09303994259746472, tpr: 0.985809612298336, threshold: 0.002772663254290819, 
fpr: 0.09303994259746472, tpr: 0.9858940788917983, threshold: 0.0027567362412810326, 
fpr: 0.0932791198277924, tpr: 0.9858940788917983, threshold: 0.002722995588555932, 
fpr: 0.0932791198277924, tpr: 0.9861474786721851, threshold: 0.002702512312680483, 
fpr: 0.09351829705812006, tpr: 0.9861474786721851, threshold: 0.0026804578956216574, 
fpr: 0.09351829705812006, tpr: 0.9862319452656474, threshold: 0.0026756462175399065, 
fpr: 0.09399665151877541, tpr: 0.9862319452656474, threshold: 0.002673330018296838, 
fpr: 0.09399665151877541, tpr: 0.986400878452572, threshold: 0.002648361027240753, 
fpr: 0.09423582874910308, tpr: 0.986400878452572, threshold: 0.002647168468683958, 
fpr: 0.09423582874910308, tpr: 0.9865698116394965, threshold: 0.0026344566140323877, 
fpr: 0.09471418320975843, tpr: 0.9865698116394965, threshold: 0.0026052005123347044, 
fpr: 0.09471418320975843, tpr: 0.9866542782329588, threshold: 0.0026035120245069265, 
fpr: 0.0959100693613968, tpr: 0.9866542782329588, threshold: 0.0025472945999354124, 
fpr: 0.0959100693613968, tpr: 0.9867387448264211, threshold: 0.0025411327369511127, 
fpr: 0.09614924659172447, tpr: 0.9867387448264211, threshold: 0.002533868420869112, 
fpr: 0.09614924659172447, tpr: 0.9868232114198834, threshold: 0.002522621536627412, 
fpr: 0.09638842382205214, tpr: 0.9868232114198834, threshold: 0.0025081902276724577, 
fpr: 0.09638842382205214, tpr: 0.9869076780133457, threshold: 0.0024943421594798565, 
fpr: 0.09782348720401818, tpr: 0.9869076780133457, threshold: 0.0024149040691554546, 
fpr: 0.09782348720401818, tpr: 0.986992144606808, threshold: 0.002408804139122367, 
fpr: 0.09830184166467353, tpr: 0.986992144606808, threshold: 0.0023963500279933214, 
fpr: 0.09830184166467353, tpr: 0.9873300109806572, threshold: 0.0023765629157423973, 
fpr: 0.09878019612532887, tpr: 0.9873300109806572, threshold: 0.0023664592299610376, 
fpr: 0.09878019612532887, tpr: 0.9875834107610441, threshold: 0.0023427321575582027, 
fpr: 0.09925855058598422, tpr: 0.9875834107610441, threshold: 0.002334082033485174, 
fpr: 0.09925855058598422, tpr: 0.9876678773545063, threshold: 0.0023144774604588747, 
fpr: 0.09973690504663955, tpr: 0.9876678773545063, threshold: 0.002308458089828491, 
fpr: 0.09973690504663955, tpr: 0.9877523439479686, threshold: 0.0023040364030748606, 
fpr: 0.1002152595072949, tpr: 0.9877523439479686, threshold: 0.002298687119036913, 
fpr: 0.1002152595072949, tpr: 0.9878368105414309, threshold: 0.002296416787430644, 
fpr: 0.10093279119827793, tpr: 0.9878368105414309, threshold: 0.0022823906037956476, 
fpr: 0.10093279119827793, tpr: 0.9879212771348932, threshold: 0.002229287987574935, 
fpr: 0.10165032288926094, tpr: 0.9879212771348932, threshold: 0.002220200840383768, 
fpr: 0.10165032288926094, tpr: 0.98817467691528, threshold: 0.002203770447522402, 
fpr: 0.10212867734991629, tpr: 0.98817467691528, threshold: 0.002188623184338212, 
fpr: 0.10212867734991629, tpr: 0.9884280766956669, threshold: 0.0021447723265737295, 
fpr: 0.1028462090408993, tpr: 0.9884280766956669, threshold: 0.0021157527808099985, 
fpr: 0.1028462090408993, tpr: 0.9885125432891292, threshold: 0.0021134535782039165, 
fpr: 0.10308538627122697, tpr: 0.9885125432891292, threshold: 0.0021060057915747166, 
fpr: 0.10308538627122697, tpr: 0.988765943069516, threshold: 0.0020833644084632397, 
fpr: 0.10332456350155465, tpr: 0.988765943069516, threshold: 0.002079632133245468, 
fpr: 0.10332456350155465, tpr: 0.9892727426302897, threshold: 0.0020456237252801657, 
fpr: 0.10499880411384836, tpr: 0.9892727426302897, threshold: 0.0020043146796524525, 
fpr: 0.10499880411384836, tpr: 0.9894416758172143, threshold: 0.001993113663047552, 
fpr: 0.10523798134417603, tpr: 0.9894416758172143, threshold: 0.0019913134165108204, 
fpr: 0.10523798134417603, tpr: 0.9896950755976012, threshold: 0.001972924219444394, 
fpr: 0.10547715857450371, tpr: 0.9896950755976012, threshold: 0.001972606172785163, 
fpr: 0.10547715857450371, tpr: 0.9897795421910635, threshold: 0.0019685951992869377, 
fpr: 0.10595551303515906, tpr: 0.9897795421910635, threshold: 0.0019437270238995552, 
fpr: 0.10595551303515906, tpr: 0.9900329419714503, threshold: 0.0019108470296487212, 
fpr: 0.10619469026548672, tpr: 0.9900329419714503, threshold: 0.0019078045152127743, 
fpr: 0.10619469026548672, tpr: 0.9902018751583749, threshold: 0.0019003041088581085, 
fpr: 0.10691222195646974, tpr: 0.9902018751583749, threshold: 0.0018766883295029402, 
fpr: 0.10691222195646974, tpr: 0.9902863417518372, threshold: 0.0018627074314281344, 
fpr: 0.10715139918679742, tpr: 0.9902863417518372, threshold: 0.0018610707484185696, 
fpr: 0.10715139918679742, tpr: 0.9903708083452994, threshold: 0.001843845471739769, 
fpr: 0.10739057641712509, tpr: 0.9903708083452994, threshold: 0.0018334899796172976, 
fpr: 0.10739057641712509, tpr: 0.9904552749387617, threshold: 0.0018125292845070362, 
fpr: 0.10786893087778043, tpr: 0.9904552749387617, threshold: 0.0018000047421082854, 
fpr: 0.10786893087778043, tpr: 0.990539741532224, threshold: 0.001796642318367958, 
fpr: 0.10858646256876345, tpr: 0.990539741532224, threshold: 0.001768972259014845, 
fpr: 0.10858646256876345, tpr: 0.9907086747191486, threshold: 0.0017270698444917798, 
fpr: 0.10882563979909113, tpr: 0.9907086747191486, threshold: 0.0016977021005004644, 
fpr: 0.10882563979909113, tpr: 0.9907931413126109, threshold: 0.001691778190433979, 
fpr: 0.10978234872040182, tpr: 0.9907931413126109, threshold: 0.0016726243775337934, 
fpr: 0.10978234872040182, tpr: 0.9908776079060732, threshold: 0.0016639053355902433, 
fpr: 0.1107390576417125, tpr: 0.9908776079060732, threshold: 0.0016359470319002867, 
fpr: 0.1107390576417125, tpr: 0.99113100768646, threshold: 0.001617402071133256, 
fpr: 0.11193494379335087, tpr: 0.99113100768646, threshold: 0.0015978682786226273, 
fpr: 0.11193494379335087, tpr: 0.9912154742799223, threshold: 0.0015952012035995722, 
fpr: 0.11217412102367855, tpr: 0.9912154742799223, threshold: 0.0015726687852293253, 
fpr: 0.11217412102367855, tpr: 0.9913844074668469, threshold: 0.0015476967673748732, 
fpr: 0.11360918440564459, tpr: 0.9913844074668469, threshold: 0.0015164172509685159, 
fpr: 0.11360918440564459, tpr: 0.9914688740603091, threshold: 0.0015155532164499164, 
fpr: 0.11480507055728295, tpr: 0.9914688740603091, threshold: 0.0014876320492476225, 
fpr: 0.11480507055728295, tpr: 0.9915533406537714, threshold: 0.001485525630414486, 
fpr: 0.11504424778761062, tpr: 0.9915533406537714, threshold: 0.0014821337535977364, 
fpr: 0.11504424778761062, tpr: 0.991722273840696, threshold: 0.0014719784958288074, 
fpr: 0.1152834250179383, tpr: 0.991722273840696, threshold: 0.0014651832170784473, 
fpr: 0.1152834250179383, tpr: 0.9918067404341583, threshold: 0.0014641741290688515, 
fpr: 0.11552260224826597, tpr: 0.9918067404341583, threshold: 0.001461511361412704, 
fpr: 0.11552260224826597, tpr: 0.9918912070276206, threshold: 0.0014605430187657475, 
fpr: 0.11624013393924898, tpr: 0.9918912070276206, threshold: 0.0014447660651057959, 
fpr: 0.11624013393924898, tpr: 0.9919756736210829, threshold: 0.0014237751020118594, 
fpr: 0.11671848839990433, tpr: 0.9919756736210829, threshold: 0.0014187503838911653, 
fpr: 0.11671848839990433, tpr: 0.9920601402145451, threshold: 0.0014184484025463462, 
fpr: 0.11695766563023201, tpr: 0.9920601402145451, threshold: 0.0014136395184323192, 
fpr: 0.11695766563023201, tpr: 0.9922290734014697, threshold: 0.0013990052975714207, 
fpr: 0.11719684286055967, tpr: 0.9922290734014697, threshold: 0.001397408195771277, 
fpr: 0.11719684286055967, tpr: 0.9924824731818566, threshold: 0.0013778185239061713, 
fpr: 0.11839272901219804, tpr: 0.9924824731818566, threshold: 0.0013512359000742435, 
fpr: 0.11839272901219804, tpr: 0.9925669397753188, threshold: 0.0013493745354935527, 
fpr: 0.1222195646974408, tpr: 0.9925669397753188, threshold: 0.0012425582390278578, 
fpr: 0.1222195646974408, tpr: 0.9928203395557057, threshold: 0.0012338126543909311, 
fpr: 0.12269791915809615, tpr: 0.9928203395557057, threshold: 0.0012240735813975334, 
fpr: 0.12269791915809615, tpr: 0.9929892727426303, threshold: 0.0012150609400123358, 
fpr: 0.1258072231523559, tpr: 0.9929892727426303, threshold: 0.0011533385841175914, 
fpr: 0.1258072231523559, tpr: 0.9930737393360926, threshold: 0.0011529393959790468, 
fpr: 0.12604640038268358, tpr: 0.9930737393360926, threshold: 0.001149932504631579, 
fpr: 0.12604640038268358, tpr: 0.9931582059295548, threshold: 0.0011481039691716433, 
fpr: 0.12628557761301124, tpr: 0.9931582059295548, threshold: 0.0011467591393738985, 
fpr: 0.12628557761301124, tpr: 0.9933271391164794, threshold: 0.001143682631663978, 
fpr: 0.12652475484333892, tpr: 0.9933271391164794, threshold: 0.0011387038975954056, 
fpr: 0.12652475484333892, tpr: 0.993496072303404, threshold: 0.001122232642956078, 
fpr: 0.1274814637646496, tpr: 0.993496072303404, threshold: 0.001103307236917317, 
fpr: 0.1274814637646496, tpr: 0.9935805388968663, threshold: 0.0011003268882632256, 
fpr: 0.12819899545563262, tpr: 0.9935805388968663, threshold: 0.0010812768014147878, 
fpr: 0.12819899545563262, tpr: 0.9937494720837908, threshold: 0.0010764903854578733, 
fpr: 0.12963405883759865, tpr: 0.9937494720837908, threshold: 0.001040323986671865, 
fpr: 0.12963405883759865, tpr: 0.9938339386772531, threshold: 0.0010364550398662686, 
fpr: 0.13059076775890935, tpr: 0.9938339386772531, threshold: 0.0010195557260885835, 
fpr: 0.13059076775890935, tpr: 0.9939184052707154, threshold: 0.0010165141429752111, 
fpr: 0.13082994498923703, tpr: 0.9939184052707154, threshold: 0.001015196554362774, 
fpr: 0.13082994498923703, tpr: 0.99408733845764, threshold: 0.001011281623505056, 
fpr: 0.1380052618990672, tpr: 0.99408733845764, threshold: 0.0008555838721804321, 
fpr: 0.1380052618990672, tpr: 0.9942562716445645, threshold: 0.0008500742842443287, 
fpr: 0.13824443912939488, tpr: 0.9942562716445645, threshold: 0.0008494268404319882, 
fpr: 0.13824443912939488, tpr: 0.9943407382380268, threshold: 0.0008473077323287725, 
fpr: 0.13920114805070558, tpr: 0.9943407382380268, threshold: 0.0008418686338700354, 
fpr: 0.13920114805070558, tpr: 0.9944252048314891, threshold: 0.0008350082789547741, 
fpr: 0.1399186797416886, tpr: 0.9944252048314891, threshold: 0.0008230985840782523, 
fpr: 0.1399186797416886, tpr: 0.9945096714249514, threshold: 0.0008230849052779377, 
fpr: 0.14996412341545085, tpr: 0.9945096714249514, threshold: 0.0006386245368048549, 
fpr: 0.14996412341545085, tpr: 0.9945941380184137, threshold: 0.0006362078711390495, 
fpr: 0.15307342740971058, tpr: 0.9945941380184137, threshold: 0.0006094353157095611, 
fpr: 0.15307342740971058, tpr: 0.994678604611876, threshold: 0.0006088687223382294, 
fpr: 0.15450849079167664, tpr: 0.994678604611876, threshold: 0.0006032569799572229, 
fpr: 0.15450849079167664, tpr: 0.9947630712053382, threshold: 0.0006026268820278347, 
fpr: 0.1547476680220043, tpr: 0.9947630712053382, threshold: 0.0006007550400681794, 
fpr: 0.1547476680220043, tpr: 0.9948475377988005, threshold: 0.000599766499362886, 
fpr: 0.15666108586462568, tpr: 0.9948475377988005, threshold: 0.0005718242609873414, 
fpr: 0.15666108586462568, tpr: 0.9949320043922628, threshold: 0.0005714706494472921, 
fpr: 0.16144463047117916, tpr: 0.9949320043922628, threshold: 0.0005423467373475432, 
fpr: 0.16144463047117916, tpr: 0.9951009375791874, threshold: 0.0005414121551439166, 
fpr: 0.16407558000478353, tpr: 0.9951009375791874, threshold: 0.0005198922590352595, 
fpr: 0.16407558000478353, tpr: 0.9951854041726497, threshold: 0.0005197119317017496, 
fpr: 0.1652714661564219, tpr: 0.9951854041726497, threshold: 0.0005144932074472308, 
fpr: 0.1652714661564219, tpr: 0.995269870766112, threshold: 0.0005120750865899026, 
fpr: 0.1671848839990433, tpr: 0.995269870766112, threshold: 0.0005005095154047012, 
fpr: 0.1671848839990433, tpr: 0.9953543373595742, threshold: 0.0004992710892111063, 
fpr: 0.1698158335326477, tpr: 0.9953543373595742, threshold: 0.000486005621496588, 
fpr: 0.1698158335326477, tpr: 0.9954388039530365, threshold: 0.0004851641715504229, 
fpr: 0.17005501076297536, tpr: 0.9954388039530365, threshold: 0.00048478689859621227, 
fpr: 0.17005501076297536, tpr: 0.9955232705464988, threshold: 0.0004826509684789926, 
fpr: 0.17053336522363072, tpr: 0.9955232705464988, threshold: 0.000473524269182235, 
fpr: 0.17053336522363072, tpr: 0.9956077371399611, threshold: 0.00047186657320708036, 
fpr: 0.17101171968428605, tpr: 0.9956077371399611, threshold: 0.0004708695341832936, 
fpr: 0.17101171968428605, tpr: 0.9956922037334235, threshold: 0.0004669849295169115, 
fpr: 0.17125089691461373, tpr: 0.9956922037334235, threshold: 0.0004628104215953499, 
fpr: 0.17125089691461373, tpr: 0.9957766703268858, threshold: 0.0004622938868124038, 
fpr: 0.17388184644821814, tpr: 0.9957766703268858, threshold: 0.00044738341239281, 
fpr: 0.17388184644821814, tpr: 0.9958611369203481, threshold: 0.0004469465056899935, 
fpr: 0.17483855536952883, tpr: 0.9958611369203481, threshold: 0.00044005803647451103, 
fpr: 0.17483855536952883, tpr: 0.9959456035138103, threshold: 0.0004390754329506308, 
fpr: 0.1810571633580483, tpr: 0.9959456035138103, threshold: 0.00041083458927460015, 
fpr: 0.1810571633580483, tpr: 0.9960300701072726, threshold: 0.00041041182703338563, 
fpr: 0.18153551781870367, tpr: 0.9960300701072726, threshold: 0.0004100325459148735, 
fpr: 0.18153551781870367, tpr: 0.9961145367007349, threshold: 0.0004088222631253302, 
fpr: 0.18249222674001436, tpr: 0.9961145367007349, threshold: 0.00040160297066904604, 
fpr: 0.18249222674001436, tpr: 0.9961990032941972, threshold: 0.0004004265065304935, 
fpr: 0.1882324802678785, tpr: 0.9961990032941972, threshold: 0.0003695193154271692, 
fpr: 0.1882324802678785, tpr: 0.9962834698876595, threshold: 0.0003664359974209219, 
fpr: 0.19469026548672566, tpr: 0.9962834698876595, threshold: 0.0003313424240332097, 
fpr: 0.19469026548672566, tpr: 0.996452403074584, threshold: 0.00032972649205476046, 
fpr: 0.19756039225065775, tpr: 0.996452403074584, threshold: 0.0003198439080733806, 
fpr: 0.19756039225065775, tpr: 0.9965368696680463, threshold: 0.0003197499900124967, 
fpr: 0.2004305190145898, tpr: 0.9965368696680463, threshold: 0.000304044020595029, 
fpr: 0.2004305190145898, tpr: 0.9966213362615086, threshold: 0.0003030661609955132, 
fpr: 0.2021047596268835, tpr: 0.9966213362615086, threshold: 0.00029753378476016223, 
fpr: 0.2021047596268835, tpr: 0.9967058028549709, threshold: 0.0002967818873003125, 
fpr: 0.20784501315474765, tpr: 0.9967058028549709, threshold: 0.0002735562447924167, 
fpr: 0.20784501315474765, tpr: 0.9967902694484332, threshold: 0.00027346733259037137, 
fpr: 0.21765127959818226, tpr: 0.9967902694484332, threshold: 0.0002370864531258121, 
fpr: 0.21765127959818226, tpr: 0.9968747360418955, threshold: 0.00023685081396251917, 
fpr: 0.22386988758670173, tpr: 0.9968747360418955, threshold: 0.000220869857002981, 
fpr: 0.22386988758670173, tpr: 0.99704366922882, threshold: 0.00022041020565666258, 
fpr: 0.22626165988997848, tpr: 0.99704366922882, threshold: 0.00021166869555599988, 
fpr: 0.22626165988997848, tpr: 0.9971281358222823, threshold: 0.00020924748969264328, 
fpr: 0.22721836881128918, tpr: 0.9971281358222823, threshold: 0.0002045956498477608, 
fpr: 0.22721836881128918, tpr: 0.9972126024157446, threshold: 0.00020365694945212454, 
fpr: 0.23008849557522124, tpr: 0.9972126024157446, threshold: 0.0001982501707971096, 
fpr: 0.23008849557522124, tpr: 0.9972970690092069, threshold: 0.00019767558842431754, 
fpr: 0.23630710356374074, tpr: 0.9972970690092069, threshold: 0.00018003297736868262, 
fpr: 0.23630710356374074, tpr: 0.9973815356026692, threshold: 0.00017968467727769166, 
fpr: 0.2408514709399665, tpr: 0.9973815356026692, threshold: 0.00016693156794644892, 
fpr: 0.2408514709399665, tpr: 0.9974660021961315, threshold: 0.00016543635865673423, 
fpr: 0.25209280076536716, tpr: 0.9974660021961315, threshold: 0.0001449539850000292, 
fpr: 0.25209280076536716, tpr: 0.9975504687895937, threshold: 0.00014452461618930101, 
fpr: 0.2575938770629036, tpr: 0.9975504687895937, threshold: 0.00013156615023035556, 
fpr: 0.2575938770629036, tpr: 0.9977194019765183, threshold: 0.00013104079698678106, 
fpr: 0.2585505859842143, tpr: 0.9977194019765183, threshold: 0.00012841015995945781, 
fpr: 0.2585505859842143, tpr: 0.9978038685699806, threshold: 0.0001283886085730046, 
fpr: 0.260942358287491, tpr: 0.9978038685699806, threshold: 0.00012682698434218764, 
fpr: 0.260942358287491, tpr: 0.9978883351634429, threshold: 0.00012599957699421793, 
fpr: 0.2626165988997847, tpr: 0.9978883351634429, threshold: 0.00012379327381495386, 
fpr: 0.2626165988997847, tpr: 0.9979728017569052, threshold: 0.00012316404900047928, 
fpr: 0.26548672566371684, tpr: 0.9979728017569052, threshold: 0.00011951603664783761, 
fpr: 0.26548672566371684, tpr: 0.9980572683503675, threshold: 0.00011948835162911564, 
fpr: 0.26931356134895956, tpr: 0.9980572683503675, threshold: 0.00011307306704111397, 
fpr: 0.26931356134895956, tpr: 0.9981417349438297, threshold: 0.00011282374180154875, 
fpr: 0.2793590050227218, tpr: 0.9981417349438297, threshold: 9.710447193356231e-05, 
fpr: 0.2793590050227218, tpr: 0.998226201537292, threshold: 9.653013694332913e-05, 
fpr: 0.2810332456350155, tpr: 0.998226201537292, threshold: 9.50479443417862e-05, 
fpr: 0.2810332456350155, tpr: 0.9983106681307543, threshold: 9.496577695244923e-05, 
fpr: 0.28581679024156903, tpr: 0.9983106681307543, threshold: 9.047758067026734e-05, 
fpr: 0.28581679024156903, tpr: 0.9983951347242166, threshold: 9.031569061335176e-05, 
fpr: 0.29131786653910546, tpr: 0.9983951347242166, threshold: 8.62573942868039e-05, 
fpr: 0.29131786653910546, tpr: 0.9984796013176789, threshold: 8.607186464359984e-05, 
fpr: 0.299689069600574, tpr: 0.9984796013176789, threshold: 8.073764911387116e-05, 
fpr: 0.299689069600574, tpr: 0.9985640679111412, threshold: 8.047929441090673e-05, 
fpr: 0.337718249222674, tpr: 0.9985640679111412, threshold: 5.995655374135822e-05, 
fpr: 0.337718249222674, tpr: 0.9986485345046034, threshold: 5.991209400235675e-05, 
fpr: 0.3570916048792155, tpr: 0.9986485345046034, threshold: 5.0764054321916774e-05, 
fpr: 0.3570916048792155, tpr: 0.9987330010980657, threshold: 5.076196976006031e-05, 
fpr: 0.3582874910308539, tpr: 0.9987330010980657, threshold: 5.014936687075533e-05, 
fpr: 0.3582874910308539, tpr: 0.998817467691528, threshold: 5.014568523620255e-05, 
fpr: 0.3606792633341306, tpr: 0.998817467691528, threshold: 4.873335637967102e-05, 
fpr: 0.3606792633341306, tpr: 0.9989019342849903, threshold: 4.8698417231207713e-05, 
fpr: 0.3915331260464004, tpr: 0.9989019342849903, threshold: 3.787003151956014e-05, 
fpr: 0.3915331260464004, tpr: 0.9989864008784526, threshold: 3.763522545341402e-05, 
fpr: 0.39990432910786894, tpr: 0.9989864008784526, threshold: 3.443714012973942e-05, 
fpr: 0.39990432910786894, tpr: 0.9990708674719149, threshold: 3.4275417419848964e-05, 
fpr: 0.404209519253767, tpr: 0.9990708674719149, threshold: 3.3383672416675836e-05, 
fpr: 0.4046878737144224, tpr: 0.9990708674719149, threshold: 3.3344407711410895e-05, 
fpr: 0.4470222434824205, tpr: 0.9990708674719149, threshold: 2.3479375158785842e-05, 
fpr: 0.4470222434824205, tpr: 0.9991553340653772, threshold: 2.3443933969247155e-05, 
fpr: 0.4482181296340588, tpr: 0.9991553340653772, threshold: 2.326688809262123e-05, 
fpr: 0.4482181296340588, tpr: 0.9992398006588394, threshold: 2.3250249796546996e-05, 
fpr: 0.4747668022004305, tpr: 0.9992398006588394, threshold: 1.8507640561438166e-05, 
fpr: 0.4747668022004305, tpr: 0.9993242672523017, threshold: 1.846131453930866e-05, 
fpr: 0.5005979430758192, tpr: 0.9993242672523017, threshold: 1.496347613283433e-05, 
fpr: 0.5005979430758192, tpr: 0.999408733845764, threshold: 1.4943667338229716e-05, 
fpr: 0.5369528820856254, tpr: 0.999408733845764, threshold: 1.0849586942640599e-05, 
fpr: 0.5369528820856254, tpr: 0.9994932004392263, threshold: 1.0842109077202622e-05, 
fpr: 0.5678067447978953, tpr: 0.9994932004392263, threshold: 7.817163350409828e-06, 
fpr: 0.5678067447978953, tpr: 0.9995776670326886, threshold: 7.812118383299094e-06, 
fpr: 0.6106194690265486, tpr: 0.9995776670326886, threshold: 4.460978288989281e-06, 
fpr: 0.6106194690265486, tpr: 0.9996621336261509, threshold: 4.4558464651345275e-06, 
fpr: 0.6866778282707486, tpr: 0.9996621336261509, threshold: 1.4106300341154565e-06, 
fpr: 0.6866778282707486, tpr: 0.9997466002196131, threshold: 1.3948938430985436e-06, 
fpr: 0.7003109303994259, tpr: 0.9997466002196131, threshold: 1.1565126669665915e-06, 
fpr: 0.7003109303994259, tpr: 0.9998310668130754, threshold: 1.149452373283566e-06, 
fpr: 0.7038985888543411, tpr: 0.9998310668130754, threshold: 1.0909908496614662e-06, 
fpr: 0.7038985888543411, tpr: 0.9999155334065377, threshold: 1.072108602784283e-06, 
fpr: 0.9138961970820378, tpr: 0.9999155334065377, threshold: 5.726953133944335e-08, 
fpr: 0.9143745515426931, tpr: 0.9999155334065377, threshold: 5.656001178522274e-08, 
fpr: 0.985410188950012, tpr: 0.9999155334065377, threshold: 5.523176138666486e-09, 
fpr: 0.985410188950012, tpr: 1.0, threshold: 5.149403570214872e-09, 
fpr: 1.0, tpr: 1.0, threshold: 5.482541157175724e-11, 

=== best_threshold: 0.016265682876110077, best_fpr: 0.04209519253767041, best_tpr: 0.9589492355773291 ===
