cuda:0
Subjects num: 78

30min inputs: chc001-nsrr (13)
30min inputs: chc004-nsrr (17)
30min inputs: chc005-nsrr (15)
30min inputs: chc006-nsrr (13)
30min inputs: chc008-nsrr (16)
30min inputs: chc009-nsrr (14)
30min inputs: chc010-nsrr (14)
30min inputs: chc012-nsrr (15)
30min inputs: chc013-nsrr (15)
30min inputs: chc014-nsrr (15)
30min inputs: chc015-nsrr (15)
30min inputs: chc016-nsrr (15)
30min inputs: chc022-nsrr (13)
30min inputs: chc025-nsrr (13)
30min inputs: chc027-nsrr (15)
30min inputs: chc028-nsrr (14)
30min inputs: chc033-nsrr (14)
30min inputs: chc035-nsrr (15)
30min inputs: chc037-nsrr (14)
30min inputs: chc040-nsrr (18)
30min inputs: chc041-nsrr (14)
30min inputs: chc052-nsrr (15)
30min inputs: chc056-nsrr (15)
30min inputs: chp001-nsrr (19)
30min inputs: chp002-nsrr (18)
30min inputs: chp003-nsrr (16)
30min inputs: chp004-nsrr (16)
30min inputs: chp005-nsrr (21)
30min inputs: chp006-nsrr (18)
30min inputs: chp007-nsrr (19)
30min inputs: chp008-nsrr (15)
30min inputs: chp009-nsrr (17)
30min inputs: chp010-nsrr (16)
30min inputs: chp011-nsrr (16)
30min inputs: chp012-nsrr (18)
30min inputs: chp013-nsrr (16)
30min inputs: chp014-nsrr (16)
30min inputs: chp015-nsrr (19)
30min inputs: chp016-nsrr (21)
30min inputs: chp017-nsrr (16)
30min inputs: chp018-nsrr (18)
30min inputs: chp019-nsrr (15)
30min inputs: chp020-nsrr (19)
30min inputs: chp022-nsrr (21)
30min inputs: chp024-nsrr (18)
30min inputs: chp025-nsrr (7)
30min inputs: chp026-nsrr (15)
30min inputs: chp028-nsrr (17)
30min inputs: chp029-nsrr (17)
30min inputs: chp030-nsrr (20)
30min inputs: chp031-nsrr (18)
30min inputs: chp032-nsrr (17)
30min inputs: chp033-nsrr (16)
30min inputs: chp034-nsrr (17)
30min inputs: chp036-nsrr (21)
30min inputs: chp037-nsrr (17)
30min inputs: chp038-nsrr (17)
30min inputs: chp039-nsrr (18)
30min inputs: chp040-nsrr (17)
30min inputs: chp041-nsrr (18)
30min inputs: chp042-nsrr (18)
30min inputs: chp043-nsrr (20)
30min inputs: chp044-nsrr (17)
30min inputs: chp045-nsrr (20)
30min inputs: chp046-nsrr (18)
30min inputs: chp047-nsrr (14)
30min inputs: chp048-nsrr (17)
30min inputs: chp049-nsrr (18)
30min inputs: chp051-nsrr (18)
30min inputs: chp052-nsrr (16)
30min inputs: chp053-nsrr (18)
30min inputs: chp054-nsrr (18)
30min inputs: chp055-nsrr (18)
30min inputs: chp056-nsrr (18)
30min inputs: chp057-nsrr (19)
30min inputs: chp058-nsrr (17)
30min inputs: chp059-nsrr (18)
30min inputs: chp060-nsrr (21)

=== Test on chc001-nsrr. train_data(1287), test_data(13) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.693118
0.0777 --- loss_d: 0.494685
0.1554 --- loss_d: 0.235652
0.2331 --- loss_d: 0.703611
0.3108 --- loss_d: 0.476897
0.3885 --- loss_d: 1.042900
0.4662 --- loss_d: 0.593186
0.5439 --- loss_d: 0.945787
0.6216 --- loss_d: 0.741653
0.6993 --- loss_d: 0.462827
0.7770 --- loss_d: 0.318027
0.8547 --- loss_d: 0.430671
0.9324 --- loss_d: 0.454831
Epoch finished! Loss: 0.5857231939444318
Starting epoch 2/10.
0.0000 --- loss_d: 0.555028
0.0777 --- loss_d: 0.576190
0.1554 --- loss_d: 0.508677
0.2331 --- loss_d: 0.839207
0.3108 --- loss_d: 0.396927
0.3885 --- loss_d: 0.276696
0.4662 --- loss_d: 0.343739
0.5439 --- loss_d: 0.348150
0.6216 --- loss_d: 0.651032
0.6993 --- loss_d: 0.695919
0.7770 --- loss_d: 0.372378
0.8547 --- loss_d: 0.255307
0.9324 --- loss_d: 0.176438
Epoch finished! Loss: 0.43488868555868976
Starting epoch 3/10.
0.0000 --- loss_d: 0.091798
0.0777 --- loss_d: 0.913200
0.1554 --- loss_d: 0.250615
0.2331 --- loss_d: 0.245132
0.3108 --- loss_d: 0.205781
0.3885 --- loss_d: 0.082514
0.4662 --- loss_d: 0.490454
0.5439 --- loss_d: 0.963526
0.6216 --- loss_d: 0.301262
0.6993 --- loss_d: 0.317412
0.7770 --- loss_d: 0.402613
0.8547 --- loss_d: 0.342751
0.9324 --- loss_d: 0.466473
Epoch finished! Loss: 0.3127133571833838
Starting epoch 4/10.
0.0000 --- loss_d: 0.469385
0.0777 --- loss_d: 0.267003
0.1554 --- loss_d: 0.133635
0.2331 --- loss_d: 0.081882
0.3108 --- loss_d: 0.171500
0.3885 --- loss_d: 1.218128
0.4662 --- loss_d: 0.107023
0.5439 --- loss_d: 0.103957
0.6216 --- loss_d: 0.208084
0.6993 --- loss_d: 0.344270
0.7770 --- loss_d: 0.177925
0.8547 --- loss_d: 0.114067
0.9324 --- loss_d: 0.142483
Epoch finished! Loss: 0.24980151746422052
Starting epoch 5/10.
0.0000 --- loss_d: 0.065256
0.0777 --- loss_d: 0.203080
0.1554 --- loss_d: 0.273169
0.2331 --- loss_d: 0.186519
0.3108 --- loss_d: 0.197196
0.3885 --- loss_d: 0.202159
0.4662 --- loss_d: 0.090364
0.5439 --- loss_d: 0.088168
0.6216 --- loss_d: 0.035267
0.6993 --- loss_d: 0.355182
0.7770 --- loss_d: 0.036434
0.8547 --- loss_d: 0.265280
0.9324 --- loss_d: 0.261156
Epoch finished! Loss: 0.18801135441754013
Starting epoch 6/10.
0.0000 --- loss_d: 0.549544
0.0777 --- loss_d: 0.109550
0.1554 --- loss_d: 0.052968
0.2331 --- loss_d: 0.032429
0.3108 --- loss_d: 0.027187
0.3885 --- loss_d: 0.324789
0.4662 --- loss_d: 0.347437
0.5439 --- loss_d: 0.231417
0.6216 --- loss_d: 0.049013
0.6993 --- loss_d: 0.038321
0.7770 --- loss_d: 0.026030
0.8547 --- loss_d: 0.155045
0.9324 --- loss_d: 0.052351
Epoch finished! Loss: 0.127170101599404
Starting epoch 7/10.
0.0000 --- loss_d: 0.094935
0.0777 --- loss_d: 0.066285
0.1554 --- loss_d: 0.082743
0.2331 --- loss_d: 0.012933
0.3108 --- loss_d: 0.032884
0.3885 --- loss_d: 0.024032
0.4662 --- loss_d: 0.592078
0.5439 --- loss_d: 0.002714
0.6216 --- loss_d: 0.280642
0.6993 --- loss_d: 0.213992
0.7770 --- loss_d: 0.115018
0.8547 --- loss_d: 0.235344
0.9324 --- loss_d: 0.026710
Epoch finished! Loss: 0.14118645763664972
Starting epoch 8/10.
0.0000 --- loss_d: 0.017423
0.0777 --- loss_d: 0.150498
0.1554 --- loss_d: 0.093961
0.2331 --- loss_d: 0.273509
0.3108 --- loss_d: 0.238804
0.3885 --- loss_d: 0.228875
0.4662 --- loss_d: 0.027198
0.5439 --- loss_d: 0.143556
0.6216 --- loss_d: 0.050508
0.6993 --- loss_d: 0.005551
0.7770 --- loss_d: 0.113379
0.8547 --- loss_d: 0.065431
0.9324 --- loss_d: 0.038570
Epoch finished! Loss: 0.10215169942421198
Starting epoch 9/10.
0.0000 --- loss_d: 0.022495
0.0777 --- loss_d: 0.005067
0.1554 --- loss_d: 0.050836
0.2331 --- loss_d: 0.043629
0.3108 --- loss_d: 0.012059
0.3885 --- loss_d: 0.057991
0.4662 --- loss_d: 0.002374
0.5439 --- loss_d: 0.069380
0.6216 --- loss_d: 0.008269
0.6993 --- loss_d: 0.002233
0.7770 --- loss_d: 0.000880
0.8547 --- loss_d: 0.001427
0.9324 --- loss_d: 0.003601
Epoch finished! Loss: 0.05021405104525911
Starting epoch 10/10.
0.0000 --- loss_d: 0.002999
0.0777 --- loss_d: 0.203152
0.1554 --- loss_d: 0.002868
0.2331 --- loss_d: 0.002262
0.3108 --- loss_d: 0.074405
0.3885 --- loss_d: 0.005765
0.4662 --- loss_d: 0.032313
0.5439 --- loss_d: 0.389814
0.6216 --- loss_d: 0.003407
0.6993 --- loss_d: 0.117312
0.7770 --- loss_d: 0.004875
0.8547 --- loss_d: 0.032605
0.9324 --- loss_d: 0.004911
Epoch finished! Loss: 0.05689395772515127
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.15384615384615385
[0.98994678 0.76111847 0.98834103 0.81500012 0.97799224 0.99926442
 0.99287534 0.96217763 0.99873692 0.99993646 0.06391398 0.37314382
 0.92668843]
pred: 0.834548895748762, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc001-nsrr

=== Test on chc004-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.707922
0.0779 --- loss_d: 0.356080
0.1559 --- loss_d: 0.677898
0.2338 --- loss_d: 0.559318
0.3118 --- loss_d: 0.384367
0.3897 --- loss_d: 0.817301
0.4677 --- loss_d: 0.545894
0.5456 --- loss_d: 0.600677
0.6235 --- loss_d: 0.502198
0.7015 --- loss_d: 0.536820
0.7794 --- loss_d: 0.791915
0.8574 --- loss_d: 0.549324
0.9353 --- loss_d: 1.358847
Epoch finished! Loss: 0.5825221550185233
Starting epoch 2/10.
0.0000 --- loss_d: 0.729685
0.0779 --- loss_d: 0.565207
0.1559 --- loss_d: 0.497747
0.2338 --- loss_d: 0.208261
0.3118 --- loss_d: 0.373468
0.3897 --- loss_d: 0.517178
0.4677 --- loss_d: 0.198239
0.5456 --- loss_d: 0.201083
0.6235 --- loss_d: 0.444084
0.7015 --- loss_d: 0.411873
0.7794 --- loss_d: 0.633923
0.8574 --- loss_d: 0.433774
0.9353 --- loss_d: 0.257492
Epoch finished! Loss: 0.419412886549253
Starting epoch 3/10.
0.0000 --- loss_d: 0.211359
0.0779 --- loss_d: 0.363277
0.1559 --- loss_d: 0.135647
0.2338 --- loss_d: 0.112914
0.3118 --- loss_d: 0.201835
0.3897 --- loss_d: 0.143739
0.4677 --- loss_d: 0.122526
0.5456 --- loss_d: 0.214565
0.6235 --- loss_d: 0.504566
0.7015 --- loss_d: 0.103394
0.7794 --- loss_d: 0.196345
0.8574 --- loss_d: 0.262900
0.9353 --- loss_d: 0.135723
Epoch finished! Loss: 0.2718058718746761
Starting epoch 4/10.
0.0000 --- loss_d: 0.117013
0.0779 --- loss_d: 0.035716
0.1559 --- loss_d: 0.031741
0.2338 --- loss_d: 0.156991
0.3118 --- loss_d: 0.101945
0.3897 --- loss_d: 0.233550
0.4677 --- loss_d: 0.170446
0.5456 --- loss_d: 0.080099
0.6235 --- loss_d: 0.521997
0.7015 --- loss_d: 0.233417
0.7794 --- loss_d: 0.208605
0.8574 --- loss_d: 0.197535
0.9353 --- loss_d: 0.109632
Epoch finished! Loss: 0.22748657659394667
Starting epoch 5/10.
0.0000 --- loss_d: 0.081155
0.0779 --- loss_d: 0.110416
0.1559 --- loss_d: 0.112681
0.2338 --- loss_d: 0.352500
0.3118 --- loss_d: 0.271504
0.3897 --- loss_d: 0.076780
0.4677 --- loss_d: 0.121218
0.5456 --- loss_d: 0.127023
0.6235 --- loss_d: 0.537053
0.7015 --- loss_d: 0.042741
0.7794 --- loss_d: 0.097955
0.8574 --- loss_d: 0.025426
0.9353 --- loss_d: 0.032433
Epoch finished! Loss: 0.1760428434718051
Starting epoch 6/10.
0.0000 --- loss_d: 0.016601
0.0779 --- loss_d: 0.491286
0.1559 --- loss_d: 0.107495
0.2338 --- loss_d: 0.017901
0.3118 --- loss_d: 0.055778
0.3897 --- loss_d: 0.015823
0.4677 --- loss_d: 0.226260
0.5456 --- loss_d: 0.030146
0.6235 --- loss_d: 0.054503
0.7015 --- loss_d: 0.116211
0.7794 --- loss_d: 0.068865
0.8574 --- loss_d: 0.238208
0.9353 --- loss_d: 0.078567
Epoch finished! Loss: 0.1340974701943196
Starting epoch 7/10.
0.0000 --- loss_d: 0.109008
0.0779 --- loss_d: 0.006591
0.1559 --- loss_d: 0.070868
0.2338 --- loss_d: 0.024334
0.3118 --- loss_d: 0.022500
0.3897 --- loss_d: 0.001979
0.4677 --- loss_d: 0.059475
0.5456 --- loss_d: 0.006409
0.6235 --- loss_d: 0.021837
0.7015 --- loss_d: 0.327114
0.7794 --- loss_d: 0.055755
0.8574 --- loss_d: 0.019707
0.9353 --- loss_d: 0.109160
Epoch finished! Loss: 0.1329249059454014
Starting epoch 8/10.
0.0000 --- loss_d: 0.087380
0.0779 --- loss_d: 0.015311
0.1559 --- loss_d: 0.031807
0.2338 --- loss_d: 0.220603
0.3118 --- loss_d: 0.197325
0.3897 --- loss_d: 0.079576
0.4677 --- loss_d: 0.035130
0.5456 --- loss_d: 0.052431
0.6235 --- loss_d: 0.004508
0.7015 --- loss_d: 0.041964
0.7794 --- loss_d: 0.104362
0.8574 --- loss_d: 0.297894
0.9353 --- loss_d: 0.016153
Epoch finished! Loss: 0.09749183209987677
Starting epoch 9/10.
0.0000 --- loss_d: 0.006543
0.0779 --- loss_d: 0.034952
0.1559 --- loss_d: 0.008788
0.2338 --- loss_d: 0.013475
0.3118 --- loss_d: 0.020370
0.3897 --- loss_d: 0.006876
0.4677 --- loss_d: 0.003460
0.5456 --- loss_d: 0.013599
0.6235 --- loss_d: 0.003895
0.7015 --- loss_d: 0.009467
0.7794 --- loss_d: 0.011101
0.8574 --- loss_d: 0.030837
0.9353 --- loss_d: 0.103432
Epoch finished! Loss: 0.09356369503802853
Starting epoch 10/10.
0.0000 --- loss_d: 0.169634
0.0779 --- loss_d: 0.054687
0.1559 --- loss_d: 0.014988
0.2338 --- loss_d: 0.002071
0.3118 --- loss_d: 0.364498
0.3897 --- loss_d: 0.061410
0.4677 --- loss_d: 0.062536
0.5456 --- loss_d: 0.097210
0.6235 --- loss_d: 0.015436
0.7015 --- loss_d: 0.014893
0.7794 --- loss_d: 0.084712
0.8574 --- loss_d: 0.001398
0.9353 --- loss_d: 0.038103
Epoch finished! Loss: 0.08321103051730461
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.11764705882352941
[0.03187376 0.99988031 0.99999964 0.99999976 0.90261638 0.956155
 0.98083591 0.99898094 0.99540329 0.85510421 0.99652773 0.9971239
 0.99885833 0.6880905  0.33355117 0.9929617  0.97505641]
pred: 0.8648834682124502, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc004-nsrr

=== Test on chc005-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.653347
0.0778 --- loss_d: 0.464841
0.1556 --- loss_d: 0.881623
0.2335 --- loss_d: 0.490690
0.3113 --- loss_d: 0.345067
0.3891 --- loss_d: 1.133870
0.4669 --- loss_d: 0.710123
0.5447 --- loss_d: 0.806594
0.6226 --- loss_d: 0.684921
0.7004 --- loss_d: 0.562503
0.7782 --- loss_d: 0.252441
0.8560 --- loss_d: 0.488479
0.9339 --- loss_d: 0.653597
Epoch finished! Loss: 0.5838204708416015
Starting epoch 2/10.
0.0000 --- loss_d: 0.908830
0.0778 --- loss_d: 0.395145
0.1556 --- loss_d: 0.392983
0.2335 --- loss_d: 0.615470
0.3113 --- loss_d: 0.356821
0.3891 --- loss_d: 0.208858
0.4669 --- loss_d: 0.631911
0.5447 --- loss_d: 0.236495
0.6226 --- loss_d: 0.548358
0.7004 --- loss_d: 0.239992
0.7782 --- loss_d: 0.520895
0.8560 --- loss_d: 0.317090
0.9339 --- loss_d: 0.631864
Epoch finished! Loss: 0.46048594603780657
Starting epoch 3/10.
0.0000 --- loss_d: 0.351796
0.0778 --- loss_d: 0.149464
0.1556 --- loss_d: 0.183257
0.2335 --- loss_d: 0.087149
0.3113 --- loss_d: 0.198545
0.3891 --- loss_d: 0.145587
0.4669 --- loss_d: 0.849085
0.5447 --- loss_d: 0.228479
0.6226 --- loss_d: 0.220175
0.7004 --- loss_d: 0.063064
0.7782 --- loss_d: 0.022730
0.8560 --- loss_d: 0.735397
0.9339 --- loss_d: 0.333068
Epoch finished! Loss: 0.2983127294573933
Starting epoch 4/10.
0.0000 --- loss_d: 0.441304
0.0778 --- loss_d: 0.195939
0.1556 --- loss_d: 0.254721
0.2335 --- loss_d: 0.122591
0.3113 --- loss_d: 0.124203
0.3891 --- loss_d: 0.090862
0.4669 --- loss_d: 0.166548
0.5447 --- loss_d: 0.115558
0.6226 --- loss_d: 0.281403
0.7004 --- loss_d: 0.146952
0.7782 --- loss_d: 0.943164
0.8560 --- loss_d: 0.112074
0.9339 --- loss_d: 0.147310
Epoch finished! Loss: 0.25900447971071117
Starting epoch 5/10.
0.0000 --- loss_d: 0.042754
0.0778 --- loss_d: 0.110411
0.1556 --- loss_d: 0.129371
0.2335 --- loss_d: 0.192423
0.3113 --- loss_d: 0.126637
0.3891 --- loss_d: 0.027209
0.4669 --- loss_d: 0.319082
0.5447 --- loss_d: 0.050842
0.6226 --- loss_d: 0.066124
0.7004 --- loss_d: 0.435452
0.7782 --- loss_d: 0.162954
0.8560 --- loss_d: 0.134075
0.9339 --- loss_d: 0.070961
Epoch finished! Loss: 0.1844201535859611
Starting epoch 6/10.
0.0000 --- loss_d: 0.053972
0.0778 --- loss_d: 0.016372
0.1556 --- loss_d: 0.039626
0.2335 --- loss_d: 0.066677
0.3113 --- loss_d: 0.006137
0.3891 --- loss_d: 0.035056
0.4669 --- loss_d: 0.277991
0.5447 --- loss_d: 0.046207
0.6226 --- loss_d: 0.080095
0.7004 --- loss_d: 0.044052
0.7782 --- loss_d: 0.025695
0.8560 --- loss_d: 1.069863
0.9339 --- loss_d: 0.034407
Epoch finished! Loss: 0.13558499969440163
Starting epoch 7/10.
0.0000 --- loss_d: 0.020676
0.0778 --- loss_d: 0.112720
0.1556 --- loss_d: 0.089457
0.2335 --- loss_d: 0.017101
0.3113 --- loss_d: 0.128761
0.3891 --- loss_d: 0.025765
0.4669 --- loss_d: 0.228652
0.5447 --- loss_d: 0.011611
0.6226 --- loss_d: 0.014579
0.7004 --- loss_d: 0.188046
0.7782 --- loss_d: 0.184848
0.8560 --- loss_d: 0.129562
0.9339 --- loss_d: 0.007276
Epoch finished! Loss: 0.12702877909396193
Starting epoch 8/10.
0.0000 --- loss_d: 0.217763
0.0778 --- loss_d: 0.010331
0.1556 --- loss_d: 0.064483
0.2335 --- loss_d: 0.011551
0.3113 --- loss_d: 0.056075
0.3891 --- loss_d: 0.179654
0.4669 --- loss_d: 0.373237
0.5447 --- loss_d: 0.035167
0.6226 --- loss_d: 0.021420
0.7004 --- loss_d: 0.016953
0.7782 --- loss_d: 0.021408
0.8560 --- loss_d: 0.024315
0.9339 --- loss_d: 0.011363
Epoch finished! Loss: 0.08648747171537252
Starting epoch 9/10.
0.0000 --- loss_d: 0.011586
0.0778 --- loss_d: 0.447578
0.1556 --- loss_d: 0.177466
0.2335 --- loss_d: 0.013738
0.3113 --- loss_d: 0.001954
0.3891 --- loss_d: 0.051590
0.4669 --- loss_d: 0.005222
0.5447 --- loss_d: 0.046418
0.6226 --- loss_d: 0.001133
0.7004 --- loss_d: 0.013621
0.7782 --- loss_d: 0.032867
0.8560 --- loss_d: 0.000937
0.9339 --- loss_d: 0.026306
Epoch finished! Loss: 0.07038878144840055
Starting epoch 10/10.
0.0000 --- loss_d: 0.002878
0.0778 --- loss_d: 0.002623
0.1556 --- loss_d: 0.018885
0.2335 --- loss_d: 0.007392
0.3113 --- loss_d: 0.019480
0.3891 --- loss_d: 0.000890
0.4669 --- loss_d: 0.018199
0.5447 --- loss_d: 0.008137
0.6226 --- loss_d: 0.010420
0.7004 --- loss_d: 0.020536
0.7782 --- loss_d: 0.526256
0.8560 --- loss_d: 0.152050
0.9339 --- loss_d: 0.134435
Epoch finished! Loss: 0.0731534365954758
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.8
[0.00775422 0.08581847 0.05621622 0.04852614 0.00942848 0.00777969
 0.00591851 0.58020055 0.57347512 0.31079838 0.1132036  0.59259051
 0.00883264 0.20664707 0.25250882]
pred: 0.19064656058326362, label: 0
Right! Diagnosis: Other
Save 30mins of subject chc005-nsrr

=== Test on chc006-nsrr. train_data(1287), test_data(13) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.640647
0.0777 --- loss_d: 0.603099
0.1554 --- loss_d: 0.440974
0.2331 --- loss_d: 0.451015
0.3108 --- loss_d: 0.511403
0.3885 --- loss_d: 0.600651
0.4662 --- loss_d: 0.695271
0.5439 --- loss_d: 0.555916
0.6216 --- loss_d: 0.980390
0.6993 --- loss_d: 0.461183
0.7770 --- loss_d: 0.329606
0.8547 --- loss_d: 0.490716
0.9324 --- loss_d: 0.509905
Epoch finished! Loss: 0.5911807268857956
Starting epoch 2/10.
0.0000 --- loss_d: 0.513257
0.0777 --- loss_d: 0.444281
0.1554 --- loss_d: 0.484426
0.2331 --- loss_d: 0.279776
0.3108 --- loss_d: 1.007158
0.3885 --- loss_d: 0.385234
0.4662 --- loss_d: 0.261695
0.5439 --- loss_d: 0.399888
0.6216 --- loss_d: 0.859354
0.6993 --- loss_d: 0.197628
0.7770 --- loss_d: 0.226489
0.8547 --- loss_d: 0.727440
0.9324 --- loss_d: 0.217151
Epoch finished! Loss: 0.4295038143754937
Starting epoch 3/10.
0.0000 --- loss_d: 0.238772
0.0777 --- loss_d: 0.159395
0.1554 --- loss_d: 0.177394
0.2331 --- loss_d: 0.059957
0.3108 --- loss_d: 0.633430
0.3885 --- loss_d: 0.226336
0.4662 --- loss_d: 0.686861
0.5439 --- loss_d: 0.306714
0.6216 --- loss_d: 0.100939
0.6993 --- loss_d: 0.056704
0.7770 --- loss_d: 0.642973
0.8547 --- loss_d: 0.678201
0.9324 --- loss_d: 0.386072
Epoch finished! Loss: 0.2945704729645513
Starting epoch 4/10.
0.0000 --- loss_d: 0.257383
0.0777 --- loss_d: 0.236084
0.1554 --- loss_d: 0.279464
0.2331 --- loss_d: 0.091959
0.3108 --- loss_d: 0.045898
0.3885 --- loss_d: 0.054889
0.4662 --- loss_d: 0.081362
0.5439 --- loss_d: 0.031555
0.6216 --- loss_d: 0.277855
0.6993 --- loss_d: 0.147337
0.7770 --- loss_d: 0.141584
0.8547 --- loss_d: 0.131904
0.9324 --- loss_d: 0.251119
Epoch finished! Loss: 0.22576301719527692
Starting epoch 5/10.
0.0000 --- loss_d: 0.906550
0.0777 --- loss_d: 0.265213
0.1554 --- loss_d: 0.111983
0.2331 --- loss_d: 0.149843
0.3108 --- loss_d: 0.039047
0.3885 --- loss_d: 0.061324
0.4662 --- loss_d: 0.192415
0.5439 --- loss_d: 0.126879
0.6216 --- loss_d: 0.032763
0.6993 --- loss_d: 0.186417
0.7770 --- loss_d: 0.063196
0.8547 --- loss_d: 0.239257
0.9324 --- loss_d: 0.277671
Epoch finished! Loss: 0.17720846557494951
Starting epoch 6/10.
0.0000 --- loss_d: 0.123452
0.0777 --- loss_d: 0.096530
0.1554 --- loss_d: 0.083903
0.2331 --- loss_d: 0.038063
0.3108 --- loss_d: 0.023796
0.3885 --- loss_d: 0.011162
0.4662 --- loss_d: 0.183409
0.5439 --- loss_d: 0.093820
0.6216 --- loss_d: 0.062696
0.6993 --- loss_d: 0.023651
0.7770 --- loss_d: 0.089028
0.8547 --- loss_d: 0.265038
0.9324 --- loss_d: 0.044405
Epoch finished! Loss: 0.12829054662870476
Starting epoch 7/10.
0.0000 --- loss_d: 0.282462
0.0777 --- loss_d: 0.032498
0.1554 --- loss_d: 0.296997
0.2331 --- loss_d: 0.077699
0.3108 --- loss_d: 0.162723
0.3885 --- loss_d: 0.003828
0.4662 --- loss_d: 0.291771
0.5439 --- loss_d: 0.021756
0.6216 --- loss_d: 0.049818
0.6993 --- loss_d: 0.260169
0.7770 --- loss_d: 0.401028
0.8547 --- loss_d: 0.115778
0.9324 --- loss_d: 0.101545
Epoch finished! Loss: 0.09625360347854439
Starting epoch 8/10.
0.0000 --- loss_d: 0.025441
0.0777 --- loss_d: 0.019680
0.1554 --- loss_d: 0.051580
0.2331 --- loss_d: 0.015065
0.3108 --- loss_d: 0.043937
0.3885 --- loss_d: 0.009313
0.4662 --- loss_d: 0.186945
0.5439 --- loss_d: 0.243794
0.6216 --- loss_d: 0.245714
0.6993 --- loss_d: 0.024060
0.7770 --- loss_d: 0.008360
0.8547 --- loss_d: 0.022656
0.9324 --- loss_d: 0.089998
Epoch finished! Loss: 0.07429799484816613
Starting epoch 9/10.
0.0000 --- loss_d: 0.388930
0.0777 --- loss_d: 0.005861
0.1554 --- loss_d: 0.137277
0.2331 --- loss_d: 0.202397
0.3108 --- loss_d: 0.007272
0.3885 --- loss_d: 0.040301
0.4662 --- loss_d: 0.338950
0.5439 --- loss_d: 0.051447
0.6216 --- loss_d: 0.013336
0.6993 --- loss_d: 0.053916
0.7770 --- loss_d: 0.001486
0.8547 --- loss_d: 0.002089
0.9324 --- loss_d: 0.215661
Epoch finished! Loss: 0.06311684920638072
Starting epoch 10/10.
0.0000 --- loss_d: 0.023827
0.0777 --- loss_d: 0.002673
0.1554 --- loss_d: 0.046390
0.2331 --- loss_d: 0.002631
0.3108 --- loss_d: 0.044076
0.3885 --- loss_d: 0.003558
0.4662 --- loss_d: 0.000490
0.5439 --- loss_d: 0.022887
0.6216 --- loss_d: 0.021923
0.6993 --- loss_d: 0.003699
0.7770 --- loss_d: 0.287919
0.8547 --- loss_d: 0.070639
0.9324 --- loss_d: 0.052498
Epoch finished! Loss: 0.06082732064714946
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.0
[0.99999261 0.99997437 1.         1.         0.99999988 0.99968457
 0.99999118 0.96852541 0.99999917 0.99993396 0.99965107 0.99994338
 0.99982893]
pred: 0.9975018868079553, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc006-nsrr

=== Test on chc008-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.657840
0.0779 --- loss_d: 0.676778
0.1558 --- loss_d: 0.573159
0.2336 --- loss_d: 0.598752
0.3115 --- loss_d: 0.511521
0.3894 --- loss_d: 0.564564
0.4673 --- loss_d: 0.842223
0.5452 --- loss_d: 0.686392
0.6231 --- loss_d: 0.558509
0.7009 --- loss_d: 0.507919
0.7788 --- loss_d: 0.505573
0.8567 --- loss_d: 0.911717
0.9346 --- loss_d: 0.425256
Epoch finished! Loss: 0.6011937528382987
Starting epoch 2/10.
0.0000 --- loss_d: 0.502175
0.0779 --- loss_d: 0.615126
0.1558 --- loss_d: 0.443847
0.2336 --- loss_d: 0.327420
0.3115 --- loss_d: 0.423294
0.3894 --- loss_d: 0.294905
0.4673 --- loss_d: 0.412447
0.5452 --- loss_d: 0.330891
0.6231 --- loss_d: 0.347562
0.7009 --- loss_d: 0.160990
0.7788 --- loss_d: 0.231830
0.8567 --- loss_d: 0.306087
0.9346 --- loss_d: 0.416093
Epoch finished! Loss: 0.4701871852739714
Starting epoch 3/10.
0.0000 --- loss_d: 0.202381
0.0779 --- loss_d: 0.415793
0.1558 --- loss_d: 0.780044
0.2336 --- loss_d: 0.580601
0.3115 --- loss_d: 0.304471
0.3894 --- loss_d: 0.321410
0.4673 --- loss_d: 0.369599
0.5452 --- loss_d: 0.112534
0.6231 --- loss_d: 0.356887
0.7009 --- loss_d: 0.250839
0.7788 --- loss_d: 0.568993
0.8567 --- loss_d: 0.347148
0.9346 --- loss_d: 0.098601
Epoch finished! Loss: 0.3372802426456474
Starting epoch 4/10.
0.0000 --- loss_d: 0.120816
0.0779 --- loss_d: 0.072313
0.1558 --- loss_d: 0.163813
0.2336 --- loss_d: 0.126898
0.3115 --- loss_d: 0.160055
0.3894 --- loss_d: 0.296317
0.4673 --- loss_d: 0.224342
0.5452 --- loss_d: 0.161624
0.6231 --- loss_d: 0.328134
0.7009 --- loss_d: 0.162962
0.7788 --- loss_d: 0.138174
0.8567 --- loss_d: 0.379279
0.9346 --- loss_d: 0.295080
Epoch finished! Loss: 0.23826042689324822
Starting epoch 5/10.
0.0000 --- loss_d: 0.096972
0.0779 --- loss_d: 0.459788
0.1558 --- loss_d: 0.022082
0.2336 --- loss_d: 0.238911
0.3115 --- loss_d: 0.056254
0.3894 --- loss_d: 0.029638
0.4673 --- loss_d: 0.036913
0.5452 --- loss_d: 0.104226
0.6231 --- loss_d: 0.026003
0.7009 --- loss_d: 0.049494
0.7788 --- loss_d: 0.039741
0.8567 --- loss_d: 0.554794
0.9346 --- loss_d: 0.041188
Epoch finished! Loss: 0.18286363095103297
Starting epoch 6/10.
0.0000 --- loss_d: 0.125359
0.0779 --- loss_d: 0.237542
0.1558 --- loss_d: 0.441288
0.2336 --- loss_d: 0.057204
0.3115 --- loss_d: 0.022076
0.3894 --- loss_d: 0.055094
0.4673 --- loss_d: 0.008119
0.5452 --- loss_d: 0.026734
0.6231 --- loss_d: 0.105562
0.7009 --- loss_d: 0.398143
0.7788 --- loss_d: 0.300125
0.8567 --- loss_d: 0.051808
0.9346 --- loss_d: 0.086009
Epoch finished! Loss: 0.1544332737030345
Starting epoch 7/10.
0.0000 --- loss_d: 0.040093
0.0779 --- loss_d: 0.025364
0.1558 --- loss_d: 0.118632
0.2336 --- loss_d: 0.037390
0.3115 --- loss_d: 0.021528
0.3894 --- loss_d: 0.057135
0.4673 --- loss_d: 0.027307
0.5452 --- loss_d: 0.007209
0.6231 --- loss_d: 0.141543
0.7009 --- loss_d: 0.103499
0.7788 --- loss_d: 0.024647
0.8567 --- loss_d: 0.044600
0.9346 --- loss_d: 0.006889
Epoch finished! Loss: 0.1293230890551058
Starting epoch 8/10.
0.0000 --- loss_d: 0.003260
0.0779 --- loss_d: 0.044396
0.1558 --- loss_d: 0.052999
0.2336 --- loss_d: 0.186180
0.3115 --- loss_d: 0.326133
0.3894 --- loss_d: 0.328036
0.4673 --- loss_d: 0.050587
0.5452 --- loss_d: 0.217631
0.6231 --- loss_d: 0.079552
0.7009 --- loss_d: 0.068235
0.7788 --- loss_d: 0.165893
0.8567 --- loss_d: 0.151665
0.9346 --- loss_d: 0.062359
Epoch finished! Loss: 0.10726718093246745
Starting epoch 9/10.
0.0000 --- loss_d: 0.009429
0.0779 --- loss_d: 0.005271
0.1558 --- loss_d: 0.007876
0.2336 --- loss_d: 0.039227
0.3115 --- loss_d: 0.003909
0.3894 --- loss_d: 0.018337
0.4673 --- loss_d: 0.123517
0.5452 --- loss_d: 0.008838
0.6231 --- loss_d: 0.021275
0.7009 --- loss_d: 0.025693
0.7788 --- loss_d: 0.053139
0.8567 --- loss_d: 0.214547
0.9346 --- loss_d: 0.244043
Epoch finished! Loss: 0.05907563531889082
Starting epoch 10/10.
0.0000 --- loss_d: 0.003408
0.0779 --- loss_d: 0.030143
0.1558 --- loss_d: 0.002502
0.2336 --- loss_d: 0.025808
0.3115 --- loss_d: 0.063152
0.3894 --- loss_d: 0.299127
0.4673 --- loss_d: 0.099842
0.5452 --- loss_d: 0.010329
0.6231 --- loss_d: 0.054896
0.7009 --- loss_d: 0.043122
0.7788 --- loss_d: 0.020568
0.8567 --- loss_d: 0.014648
0.9346 --- loss_d: 0.012577
Epoch finished! Loss: 0.08089305332532604
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.375
[9.98100460e-01 9.57408011e-01 1.63427606e-01 9.97739792e-01
 5.88579297e-01 3.11862469e-01 9.93472219e-01 9.98151600e-01
 9.23391342e-01 9.95102406e-01 3.56283858e-02 6.10457361e-01
 3.65147918e-01 7.39980489e-02 5.28936148e-01 2.87532312e-04]
pred: 0.5963556621845783, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc008-nsrr

=== Test on chc009-nsrr. train_data(1286), test_data(14) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.665197
0.0778 --- loss_d: 1.198795
0.1555 --- loss_d: 0.447282
0.2333 --- loss_d: 0.685941
0.3110 --- loss_d: 0.423564
0.3888 --- loss_d: 0.443028
0.4666 --- loss_d: 0.425385
0.5443 --- loss_d: 0.435782
0.6221 --- loss_d: 0.353538
0.6998 --- loss_d: 0.664065
0.7776 --- loss_d: 0.378197
0.8554 --- loss_d: 0.460300
0.9331 --- loss_d: 0.555729
Epoch finished! Loss: 0.5989772048778832
Starting epoch 2/10.
0.0000 --- loss_d: 0.374700
0.0778 --- loss_d: 0.302289
0.1555 --- loss_d: 0.766534
0.2333 --- loss_d: 0.650735
0.3110 --- loss_d: 0.643914
0.3888 --- loss_d: 0.542497
0.4666 --- loss_d: 0.449301
0.5443 --- loss_d: 0.604675
0.6221 --- loss_d: 0.956977
0.6998 --- loss_d: 0.265358
0.7776 --- loss_d: 0.279914
0.8554 --- loss_d: 0.783423
0.9331 --- loss_d: 0.617641
Epoch finished! Loss: 0.4917164258658886
Starting epoch 3/10.
0.0000 --- loss_d: 0.289767
0.0778 --- loss_d: 0.279514
0.1555 --- loss_d: 0.194703
0.2333 --- loss_d: 0.615794
0.3110 --- loss_d: 0.579892
0.3888 --- loss_d: 0.200909
0.4666 --- loss_d: 0.364700
0.5443 --- loss_d: 0.142120
0.6221 --- loss_d: 0.190052
0.6998 --- loss_d: 0.117469
0.7776 --- loss_d: 0.090963
0.8554 --- loss_d: 0.058393
0.9331 --- loss_d: 0.128481
Epoch finished! Loss: 0.2719333251006901
Starting epoch 4/10.
0.0000 --- loss_d: 0.173779
0.0778 --- loss_d: 0.075709
0.1555 --- loss_d: 0.359082
0.2333 --- loss_d: 0.122856
0.3110 --- loss_d: 0.067144
0.3888 --- loss_d: 0.214544
0.4666 --- loss_d: 0.137619
0.5443 --- loss_d: 0.233229
0.6221 --- loss_d: 0.329247
0.6998 --- loss_d: 0.216693
0.7776 --- loss_d: 0.248900
0.8554 --- loss_d: 0.166236
0.9331 --- loss_d: 0.071604
Epoch finished! Loss: 0.23964012555370573
Starting epoch 5/10.
0.0000 --- loss_d: 0.014373
0.0778 --- loss_d: 0.023507
0.1555 --- loss_d: 0.033973
0.2333 --- loss_d: 0.222949
0.3110 --- loss_d: 0.043948
0.3888 --- loss_d: 0.088469
0.4666 --- loss_d: 0.112903
0.5443 --- loss_d: 0.074095
0.6221 --- loss_d: 0.209167
0.6998 --- loss_d: 0.239018
0.7776 --- loss_d: 0.252719
0.8554 --- loss_d: 0.042634
0.9331 --- loss_d: 0.213570
Epoch finished! Loss: 0.15965955996944103
Starting epoch 6/10.
0.0000 --- loss_d: 0.085268
0.0778 --- loss_d: 0.255827
0.1555 --- loss_d: 0.087624
0.2333 --- loss_d: 0.048152
0.3110 --- loss_d: 0.030855
0.3888 --- loss_d: 0.014316
0.4666 --- loss_d: 0.037959
0.5443 --- loss_d: 0.050028
0.6221 --- loss_d: 0.012607
0.6998 --- loss_d: 0.195517
0.7776 --- loss_d: 0.088851
0.8554 --- loss_d: 0.020911
0.9331 --- loss_d: 0.047595
Epoch finished! Loss: 0.09735604110483109
Starting epoch 7/10.
0.0000 --- loss_d: 0.220966
0.0778 --- loss_d: 0.001727
0.1555 --- loss_d: 0.022266
0.2333 --- loss_d: 0.003748
0.3110 --- loss_d: 0.597676
0.3888 --- loss_d: 0.441911
0.4666 --- loss_d: 0.016900
0.5443 --- loss_d: 0.023837
0.6221 --- loss_d: 0.021306
0.6998 --- loss_d: 0.078095
0.7776 --- loss_d: 0.003040
0.8554 --- loss_d: 0.013166
0.9331 --- loss_d: 0.008718
Epoch finished! Loss: 0.08086342829074056
Starting epoch 8/10.
0.0000 --- loss_d: 0.018080
0.0778 --- loss_d: 0.001022
0.1555 --- loss_d: 0.009761
0.2333 --- loss_d: 0.016044
0.3110 --- loss_d: 0.003270
0.3888 --- loss_d: 0.009649
0.4666 --- loss_d: 0.003117
0.5443 --- loss_d: 0.004241
0.6221 --- loss_d: 0.010770
0.6998 --- loss_d: 0.129069
0.7776 --- loss_d: 0.059135
0.8554 --- loss_d: 0.007171
0.9331 --- loss_d: 0.084588
Epoch finished! Loss: 0.06728954810432697
Starting epoch 9/10.
0.0000 --- loss_d: 0.021001
0.0778 --- loss_d: 0.241597
0.1555 --- loss_d: 0.002975
0.2333 --- loss_d: 0.005231
0.3110 --- loss_d: 0.016406
0.3888 --- loss_d: 0.006555
0.4666 --- loss_d: 0.005904
0.5443 --- loss_d: 0.004281
0.6221 --- loss_d: 0.011306
0.6998 --- loss_d: 0.070512
0.7776 --- loss_d: 0.333331
0.8554 --- loss_d: 0.012899
0.9331 --- loss_d: 0.015738
Epoch finished! Loss: 0.06345421514288319
Starting epoch 10/10.
0.0000 --- loss_d: 0.017960
0.0778 --- loss_d: 0.010904
0.1555 --- loss_d: 0.002993
0.2333 --- loss_d: 0.059816
0.3110 --- loss_d: 0.017571
0.3888 --- loss_d: 0.015591
0.4666 --- loss_d: 0.019548
0.5443 --- loss_d: 0.014044
0.6221 --- loss_d: 0.015164
0.6998 --- loss_d: 0.048217
0.7776 --- loss_d: 0.027364
0.8554 --- loss_d: 0.005983
0.9331 --- loss_d: 0.019532
Epoch finished! Loss: 0.031812874470972474
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.9285714285714286
[3.83678749e-02 1.72981934e-03 5.88460360e-04 1.48467510e-03
 7.76997395e-03 2.78180428e-02 5.44871330e-01 3.36445928e-01
 2.12479220e-03 8.00718646e-03 2.33948119e-02 4.65280026e-01
 2.01782747e-03 4.24907688e-04]
pred: 0.10430897544678633, label: 0
Right! Diagnosis: Other
Save 30mins of subject chc009-nsrr

=== Test on chc010-nsrr. train_data(1286), test_data(14) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.627500
0.0778 --- loss_d: 0.478359
0.1555 --- loss_d: 0.494885
0.2333 --- loss_d: 0.748302
0.3110 --- loss_d: 0.575210
0.3888 --- loss_d: 0.518354
0.4666 --- loss_d: 0.519945
0.5443 --- loss_d: 0.850423
0.6221 --- loss_d: 0.482206
0.6998 --- loss_d: 0.697983
0.7776 --- loss_d: 0.805456
0.8554 --- loss_d: 0.308434
0.9331 --- loss_d: 0.383554
Epoch finished! Loss: 0.5749550121836364
Starting epoch 2/10.
0.0000 --- loss_d: 0.339548
0.0778 --- loss_d: 0.352956
0.1555 --- loss_d: 0.484060
0.2333 --- loss_d: 0.415544
0.3110 --- loss_d: 0.748041
0.3888 --- loss_d: 0.352604
0.4666 --- loss_d: 0.228408
0.5443 --- loss_d: 0.511978
0.6221 --- loss_d: 0.481655
0.6998 --- loss_d: 0.353673
0.7776 --- loss_d: 0.674946
0.8554 --- loss_d: 0.399501
0.9331 --- loss_d: 0.461080
Epoch finished! Loss: 0.44618760072626173
Starting epoch 3/10.
0.0000 --- loss_d: 0.206048
0.0778 --- loss_d: 0.181256
0.1555 --- loss_d: 0.180226
0.2333 --- loss_d: 0.804919
0.3110 --- loss_d: 0.333179
0.3888 --- loss_d: 0.640877
0.4666 --- loss_d: 0.324594
0.5443 --- loss_d: 0.320952
0.6221 --- loss_d: 0.476507
0.6998 --- loss_d: 0.327087
0.7776 --- loss_d: 0.265550
0.8554 --- loss_d: 0.258188
0.9331 --- loss_d: 0.118395
Epoch finished! Loss: 0.2903027841821313
Starting epoch 4/10.
0.0000 --- loss_d: 0.070151
0.0778 --- loss_d: 0.091822
0.1555 --- loss_d: 0.222731
0.2333 --- loss_d: 0.480167
0.3110 --- loss_d: 0.121525
0.3888 --- loss_d: 0.216967
0.4666 --- loss_d: 0.311567
0.5443 --- loss_d: 0.087998
0.6221 --- loss_d: 0.107837
0.6998 --- loss_d: 0.544616
0.7776 --- loss_d: 0.197447
0.8554 --- loss_d: 0.248810
0.9331 --- loss_d: 0.092401
Epoch finished! Loss: 0.21262359401589492
Starting epoch 5/10.
0.0000 --- loss_d: 0.116110
0.0778 --- loss_d: 0.032855
0.1555 --- loss_d: 0.462378
0.2333 --- loss_d: 0.098981
0.3110 --- loss_d: 0.494779
0.3888 --- loss_d: 0.067736
0.4666 --- loss_d: 0.164945
0.5443 --- loss_d: 0.051003
0.6221 --- loss_d: 0.090909
0.6998 --- loss_d: 0.573841
0.7776 --- loss_d: 0.074044
0.8554 --- loss_d: 0.508130
0.9331 --- loss_d: 0.208626
Epoch finished! Loss: 0.21067445201333612
Starting epoch 6/10.
0.0000 --- loss_d: 0.033145
0.0778 --- loss_d: 0.303476
0.1555 --- loss_d: 0.063233
0.2333 --- loss_d: 0.265805
0.3110 --- loss_d: 0.037168
0.3888 --- loss_d: 0.022868
0.4666 --- loss_d: 0.164244
0.5443 --- loss_d: 0.068427
0.6221 --- loss_d: 0.312818
0.6998 --- loss_d: 0.144375
0.7776 --- loss_d: 0.320380
0.8554 --- loss_d: 0.076938
0.9331 --- loss_d: 0.048442
Epoch finished! Loss: 0.16672776250197785
Starting epoch 7/10.
0.0000 --- loss_d: 0.031115
0.0778 --- loss_d: 0.034567
0.1555 --- loss_d: 0.016749
0.2333 --- loss_d: 0.037360
0.3110 --- loss_d: 0.012013
0.3888 --- loss_d: 0.026018
0.4666 --- loss_d: 0.034923
0.5443 --- loss_d: 0.073039
0.6221 --- loss_d: 0.155132
0.6998 --- loss_d: 0.028503
0.7776 --- loss_d: 0.033042
0.8554 --- loss_d: 0.154597
0.9331 --- loss_d: 0.021668
Epoch finished! Loss: 0.09615279708759772
Starting epoch 8/10.
0.0000 --- loss_d: 0.043029
0.0778 --- loss_d: 0.227193
0.1555 --- loss_d: 0.046556
0.2333 --- loss_d: 0.045892
0.3110 --- loss_d: 0.012131
0.3888 --- loss_d: 0.006536
0.4666 --- loss_d: 0.086287
0.5443 --- loss_d: 0.058937
0.6221 --- loss_d: 0.044683
0.6998 --- loss_d: 0.023343
0.7776 --- loss_d: 0.095222
0.8554 --- loss_d: 0.052128
0.9331 --- loss_d: 0.265680
Epoch finished! Loss: 0.10907396073616837
Starting epoch 9/10.
0.0000 --- loss_d: 0.039419
0.0778 --- loss_d: 0.006116
0.1555 --- loss_d: 0.077341
0.2333 --- loss_d: 0.016108
0.3110 --- loss_d: 0.015358
0.3888 --- loss_d: 0.007691
0.4666 --- loss_d: 0.046676
0.5443 --- loss_d: 0.008787
0.6221 --- loss_d: 0.051989
0.6998 --- loss_d: 0.067956
0.7776 --- loss_d: 0.134356
0.8554 --- loss_d: 0.035672
0.9331 --- loss_d: 0.004846
Epoch finished! Loss: 0.10932593405505031
Starting epoch 10/10.
0.0000 --- loss_d: 0.010398
0.0778 --- loss_d: 0.012435
0.1555 --- loss_d: 0.004031
0.2333 --- loss_d: 0.000728
0.3110 --- loss_d: 0.002268
0.3888 --- loss_d: 0.005889
0.4666 --- loss_d: 0.007542
0.5443 --- loss_d: 0.012052
0.6221 --- loss_d: 0.021657
0.6998 --- loss_d: 0.002614
0.7776 --- loss_d: 0.024489
0.8554 --- loss_d: 0.001892
0.9331 --- loss_d: 0.005802
Epoch finished! Loss: 0.040914783742891814
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.14285714285714285
[0.9789626  0.94845301 0.96191186 0.99987519 0.99501848 0.60459
 0.98967731 0.96482229 0.99998081 0.44798008 0.95155495 0.97797251
 0.43316251 0.98841172]
pred: 0.8744552369628634, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc010-nsrr

=== Test on chc012-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.635825
0.0778 --- loss_d: 0.815155
0.1556 --- loss_d: 0.569458
0.2335 --- loss_d: 0.687497
0.3113 --- loss_d: 0.464939
0.3891 --- loss_d: 0.595905
0.4669 --- loss_d: 1.146694
0.5447 --- loss_d: 0.497237
0.6226 --- loss_d: 0.478391
0.7004 --- loss_d: 0.646268
0.7782 --- loss_d: 0.509456
0.8560 --- loss_d: 0.516004
0.9339 --- loss_d: 0.682501
Epoch finished! Loss: 0.6004831517348066
Starting epoch 2/10.
0.0000 --- loss_d: 0.852671
0.0778 --- loss_d: 0.611684
0.1556 --- loss_d: 0.804533
0.2335 --- loss_d: 0.477463
0.3113 --- loss_d: 0.517772
0.3891 --- loss_d: 0.286563
0.4669 --- loss_d: 0.720855
0.5447 --- loss_d: 0.109122
0.6226 --- loss_d: 0.123904
0.7004 --- loss_d: 0.510136
0.7782 --- loss_d: 0.673514
0.8560 --- loss_d: 0.727589
0.9339 --- loss_d: 0.176287
Epoch finished! Loss: 0.4427807485917583
Starting epoch 3/10.
0.0000 --- loss_d: 0.445537
0.0778 --- loss_d: 0.159761
0.1556 --- loss_d: 0.245119
0.2335 --- loss_d: 0.572800
0.3113 --- loss_d: 0.202618
0.3891 --- loss_d: 0.212804
0.4669 --- loss_d: 0.168677
0.5447 --- loss_d: 0.045549
0.6226 --- loss_d: 0.274495
0.7004 --- loss_d: 0.217413
0.7782 --- loss_d: 0.685752
0.8560 --- loss_d: 0.077305
0.9339 --- loss_d: 0.144171
Epoch finished! Loss: 0.2972846964985365
Starting epoch 4/10.
0.0000 --- loss_d: 0.161432
0.0778 --- loss_d: 0.098702
0.1556 --- loss_d: 0.218689
0.2335 --- loss_d: 0.089044
0.3113 --- loss_d: 0.080543
0.3891 --- loss_d: 0.246420
0.4669 --- loss_d: 0.135942
0.5447 --- loss_d: 0.105198
0.6226 --- loss_d: 0.126247
0.7004 --- loss_d: 0.085533
0.7782 --- loss_d: 0.575262
0.8560 --- loss_d: 0.114314
0.9339 --- loss_d: 0.175045
Epoch finished! Loss: 0.19736830794863636
Starting epoch 5/10.
0.0000 --- loss_d: 0.364399
0.0778 --- loss_d: 0.329419
0.1556 --- loss_d: 0.077373
0.2335 --- loss_d: 0.048195
0.3113 --- loss_d: 0.020498
0.3891 --- loss_d: 0.068573
0.4669 --- loss_d: 0.126566
0.5447 --- loss_d: 0.038957
0.6226 --- loss_d: 0.159935
0.7004 --- loss_d: 0.036193
0.7782 --- loss_d: 0.444340
0.8560 --- loss_d: 0.193617
0.9339 --- loss_d: 0.841537
Epoch finished! Loss: 0.18834547822189052
Starting epoch 6/10.
0.0000 --- loss_d: 0.043494
0.0778 --- loss_d: 0.045637
0.1556 --- loss_d: 0.011445
0.2335 --- loss_d: 0.070877
0.3113 --- loss_d: 0.016537
0.3891 --- loss_d: 0.247267
0.4669 --- loss_d: 0.008922
0.5447 --- loss_d: 0.138005
0.6226 --- loss_d: 0.065832
0.7004 --- loss_d: 0.061843
0.7782 --- loss_d: 0.061414
0.8560 --- loss_d: 0.412510
0.9339 --- loss_d: 0.015554
Epoch finished! Loss: 0.10061561313887069
Starting epoch 7/10.
0.0000 --- loss_d: 0.071542
0.0778 --- loss_d: 0.485971
0.1556 --- loss_d: 0.002143
0.2335 --- loss_d: 0.042790
0.3113 --- loss_d: 0.155882
0.3891 --- loss_d: 0.009826
0.4669 --- loss_d: 0.046780
0.5447 --- loss_d: 0.111999
0.6226 --- loss_d: 0.010837
0.7004 --- loss_d: 0.009834
0.7782 --- loss_d: 0.122254
0.8560 --- loss_d: 0.003645
0.9339 --- loss_d: 0.054021
Epoch finished! Loss: 0.0856072084261541
Starting epoch 8/10.
0.0000 --- loss_d: 0.002309
0.0778 --- loss_d: 0.003465
0.1556 --- loss_d: 0.001634
0.2335 --- loss_d: 0.070226
0.3113 --- loss_d: 0.100749
0.3891 --- loss_d: 0.114060
0.4669 --- loss_d: 0.008518
0.5447 --- loss_d: 0.001732
0.6226 --- loss_d: 0.102305
0.7004 --- loss_d: 0.018220
0.7782 --- loss_d: 0.378485
0.8560 --- loss_d: 0.085913
0.9339 --- loss_d: 0.674883
Epoch finished! Loss: 0.08888456812974255
Starting epoch 9/10.
0.0000 --- loss_d: 0.114407
0.0778 --- loss_d: 0.076318
0.1556 --- loss_d: 0.149941
0.2335 --- loss_d: 0.058105
0.3113 --- loss_d: 0.324500
0.3891 --- loss_d: 0.027679
0.4669 --- loss_d: 0.137080
0.5447 --- loss_d: 0.025937
0.6226 --- loss_d: 0.001168
0.7004 --- loss_d: 0.006821
0.7782 --- loss_d: 0.036541
0.8560 --- loss_d: 0.001623
0.9339 --- loss_d: 0.036891
Epoch finished! Loss: 0.060946725756366504
Starting epoch 10/10.
0.0000 --- loss_d: 0.002588
0.0778 --- loss_d: 0.004348
0.1556 --- loss_d: 0.003790
0.2335 --- loss_d: 0.000293
0.3113 --- loss_d: 0.001376
0.3891 --- loss_d: 0.004187
0.4669 --- loss_d: 0.005469
0.5447 --- loss_d: 0.000175
0.6226 --- loss_d: 0.001430
0.7004 --- loss_d: 0.001928
0.7782 --- loss_d: 0.008363
0.8560 --- loss_d: 0.003550
0.9339 --- loss_d: 0.012116
Epoch finished! Loss: 0.030616732841053818
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.13333333333333333
[0.99821681 0.99998963 0.99350983 0.99785382 0.99996853 0.91030383
 0.20026626 0.99964559 0.99963927 0.99966896 0.999668   0.99962616
 0.99919552 0.2583029  0.99250799]
pred: 0.8898908724387486, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc012-nsrr

=== Test on chc013-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.777145
0.0778 --- loss_d: 0.403529
0.1556 --- loss_d: 0.359449
0.2335 --- loss_d: 0.748137
0.3113 --- loss_d: 0.608207
0.3891 --- loss_d: 0.620265
0.4669 --- loss_d: 0.322793
0.5447 --- loss_d: 0.427310
0.6226 --- loss_d: 0.361087
0.7004 --- loss_d: 0.660651
0.7782 --- loss_d: 0.534168
0.8560 --- loss_d: 0.414646
0.9339 --- loss_d: 0.410721
Epoch finished! Loss: 0.5968841988360509
Starting epoch 2/10.
0.0000 --- loss_d: 0.893882
0.0778 --- loss_d: 0.413743
0.1556 --- loss_d: 0.472060
0.2335 --- loss_d: 0.695361
0.3113 --- loss_d: 0.224223
0.3891 --- loss_d: 0.228060
0.4669 --- loss_d: 0.486578
0.5447 --- loss_d: 1.045217
0.6226 --- loss_d: 0.410975
0.7004 --- loss_d: 0.627258
0.7782 --- loss_d: 0.463555
0.8560 --- loss_d: 0.827664
0.9339 --- loss_d: 0.338108
Epoch finished! Loss: 0.4645719025284052
Starting epoch 3/10.
0.0000 --- loss_d: 0.299992
0.0778 --- loss_d: 0.140413
0.1556 --- loss_d: 0.178172
0.2335 --- loss_d: 0.046967
0.3113 --- loss_d: 0.277629
0.3891 --- loss_d: 0.452808
0.4669 --- loss_d: 0.242194
0.5447 --- loss_d: 0.169134
0.6226 --- loss_d: 0.168365
0.7004 --- loss_d: 0.345235
0.7782 --- loss_d: 0.152709
0.8560 --- loss_d: 0.337597
0.9339 --- loss_d: 0.660451
Epoch finished! Loss: 0.2861510738002835
Starting epoch 4/10.
0.0000 --- loss_d: 0.258857
0.0778 --- loss_d: 0.038635
0.1556 --- loss_d: 0.629711
0.2335 --- loss_d: 0.099148
0.3113 --- loss_d: 0.485597
0.3891 --- loss_d: 0.217778
0.4669 --- loss_d: 0.085541
0.5447 --- loss_d: 0.136381
0.6226 --- loss_d: 0.407254
0.7004 --- loss_d: 0.191944
0.7782 --- loss_d: 0.198787
0.8560 --- loss_d: 0.058387
0.9339 --- loss_d: 0.126477
Epoch finished! Loss: 0.22528019433957525
Starting epoch 5/10.
0.0000 --- loss_d: 0.373762
0.0778 --- loss_d: 0.102269
0.1556 --- loss_d: 0.103521
0.2335 --- loss_d: 0.302748
0.3113 --- loss_d: 0.368615
0.3891 --- loss_d: 0.059856
0.4669 --- loss_d: 0.043326
0.5447 --- loss_d: 0.057833
0.6226 --- loss_d: 0.307484
0.7004 --- loss_d: 0.111638
0.7782 --- loss_d: 0.176437
0.8560 --- loss_d: 0.142326
0.9339 --- loss_d: 0.031396
Epoch finished! Loss: 0.18556389429431874
Starting epoch 6/10.
0.0000 --- loss_d: 0.042462
0.0778 --- loss_d: 0.027233
0.1556 --- loss_d: 0.274897
0.2335 --- loss_d: 0.166130
0.3113 --- loss_d: 0.074831
0.3891 --- loss_d: 0.059976
0.4669 --- loss_d: 0.174025
0.5447 --- loss_d: 0.028810
0.6226 --- loss_d: 0.044555
0.7004 --- loss_d: 0.434166
0.7782 --- loss_d: 0.078313
0.8560 --- loss_d: 0.127336
0.9339 --- loss_d: 0.030271
Epoch finished! Loss: 0.12112718924618093
Starting epoch 7/10.
0.0000 --- loss_d: 0.027235
0.0778 --- loss_d: 0.020918
0.1556 --- loss_d: 0.011417
0.2335 --- loss_d: 0.056139
0.3113 --- loss_d: 0.163126
0.3891 --- loss_d: 0.053376
0.4669 --- loss_d: 0.108541
0.5447 --- loss_d: 0.006200
0.6226 --- loss_d: 0.007060
0.7004 --- loss_d: 0.338312
0.7782 --- loss_d: 0.117035
0.8560 --- loss_d: 0.056779
0.9339 --- loss_d: 0.535866
Epoch finished! Loss: 0.0941542867822136
Starting epoch 8/10.
0.0000 --- loss_d: 0.006864
0.0778 --- loss_d: 0.015153
0.1556 --- loss_d: 0.018964
0.2335 --- loss_d: 0.013853
0.3113 --- loss_d: 0.019567
0.3891 --- loss_d: 0.019411
0.4669 --- loss_d: 0.035733
0.5447 --- loss_d: 0.030873
0.6226 --- loss_d: 0.025437
0.7004 --- loss_d: 0.221841
0.7782 --- loss_d: 0.031670
0.8560 --- loss_d: 0.019738
0.9339 --- loss_d: 0.011668
Epoch finished! Loss: 0.10094247102097142
Starting epoch 9/10.
0.0000 --- loss_d: 0.022739
0.0778 --- loss_d: 0.016030
0.1556 --- loss_d: 0.001764
0.2335 --- loss_d: 0.005023
0.3113 --- loss_d: 0.019077
0.3891 --- loss_d: 0.047371
0.4669 --- loss_d: 0.006344
0.5447 --- loss_d: 0.004103
0.6226 --- loss_d: 0.018702
0.7004 --- loss_d: 0.020871
0.7782 --- loss_d: 0.010284
0.8560 --- loss_d: 0.407024
0.9339 --- loss_d: 0.001989
Epoch finished! Loss: 0.06910834964401147
Starting epoch 10/10.
0.0000 --- loss_d: 0.014805
0.0778 --- loss_d: 0.014118
0.1556 --- loss_d: 0.029581
0.2335 --- loss_d: 0.097098
0.3113 --- loss_d: 0.011400
0.3891 --- loss_d: 0.014047
0.4669 --- loss_d: 0.007312
0.5447 --- loss_d: 0.025954
0.6226 --- loss_d: 0.005372
0.7004 --- loss_d: 0.002493
0.7782 --- loss_d: 0.064494
0.8560 --- loss_d: 0.135161
0.9339 --- loss_d: 0.078681
Epoch finished! Loss: 0.04575376924981356
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.0
[0.99999881 0.99978417 0.99967933 0.99999034 0.99993324 0.99915147
 0.82730049 0.99963152 0.99636239 0.99986255 0.99953175 0.99993074
 0.99893683 0.91148597 0.99998558]
pred: 0.9821043451627095, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc013-nsrr

=== Test on chc014-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.671726
0.0778 --- loss_d: 0.461530
0.1556 --- loss_d: 0.427772
0.2335 --- loss_d: 0.638197
0.3113 --- loss_d: 0.860616
0.3891 --- loss_d: 0.665094
0.4669 --- loss_d: 0.533123
0.5447 --- loss_d: 0.486840
0.6226 --- loss_d: 0.558006
0.7004 --- loss_d: 0.708375
0.7782 --- loss_d: 0.481150
0.8560 --- loss_d: 0.685988
0.9339 --- loss_d: 0.512493
Epoch finished! Loss: 0.609477254038211
Starting epoch 2/10.
0.0000 --- loss_d: 0.594549
0.0778 --- loss_d: 0.494374
0.1556 --- loss_d: 0.651862
0.2335 --- loss_d: 0.153016
0.3113 --- loss_d: 0.415602
0.3891 --- loss_d: 0.437315
0.4669 --- loss_d: 0.366038
0.5447 --- loss_d: 0.801925
0.6226 --- loss_d: 0.327196
0.7004 --- loss_d: 0.462612
0.7782 --- loss_d: 0.544593
0.8560 --- loss_d: 0.502142
0.9339 --- loss_d: 0.439556
Epoch finished! Loss: 0.5160870089894161
Starting epoch 3/10.
0.0000 --- loss_d: 0.293043
0.0778 --- loss_d: 0.833818
0.1556 --- loss_d: 0.327772
0.2335 --- loss_d: 0.361326
0.3113 --- loss_d: 0.317122
0.3891 --- loss_d: 0.506665
0.4669 --- loss_d: 0.229888
0.5447 --- loss_d: 0.388179
0.6226 --- loss_d: 0.627068
0.7004 --- loss_d: 0.503601
0.7782 --- loss_d: 0.208413
0.8560 --- loss_d: 0.332768
0.9339 --- loss_d: 0.175180
Epoch finished! Loss: 0.3998965975479223
Starting epoch 4/10.
0.0000 --- loss_d: 0.341782
0.0778 --- loss_d: 0.210111
0.1556 --- loss_d: 0.067751
0.2335 --- loss_d: 0.487286
0.3113 --- loss_d: 0.217218
0.3891 --- loss_d: 0.198984
0.4669 --- loss_d: 0.147553
0.5447 --- loss_d: 0.013556
0.6226 --- loss_d: 0.122724
0.7004 --- loss_d: 0.213703
0.7782 --- loss_d: 0.116775
0.8560 --- loss_d: 0.268790
0.9339 --- loss_d: 0.247231
Epoch finished! Loss: 0.24845657094556373
Starting epoch 5/10.
0.0000 --- loss_d: 0.119378
0.0778 --- loss_d: 0.297203
0.1556 --- loss_d: 0.097967
0.2335 --- loss_d: 0.050375
0.3113 --- loss_d: 0.144689
0.3891 --- loss_d: 0.088182
0.4669 --- loss_d: 0.077635
0.5447 --- loss_d: 0.030929
0.6226 --- loss_d: 0.154790
0.7004 --- loss_d: 0.089533
0.7782 --- loss_d: 0.553483
0.8560 --- loss_d: 0.130540
0.9339 --- loss_d: 0.178040
Epoch finished! Loss: 0.2054462659289129
Starting epoch 6/10.
0.0000 --- loss_d: 0.153948
0.0778 --- loss_d: 0.066923
0.1556 --- loss_d: 0.073214
0.2335 --- loss_d: 0.086233
0.3113 --- loss_d: 0.064647
0.3891 --- loss_d: 0.070214
0.4669 --- loss_d: 0.032618
0.5447 --- loss_d: 0.342617
0.6226 --- loss_d: 0.072955
0.7004 --- loss_d: 0.101281
0.7782 --- loss_d: 0.028939
0.8560 --- loss_d: 0.067187
0.9339 --- loss_d: 0.115322
Epoch finished! Loss: 0.1478532585897483
Starting epoch 7/10.
0.0000 --- loss_d: 0.009208
0.0778 --- loss_d: 0.046551
0.1556 --- loss_d: 0.205471
0.2335 --- loss_d: 0.099515
0.3113 --- loss_d: 0.147224
0.3891 --- loss_d: 0.033028
0.4669 --- loss_d: 0.077513
0.5447 --- loss_d: 0.043792
0.6226 --- loss_d: 0.009219
0.7004 --- loss_d: 0.026505
0.7782 --- loss_d: 0.059325
0.8560 --- loss_d: 0.088908
0.9339 --- loss_d: 0.014153
Epoch finished! Loss: 0.09912325508412323
Starting epoch 8/10.
0.0000 --- loss_d: 0.048547
0.0778 --- loss_d: 0.003632
0.1556 --- loss_d: 0.351866
0.2335 --- loss_d: 0.012668
0.3113 --- loss_d: 0.003984
0.3891 --- loss_d: 0.064321
0.4669 --- loss_d: 0.208899
0.5447 --- loss_d: 0.044114
0.6226 --- loss_d: 0.124002
0.7004 --- loss_d: 0.026858
0.7782 --- loss_d: 0.027620
0.8560 --- loss_d: 0.031877
0.9339 --- loss_d: 0.006367
Epoch finished! Loss: 0.10743852189352765
Starting epoch 9/10.
0.0000 --- loss_d: 0.065654
0.0778 --- loss_d: 0.437661
0.1556 --- loss_d: 0.011951
0.2335 --- loss_d: 0.019796
0.3113 --- loss_d: 0.032827
0.3891 --- loss_d: 0.021067
0.4669 --- loss_d: 0.251415
0.5447 --- loss_d: 0.043388
0.6226 --- loss_d: 0.357039
0.7004 --- loss_d: 0.210879
0.7782 --- loss_d: 0.009298
0.8560 --- loss_d: 0.042411
0.9339 --- loss_d: 0.145620
Epoch finished! Loss: 0.10026430456218804
Starting epoch 10/10.
0.0000 --- loss_d: 0.533252
0.0778 --- loss_d: 0.140012
0.1556 --- loss_d: 0.045833
0.2335 --- loss_d: 0.013149
0.3113 --- loss_d: 0.452335
0.3891 --- loss_d: 0.079163
0.4669 --- loss_d: 0.005627
0.5447 --- loss_d: 0.010647
0.6226 --- loss_d: 0.194221
0.7004 --- loss_d: 0.243378
0.7782 --- loss_d: 0.004088
0.8560 --- loss_d: 0.009004
0.9339 --- loss_d: 0.029701
Epoch finished! Loss: 0.07346193899502396
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.3333333333333333
[0.00368287 0.99790609 0.68743503 0.99182469 0.17272529 0.55021191
 0.2187202  0.83488989 0.7742548  0.15525368 0.11303542 0.97534311
 0.97817594 0.56030399 0.74014777]
pred: 0.5835940436615298, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc014-nsrr

=== Test on chc015-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.742730
0.0778 --- loss_d: 0.416882
0.1556 --- loss_d: 0.646270
0.2335 --- loss_d: 1.088712
0.3113 --- loss_d: 0.384610
0.3891 --- loss_d: 0.359931
0.4669 --- loss_d: 0.515465
0.5447 --- loss_d: 0.389250
0.6226 --- loss_d: 0.397260
0.7004 --- loss_d: 0.372133
0.7782 --- loss_d: 0.725868
0.8560 --- loss_d: 0.662343
0.9339 --- loss_d: 0.639513
Epoch finished! Loss: 0.5995955946855247
Starting epoch 2/10.
0.0000 --- loss_d: 0.690940
0.0778 --- loss_d: 0.453676
0.1556 --- loss_d: 0.256247
0.2335 --- loss_d: 0.721729
0.3113 --- loss_d: 0.548109
0.3891 --- loss_d: 0.515373
0.4669 --- loss_d: 0.505897
0.5447 --- loss_d: 0.643965
0.6226 --- loss_d: 0.272780
0.7004 --- loss_d: 0.737139
0.7782 --- loss_d: 0.212663
0.8560 --- loss_d: 0.343353
0.9339 --- loss_d: 0.634697
Epoch finished! Loss: 0.42985567240975797
Starting epoch 3/10.
0.0000 --- loss_d: 0.153774
0.0778 --- loss_d: 0.219005
0.1556 --- loss_d: 0.195302
0.2335 --- loss_d: 0.210344
0.3113 --- loss_d: 0.354031
0.3891 --- loss_d: 0.378232
0.4669 --- loss_d: 0.125880
0.5447 --- loss_d: 0.153168
0.6226 --- loss_d: 0.234286
0.7004 --- loss_d: 0.251362
0.7782 --- loss_d: 0.078182
0.8560 --- loss_d: 0.077061
0.9339 --- loss_d: 0.279398
Epoch finished! Loss: 0.2685388941463316
Starting epoch 4/10.
0.0000 --- loss_d: 0.143390
0.0778 --- loss_d: 0.034918
0.1556 --- loss_d: 0.043051
0.2335 --- loss_d: 0.019265
0.3113 --- loss_d: 0.127447
0.3891 --- loss_d: 0.064337
0.4669 --- loss_d: 0.091366
0.5447 --- loss_d: 0.141458
0.6226 --- loss_d: 0.084155
0.7004 --- loss_d: 0.267321
0.7782 --- loss_d: 0.324889
0.8560 --- loss_d: 0.235695
0.9339 --- loss_d: 0.065819
Epoch finished! Loss: 0.178588437178405
Starting epoch 5/10.
0.0000 --- loss_d: 0.078621
0.0778 --- loss_d: 0.249255
0.1556 --- loss_d: 0.230449
0.2335 --- loss_d: 0.036113
0.3113 --- loss_d: 0.051544
0.3891 --- loss_d: 0.021187
0.4669 --- loss_d: 0.305719
0.5447 --- loss_d: 0.050816
0.6226 --- loss_d: 0.807809
0.7004 --- loss_d: 0.122170
0.7782 --- loss_d: 0.293038
0.8560 --- loss_d: 0.071294
0.9339 --- loss_d: 0.008723
Epoch finished! Loss: 0.1324599727158784
Starting epoch 6/10.
0.0000 --- loss_d: 0.066790
0.0778 --- loss_d: 0.041736
0.1556 --- loss_d: 0.008235
0.2335 --- loss_d: 0.048018
0.3113 --- loss_d: 0.120590
0.3891 --- loss_d: 0.007238
0.4669 --- loss_d: 0.133134
0.5447 --- loss_d: 0.315482
0.6226 --- loss_d: 0.007552
0.7004 --- loss_d: 0.067669
0.7782 --- loss_d: 0.020163
0.8560 --- loss_d: 1.473192
0.9339 --- loss_d: 0.124724
Epoch finished! Loss: 0.1163940244305195
Starting epoch 7/10.
0.0000 --- loss_d: 0.346832
0.0778 --- loss_d: 0.031341
0.1556 --- loss_d: 0.042035
0.2335 --- loss_d: 0.005777
0.3113 --- loss_d: 0.020903
0.3891 --- loss_d: 0.003695
0.4669 --- loss_d: 0.008346
0.5447 --- loss_d: 0.014325
0.6226 --- loss_d: 0.007330
0.7004 --- loss_d: 0.928310
0.7782 --- loss_d: 0.057014
0.8560 --- loss_d: 0.087782
0.9339 --- loss_d: 0.052486
Epoch finished! Loss: 0.07532005866050895
Starting epoch 8/10.
0.0000 --- loss_d: 0.445649
0.0778 --- loss_d: 0.167993
0.1556 --- loss_d: 0.063103
0.2335 --- loss_d: 0.019093
0.3113 --- loss_d: 0.011370
0.3891 --- loss_d: 0.001400
0.4669 --- loss_d: 0.003442
0.5447 --- loss_d: 0.020228
0.6226 --- loss_d: 0.015429
0.7004 --- loss_d: 0.001779
0.7782 --- loss_d: 0.017770
0.8560 --- loss_d: 0.008702
0.9339 --- loss_d: 0.029111
Epoch finished! Loss: 0.05896088970985147
Starting epoch 9/10.
0.0000 --- loss_d: 0.002778
0.0778 --- loss_d: 0.042129
0.1556 --- loss_d: 0.154356
0.2335 --- loss_d: 0.001290
0.3113 --- loss_d: 0.006838
0.3891 --- loss_d: 0.001959
0.4669 --- loss_d: 0.001329
0.5447 --- loss_d: 0.030065
0.6226 --- loss_d: 0.000606
0.7004 --- loss_d: 0.018296
0.7782 --- loss_d: 0.173946
0.8560 --- loss_d: 0.015807
0.9339 --- loss_d: 0.015169
Epoch finished! Loss: 0.04846610056119971
Starting epoch 10/10.
0.0000 --- loss_d: 0.009638
0.0778 --- loss_d: 0.001154
0.1556 --- loss_d: 0.543026
0.2335 --- loss_d: 0.003382
0.3113 --- loss_d: 0.010933
0.3891 --- loss_d: 0.365429
0.4669 --- loss_d: 0.009947
0.5447 --- loss_d: 0.007082
0.6226 --- loss_d: 0.090642
0.7004 --- loss_d: 0.011401
0.7782 --- loss_d: 0.008785
0.8560 --- loss_d: 0.001712
0.9339 --- loss_d: 0.002384
Epoch finished! Loss: 0.061447406638308166
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.0
[0.99779415 0.99632263 0.98653305 0.99933511 0.99989855 0.99251938
 0.99964702 0.99979645 0.99997973 0.98283088 0.99529594 0.97887737
 0.99918526 0.99840647 0.9957338 ]
pred: 0.9948103864987691, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc015-nsrr

=== Test on chc016-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.727304
0.0778 --- loss_d: 0.499532
0.1556 --- loss_d: 0.505486
0.2335 --- loss_d: 0.936395
0.3113 --- loss_d: 0.872036
0.3891 --- loss_d: 0.635356
0.4669 --- loss_d: 0.455027
0.5447 --- loss_d: 0.643187
0.6226 --- loss_d: 0.333496
0.7004 --- loss_d: 0.322378
0.7782 --- loss_d: 0.638207
0.8560 --- loss_d: 0.359612
0.9339 --- loss_d: 0.543032
Epoch finished! Loss: 0.5909767667762935
Starting epoch 2/10.
0.0000 --- loss_d: 0.427268
0.0778 --- loss_d: 0.960437
0.1556 --- loss_d: 0.584428
0.2335 --- loss_d: 0.954862
0.3113 --- loss_d: 0.408677
0.3891 --- loss_d: 0.287586
0.4669 --- loss_d: 0.481904
0.5447 --- loss_d: 0.787307
0.6226 --- loss_d: 0.608254
0.7004 --- loss_d: 0.619917
0.7782 --- loss_d: 0.819880
0.8560 --- loss_d: 0.224848
0.9339 --- loss_d: 0.271909
Epoch finished! Loss: 0.46682493732078
Starting epoch 3/10.
0.0000 --- loss_d: 0.362071
0.0778 --- loss_d: 0.184759
0.1556 --- loss_d: 0.210756
0.2335 --- loss_d: 0.486752
0.3113 --- loss_d: 0.529112
0.3891 --- loss_d: 0.181123
0.4669 --- loss_d: 0.256213
0.5447 --- loss_d: 0.045940
0.6226 --- loss_d: 0.320390
0.7004 --- loss_d: 0.457703
0.7782 --- loss_d: 0.306684
0.8560 --- loss_d: 0.351022
0.9339 --- loss_d: 0.129936
Epoch finished! Loss: 0.3114099537197035
Starting epoch 4/10.
0.0000 --- loss_d: 0.252828
0.0778 --- loss_d: 0.156319
0.1556 --- loss_d: 0.236452
0.2335 --- loss_d: 0.170707
0.3113 --- loss_d: 0.265540
0.3891 --- loss_d: 0.116670
0.4669 --- loss_d: 0.554111
0.5447 --- loss_d: 0.075075
0.6226 --- loss_d: 0.520304
0.7004 --- loss_d: 0.227611
0.7782 --- loss_d: 0.298368
0.8560 --- loss_d: 0.181112
0.9339 --- loss_d: 0.166019
Epoch finished! Loss: 0.21011804492445663
Starting epoch 5/10.
0.0000 --- loss_d: 0.144583
0.0778 --- loss_d: 0.130871
0.1556 --- loss_d: 0.110034
0.2335 --- loss_d: 0.041209
0.3113 --- loss_d: 0.419242
0.3891 --- loss_d: 0.119873
0.4669 --- loss_d: 0.037637
0.5447 --- loss_d: 0.181757
0.6226 --- loss_d: 0.414927
0.7004 --- loss_d: 0.064482
0.7782 --- loss_d: 0.070133
0.8560 --- loss_d: 0.098058
0.9339 --- loss_d: 0.020994
Epoch finished! Loss: 0.13639838014205452
Starting epoch 6/10.
0.0000 --- loss_d: 0.162896
0.0778 --- loss_d: 0.096058
0.1556 --- loss_d: 0.006494
0.2335 --- loss_d: 1.334160
0.3113 --- loss_d: 0.078919
0.3891 --- loss_d: 0.120944
0.4669 --- loss_d: 0.075181
0.5447 --- loss_d: 0.030007
0.6226 --- loss_d: 0.116834
0.7004 --- loss_d: 0.046833
0.7782 --- loss_d: 0.003141
0.8560 --- loss_d: 0.012841
0.9339 --- loss_d: 0.021118
Epoch finished! Loss: 0.11254875485064986
Starting epoch 7/10.
0.0000 --- loss_d: 0.035170
0.0778 --- loss_d: 0.048124
0.1556 --- loss_d: 0.014493
0.2335 --- loss_d: 0.060991
0.3113 --- loss_d: 0.687579
0.3891 --- loss_d: 0.083336
0.4669 --- loss_d: 0.055984
0.5447 --- loss_d: 0.091125
0.6226 --- loss_d: 0.005245
0.7004 --- loss_d: 0.006993
0.7782 --- loss_d: 0.343431
0.8560 --- loss_d: 0.574113
0.9339 --- loss_d: 0.133932
Epoch finished! Loss: 0.08336168391087995
Starting epoch 8/10.
0.0000 --- loss_d: 0.006811
0.0778 --- loss_d: 0.199434
0.1556 --- loss_d: 0.044404
0.2335 --- loss_d: 0.015248
0.3113 --- loss_d: 0.021725
0.3891 --- loss_d: 0.132402
0.4669 --- loss_d: 0.001459
0.5447 --- loss_d: 0.007084
0.6226 --- loss_d: 0.007078
0.7004 --- loss_d: 0.156463
0.7782 --- loss_d: 0.155137
0.8560 --- loss_d: 0.016425
0.9339 --- loss_d: 0.002516
Epoch finished! Loss: 0.06094563987176116
Starting epoch 9/10.
0.0000 --- loss_d: 0.002371
0.0778 --- loss_d: 0.133494
0.1556 --- loss_d: 0.009135
0.2335 --- loss_d: 0.002268
0.3113 --- loss_d: 0.014815
0.3891 --- loss_d: 0.000740
0.4669 --- loss_d: 0.005817
0.5447 --- loss_d: 0.010387
0.6226 --- loss_d: 0.001992
0.7004 --- loss_d: 0.017750
0.7782 --- loss_d: 0.038405
0.8560 --- loss_d: 0.024537
0.9339 --- loss_d: 0.041393
Epoch finished! Loss: 0.05308677690834429
Starting epoch 10/10.
0.0000 --- loss_d: 0.002433
0.0778 --- loss_d: 0.000312
0.1556 --- loss_d: 0.322399
0.2335 --- loss_d: 0.038993
0.3113 --- loss_d: 0.003020
0.3891 --- loss_d: 0.003322
0.4669 --- loss_d: 0.374814
0.5447 --- loss_d: 0.082074
0.6226 --- loss_d: 0.002050
0.7004 --- loss_d: 0.042827
0.7782 --- loss_d: 0.031559
0.8560 --- loss_d: 0.013160
0.9339 --- loss_d: 0.410878
Epoch finished! Loss: 0.08256756829359801
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.6
[0.99877447 0.94436485 0.11913208 0.22316213 0.01748132 0.00113587
 0.97693729 0.01861964 0.67797077 0.57651675 0.05321477 0.0520044
 0.97180712 0.06875122 0.01355811]
pred: 0.38089538577478377, label: 0
Right! Diagnosis: Other
Save 30mins of subject chc016-nsrr

=== Test on chc022-nsrr. train_data(1287), test_data(13) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.665005
0.0777 --- loss_d: 0.607315
0.1554 --- loss_d: 0.536246
0.2331 --- loss_d: 0.545979
0.3108 --- loss_d: 0.490047
0.3885 --- loss_d: 0.418006
0.4662 --- loss_d: 1.080323
0.5439 --- loss_d: 1.065281
0.6216 --- loss_d: 0.518685
0.6993 --- loss_d: 0.415291
0.7770 --- loss_d: 0.713110
0.8547 --- loss_d: 0.619228
0.9324 --- loss_d: 0.624125
Epoch finished! Loss: 0.5928768590092659
Starting epoch 2/10.
0.0000 --- loss_d: 0.263305
0.0777 --- loss_d: 0.432573
0.1554 --- loss_d: 0.505361
0.2331 --- loss_d: 0.355242
0.3108 --- loss_d: 0.420535
0.3885 --- loss_d: 0.360708
0.4662 --- loss_d: 0.675843
0.5439 --- loss_d: 0.622537
0.6216 --- loss_d: 0.539945
0.6993 --- loss_d: 0.202715
0.7770 --- loss_d: 0.173153
0.8547 --- loss_d: 0.453099
0.9324 --- loss_d: 0.497573
Epoch finished! Loss: 0.49224231793778017
Starting epoch 3/10.
0.0000 --- loss_d: 0.179453
0.0777 --- loss_d: 0.317106
0.1554 --- loss_d: 0.457003
0.2331 --- loss_d: 0.117918
0.3108 --- loss_d: 0.240840
0.3885 --- loss_d: 0.554145
0.4662 --- loss_d: 0.462772
0.5439 --- loss_d: 0.329967
0.6216 --- loss_d: 0.250660
0.6993 --- loss_d: 0.415630
0.7770 --- loss_d: 0.079118
0.8547 --- loss_d: 0.806770
0.9324 --- loss_d: 0.948271
Epoch finished! Loss: 0.29874742284300737
Starting epoch 4/10.
0.0000 --- loss_d: 0.070491
0.0777 --- loss_d: 0.195027
0.1554 --- loss_d: 0.057481
0.2331 --- loss_d: 0.075440
0.3108 --- loss_d: 0.237025
0.3885 --- loss_d: 0.368526
0.4662 --- loss_d: 0.178285
0.5439 --- loss_d: 0.102375
0.6216 --- loss_d: 0.237700
0.6993 --- loss_d: 0.433421
0.7770 --- loss_d: 0.174771
0.8547 --- loss_d: 0.152735
0.9324 --- loss_d: 0.046030
Epoch finished! Loss: 0.22761256282683462
Starting epoch 5/10.
0.0000 --- loss_d: 0.087383
0.0777 --- loss_d: 0.118990
0.1554 --- loss_d: 0.068882
0.2331 --- loss_d: 0.072541
0.3108 --- loss_d: 0.038181
0.3885 --- loss_d: 0.649676
0.4662 --- loss_d: 0.205918
0.5439 --- loss_d: 0.055898
0.6216 --- loss_d: 0.405957
0.6993 --- loss_d: 0.590458
0.7770 --- loss_d: 0.051400
0.8547 --- loss_d: 0.027570
0.9324 --- loss_d: 0.223783
Epoch finished! Loss: 0.17403510959047708
Starting epoch 6/10.
0.0000 --- loss_d: 0.030173
0.0777 --- loss_d: 0.047310
0.1554 --- loss_d: 0.043413
0.2331 --- loss_d: 0.030734
0.3108 --- loss_d: 0.085835
0.3885 --- loss_d: 0.041190
0.4662 --- loss_d: 0.094397
0.5439 --- loss_d: 0.143927
0.6216 --- loss_d: 0.535455
0.6993 --- loss_d: 0.013957
0.7770 --- loss_d: 0.098083
0.8547 --- loss_d: 0.016182
0.9324 --- loss_d: 0.015185
Epoch finished! Loss: 0.10821422062417696
Starting epoch 7/10.
0.0000 --- loss_d: 0.013677
0.0777 --- loss_d: 0.080867
0.1554 --- loss_d: 0.026956
0.2331 --- loss_d: 0.039817
0.3108 --- loss_d: 0.004897
0.3885 --- loss_d: 0.058037
0.4662 --- loss_d: 0.004709
0.5439 --- loss_d: 0.025961
0.6216 --- loss_d: 0.218024
0.6993 --- loss_d: 0.126974
0.7770 --- loss_d: 0.048262
0.8547 --- loss_d: 0.005342
0.9324 --- loss_d: 0.021084
Epoch finished! Loss: 0.09131625749432715
Starting epoch 8/10.
0.0000 --- loss_d: 0.005175
0.0777 --- loss_d: 0.003930
0.1554 --- loss_d: 0.007666
0.2331 --- loss_d: 0.074364
0.3108 --- loss_d: 0.224889
0.3885 --- loss_d: 0.152055
0.4662 --- loss_d: 0.069494
0.5439 --- loss_d: 0.009169
0.6216 --- loss_d: 0.287902
0.6993 --- loss_d: 0.219928
0.7770 --- loss_d: 0.107172
0.8547 --- loss_d: 0.041522
0.9324 --- loss_d: 0.004552
Epoch finished! Loss: 0.06780504259859299
Starting epoch 9/10.
0.0000 --- loss_d: 0.237403
0.0777 --- loss_d: 0.020130
0.1554 --- loss_d: 0.012302
0.2331 --- loss_d: 0.040486
0.3108 --- loss_d: 0.036696
0.3885 --- loss_d: 0.259412
0.4662 --- loss_d: 0.048745
0.5439 --- loss_d: 0.012460
0.6216 --- loss_d: 0.161135
0.6993 --- loss_d: 0.098976
0.7770 --- loss_d: 0.004049
0.8547 --- loss_d: 0.056651
0.9324 --- loss_d: 0.006556
Epoch finished! Loss: 0.05745823221286628
Starting epoch 10/10.
0.0000 --- loss_d: 0.008068
0.0777 --- loss_d: 0.261213
0.1554 --- loss_d: 0.256416
0.2331 --- loss_d: 0.013756
0.3108 --- loss_d: 0.010447
0.3885 --- loss_d: 0.104700
0.4662 --- loss_d: 0.010876
0.5439 --- loss_d: 0.132654
0.6216 --- loss_d: 0.035324
0.6993 --- loss_d: 0.115236
0.7770 --- loss_d: 0.014894
0.8547 --- loss_d: 0.010419
0.9324 --- loss_d: 0.068571
Epoch finished! Loss: 0.08342532293363547
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[8.60595537e-05 2.36585829e-03 4.23914840e-04 7.17936928e-05
 4.78879410e-05 2.05308708e-04 5.75427548e-04 2.15411093e-03
 1.55777263e-03 7.55262896e-02 2.10643727e-02 2.41264561e-03
 3.24473046e-02]
pred: 0.01068759590019069, label: 0
Right! Diagnosis: Other
Save 30mins of subject chc022-nsrr

=== Test on chc025-nsrr. train_data(1287), test_data(13) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.641495
0.0777 --- loss_d: 0.614863
0.1554 --- loss_d: 0.517807
0.2331 --- loss_d: 0.542961
0.3108 --- loss_d: 0.594036
0.3885 --- loss_d: 0.642314
0.4662 --- loss_d: 0.335795
0.5439 --- loss_d: 0.703238
0.6216 --- loss_d: 0.512235
0.6993 --- loss_d: 0.438661
0.7770 --- loss_d: 0.532784
0.8547 --- loss_d: 0.400352
0.9324 --- loss_d: 0.850682
Epoch finished! Loss: 0.5750972412060946
Starting epoch 2/10.
0.0000 --- loss_d: 0.506679
0.0777 --- loss_d: 0.250540
0.1554 --- loss_d: 0.283927
0.2331 --- loss_d: 0.374989
0.3108 --- loss_d: 0.424987
0.3885 --- loss_d: 0.446387
0.4662 --- loss_d: 0.311835
0.5439 --- loss_d: 0.519701
0.6216 --- loss_d: 0.811169
0.6993 --- loss_d: 0.149593
0.7770 --- loss_d: 0.174429
0.8547 --- loss_d: 0.457524
0.9324 --- loss_d: 0.390863
Epoch finished! Loss: 0.410377123625949
Starting epoch 3/10.
0.0000 --- loss_d: 0.122634
0.0777 --- loss_d: 0.107415
0.1554 --- loss_d: 0.075414
0.2331 --- loss_d: 0.324361
0.3108 --- loss_d: 0.265345
0.3885 --- loss_d: 0.080383
0.4662 --- loss_d: 0.190258
0.5439 --- loss_d: 0.315713
0.6216 --- loss_d: 0.739057
0.6993 --- loss_d: 0.148673
0.7770 --- loss_d: 0.193656
0.8547 --- loss_d: 0.154223
0.9324 --- loss_d: 0.089372
Epoch finished! Loss: 0.27492732770042494
Starting epoch 4/10.
0.0000 --- loss_d: 0.182249
0.0777 --- loss_d: 0.205387
0.1554 --- loss_d: 0.200018
0.2331 --- loss_d: 0.046251
0.3108 --- loss_d: 0.123219
0.3885 --- loss_d: 0.163754
0.4662 --- loss_d: 0.669914
0.5439 --- loss_d: 0.072456
0.6216 --- loss_d: 0.582802
0.6993 --- loss_d: 0.402127
0.7770 --- loss_d: 0.054138
0.8547 --- loss_d: 0.762417
0.9324 --- loss_d: 0.448304
Epoch finished! Loss: 0.2023546716227429
Starting epoch 5/10.
0.0000 --- loss_d: 0.079141
0.0777 --- loss_d: 0.016158
0.1554 --- loss_d: 0.262408
0.2331 --- loss_d: 0.238283
0.3108 --- loss_d: 0.258311
0.3885 --- loss_d: 0.117451
0.4662 --- loss_d: 0.031422
0.5439 --- loss_d: 0.144775
0.6216 --- loss_d: 0.626193
0.6993 --- loss_d: 0.040341
0.7770 --- loss_d: 0.402862
0.8547 --- loss_d: 0.258564
0.9324 --- loss_d: 0.186651
Epoch finished! Loss: 0.17076616324629867
Starting epoch 6/10.
0.0000 --- loss_d: 0.066599
0.0777 --- loss_d: 0.127147
0.1554 --- loss_d: 0.023387
0.2331 --- loss_d: 0.142375
0.3108 --- loss_d: 0.015323
0.3885 --- loss_d: 0.004511
0.4662 --- loss_d: 0.078110
0.5439 --- loss_d: 0.147562
0.6216 --- loss_d: 0.030201
0.6993 --- loss_d: 0.012273
0.7770 --- loss_d: 0.087119
0.8547 --- loss_d: 0.047830
0.9324 --- loss_d: 0.024138
Epoch finished! Loss: 0.1242698996920808
Starting epoch 7/10.
0.0000 --- loss_d: 0.026667
0.0777 --- loss_d: 0.028968
0.1554 --- loss_d: 0.012621
0.2331 --- loss_d: 0.179694
0.3108 --- loss_d: 0.027767
0.3885 --- loss_d: 0.184668
0.4662 --- loss_d: 0.029181
0.5439 --- loss_d: 0.024818
0.6216 --- loss_d: 0.006827
0.6993 --- loss_d: 0.002551
0.7770 --- loss_d: 0.030216
0.8547 --- loss_d: 0.021392
0.9324 --- loss_d: 0.257872
Epoch finished! Loss: 0.09309756501897937
Starting epoch 8/10.
0.0000 --- loss_d: 0.015094
0.0777 --- loss_d: 0.070854
0.1554 --- loss_d: 0.011935
0.2331 --- loss_d: 0.007134
0.3108 --- loss_d: 0.089490
0.3885 --- loss_d: 0.011435
0.4662 --- loss_d: 0.078825
0.5439 --- loss_d: 0.038137
0.6216 --- loss_d: 0.008969
0.6993 --- loss_d: 0.186326
0.7770 --- loss_d: 0.139274
0.8547 --- loss_d: 0.019292
0.9324 --- loss_d: 0.008356
Epoch finished! Loss: 0.07828418881672405
Starting epoch 9/10.
0.0000 --- loss_d: 0.011943
0.0777 --- loss_d: 0.004583
0.1554 --- loss_d: 0.035736
0.2331 --- loss_d: 0.013159
0.3108 --- loss_d: 0.003943
0.3885 --- loss_d: 0.000455
0.4662 --- loss_d: 0.011471
0.5439 --- loss_d: 0.004279
0.6216 --- loss_d: 0.012798
0.6993 --- loss_d: 0.013808
0.7770 --- loss_d: 0.043508
0.8547 --- loss_d: 0.016143
0.9324 --- loss_d: 0.453840
Epoch finished! Loss: 0.08054446562505291
Starting epoch 10/10.
0.0000 --- loss_d: 0.125347
0.0777 --- loss_d: 0.083024
0.1554 --- loss_d: 0.005390
0.2331 --- loss_d: 0.106085
0.3108 --- loss_d: 0.028740
0.3885 --- loss_d: 0.007292
0.4662 --- loss_d: 0.003769
0.5439 --- loss_d: 0.018433
0.6216 --- loss_d: 0.064541
0.6993 --- loss_d: 0.002881
0.7770 --- loss_d: 0.023322
0.8547 --- loss_d: 0.002025
0.9324 --- loss_d: 0.005785
Epoch finished! Loss: 0.052790224216550996
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.3076923076923077
[0.99919075 0.99906975 0.98059332 0.99725145 0.82759672 0.01107589
 0.00636687 0.05648659 0.72520471 0.9741255  0.99958473 0.04616588
 0.75830829]
pred: 0.6446938819180315, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc025-nsrr

=== Test on chc027-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.761806
0.0778 --- loss_d: 0.470418
0.1556 --- loss_d: 0.806035
0.2335 --- loss_d: 0.816474
0.3113 --- loss_d: 0.418417
0.3891 --- loss_d: 0.476629
0.4669 --- loss_d: 0.670297
0.5447 --- loss_d: 0.336234
0.6226 --- loss_d: 0.499957
0.7004 --- loss_d: 0.450394
0.7782 --- loss_d: 0.376238
0.8560 --- loss_d: 0.446234
0.9339 --- loss_d: 0.954716
Epoch finished! Loss: 0.582050146185793
Starting epoch 2/10.
0.0000 --- loss_d: 0.722322
0.0778 --- loss_d: 0.588223
0.1556 --- loss_d: 0.411667
0.2335 --- loss_d: 0.616141
0.3113 --- loss_d: 0.774971
0.3891 --- loss_d: 0.488486
0.4669 --- loss_d: 0.431386
0.5447 --- loss_d: 0.671698
0.6226 --- loss_d: 0.959853
0.7004 --- loss_d: 0.412711
0.7782 --- loss_d: 1.120904
0.8560 --- loss_d: 0.127220
0.9339 --- loss_d: 0.499209
Epoch finished! Loss: 0.44437669962644577
Starting epoch 3/10.
0.0000 --- loss_d: 0.192454
0.0778 --- loss_d: 0.079659
0.1556 --- loss_d: 0.082846
0.2335 --- loss_d: 0.273673
0.3113 --- loss_d: 0.280364
0.3891 --- loss_d: 0.345616
0.4669 --- loss_d: 0.231508
0.5447 --- loss_d: 0.390306
0.6226 --- loss_d: 0.144974
0.7004 --- loss_d: 0.117749
0.7782 --- loss_d: 0.101241
0.8560 --- loss_d: 0.030294
0.9339 --- loss_d: 0.220220
Epoch finished! Loss: 0.3047833922901191
Starting epoch 4/10.
0.0000 --- loss_d: 0.106771
0.0778 --- loss_d: 0.207257
0.1556 --- loss_d: 0.150402
0.2335 --- loss_d: 0.234137
0.3113 --- loss_d: 0.117603
0.3891 --- loss_d: 0.033847
0.4669 --- loss_d: 0.116252
0.5447 --- loss_d: 0.298148
0.6226 --- loss_d: 0.104266
0.7004 --- loss_d: 0.457611
0.7782 --- loss_d: 0.318834
0.8560 --- loss_d: 0.135965
0.9339 --- loss_d: 0.354150
Epoch finished! Loss: 0.21307443724072073
Starting epoch 5/10.
0.0000 --- loss_d: 0.072812
0.0778 --- loss_d: 0.366946
0.1556 --- loss_d: 0.103541
0.2335 --- loss_d: 0.080108
0.3113 --- loss_d: 0.059975
0.3891 --- loss_d: 0.653269
0.4669 --- loss_d: 0.049972
0.5447 --- loss_d: 0.071145
0.6226 --- loss_d: 0.372404
0.7004 --- loss_d: 0.131600
0.7782 --- loss_d: 0.134845
0.8560 --- loss_d: 0.078943
0.9339 --- loss_d: 0.317794
Epoch finished! Loss: 0.17950860206474317
Starting epoch 6/10.
0.0000 --- loss_d: 0.185209
0.0778 --- loss_d: 0.027290
0.1556 --- loss_d: 0.031815
0.2335 --- loss_d: 0.037289
0.3113 --- loss_d: 0.038582
0.3891 --- loss_d: 0.486459
0.4669 --- loss_d: 0.268045
0.5447 --- loss_d: 0.074380
0.6226 --- loss_d: 0.066525
0.7004 --- loss_d: 0.071932
0.7782 --- loss_d: 0.052625
0.8560 --- loss_d: 0.041099
0.9339 --- loss_d: 0.138040
Epoch finished! Loss: 0.13080106003690162
Starting epoch 7/10.
0.0000 --- loss_d: 0.030581
0.0778 --- loss_d: 0.254993
0.1556 --- loss_d: 0.476667
0.2335 --- loss_d: 0.040915
0.3113 --- loss_d: 0.021467
0.3891 --- loss_d: 0.077957
0.4669 --- loss_d: 0.243963
0.5447 --- loss_d: 0.005971
0.6226 --- loss_d: 0.129968
0.7004 --- loss_d: 0.009145
0.7782 --- loss_d: 0.151536
0.8560 --- loss_d: 0.023700
0.9339 --- loss_d: 0.006209
Epoch finished! Loss: 0.09047460661895457
Starting epoch 8/10.
0.0000 --- loss_d: 0.410989
0.0778 --- loss_d: 0.067049
0.1556 --- loss_d: 0.018465
0.2335 --- loss_d: 0.192808
0.3113 --- loss_d: 0.209688
0.3891 --- loss_d: 0.039711
0.4669 --- loss_d: 0.005911
0.5447 --- loss_d: 0.046865
0.6226 --- loss_d: 0.131821
0.7004 --- loss_d: 0.363868
0.7782 --- loss_d: 0.015606
0.8560 --- loss_d: 0.006960
0.9339 --- loss_d: 0.003932
Epoch finished! Loss: 0.09580887087849987
Starting epoch 9/10.
0.0000 --- loss_d: 0.008009
0.0778 --- loss_d: 0.080332
0.1556 --- loss_d: 0.011117
0.2335 --- loss_d: 0.005875
0.3113 --- loss_d: 0.012473
0.3891 --- loss_d: 0.003225
0.4669 --- loss_d: 0.039372
0.5447 --- loss_d: 0.677100
0.6226 --- loss_d: 0.656598
0.7004 --- loss_d: 0.174355
0.7782 --- loss_d: 0.438331
0.8560 --- loss_d: 0.357557
0.9339 --- loss_d: 0.171996
Epoch finished! Loss: 0.09961585160817776
Starting epoch 10/10.
0.0000 --- loss_d: 0.081090
0.0778 --- loss_d: 0.055029
0.1556 --- loss_d: 0.008561
0.2335 --- loss_d: 0.072324
0.3113 --- loss_d: 0.034159
0.3891 --- loss_d: 0.087707
0.4669 --- loss_d: 0.272826
0.5447 --- loss_d: 0.062354
0.6226 --- loss_d: 0.012962
0.7004 --- loss_d: 0.104007
0.7782 --- loss_d: 0.080099
0.8560 --- loss_d: 0.086031
0.9339 --- loss_d: 0.655491
Epoch finished! Loss: 0.0678645291900466
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.3333333333333333
[0.99957556 0.99599898 0.99837625 0.95134228 0.99838459 0.79814398
 0.00975352 0.99840218 0.99999928 0.99950159 0.10943376 0.03894377
 0.1193683  0.99779725 0.22397226]
pred: 0.6825995702917377, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc027-nsrr

=== Test on chc028-nsrr. train_data(1286), test_data(14) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.668386
0.0778 --- loss_d: 0.697794
0.1555 --- loss_d: 0.824386
0.2333 --- loss_d: 0.502170
0.3110 --- loss_d: 0.441980
0.3888 --- loss_d: 0.501475
0.4666 --- loss_d: 0.485903
0.5443 --- loss_d: 1.122896
0.6221 --- loss_d: 0.648178
0.6998 --- loss_d: 0.790581
0.7776 --- loss_d: 0.680167
0.8554 --- loss_d: 0.331018
0.9331 --- loss_d: 0.685414
Epoch finished! Loss: 0.5900065100286156
Starting epoch 2/10.
0.0000 --- loss_d: 0.543912
0.0778 --- loss_d: 0.545620
0.1555 --- loss_d: 0.693660
0.2333 --- loss_d: 0.462087
0.3110 --- loss_d: 0.361205
0.3888 --- loss_d: 0.599844
0.4666 --- loss_d: 0.863822
0.5443 --- loss_d: 0.341813
0.6221 --- loss_d: 0.218945
0.6998 --- loss_d: 0.146985
0.7776 --- loss_d: 0.253530
0.8554 --- loss_d: 0.704661
0.9331 --- loss_d: 0.592529
Epoch finished! Loss: 0.4645879903691821
Starting epoch 3/10.
0.0000 --- loss_d: 0.409805
0.0778 --- loss_d: 0.224722
0.1555 --- loss_d: 0.176448
0.2333 --- loss_d: 0.100587
0.3110 --- loss_d: 0.211891
0.3888 --- loss_d: 0.330363
0.4666 --- loss_d: 0.544651
0.5443 --- loss_d: 0.139363
0.6221 --- loss_d: 0.230967
0.6998 --- loss_d: 0.400012
0.7776 --- loss_d: 0.759522
0.8554 --- loss_d: 0.107894
0.9331 --- loss_d: 0.135324
Epoch finished! Loss: 0.30031513440189883
Starting epoch 4/10.
0.0000 --- loss_d: 0.247472
0.0778 --- loss_d: 0.108699
0.1555 --- loss_d: 0.076269
0.2333 --- loss_d: 0.109000
0.3110 --- loss_d: 0.093165
0.3888 --- loss_d: 0.028962
0.4666 --- loss_d: 0.049715
0.5443 --- loss_d: 0.367460
0.6221 --- loss_d: 0.026692
0.6998 --- loss_d: 0.182885
0.7776 --- loss_d: 0.067607
0.8554 --- loss_d: 0.065739
0.9331 --- loss_d: 0.734476
Epoch finished! Loss: 0.1947362095306744
Starting epoch 5/10.
0.0000 --- loss_d: 0.086741
0.0778 --- loss_d: 0.111790
0.1555 --- loss_d: 0.277823
0.2333 --- loss_d: 0.326644
0.3110 --- loss_d: 0.102113
0.3888 --- loss_d: 0.360882
0.4666 --- loss_d: 0.083084
0.5443 --- loss_d: 0.031214
0.6221 --- loss_d: 0.069823
0.6998 --- loss_d: 0.108054
0.7776 --- loss_d: 0.106441
0.8554 --- loss_d: 0.015804
0.9331 --- loss_d: 0.030702
Epoch finished! Loss: 0.13228534994777874
Starting epoch 6/10.
0.0000 --- loss_d: 0.004084
0.0778 --- loss_d: 0.203537
0.1555 --- loss_d: 0.015646
0.2333 --- loss_d: 0.530166
0.3110 --- loss_d: 0.006514
0.3888 --- loss_d: 0.081553
0.4666 --- loss_d: 0.324408
0.5443 --- loss_d: 0.087946
0.6221 --- loss_d: 0.005789
0.6998 --- loss_d: 0.087726
0.7776 --- loss_d: 0.116051
0.8554 --- loss_d: 0.369529
0.9331 --- loss_d: 0.031965
Epoch finished! Loss: 0.0856050215443247
Starting epoch 7/10.
0.0000 --- loss_d: 0.023213
0.0778 --- loss_d: 0.029849
0.1555 --- loss_d: 0.002816
0.2333 --- loss_d: 0.010547
0.3110 --- loss_d: 0.099441
0.3888 --- loss_d: 0.028271
0.4666 --- loss_d: 0.044209
0.5443 --- loss_d: 0.015949
0.6221 --- loss_d: 0.024307
0.6998 --- loss_d: 0.020498
0.7776 --- loss_d: 0.232805
0.8554 --- loss_d: 0.759693
0.9331 --- loss_d: 0.506829
Epoch finished! Loss: 0.0942458298748079
Starting epoch 8/10.
0.0000 --- loss_d: 0.103892
0.0778 --- loss_d: 0.012444
0.1555 --- loss_d: 0.022003
0.2333 --- loss_d: 0.046226
0.3110 --- loss_d: 0.019035
0.3888 --- loss_d: 0.080265
0.4666 --- loss_d: 0.239451
0.5443 --- loss_d: 0.006644
0.6221 --- loss_d: 0.003461
0.6998 --- loss_d: 0.065159
0.7776 --- loss_d: 0.109618
0.8554 --- loss_d: 0.022871
0.9331 --- loss_d: 0.023385
Epoch finished! Loss: 0.08575253280014294
Starting epoch 9/10.
0.0000 --- loss_d: 0.066494
0.0778 --- loss_d: 0.003721
0.1555 --- loss_d: 0.015123
0.2333 --- loss_d: 0.013442
0.3110 --- loss_d: 0.331926
0.3888 --- loss_d: 0.010187
0.4666 --- loss_d: 0.221178
0.5443 --- loss_d: 0.097661
0.6221 --- loss_d: 0.145480
0.6998 --- loss_d: 0.206526
0.7776 --- loss_d: 0.022164
0.8554 --- loss_d: 0.007998
0.9331 --- loss_d: 0.009890
Epoch finished! Loss: 0.0645150476557319
Starting epoch 10/10.
0.0000 --- loss_d: 0.053690
0.0778 --- loss_d: 0.032948
0.1555 --- loss_d: 0.025814
0.2333 --- loss_d: 0.032231
0.3110 --- loss_d: 0.010684
0.3888 --- loss_d: 0.043220
0.4666 --- loss_d: 0.002701
0.5443 --- loss_d: 0.002400
0.6221 --- loss_d: 0.000579
0.6998 --- loss_d: 0.001914
0.7776 --- loss_d: 0.000549
0.8554 --- loss_d: 0.029992
0.9331 --- loss_d: 0.001894
Epoch finished! Loss: 0.054595514653556165
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.35714285714285715
[0.98915648 0.06717613 0.97929209 0.05195272 0.63096654 0.04599698
 0.73598021 0.86528516 0.02709336 0.94080198 0.88533717 0.98597521
 0.00269782 0.50745738]
pred: 0.551083516462573, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc028-nsrr

=== Test on chc033-nsrr. train_data(1286), test_data(14) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.738955
0.0778 --- loss_d: 1.344710
0.1555 --- loss_d: 0.666076
0.2333 --- loss_d: 0.600215
0.3110 --- loss_d: 0.392176
0.3888 --- loss_d: 0.887587
0.4666 --- loss_d: 0.504203
0.5443 --- loss_d: 0.636889
0.6221 --- loss_d: 0.622181
0.6998 --- loss_d: 0.522727
0.7776 --- loss_d: 0.444528
0.8554 --- loss_d: 0.442149
0.9331 --- loss_d: 0.802719
Epoch finished! Loss: 0.5991667390335351
Starting epoch 2/10.
0.0000 --- loss_d: 0.395736
0.0778 --- loss_d: 0.424030
0.1555 --- loss_d: 0.286111
0.2333 --- loss_d: 0.513124
0.3110 --- loss_d: 0.551649
0.3888 --- loss_d: 0.304059
0.4666 --- loss_d: 0.724089
0.5443 --- loss_d: 0.444251
0.6221 --- loss_d: 0.396537
0.6998 --- loss_d: 0.506223
0.7776 --- loss_d: 0.797000
0.8554 --- loss_d: 0.385846
0.9331 --- loss_d: 0.269676
Epoch finished! Loss: 0.504613091587089
Starting epoch 3/10.
0.0000 --- loss_d: 0.215900
0.0778 --- loss_d: 0.794548
0.1555 --- loss_d: 0.314912
0.2333 --- loss_d: 0.389545
0.3110 --- loss_d: 0.194590
0.3888 --- loss_d: 0.516024
0.4666 --- loss_d: 0.169836
0.5443 --- loss_d: 0.167481
0.6221 --- loss_d: 0.750102
0.6998 --- loss_d: 0.331879
0.7776 --- loss_d: 0.821998
0.8554 --- loss_d: 0.254511
0.9331 --- loss_d: 0.704531
Epoch finished! Loss: 0.368721035978524
Starting epoch 4/10.
0.0000 --- loss_d: 0.170999
0.0778 --- loss_d: 0.089377
0.1555 --- loss_d: 0.122460
0.2333 --- loss_d: 0.138576
0.3110 --- loss_d: 0.067607
0.3888 --- loss_d: 0.034039
0.4666 --- loss_d: 0.192209
0.5443 --- loss_d: 0.249828
0.6221 --- loss_d: 0.126300
0.6998 --- loss_d: 0.599232
0.7776 --- loss_d: 0.081968
0.8554 --- loss_d: 0.066961
0.9331 --- loss_d: 0.311089
Epoch finished! Loss: 0.2035440777108306
Starting epoch 5/10.
0.0000 --- loss_d: 0.064921
0.0778 --- loss_d: 0.088144
0.1555 --- loss_d: 0.045868
0.2333 --- loss_d: 0.280207
0.3110 --- loss_d: 0.407634
0.3888 --- loss_d: 0.068708
0.4666 --- loss_d: 0.064672
0.5443 --- loss_d: 0.095126
0.6221 --- loss_d: 0.023496
0.6998 --- loss_d: 0.326524
0.7776 --- loss_d: 0.055077
0.8554 --- loss_d: 0.111382
0.9331 --- loss_d: 0.181511
Epoch finished! Loss: 0.1485337088779488
Starting epoch 6/10.
0.0000 --- loss_d: 0.071500
0.0778 --- loss_d: 0.101297
0.1555 --- loss_d: 0.018338
0.2333 --- loss_d: 0.665659
0.3110 --- loss_d: 0.135293
0.3888 --- loss_d: 0.095156
0.4666 --- loss_d: 0.065502
0.5443 --- loss_d: 0.027361
0.6221 --- loss_d: 0.107151
0.6998 --- loss_d: 0.015403
0.7776 --- loss_d: 0.198239
0.8554 --- loss_d: 0.096361
0.9331 --- loss_d: 0.017965
Epoch finished! Loss: 0.09769286347727757
Starting epoch 7/10.
0.0000 --- loss_d: 0.010861
0.0778 --- loss_d: 0.025147
0.1555 --- loss_d: 0.114377
0.2333 --- loss_d: 0.342259
0.3110 --- loss_d: 0.003788
0.3888 --- loss_d: 0.011415
0.4666 --- loss_d: 0.010793
0.5443 --- loss_d: 0.101953
0.6221 --- loss_d: 0.007157
0.6998 --- loss_d: 0.169227
0.7776 --- loss_d: 0.005255
0.8554 --- loss_d: 0.034563
0.9331 --- loss_d: 0.016289
Epoch finished! Loss: 0.05678172472471488
Starting epoch 8/10.
0.0000 --- loss_d: 0.001713
0.0778 --- loss_d: 0.036024
0.1555 --- loss_d: 0.003585
0.2333 --- loss_d: 0.022525
0.3110 --- loss_d: 0.094581
0.3888 --- loss_d: 0.091151
0.4666 --- loss_d: 0.001861
0.5443 --- loss_d: 0.017250
0.6221 --- loss_d: 0.005640
0.6998 --- loss_d: 0.007880
0.7776 --- loss_d: 0.018779
0.8554 --- loss_d: 0.043790
0.9331 --- loss_d: 0.021052
Epoch finished! Loss: 0.05962981667062195
Starting epoch 9/10.
0.0000 --- loss_d: 0.016350
0.0778 --- loss_d: 0.015519
0.1555 --- loss_d: 0.000380
0.2333 --- loss_d: 0.002449
0.3110 --- loss_d: 0.010421
0.3888 --- loss_d: 0.192441
0.4666 --- loss_d: 0.003368
0.5443 --- loss_d: 0.115172
0.6221 --- loss_d: 0.020245
0.6998 --- loss_d: 0.004892
0.7776 --- loss_d: 0.001411
0.8554 --- loss_d: 0.003265
0.9331 --- loss_d: 0.008448
Epoch finished! Loss: 0.022043651491230776
Starting epoch 10/10.
0.0000 --- loss_d: 0.001990
0.0778 --- loss_d: 0.000169
0.1555 --- loss_d: 0.000811
0.2333 --- loss_d: 0.006861
0.3110 --- loss_d: 0.140961
0.3888 --- loss_d: 0.182505
0.4666 --- loss_d: 0.001428
0.5443 --- loss_d: 0.003749
0.6221 --- loss_d: 0.004459
0.6998 --- loss_d: 0.006836
0.7776 --- loss_d: 0.002742
0.8554 --- loss_d: 0.240701
0.9331 --- loss_d: 0.004463
Epoch finished! Loss: 0.04208093075232
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.0
[0.99998879 0.999964   0.99988377 0.99998319 0.99980015 0.95974392
 0.99984217 0.99999976 0.99999952 0.99999857 0.99995494 1.
 0.99999988 0.99999952]
pred: 0.9970827272960118, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc033-nsrr

=== Test on chc035-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.648900
0.0778 --- loss_d: 0.863497
0.1556 --- loss_d: 0.552083
0.2335 --- loss_d: 0.505906
0.3113 --- loss_d: 0.353400
0.3891 --- loss_d: 0.454832
0.4669 --- loss_d: 0.514660
0.5447 --- loss_d: 0.597448
0.6226 --- loss_d: 0.792815
0.7004 --- loss_d: 0.572436
0.7782 --- loss_d: 0.594319
0.8560 --- loss_d: 0.513922
0.9339 --- loss_d: 0.770841
Epoch finished! Loss: 0.6030322394799441
Starting epoch 2/10.
0.0000 --- loss_d: 0.434885
0.0778 --- loss_d: 0.340627
0.1556 --- loss_d: 0.526472
0.2335 --- loss_d: 0.319000
0.3113 --- loss_d: 0.385414
0.3891 --- loss_d: 0.501455
0.4669 --- loss_d: 0.425764
0.5447 --- loss_d: 0.338250
0.6226 --- loss_d: 0.842533
0.7004 --- loss_d: 0.366387
0.7782 --- loss_d: 0.773412
0.8560 --- loss_d: 0.430497
0.9339 --- loss_d: 0.685375
Epoch finished! Loss: 0.48448253504466265
Starting epoch 3/10.
0.0000 --- loss_d: 0.515328
0.0778 --- loss_d: 0.338437
0.1556 --- loss_d: 0.322367
0.2335 --- loss_d: 0.429617
0.3113 --- loss_d: 0.235350
0.3891 --- loss_d: 0.438939
0.4669 --- loss_d: 0.204852
0.5447 --- loss_d: 0.614779
0.6226 --- loss_d: 0.289388
0.7004 --- loss_d: 0.172043
0.7782 --- loss_d: 0.244905
0.8560 --- loss_d: 0.287561
0.9339 --- loss_d: 0.366952
Epoch finished! Loss: 0.37948475987650454
Starting epoch 4/10.
0.0000 --- loss_d: 0.202573
0.0778 --- loss_d: 0.183593
0.1556 --- loss_d: 0.147144
0.2335 --- loss_d: 0.255690
0.3113 --- loss_d: 0.105792
0.3891 --- loss_d: 0.111437
0.4669 --- loss_d: 0.124143
0.5447 --- loss_d: 0.108457
0.6226 --- loss_d: 0.196329
0.7004 --- loss_d: 0.322946
0.7782 --- loss_d: 0.133349
0.8560 --- loss_d: 0.085956
0.9339 --- loss_d: 0.497623
Epoch finished! Loss: 0.24409425987687428
Starting epoch 5/10.
0.0000 --- loss_d: 0.165816
0.0778 --- loss_d: 0.068260
0.1556 --- loss_d: 0.033792
0.2335 --- loss_d: 0.248324
0.3113 --- loss_d: 0.058609
0.3891 --- loss_d: 0.188179
0.4669 --- loss_d: 0.331588
0.5447 --- loss_d: 0.021745
0.6226 --- loss_d: 0.167328
0.7004 --- loss_d: 0.130789
0.7782 --- loss_d: 0.488456
0.8560 --- loss_d: 0.290749
0.9339 --- loss_d: 0.136818
Epoch finished! Loss: 0.18393194457166828
Starting epoch 6/10.
0.0000 --- loss_d: 0.144892
0.0778 --- loss_d: 0.039875
0.1556 --- loss_d: 0.028847
0.2335 --- loss_d: 0.017210
0.3113 --- loss_d: 0.011497
0.3891 --- loss_d: 0.142123
0.4669 --- loss_d: 0.009004
0.5447 --- loss_d: 0.027756
0.6226 --- loss_d: 0.014585
0.7004 --- loss_d: 0.021517
0.7782 --- loss_d: 0.062576
0.8560 --- loss_d: 0.006203
0.9339 --- loss_d: 0.002567
Epoch finished! Loss: 0.11164924920740305
Starting epoch 7/10.
0.0000 --- loss_d: 0.013057
0.0778 --- loss_d: 0.178820
0.1556 --- loss_d: 0.026945
0.2335 --- loss_d: 0.014615
0.3113 --- loss_d: 0.012020
0.3891 --- loss_d: 0.000623
0.4669 --- loss_d: 0.004940
0.5447 --- loss_d: 0.001954
0.6226 --- loss_d: 0.000686
0.7004 --- loss_d: 0.062194
0.7782 --- loss_d: 0.189012
0.8560 --- loss_d: 0.351107
0.9339 --- loss_d: 0.101082
Epoch finished! Loss: 0.05315342130825229
Starting epoch 8/10.
0.0000 --- loss_d: 0.014919
0.0778 --- loss_d: 0.023102
0.1556 --- loss_d: 0.022176
0.2335 --- loss_d: 0.003483
0.3113 --- loss_d: 0.339278
0.3891 --- loss_d: 0.004034
0.4669 --- loss_d: 0.023030
0.5447 --- loss_d: 0.058272
0.6226 --- loss_d: 0.000201
0.7004 --- loss_d: 0.003188
0.7782 --- loss_d: 0.340094
0.8560 --- loss_d: 0.001004
0.9339 --- loss_d: 0.003548
Epoch finished! Loss: 0.057470951382924795
Starting epoch 9/10.
0.0000 --- loss_d: 0.005191
0.0778 --- loss_d: 0.020116
0.1556 --- loss_d: 0.024406
0.2335 --- loss_d: 0.021440
0.3113 --- loss_d: 0.026477
0.3891 --- loss_d: 0.111170
0.4669 --- loss_d: 0.086499
0.5447 --- loss_d: 0.005634
0.6226 --- loss_d: 0.009199
0.7004 --- loss_d: 0.012400
0.7782 --- loss_d: 0.010464
0.8560 --- loss_d: 0.023728
0.9339 --- loss_d: 0.004853
Epoch finished! Loss: 0.061623817860208874
Starting epoch 10/10.
0.0000 --- loss_d: 0.015511
0.0778 --- loss_d: 0.011384
0.1556 --- loss_d: 0.002116
0.2335 --- loss_d: 0.005208
0.3113 --- loss_d: 0.005549
0.3891 --- loss_d: 0.009311
0.4669 --- loss_d: 0.164098
0.5447 --- loss_d: 0.302380
0.6226 --- loss_d: 0.131489
0.7004 --- loss_d: 0.004324
0.7782 --- loss_d: 0.004376
0.8560 --- loss_d: 0.338612
0.9339 --- loss_d: 0.003885
Epoch finished! Loss: 0.045373334564601464
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.6
[5.59987081e-03 5.25806332e-03 2.88395328e-03 9.87796485e-01
 8.63006717e-05 8.13142136e-02 2.67050683e-01 9.94791269e-01
 9.66518104e-01 3.33810761e-03 9.99966621e-01 3.66282254e-01
 4.45295751e-01 7.60142565e-01 9.99995828e-01]
pred: 0.4590880047306806, label: 0
Right! Diagnosis: Other
Save 30mins of subject chc035-nsrr

=== Test on chc037-nsrr. train_data(1286), test_data(14) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.685127
0.0778 --- loss_d: 0.685480
0.1555 --- loss_d: 0.456958
0.2333 --- loss_d: 0.823922
0.3110 --- loss_d: 0.460009
0.3888 --- loss_d: 0.531554
0.4666 --- loss_d: 0.566377
0.5443 --- loss_d: 0.677686
0.6221 --- loss_d: 0.219477
0.6998 --- loss_d: 0.374130
0.7776 --- loss_d: 0.529495
0.8554 --- loss_d: 0.504509
0.9331 --- loss_d: 0.533496
Epoch finished! Loss: 0.5896361847408116
Starting epoch 2/10.
0.0000 --- loss_d: 0.474781
0.0778 --- loss_d: 0.339028
0.1555 --- loss_d: 0.339954
0.2333 --- loss_d: 0.531891
0.3110 --- loss_d: 0.314215
0.3888 --- loss_d: 0.394466
0.4666 --- loss_d: 0.310278
0.5443 --- loss_d: 0.305046
0.6221 --- loss_d: 0.505653
0.6998 --- loss_d: 0.282571
0.7776 --- loss_d: 0.638066
0.8554 --- loss_d: 0.438426
0.9331 --- loss_d: 0.380967
Epoch finished! Loss: 0.4135808711289428
Starting epoch 3/10.
0.0000 --- loss_d: 0.376709
0.0778 --- loss_d: 0.403932
0.1555 --- loss_d: 0.223445
0.2333 --- loss_d: 0.409653
0.3110 --- loss_d: 0.289306
0.3888 --- loss_d: 0.586254
0.4666 --- loss_d: 0.181569
0.5443 --- loss_d: 0.161059
0.6221 --- loss_d: 0.057893
0.6998 --- loss_d: 0.192735
0.7776 --- loss_d: 0.281075
0.8554 --- loss_d: 0.340531
0.9331 --- loss_d: 0.304556
Epoch finished! Loss: 0.3276523165695835
Starting epoch 4/10.
0.0000 --- loss_d: 0.842169
0.0778 --- loss_d: 0.097685
0.1555 --- loss_d: 0.212845
0.2333 --- loss_d: 0.259242
0.3110 --- loss_d: 0.297314
0.3888 --- loss_d: 0.068835
0.4666 --- loss_d: 0.287157
0.5443 --- loss_d: 0.155143
0.6221 --- loss_d: 0.222370
0.6998 --- loss_d: 0.608911
0.7776 --- loss_d: 0.087697
0.8554 --- loss_d: 0.626774
0.9331 --- loss_d: 0.269279
Epoch finished! Loss: 0.25104271473537665
Starting epoch 5/10.
0.0000 --- loss_d: 0.258295
0.0778 --- loss_d: 0.089871
0.1555 --- loss_d: 0.179421
0.2333 --- loss_d: 0.242093
0.3110 --- loss_d: 0.091731
0.3888 --- loss_d: 0.204411
0.4666 --- loss_d: 0.144851
0.5443 --- loss_d: 0.192942
0.6221 --- loss_d: 0.265444
0.6998 --- loss_d: 0.105550
0.7776 --- loss_d: 0.271907
0.8554 --- loss_d: 0.060455
0.9331 --- loss_d: 0.032121
Epoch finished! Loss: 0.2070489178149728
Starting epoch 6/10.
0.0000 --- loss_d: 0.214269
0.0778 --- loss_d: 0.019064
0.1555 --- loss_d: 0.087859
0.2333 --- loss_d: 0.111765
0.3110 --- loss_d: 0.087531
0.3888 --- loss_d: 0.027881
0.4666 --- loss_d: 0.371954
0.5443 --- loss_d: 0.381415
0.6221 --- loss_d: 0.283740
0.6998 --- loss_d: 0.522196
0.7776 --- loss_d: 0.094370
0.8554 --- loss_d: 0.022804
0.9331 --- loss_d: 0.055325
Epoch finished! Loss: 0.15867509806412272
Starting epoch 7/10.
0.0000 --- loss_d: 0.138145
0.0778 --- loss_d: 0.067573
0.1555 --- loss_d: 0.037628
0.2333 --- loss_d: 0.110871
0.3110 --- loss_d: 0.016616
0.3888 --- loss_d: 0.106580
0.4666 --- loss_d: 0.160528
0.5443 --- loss_d: 0.119153
0.6221 --- loss_d: 0.061040
0.6998 --- loss_d: 0.140045
0.7776 --- loss_d: 0.079125
0.8554 --- loss_d: 0.197965
0.9331 --- loss_d: 0.036555
Epoch finished! Loss: 0.13322038279511617
Starting epoch 8/10.
0.0000 --- loss_d: 0.052467
0.0778 --- loss_d: 0.011582
0.1555 --- loss_d: 0.002174
0.2333 --- loss_d: 0.009016
0.3110 --- loss_d: 0.019357
0.3888 --- loss_d: 0.532897
0.4666 --- loss_d: 0.018623
0.5443 --- loss_d: 0.040598
0.6221 --- loss_d: 0.044856
0.6998 --- loss_d: 0.028772
0.7776 --- loss_d: 0.028484
0.8554 --- loss_d: 0.034330
0.9331 --- loss_d: 0.152388
Epoch finished! Loss: 0.08743709638110886
Starting epoch 9/10.
0.0000 --- loss_d: 0.007620
0.0778 --- loss_d: 0.023642
0.1555 --- loss_d: 0.447981
0.2333 --- loss_d: 0.013389
0.3110 --- loss_d: 0.008603
0.3888 --- loss_d: 0.030079
0.4666 --- loss_d: 0.011575
0.5443 --- loss_d: 0.146715
0.6221 --- loss_d: 0.009606
0.6998 --- loss_d: 0.049360
0.7776 --- loss_d: 0.019510
0.8554 --- loss_d: 0.606668
0.9331 --- loss_d: 0.036363
Epoch finished! Loss: 0.0711078181548146
Starting epoch 10/10.
0.0000 --- loss_d: 0.006014
0.0778 --- loss_d: 0.065415
0.1555 --- loss_d: 0.169022
0.2333 --- loss_d: 0.003979
0.3110 --- loss_d: 0.003564
0.3888 --- loss_d: 0.006214
0.4666 --- loss_d: 0.043418
0.5443 --- loss_d: 0.058111
0.6221 --- loss_d: 0.008794
0.6998 --- loss_d: 0.011604
0.7776 --- loss_d: 0.150439
0.8554 --- loss_d: 0.207715
0.9331 --- loss_d: 0.015806
Epoch finished! Loss: 0.049181385227257124
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.2857142857142857
[0.79104376 0.18449377 0.96317244 0.91539997 0.39725032 0.96781856
 0.57087862 0.49052769 0.70785606 0.99825341 0.97658461 0.32001683
 0.99987817 0.99872583]
pred: 0.7344214309539113, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc037-nsrr

=== Test on chc040-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.709334
0.0780 --- loss_d: 0.553374
0.1560 --- loss_d: 0.494894
0.2340 --- loss_d: 0.590332
0.3120 --- loss_d: 0.662105
0.3900 --- loss_d: 0.444752
0.4680 --- loss_d: 0.836075
0.5460 --- loss_d: 0.546357
0.6240 --- loss_d: 0.901793
0.7020 --- loss_d: 0.440525
0.7800 --- loss_d: 0.662924
0.8580 --- loss_d: 0.446355
0.9360 --- loss_d: 0.350030
Epoch finished! Loss: 0.5943400806281716
Starting epoch 2/10.
0.0000 --- loss_d: 0.668064
0.0780 --- loss_d: 0.351884
0.1560 --- loss_d: 0.561596
0.2340 --- loss_d: 0.407320
0.3120 --- loss_d: 0.313888
0.3900 --- loss_d: 0.324856
0.4680 --- loss_d: 0.231266
0.5460 --- loss_d: 0.444488
0.6240 --- loss_d: 1.163222
0.7020 --- loss_d: 0.435025
0.7800 --- loss_d: 0.288333
0.8580 --- loss_d: 0.284355
0.9360 --- loss_d: 0.164645
Epoch finished! Loss: 0.42250460846116766
Starting epoch 3/10.
0.0000 --- loss_d: 0.230549
0.0780 --- loss_d: 0.752150
0.1560 --- loss_d: 0.366021
0.2340 --- loss_d: 0.334832
0.3120 --- loss_d: 0.346686
0.3900 --- loss_d: 0.155740
0.4680 --- loss_d: 0.241105
0.5460 --- loss_d: 0.201682
0.6240 --- loss_d: 0.333260
0.7020 --- loss_d: 0.391328
0.7800 --- loss_d: 0.159725
0.8580 --- loss_d: 0.155101
0.9360 --- loss_d: 0.171887
Epoch finished! Loss: 0.30157519842032343
Starting epoch 4/10.
0.0000 --- loss_d: 0.089705
0.0780 --- loss_d: 0.241490
0.1560 --- loss_d: 0.187741
0.2340 --- loss_d: 0.125954
0.3120 --- loss_d: 0.293618
0.3900 --- loss_d: 0.284908
0.4680 --- loss_d: 0.367048
0.5460 --- loss_d: 0.128596
0.6240 --- loss_d: 0.258185
0.7020 --- loss_d: 0.090070
0.7800 --- loss_d: 0.085754
0.8580 --- loss_d: 0.062537
0.9360 --- loss_d: 0.049928
Epoch finished! Loss: 0.25328953440475743
Starting epoch 5/10.
0.0000 --- loss_d: 0.128707
0.0780 --- loss_d: 0.321919
0.1560 --- loss_d: 0.381795
0.2340 --- loss_d: 0.027229
0.3120 --- loss_d: 0.291293
0.3900 --- loss_d: 0.053185
0.4680 --- loss_d: 0.074320
0.5460 --- loss_d: 0.309294
0.6240 --- loss_d: 0.187762
0.7020 --- loss_d: 0.025012
0.7800 --- loss_d: 0.832065
0.8580 --- loss_d: 0.147042
0.9360 --- loss_d: 0.118190
Epoch finished! Loss: 0.20123252144549042
Starting epoch 6/10.
0.0000 --- loss_d: 0.244359
0.0780 --- loss_d: 0.204978
0.1560 --- loss_d: 0.027340
0.2340 --- loss_d: 0.278149
0.3120 --- loss_d: 0.541215
0.3900 --- loss_d: 0.087691
0.4680 --- loss_d: 0.011715
0.5460 --- loss_d: 0.281039
0.6240 --- loss_d: 0.025731
0.7020 --- loss_d: 0.010788
0.7800 --- loss_d: 0.028067
0.8580 --- loss_d: 0.356236
0.9360 --- loss_d: 0.338608
Epoch finished! Loss: 0.1448474533681292
Starting epoch 7/10.
0.0000 --- loss_d: 0.179742
0.0780 --- loss_d: 0.055699
0.1560 --- loss_d: 0.078932
0.2340 --- loss_d: 0.024602
0.3120 --- loss_d: 0.053804
0.3900 --- loss_d: 0.146274
0.4680 --- loss_d: 0.008190
0.5460 --- loss_d: 0.047090
0.6240 --- loss_d: 0.103027
0.7020 --- loss_d: 0.085367
0.7800 --- loss_d: 0.275072
0.8580 --- loss_d: 0.018422
0.9360 --- loss_d: 0.181865
Epoch finished! Loss: 0.14332394082521205
Starting epoch 8/10.
0.0000 --- loss_d: 0.013711
0.0780 --- loss_d: 0.003850
0.1560 --- loss_d: 0.015299
0.2340 --- loss_d: 0.169176
0.3120 --- loss_d: 0.002432
0.3900 --- loss_d: 0.064021
0.4680 --- loss_d: 0.110079
0.5460 --- loss_d: 0.026076
0.6240 --- loss_d: 0.181212
0.7020 --- loss_d: 0.086077
0.7800 --- loss_d: 0.008393
0.8580 --- loss_d: 0.054388
0.9360 --- loss_d: 0.157884
Epoch finished! Loss: 0.07893301033436728
Starting epoch 9/10.
0.0000 --- loss_d: 0.015224
0.0780 --- loss_d: 0.005901
0.1560 --- loss_d: 0.002997
0.2340 --- loss_d: 0.065756
0.3120 --- loss_d: 0.051598
0.3900 --- loss_d: 0.130329
0.4680 --- loss_d: 0.006448
0.5460 --- loss_d: 0.006831
0.6240 --- loss_d: 0.019786
0.7020 --- loss_d: 0.022570
0.7800 --- loss_d: 0.028413
0.8580 --- loss_d: 0.011074
0.9360 --- loss_d: 0.008481
Epoch finished! Loss: 0.05137432575065759
Starting epoch 10/10.
0.0000 --- loss_d: 0.000134
0.0780 --- loss_d: 0.000998
0.1560 --- loss_d: 0.009992
0.2340 --- loss_d: 0.001210
0.3120 --- loss_d: 0.023920
0.3900 --- loss_d: 0.000378
0.4680 --- loss_d: 0.006892
0.5460 --- loss_d: 0.001354
0.6240 --- loss_d: 0.033714
0.7020 --- loss_d: 0.011769
0.7800 --- loss_d: 0.016241
0.8580 --- loss_d: 0.002994
0.9360 --- loss_d: 0.016123
Epoch finished! Loss: 0.05406353144576315
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.5555555555555556
[0.56809002 1.         0.97962886 0.01085672 0.04567893 0.94517142
 0.0613079  0.88837677 0.73332381 0.92674637 0.02038642 0.40551898
 0.08868515 0.19311664 0.1830202  0.01200595 0.95241076 0.10443895]
pred: 0.4510424359080692, label: 0
Right! Diagnosis: Other
Save 30mins of subject chc040-nsrr

=== Test on chc041-nsrr. train_data(1286), test_data(14) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.643856
0.0778 --- loss_d: 0.663244
0.1555 --- loss_d: 0.751824
0.2333 --- loss_d: 0.496777
0.3110 --- loss_d: 0.496944
0.3888 --- loss_d: 0.577678
0.4666 --- loss_d: 0.882966
0.5443 --- loss_d: 0.559705
0.6221 --- loss_d: 0.469329
0.6998 --- loss_d: 0.458444
0.7776 --- loss_d: 0.534346
0.8554 --- loss_d: 0.282871
0.9331 --- loss_d: 0.379819
Epoch finished! Loss: 0.5953446654602885
Starting epoch 2/10.
0.0000 --- loss_d: 0.363883
0.0778 --- loss_d: 0.411658
0.1555 --- loss_d: 0.274137
0.2333 --- loss_d: 0.577574
0.3110 --- loss_d: 1.029113
0.3888 --- loss_d: 0.563666
0.4666 --- loss_d: 0.326077
0.5443 --- loss_d: 0.296916
0.6221 --- loss_d: 0.244676
0.6998 --- loss_d: 0.365305
0.7776 --- loss_d: 0.484774
0.8554 --- loss_d: 0.234382
0.9331 --- loss_d: 0.436770
Epoch finished! Loss: 0.4100183831178583
Starting epoch 3/10.
0.0000 --- loss_d: 0.179971
0.0778 --- loss_d: 0.213349
0.1555 --- loss_d: 0.290842
0.2333 --- loss_d: 0.246615
0.3110 --- loss_d: 0.277278
0.3888 --- loss_d: 0.182107
0.4666 --- loss_d: 0.022690
0.5443 --- loss_d: 0.119680
0.6221 --- loss_d: 0.308726
0.6998 --- loss_d: 0.470987
0.7776 --- loss_d: 0.688041
0.8554 --- loss_d: 0.160553
0.9331 --- loss_d: 0.296362
Epoch finished! Loss: 0.27314810242387466
Starting epoch 4/10.
0.0000 --- loss_d: 0.347024
0.0778 --- loss_d: 0.105130
0.1555 --- loss_d: 0.087226
0.2333 --- loss_d: 0.131221
0.3110 --- loss_d: 0.227415
0.3888 --- loss_d: 0.254377
0.4666 --- loss_d: 0.173910
0.5443 --- loss_d: 0.141409
0.6221 --- loss_d: 0.228114
0.6998 --- loss_d: 0.193146
0.7776 --- loss_d: 0.099027
0.8554 --- loss_d: 0.569593
0.9331 --- loss_d: 0.336960
Epoch finished! Loss: 0.24315647246839944
Starting epoch 5/10.
0.0000 --- loss_d: 0.069654
0.0778 --- loss_d: 0.053615
0.1555 --- loss_d: 0.053375
0.2333 --- loss_d: 0.051805
0.3110 --- loss_d: 0.157352
0.3888 --- loss_d: 0.058228
0.4666 --- loss_d: 0.252327
0.5443 --- loss_d: 0.633294
0.6221 --- loss_d: 0.066291
0.6998 --- loss_d: 0.361978
0.7776 --- loss_d: 0.071663
0.8554 --- loss_d: 0.188606
0.9331 --- loss_d: 0.102272
Epoch finished! Loss: 0.18851187386462698
Starting epoch 6/10.
0.0000 --- loss_d: 0.116135
0.0778 --- loss_d: 0.078680
0.1555 --- loss_d: 0.099000
0.2333 --- loss_d: 0.087312
0.3110 --- loss_d: 0.015109
0.3888 --- loss_d: 0.092096
0.4666 --- loss_d: 0.011800
0.5443 --- loss_d: 0.017588
0.6221 --- loss_d: 0.010988
0.6998 --- loss_d: 0.017053
0.7776 --- loss_d: 0.061356
0.8554 --- loss_d: 0.165962
0.9331 --- loss_d: 0.044838
Epoch finished! Loss: 0.11533528978543472
Starting epoch 7/10.
0.0000 --- loss_d: 0.021592
0.0778 --- loss_d: 0.016078
0.1555 --- loss_d: 0.051579
0.2333 --- loss_d: 0.007710
0.3110 --- loss_d: 0.446339
0.3888 --- loss_d: 0.075599
0.4666 --- loss_d: 0.039560
0.5443 --- loss_d: 0.220017
0.6221 --- loss_d: 0.139856
0.6998 --- loss_d: 0.114384
0.7776 --- loss_d: 0.137129
0.8554 --- loss_d: 0.027163
0.9331 --- loss_d: 0.298953
Epoch finished! Loss: 0.0953712119762713
Starting epoch 8/10.
0.0000 --- loss_d: 0.010212
0.0778 --- loss_d: 0.003242
0.1555 --- loss_d: 0.037494
0.2333 --- loss_d: 0.009901
0.3110 --- loss_d: 0.019973
0.3888 --- loss_d: 0.007670
0.4666 --- loss_d: 0.035866
0.5443 --- loss_d: 0.094768
0.6221 --- loss_d: 0.114841
0.6998 --- loss_d: 0.003819
0.7776 --- loss_d: 0.003768
0.8554 --- loss_d: 0.335772
0.9331 --- loss_d: 0.001850
Epoch finished! Loss: 0.06118511866770859
Starting epoch 9/10.
0.0000 --- loss_d: 0.013979
0.0778 --- loss_d: 0.003631
0.1555 --- loss_d: 0.545149
0.2333 --- loss_d: 0.050659
0.3110 --- loss_d: 0.013311
0.3888 --- loss_d: 0.002252
0.4666 --- loss_d: 0.045351
0.5443 --- loss_d: 0.228446
0.6221 --- loss_d: 0.128051
0.6998 --- loss_d: 0.010680
0.7776 --- loss_d: 0.004466
0.8554 --- loss_d: 0.006731
0.9331 --- loss_d: 0.676529
Epoch finished! Loss: 0.08378049923885555
Starting epoch 10/10.
0.0000 --- loss_d: 0.011368
0.0778 --- loss_d: 0.005709
0.1555 --- loss_d: 0.062233
0.2333 --- loss_d: 0.076398
0.3110 --- loss_d: 0.003374
0.3888 --- loss_d: 0.081162
0.4666 --- loss_d: 0.008532
0.5443 --- loss_d: 0.015629
0.6221 --- loss_d: 0.004683
0.6998 --- loss_d: 0.013288
0.7776 --- loss_d: 0.014159
0.8554 --- loss_d: 0.002189
0.9331 --- loss_d: 0.265961
Epoch finished! Loss: 0.042953457965495545
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.07142857142857142
[0.93438339 0.9992792  0.93386877 0.999897   0.9998579  0.99960011
 0.99999774 0.99992955 0.99996901 0.99999833 0.99958748 0.9991985
 0.99358153 0.01842961]
pred: 0.9198270076885819, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc041-nsrr

=== Test on chc052-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.659010
0.0778 --- loss_d: 0.483926
0.1556 --- loss_d: 0.763846
0.2335 --- loss_d: 0.729779
0.3113 --- loss_d: 0.503806
0.3891 --- loss_d: 0.553275
0.4669 --- loss_d: 0.457993
0.5447 --- loss_d: 0.412004
0.6226 --- loss_d: 0.662973
0.7004 --- loss_d: 0.429645
0.7782 --- loss_d: 1.373939
0.8560 --- loss_d: 0.539044
0.9339 --- loss_d: 0.743597
Epoch finished! Loss: 0.59219322912395
Starting epoch 2/10.
0.0000 --- loss_d: 0.526995
0.0778 --- loss_d: 0.515019
0.1556 --- loss_d: 0.406140
0.2335 --- loss_d: 0.524208
0.3113 --- loss_d: 1.044705
0.3891 --- loss_d: 0.620086
0.4669 --- loss_d: 0.490628
0.5447 --- loss_d: 0.321444
0.6226 --- loss_d: 0.230734
0.7004 --- loss_d: 0.311259
0.7782 --- loss_d: 0.286081
0.8560 --- loss_d: 0.235758
0.9339 --- loss_d: 0.330612
Epoch finished! Loss: 0.42334205051884055
Starting epoch 3/10.
0.0000 --- loss_d: 0.307503
0.0778 --- loss_d: 0.102064
0.1556 --- loss_d: 0.156939
0.2335 --- loss_d: 0.218382
0.3113 --- loss_d: 0.122583
0.3891 --- loss_d: 0.244141
0.4669 --- loss_d: 1.120949
0.5447 --- loss_d: 0.549492
0.6226 --- loss_d: 0.361140
0.7004 --- loss_d: 0.350822
0.7782 --- loss_d: 0.176680
0.8560 --- loss_d: 0.439648
0.9339 --- loss_d: 0.430113
Epoch finished! Loss: 0.3343043197528459
Starting epoch 4/10.
0.0000 --- loss_d: 0.516090
0.0778 --- loss_d: 0.292546
0.1556 --- loss_d: 0.319776
0.2335 --- loss_d: 0.104025
0.3113 --- loss_d: 0.022499
0.3891 --- loss_d: 0.162914
0.4669 --- loss_d: 0.623749
0.5447 --- loss_d: 0.299060
0.6226 --- loss_d: 0.936172
0.7004 --- loss_d: 0.400418
0.7782 --- loss_d: 0.371017
0.8560 --- loss_d: 0.552076
0.9339 --- loss_d: 0.291502
Epoch finished! Loss: 0.2351478903874522
Starting epoch 5/10.
0.0000 --- loss_d: 0.078390
0.0778 --- loss_d: 0.119940
0.1556 --- loss_d: 0.136726
0.2335 --- loss_d: 0.101639
0.3113 --- loss_d: 0.108050
0.3891 --- loss_d: 0.065258
0.4669 --- loss_d: 0.082729
0.5447 --- loss_d: 0.831229
0.6226 --- loss_d: 0.065013
0.7004 --- loss_d: 0.136629
0.7782 --- loss_d: 0.131851
0.8560 --- loss_d: 0.198770
0.9339 --- loss_d: 0.021268
Epoch finished! Loss: 0.14061625449903659
Starting epoch 6/10.
0.0000 --- loss_d: 0.022939
0.0778 --- loss_d: 0.031027
0.1556 --- loss_d: 0.017766
0.2335 --- loss_d: 0.214944
0.3113 --- loss_d: 0.120550
0.3891 --- loss_d: 0.057936
0.4669 --- loss_d: 0.016907
0.5447 --- loss_d: 0.122930
0.6226 --- loss_d: 0.233633
0.7004 --- loss_d: 0.060224
0.7782 --- loss_d: 0.049021
0.8560 --- loss_d: 0.015506
0.9339 --- loss_d: 0.170325
Epoch finished! Loss: 0.13456693985426682
Starting epoch 7/10.
0.0000 --- loss_d: 0.125658
0.0778 --- loss_d: 0.008986
0.1556 --- loss_d: 0.016165
0.2335 --- loss_d: 0.005582
0.3113 --- loss_d: 0.470205
0.3891 --- loss_d: 0.304875
0.4669 --- loss_d: 0.240477
0.5447 --- loss_d: 0.020128
0.6226 --- loss_d: 0.031896
0.7004 --- loss_d: 0.081282
0.7782 --- loss_d: 0.084071
0.8560 --- loss_d: 0.017201
0.9339 --- loss_d: 0.016535
Epoch finished! Loss: 0.09758273925854155
Starting epoch 8/10.
0.0000 --- loss_d: 0.570747
0.0778 --- loss_d: 0.010755
0.1556 --- loss_d: 0.131098
0.2335 --- loss_d: 0.058684
0.3113 --- loss_d: 0.232896
0.3891 --- loss_d: 0.011067
0.4669 --- loss_d: 0.016425
0.5447 --- loss_d: 0.011812
0.6226 --- loss_d: 0.007961
0.7004 --- loss_d: 0.070752
0.7782 --- loss_d: 0.049622
0.8560 --- loss_d: 0.003147
0.9339 --- loss_d: 0.211149
Epoch finished! Loss: 0.07734180948136782
Starting epoch 9/10.
0.0000 --- loss_d: 0.010196
0.0778 --- loss_d: 0.073342
0.1556 --- loss_d: 0.003859
0.2335 --- loss_d: 0.005819
0.3113 --- loss_d: 0.328713
0.3891 --- loss_d: 0.288935
0.4669 --- loss_d: 0.023918
0.5447 --- loss_d: 0.045672
0.6226 --- loss_d: 0.043167
0.7004 --- loss_d: 0.004069
0.7782 --- loss_d: 0.077279
0.8560 --- loss_d: 0.015044
0.9339 --- loss_d: 0.004793
Epoch finished! Loss: 0.06630256195239781
Starting epoch 10/10.
0.0000 --- loss_d: 0.043679
0.0778 --- loss_d: 0.286428
0.1556 --- loss_d: 0.010878
0.2335 --- loss_d: 0.010460
0.3113 --- loss_d: 0.051015
0.3891 --- loss_d: 0.000899
0.4669 --- loss_d: 0.005967
0.5447 --- loss_d: 0.001777
0.6226 --- loss_d: 0.004769
0.7004 --- loss_d: 0.014692
0.7782 --- loss_d: 0.032589
0.8560 --- loss_d: 0.012761
0.9339 --- loss_d: 0.021531
Epoch finished! Loss: 0.048582947400518606
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.8666666666666667
[0.00218794 0.01771365 0.00300281 0.33149442 0.00224566 0.00150906
 0.53607482 0.30579275 0.00820165 0.11123415 0.01315795 0.00665727
 0.31158563 0.39677671 0.64938384]
pred: 0.17980122027608256, label: 0
Right! Diagnosis: Other
Save 30mins of subject chc052-nsrr

=== Test on chc056-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.666498
0.0778 --- loss_d: 0.598924
0.1556 --- loss_d: 0.570151
0.2335 --- loss_d: 0.530350
0.3113 --- loss_d: 0.288898
0.3891 --- loss_d: 1.127338
0.4669 --- loss_d: 0.705387
0.5447 --- loss_d: 0.591015
0.6226 --- loss_d: 0.539176
0.7004 --- loss_d: 0.562564
0.7782 --- loss_d: 0.442984
0.8560 --- loss_d: 0.534536
0.9339 --- loss_d: 0.806109
Epoch finished! Loss: 0.5945050553418696
Starting epoch 2/10.
0.0000 --- loss_d: 0.595095
0.0778 --- loss_d: 0.350810
0.1556 --- loss_d: 1.069043
0.2335 --- loss_d: 0.587834
0.3113 --- loss_d: 0.906802
0.3891 --- loss_d: 0.652701
0.4669 --- loss_d: 0.286744
0.5447 --- loss_d: 0.313817
0.6226 --- loss_d: 0.477399
0.7004 --- loss_d: 0.311824
0.7782 --- loss_d: 0.212768
0.8560 --- loss_d: 0.411152
0.9339 --- loss_d: 0.128212
Epoch finished! Loss: 0.4343572715879418
Starting epoch 3/10.
0.0000 --- loss_d: 0.256758
0.0778 --- loss_d: 0.286101
0.1556 --- loss_d: 0.371561
0.2335 --- loss_d: 0.090169
0.3113 --- loss_d: 0.714089
0.3891 --- loss_d: 0.202944
0.4669 --- loss_d: 0.324826
0.5447 --- loss_d: 0.292330
0.6226 --- loss_d: 0.305740
0.7004 --- loss_d: 0.245645
0.7782 --- loss_d: 0.289229
0.8560 --- loss_d: 0.082541
0.9339 --- loss_d: 0.097390
Epoch finished! Loss: 0.2718539555062307
Starting epoch 4/10.
0.0000 --- loss_d: 0.310990
0.0778 --- loss_d: 0.189142
0.1556 --- loss_d: 0.326106
0.2335 --- loss_d: 0.275757
0.3113 --- loss_d: 0.224394
0.3891 --- loss_d: 0.078090
0.4669 --- loss_d: 0.106875
0.5447 --- loss_d: 0.100148
0.6226 --- loss_d: 0.444006
0.7004 --- loss_d: 0.055344
0.7782 --- loss_d: 0.026561
0.8560 --- loss_d: 0.060495
0.9339 --- loss_d: 0.251024
Epoch finished! Loss: 0.22801237771636806
Starting epoch 5/10.
0.0000 --- loss_d: 0.044353
0.0778 --- loss_d: 0.114449
0.1556 --- loss_d: 0.118661
0.2335 --- loss_d: 0.145367
0.3113 --- loss_d: 0.840470
0.3891 --- loss_d: 0.065872
0.4669 --- loss_d: 0.062716
0.5447 --- loss_d: 0.124080
0.6226 --- loss_d: 0.248112
0.7004 --- loss_d: 0.089616
0.7782 --- loss_d: 0.060917
0.8560 --- loss_d: 0.551880
0.9339 --- loss_d: 0.282419
Epoch finished! Loss: 0.18188145494059427
Starting epoch 6/10.
0.0000 --- loss_d: 0.055690
0.0778 --- loss_d: 0.103307
0.1556 --- loss_d: 0.320691
0.2335 --- loss_d: 0.049163
0.3113 --- loss_d: 0.366221
0.3891 --- loss_d: 0.174083
0.4669 --- loss_d: 0.412864
0.5447 --- loss_d: 0.013294
0.6226 --- loss_d: 0.034409
0.7004 --- loss_d: 0.699176
0.7782 --- loss_d: 0.064809
0.8560 --- loss_d: 0.006031
0.9339 --- loss_d: 0.075991
Epoch finished! Loss: 0.14375005018519005
Starting epoch 7/10.
0.0000 --- loss_d: 0.016188
0.0778 --- loss_d: 0.066728
0.1556 --- loss_d: 0.062892
0.2335 --- loss_d: 0.025703
0.3113 --- loss_d: 0.097034
0.3891 --- loss_d: 0.114543
0.4669 --- loss_d: 0.027962
0.5447 --- loss_d: 0.014253
0.6226 --- loss_d: 0.037481
0.7004 --- loss_d: 0.010857
0.7782 --- loss_d: 0.076123
0.8560 --- loss_d: 0.193533
0.9339 --- loss_d: 0.371417
Epoch finished! Loss: 0.10461245842589051
Starting epoch 8/10.
0.0000 --- loss_d: 0.021721
0.0778 --- loss_d: 0.254035
0.1556 --- loss_d: 0.017162
0.2335 --- loss_d: 0.049518
0.3113 --- loss_d: 0.018169
0.3891 --- loss_d: 0.277745
0.4669 --- loss_d: 0.124237
0.5447 --- loss_d: 0.114534
0.6226 --- loss_d: 0.008714
0.7004 --- loss_d: 0.006541
0.7782 --- loss_d: 0.151408
0.8560 --- loss_d: 0.352571
0.9339 --- loss_d: 0.015098
Epoch finished! Loss: 0.09457040966753993
Starting epoch 9/10.
0.0000 --- loss_d: 0.014176
0.0778 --- loss_d: 0.017436
0.1556 --- loss_d: 0.056007
0.2335 --- loss_d: 0.134479
0.3113 --- loss_d: 0.022647
0.3891 --- loss_d: 0.011840
0.4669 --- loss_d: 0.009867
0.5447 --- loss_d: 0.001997
0.6226 --- loss_d: 0.212293
0.7004 --- loss_d: 0.053015
0.7782 --- loss_d: 0.004403
0.8560 --- loss_d: 0.299269
0.9339 --- loss_d: 0.022455
Epoch finished! Loss: 0.07170965513046212
Starting epoch 10/10.
0.0000 --- loss_d: 0.002695
0.0778 --- loss_d: 0.065390
0.1556 --- loss_d: 0.035894
0.2335 --- loss_d: 0.008380
0.3113 --- loss_d: 0.036482
0.3891 --- loss_d: 0.005712
0.4669 --- loss_d: 0.111072
0.5447 --- loss_d: 0.012853
0.6226 --- loss_d: 0.004529
0.7004 --- loss_d: 0.001972
0.7782 --- loss_d: 0.019926
0.8560 --- loss_d: 0.004394
0.9339 --- loss_d: 0.002602
Epoch finished! Loss: 0.049870988573729846
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.13333333333333333
[2.02744897e-03 9.98697519e-01 9.99644756e-01 9.99075651e-01
 9.99966860e-01 9.99985099e-01 9.99999285e-01 8.25331081e-04
 9.99939322e-01 9.99924898e-01 9.72667813e-01 9.99913335e-01
 9.99911666e-01 9.80432987e-01 9.99873638e-01]
pred: 0.8635257073522856, label: 0
Wrong!!! Real Diagnosis: Other
Save 30mins of subject chc056-nsrr

=== Test on chp001-nsrr. train_data(1281), test_data(19) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.700117
0.0781 --- loss_d: 0.527693
0.1561 --- loss_d: 0.743210
0.2342 --- loss_d: 0.813365
0.3123 --- loss_d: 0.700832
0.3903 --- loss_d: 0.295909
0.4684 --- loss_d: 0.597778
0.5464 --- loss_d: 0.396428
0.6245 --- loss_d: 0.771720
0.7026 --- loss_d: 0.657434
0.7806 --- loss_d: 0.507847
0.8587 --- loss_d: 0.602345
0.9368 --- loss_d: 0.541968
Epoch finished! Loss: 0.5981516164029017
Starting epoch 2/10.
0.0000 --- loss_d: 0.583364
0.0781 --- loss_d: 0.422321
0.1561 --- loss_d: 0.339703
0.2342 --- loss_d: 0.276083
0.3123 --- loss_d: 0.537125
0.3903 --- loss_d: 0.592087
0.4684 --- loss_d: 0.252178
0.5464 --- loss_d: 0.162853
0.6245 --- loss_d: 0.443363
0.7026 --- loss_d: 0.460284
0.7806 --- loss_d: 0.277491
0.8587 --- loss_d: 0.406908
0.9368 --- loss_d: 0.473981
Epoch finished! Loss: 0.4254339998587966
Starting epoch 3/10.
0.0000 --- loss_d: 0.108550
0.0781 --- loss_d: 0.238261
0.1561 --- loss_d: 0.433629
0.2342 --- loss_d: 0.111716
0.3123 --- loss_d: 0.143160
0.3903 --- loss_d: 0.291484
0.4684 --- loss_d: 0.248070
0.5464 --- loss_d: 0.082369
0.6245 --- loss_d: 0.128648
0.7026 --- loss_d: 0.328582
0.7806 --- loss_d: 0.623955
0.8587 --- loss_d: 0.137190
0.9368 --- loss_d: 0.226959
Epoch finished! Loss: 0.2964748531812802
Starting epoch 4/10.
0.0000 --- loss_d: 0.298152
0.0781 --- loss_d: 0.051149
0.1561 --- loss_d: 0.120577
0.2342 --- loss_d: 0.116798
0.3123 --- loss_d: 0.112873
0.3903 --- loss_d: 0.061581
0.4684 --- loss_d: 0.049447
0.5464 --- loss_d: 0.179881
0.6245 --- loss_d: 0.256904
0.7026 --- loss_d: 0.159577
0.7806 --- loss_d: 0.159277
0.8587 --- loss_d: 0.264200
0.9368 --- loss_d: 0.536380
Epoch finished! Loss: 0.2168518873368157
Starting epoch 5/10.
0.0000 --- loss_d: 0.293937
0.0781 --- loss_d: 0.058958
0.1561 --- loss_d: 0.362643
0.2342 --- loss_d: 0.036971
0.3123 --- loss_d: 0.058279
0.3903 --- loss_d: 0.147670
0.4684 --- loss_d: 0.207072
0.5464 --- loss_d: 0.332367
0.6245 --- loss_d: 0.076743
0.7026 --- loss_d: 0.480905
0.7806 --- loss_d: 0.427257
0.8587 --- loss_d: 0.088024
0.9368 --- loss_d: 0.168775
Epoch finished! Loss: 0.1402843367159221
Starting epoch 6/10.
0.0000 --- loss_d: 0.019997
0.0781 --- loss_d: 0.048891
0.1561 --- loss_d: 0.058905
0.2342 --- loss_d: 0.014440
0.3123 --- loss_d: 0.068515
0.3903 --- loss_d: 0.012297
0.4684 --- loss_d: 0.036035
0.5464 --- loss_d: 0.040323
0.6245 --- loss_d: 0.158469
0.7026 --- loss_d: 0.117255
0.7806 --- loss_d: 0.213235
0.8587 --- loss_d: 0.217978
0.9368 --- loss_d: 0.136091
Epoch finished! Loss: 0.1312231222509581
Starting epoch 7/10.
0.0000 --- loss_d: 0.053697
0.0781 --- loss_d: 0.076180
0.1561 --- loss_d: 0.049110
0.2342 --- loss_d: 0.390558
0.3123 --- loss_d: 0.110445
0.3903 --- loss_d: 0.296218
0.4684 --- loss_d: 0.065781
0.5464 --- loss_d: 0.182577
0.6245 --- loss_d: 0.329441
0.7026 --- loss_d: 0.014743
0.7806 --- loss_d: 0.027641
0.8587 --- loss_d: 0.588329
0.9368 --- loss_d: 0.288889
Epoch finished! Loss: 0.1466085216452484
Starting epoch 8/10.
0.0000 --- loss_d: 0.014323
0.0781 --- loss_d: 0.016941
0.1561 --- loss_d: 0.006397
0.2342 --- loss_d: 0.015623
0.3123 --- loss_d: 0.032254
0.3903 --- loss_d: 0.056578
0.4684 --- loss_d: 0.026170
0.5464 --- loss_d: 0.028451
0.6245 --- loss_d: 0.006981
0.7026 --- loss_d: 0.021363
0.7806 --- loss_d: 0.002763
0.8587 --- loss_d: 0.102524
0.9368 --- loss_d: 0.055080
Epoch finished! Loss: 0.11302169717691868
Starting epoch 9/10.
0.0000 --- loss_d: 0.023037
0.0781 --- loss_d: 0.564442
0.1561 --- loss_d: 0.021982
0.2342 --- loss_d: 0.064906
0.3123 --- loss_d: 0.055187
0.3903 --- loss_d: 0.014432
0.4684 --- loss_d: 0.069944
0.5464 --- loss_d: 0.004821
0.6245 --- loss_d: 0.015770
0.7026 --- loss_d: 0.006885
0.7806 --- loss_d: 0.025667
0.8587 --- loss_d: 0.008448
0.9368 --- loss_d: 0.023231
Epoch finished! Loss: 0.09061940545188918
Starting epoch 10/10.
0.0000 --- loss_d: 0.003222
0.0781 --- loss_d: 0.022574
0.1561 --- loss_d: 0.001097
0.2342 --- loss_d: 0.267968
0.3123 --- loss_d: 0.014916
0.3903 --- loss_d: 0.002830
0.4684 --- loss_d: 0.008882
0.5464 --- loss_d: 0.010846
0.6245 --- loss_d: 0.005232
0.7026 --- loss_d: 0.001965
0.7806 --- loss_d: 0.000682
0.8587 --- loss_d: 0.009902
0.9368 --- loss_d: 0.010016
Epoch finished! Loss: 0.03930634776077113
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99992585 0.9997744  0.99999797 0.99999952 0.99999881 0.98465168
 0.99999142 0.99999809 0.99994183 0.99999857 0.99999833 0.99998355
 0.99998331 0.9999603  0.99999905 0.99999905 0.99998486 0.99989712
 0.9999752 ]
pred: 0.9991609956088819, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp001-nsrr

=== Test on chp002-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.777079
0.0780 --- loss_d: 0.652461
0.1560 --- loss_d: 0.592649
0.2340 --- loss_d: 0.743215
0.3120 --- loss_d: 0.488483
0.3900 --- loss_d: 0.671990
0.4680 --- loss_d: 0.342465
0.5460 --- loss_d: 0.446829
0.6240 --- loss_d: 0.892334
0.7020 --- loss_d: 0.391479
0.7800 --- loss_d: 0.619092
0.8580 --- loss_d: 0.525146
0.9360 --- loss_d: 0.516584
Epoch finished! Loss: 0.6185907832114026
Starting epoch 2/10.
0.0000 --- loss_d: 0.485794
0.0780 --- loss_d: 0.691126
0.1560 --- loss_d: 0.557867
0.2340 --- loss_d: 0.474963
0.3120 --- loss_d: 0.378646
0.3900 --- loss_d: 0.811274
0.4680 --- loss_d: 0.495333
0.5460 --- loss_d: 0.792601
0.6240 --- loss_d: 0.320572
0.7020 --- loss_d: 0.460726
0.7800 --- loss_d: 0.296153
0.8580 --- loss_d: 0.599712
0.9360 --- loss_d: 0.186603
Epoch finished! Loss: 0.45864521944895387
Starting epoch 3/10.
0.0000 --- loss_d: 0.443336
0.0780 --- loss_d: 0.412620
0.1560 --- loss_d: 0.194268
0.2340 --- loss_d: 0.136725
0.3120 --- loss_d: 0.302079
0.3900 --- loss_d: 0.123873
0.4680 --- loss_d: 0.180248
0.5460 --- loss_d: 0.469652
0.6240 --- loss_d: 0.480867
0.7020 --- loss_d: 0.431243
0.7800 --- loss_d: 0.247447
0.8580 --- loss_d: 0.245083
0.9360 --- loss_d: 0.072975
Epoch finished! Loss: 0.2877322007843759
Starting epoch 4/10.
0.0000 --- loss_d: 0.065055
0.0780 --- loss_d: 0.155386
0.1560 --- loss_d: 0.097728
0.2340 --- loss_d: 0.157521
0.3120 --- loss_d: 0.137217
0.3900 --- loss_d: 0.121111
0.4680 --- loss_d: 0.150503
0.5460 --- loss_d: 0.184963
0.6240 --- loss_d: 0.039223
0.7020 --- loss_d: 0.559460
0.7800 --- loss_d: 0.185633
0.8580 --- loss_d: 0.826671
0.9360 --- loss_d: 0.195220
Epoch finished! Loss: 0.24007070629158989
Starting epoch 5/10.
0.0000 --- loss_d: 0.211647
0.0780 --- loss_d: 0.356025
0.1560 --- loss_d: 0.074417
0.2340 --- loss_d: 0.116184
0.3120 --- loss_d: 0.233579
0.3900 --- loss_d: 0.315916
0.4680 --- loss_d: 0.141734
0.5460 --- loss_d: 0.304597
0.6240 --- loss_d: 0.205649
0.7020 --- loss_d: 0.134859
0.7800 --- loss_d: 0.283521
0.8580 --- loss_d: 0.061286
0.9360 --- loss_d: 0.018108
Epoch finished! Loss: 0.22054676034895238
Starting epoch 6/10.
0.0000 --- loss_d: 0.205761
0.0780 --- loss_d: 0.036917
0.1560 --- loss_d: 0.163786
0.2340 --- loss_d: 0.087907
0.3120 --- loss_d: 0.148844
0.3900 --- loss_d: 0.138767
0.4680 --- loss_d: 0.136932
0.5460 --- loss_d: 0.150097
0.6240 --- loss_d: 0.102420
0.7020 --- loss_d: 0.015898
0.7800 --- loss_d: 0.125971
0.8580 --- loss_d: 0.085211
0.9360 --- loss_d: 0.071897
Epoch finished! Loss: 0.13408672489822493
Starting epoch 7/10.
0.0000 --- loss_d: 0.005268
0.0780 --- loss_d: 0.051173
0.1560 --- loss_d: 0.024293
0.2340 --- loss_d: 0.061199
0.3120 --- loss_d: 0.211805
0.3900 --- loss_d: 0.192949
0.4680 --- loss_d: 0.011847
0.5460 --- loss_d: 0.305634
0.6240 --- loss_d: 0.056136
0.7020 --- loss_d: 0.027714
0.7800 --- loss_d: 0.067460
0.8580 --- loss_d: 0.587258
0.9360 --- loss_d: 0.169401
Epoch finished! Loss: 0.1611641084200528
Starting epoch 8/10.
0.0000 --- loss_d: 0.091291
0.0780 --- loss_d: 0.601713
0.1560 --- loss_d: 0.052796
0.2340 --- loss_d: 0.036258
0.3120 --- loss_d: 0.011364
0.3900 --- loss_d: 0.053008
0.4680 --- loss_d: 0.043791
0.5460 --- loss_d: 0.019046
0.6240 --- loss_d: 0.012384
0.7020 --- loss_d: 0.275918
0.7800 --- loss_d: 0.031891
0.8580 --- loss_d: 0.028818
0.9360 --- loss_d: 0.266659
Epoch finished! Loss: 0.1194147610804066
Starting epoch 9/10.
0.0000 --- loss_d: 0.016103
0.0780 --- loss_d: 0.208820
0.1560 --- loss_d: 0.213480
0.2340 --- loss_d: 0.039398
0.3120 --- loss_d: 0.071615
0.3900 --- loss_d: 0.038302
0.4680 --- loss_d: 0.033382
0.5460 --- loss_d: 0.109734
0.6240 --- loss_d: 0.041409
0.7020 --- loss_d: 0.345237
0.7800 --- loss_d: 0.030217
0.8580 --- loss_d: 0.017310
0.9360 --- loss_d: 0.263541
Epoch finished! Loss: 0.11596468234893109
Starting epoch 10/10.
0.0000 --- loss_d: 0.005819
0.0780 --- loss_d: 0.087328
0.1560 --- loss_d: 0.010513
0.2340 --- loss_d: 0.054411
0.3120 --- loss_d: 0.006189
0.3900 --- loss_d: 0.099023
0.4680 --- loss_d: 0.011094
0.5460 --- loss_d: 0.145113
0.6240 --- loss_d: 0.076177
0.7020 --- loss_d: 0.005491
0.7800 --- loss_d: 0.349182
0.8580 --- loss_d: 0.002431
0.9360 --- loss_d: 0.038771
Epoch finished! Loss: 0.0672904659049891
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[1.         0.99995339 0.99999785 0.99999988 0.99999964 0.99999845
 1.         0.99999988 1.         0.99999976 1.         1.
 0.99999952 1.         0.99999988 0.99993837 0.99999869 0.99999928]
pred: 0.9999935891893175, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp002-nsrr

=== Test on chp003-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.689072
0.0779 --- loss_d: 0.558620
0.1558 --- loss_d: 0.585021
0.2336 --- loss_d: 0.621750
0.3115 --- loss_d: 0.536918
0.3894 --- loss_d: 0.440890
0.4673 --- loss_d: 0.651055
0.5452 --- loss_d: 0.523613
0.6231 --- loss_d: 0.344919
0.7009 --- loss_d: 0.613425
0.7788 --- loss_d: 0.543482
0.8567 --- loss_d: 0.817293
0.9346 --- loss_d: 0.250226
Epoch finished! Loss: 0.5921118084806949
Starting epoch 2/10.
0.0000 --- loss_d: 0.295377
0.0779 --- loss_d: 0.762998
0.1558 --- loss_d: 0.349821
0.2336 --- loss_d: 0.294543
0.3115 --- loss_d: 0.485156
0.3894 --- loss_d: 0.642293
0.4673 --- loss_d: 0.564094
0.5452 --- loss_d: 0.324486
0.6231 --- loss_d: 0.244845
0.7009 --- loss_d: 0.079388
0.7788 --- loss_d: 0.575428
0.8567 --- loss_d: 0.197108
0.9346 --- loss_d: 0.461835
Epoch finished! Loss: 0.41584258317016065
Starting epoch 3/10.
0.0000 --- loss_d: 0.317935
0.0779 --- loss_d: 0.225271
0.1558 --- loss_d: 0.205520
0.2336 --- loss_d: 0.072367
0.3115 --- loss_d: 0.235094
0.3894 --- loss_d: 0.178542
0.4673 --- loss_d: 0.176236
0.5452 --- loss_d: 0.229027
0.6231 --- loss_d: 0.148429
0.7009 --- loss_d: 0.439578
0.7788 --- loss_d: 0.465266
0.8567 --- loss_d: 0.100486
0.9346 --- loss_d: 0.147772
Epoch finished! Loss: 0.29588057822547853
Starting epoch 4/10.
0.0000 --- loss_d: 0.288767
0.0779 --- loss_d: 0.119281
0.1558 --- loss_d: 0.164440
0.2336 --- loss_d: 0.052056
0.3115 --- loss_d: 0.142764
0.3894 --- loss_d: 0.286543
0.4673 --- loss_d: 0.265005
0.5452 --- loss_d: 0.484257
0.6231 --- loss_d: 0.198677
0.7009 --- loss_d: 0.432650
0.7788 --- loss_d: 0.133241
0.8567 --- loss_d: 0.584287
0.9346 --- loss_d: 0.111576
Epoch finished! Loss: 0.21799721599381883
Starting epoch 5/10.
0.0000 --- loss_d: 0.107529
0.0779 --- loss_d: 0.028139
0.1558 --- loss_d: 0.096985
0.2336 --- loss_d: 0.058960
0.3115 --- loss_d: 0.144212
0.3894 --- loss_d: 0.167488
0.4673 --- loss_d: 0.104989
0.5452 --- loss_d: 0.039753
0.6231 --- loss_d: 0.116952
0.7009 --- loss_d: 0.141864
0.7788 --- loss_d: 0.123448
0.8567 --- loss_d: 0.038975
0.9346 --- loss_d: 1.598158
Epoch finished! Loss: 0.19290022185305133
Starting epoch 6/10.
0.0000 --- loss_d: 0.096384
0.0779 --- loss_d: 0.308332
0.1558 --- loss_d: 0.475241
0.2336 --- loss_d: 0.111645
0.3115 --- loss_d: 0.357780
0.3894 --- loss_d: 0.100450
0.4673 --- loss_d: 0.010208
0.5452 --- loss_d: 0.050028
0.6231 --- loss_d: 0.114409
0.7009 --- loss_d: 0.027552
0.7788 --- loss_d: 0.062033
0.8567 --- loss_d: 0.023019
0.9346 --- loss_d: 0.020713
Epoch finished! Loss: 0.1579593120404752
Starting epoch 7/10.
0.0000 --- loss_d: 0.020531
0.0779 --- loss_d: 0.011271
0.1558 --- loss_d: 0.041726
0.2336 --- loss_d: 0.060875
0.3115 --- loss_d: 0.106613
0.3894 --- loss_d: 0.011369
0.4673 --- loss_d: 0.459465
0.5452 --- loss_d: 0.045392
0.6231 --- loss_d: 0.140254
0.7009 --- loss_d: 0.027976
0.7788 --- loss_d: 0.030752
0.8567 --- loss_d: 0.221280
0.9346 --- loss_d: 0.032537
Epoch finished! Loss: 0.08804159107057785
Starting epoch 8/10.
0.0000 --- loss_d: 0.008665
0.0779 --- loss_d: 0.008299
0.1558 --- loss_d: 0.145861
0.2336 --- loss_d: 0.293896
0.3115 --- loss_d: 0.012983
0.3894 --- loss_d: 0.034829
0.4673 --- loss_d: 0.047476
0.5452 --- loss_d: 0.010293
0.6231 --- loss_d: 0.088156
0.7009 --- loss_d: 0.008589
0.7788 --- loss_d: 0.019276
0.8567 --- loss_d: 0.057976
0.9346 --- loss_d: 0.063946
Epoch finished! Loss: 0.10770146476897935
Starting epoch 9/10.
0.0000 --- loss_d: 0.075993
0.0779 --- loss_d: 0.048846
0.1558 --- loss_d: 0.049507
0.2336 --- loss_d: 0.064966
0.3115 --- loss_d: 0.014397
0.3894 --- loss_d: 0.011056
0.4673 --- loss_d: 0.004502
0.5452 --- loss_d: 0.075269
0.6231 --- loss_d: 0.002765
0.7009 --- loss_d: 0.013910
0.7788 --- loss_d: 0.004722
0.8567 --- loss_d: 0.012939
0.9346 --- loss_d: 0.003261
Epoch finished! Loss: 0.07310956034143601
Starting epoch 10/10.
0.0000 --- loss_d: 0.009809
0.0779 --- loss_d: 0.073730
0.1558 --- loss_d: 0.789955
0.2336 --- loss_d: 0.005093
0.3115 --- loss_d: 0.027614
0.3894 --- loss_d: 0.011993
0.4673 --- loss_d: 0.022727
0.5452 --- loss_d: 0.072612
0.6231 --- loss_d: 0.154407
0.7009 --- loss_d: 0.007006
0.7788 --- loss_d: 0.112564
0.8567 --- loss_d: 0.035108
0.9346 --- loss_d: 0.330356
Epoch finished! Loss: 0.07280959330910264
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999166 0.99994588 0.93785661 0.99672502 0.98372042 0.99999964
 0.99998903 0.99056023 0.9914546  0.99999666 0.99999678 0.99958044
 1.         0.99976116 0.98965234 0.99997854]
pred: 0.9930755645036697, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp003-nsrr

=== Test on chp004-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.668362
0.0779 --- loss_d: 0.756964
0.1558 --- loss_d: 0.688404
0.2336 --- loss_d: 0.982226
0.3115 --- loss_d: 0.715384
0.3894 --- loss_d: 0.460197
0.4673 --- loss_d: 0.961277
0.5452 --- loss_d: 0.567451
0.6231 --- loss_d: 0.524529
0.7009 --- loss_d: 0.351444
0.7788 --- loss_d: 0.451530
0.8567 --- loss_d: 0.462475
0.9346 --- loss_d: 0.499230
Epoch finished! Loss: 0.5843038843013346
Starting epoch 2/10.
0.0000 --- loss_d: 0.477890
0.0779 --- loss_d: 0.453627
0.1558 --- loss_d: 0.437112
0.2336 --- loss_d: 0.666393
0.3115 --- loss_d: 0.432204
0.3894 --- loss_d: 0.742461
0.4673 --- loss_d: 0.219191
0.5452 --- loss_d: 0.313952
0.6231 --- loss_d: 0.594743
0.7009 --- loss_d: 0.538529
0.7788 --- loss_d: 0.326998
0.8567 --- loss_d: 0.341517
0.9346 --- loss_d: 0.523551
Epoch finished! Loss: 0.46092688071075827
Starting epoch 3/10.
0.0000 --- loss_d: 0.266479
0.0779 --- loss_d: 0.531204
0.1558 --- loss_d: 0.275744
0.2336 --- loss_d: 0.645114
0.3115 --- loss_d: 0.247914
0.3894 --- loss_d: 0.186642
0.4673 --- loss_d: 0.390453
0.5452 --- loss_d: 0.167465
0.6231 --- loss_d: 0.134935
0.7009 --- loss_d: 0.472233
0.7788 --- loss_d: 0.184617
0.8567 --- loss_d: 0.184312
0.9346 --- loss_d: 0.109388
Epoch finished! Loss: 0.3025362107437104
Starting epoch 4/10.
0.0000 --- loss_d: 0.511392
0.0779 --- loss_d: 0.182219
0.1558 --- loss_d: 0.101108
0.2336 --- loss_d: 0.131281
0.3115 --- loss_d: 0.314265
0.3894 --- loss_d: 0.108113
0.4673 --- loss_d: 0.076485
0.5452 --- loss_d: 0.116261
0.6231 --- loss_d: 0.584491
0.7009 --- loss_d: 0.083163
0.7788 --- loss_d: 0.354620
0.8567 --- loss_d: 0.072337
0.9346 --- loss_d: 0.310318
Epoch finished! Loss: 0.25823236210271716
Starting epoch 5/10.
0.0000 --- loss_d: 0.168879
0.0779 --- loss_d: 0.130831
0.1558 --- loss_d: 0.095235
0.2336 --- loss_d: 0.109172
0.3115 --- loss_d: 0.009032
0.3894 --- loss_d: 0.195639
0.4673 --- loss_d: 0.106037
0.5452 --- loss_d: 0.066471
0.6231 --- loss_d: 0.651150
0.7009 --- loss_d: 0.024581
0.7788 --- loss_d: 0.202957
0.8567 --- loss_d: 0.085036
0.9346 --- loss_d: 0.049349
Epoch finished! Loss: 0.17764988401177106
Starting epoch 6/10.
0.0000 --- loss_d: 0.012701
0.0779 --- loss_d: 0.773612
0.1558 --- loss_d: 0.076793
0.2336 --- loss_d: 0.064095
0.3115 --- loss_d: 0.105370
0.3894 --- loss_d: 0.154472
0.4673 --- loss_d: 0.021966
0.5452 --- loss_d: 0.009430
0.6231 --- loss_d: 0.052190
0.7009 --- loss_d: 0.035499
0.7788 --- loss_d: 0.228902
0.8567 --- loss_d: 0.308686
0.9346 --- loss_d: 0.123491
Epoch finished! Loss: 0.16278752614016412
Starting epoch 7/10.
0.0000 --- loss_d: 0.172438
0.0779 --- loss_d: 0.048782
0.1558 --- loss_d: 0.009393
0.2336 --- loss_d: 0.015783
0.3115 --- loss_d: 0.144703
0.3894 --- loss_d: 0.204965
0.4673 --- loss_d: 0.028614
0.5452 --- loss_d: 0.144157
0.6231 --- loss_d: 0.015642
0.7009 --- loss_d: 0.014725
0.7788 --- loss_d: 0.021795
0.8567 --- loss_d: 0.028113
0.9346 --- loss_d: 0.020523
Epoch finished! Loss: 0.11564741106121801
Starting epoch 8/10.
0.0000 --- loss_d: 0.043933
0.0779 --- loss_d: 0.637401
0.1558 --- loss_d: 0.014037
0.2336 --- loss_d: 0.102727
0.3115 --- loss_d: 0.024535
0.3894 --- loss_d: 0.178686
0.4673 --- loss_d: 0.038568
0.5452 --- loss_d: 0.057560
0.6231 --- loss_d: 0.236691
0.7009 --- loss_d: 0.058697
0.7788 --- loss_d: 0.026078
0.8567 --- loss_d: 0.015580
0.9346 --- loss_d: 0.004827
Epoch finished! Loss: 0.1101949380717997
Starting epoch 9/10.
0.0000 --- loss_d: 0.012474
0.0779 --- loss_d: 0.040823
0.1558 --- loss_d: 0.048479
0.2336 --- loss_d: 0.122359
0.3115 --- loss_d: 0.004864
0.3894 --- loss_d: 0.066192
0.4673 --- loss_d: 0.017527
0.5452 --- loss_d: 0.003039
0.6231 --- loss_d: 0.005624
0.7009 --- loss_d: 0.007336
0.7788 --- loss_d: 0.194093
0.8567 --- loss_d: 0.073952
0.9346 --- loss_d: 0.186083
Epoch finished! Loss: 0.0693161453700668
Starting epoch 10/10.
0.0000 --- loss_d: 0.079200
0.0779 --- loss_d: 0.005419
0.1558 --- loss_d: 0.027931
0.2336 --- loss_d: 0.245907
0.3115 --- loss_d: 0.003094
0.3894 --- loss_d: 0.002455
0.4673 --- loss_d: 0.014255
0.5452 --- loss_d: 0.037041
0.6231 --- loss_d: 0.017741
0.7009 --- loss_d: 0.006115
0.7788 --- loss_d: 0.006368
0.8567 --- loss_d: 0.029879
0.9346 --- loss_d: 0.003249
Epoch finished! Loss: 0.04589202259785452
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99998689 0.97068858 1.         0.99999845 0.99997091 0.99999928
 0.99998355 0.99999797 0.99888998 0.99552661 0.9999789  0.99997616
 0.99616587 0.98394161 0.99921775 0.99213225]
pred: 0.9960284233093262, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp004-nsrr

=== Test on chp005-nsrr. train_data(1279), test_data(21) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.756574
0.0782 --- loss_d: 0.476307
0.1564 --- loss_d: 0.503953
0.2346 --- loss_d: 0.592678
0.3127 --- loss_d: 0.474713
0.3909 --- loss_d: 0.826795
0.4691 --- loss_d: 0.553888
0.5473 --- loss_d: 0.526970
0.6255 --- loss_d: 0.754159
0.7037 --- loss_d: 0.671825
0.7819 --- loss_d: 0.509418
0.8600 --- loss_d: 0.760159
0.9382 --- loss_d: 0.499723
Epoch finished! Loss: 0.5930509326730188
Starting epoch 2/10.
0.0000 --- loss_d: 0.592418
0.0782 --- loss_d: 0.513100
0.1564 --- loss_d: 0.499730
0.2346 --- loss_d: 0.541235
0.3127 --- loss_d: 0.249819
0.3909 --- loss_d: 0.669289
0.4691 --- loss_d: 0.465839
0.5473 --- loss_d: 0.520992
0.6255 --- loss_d: 0.352925
0.7037 --- loss_d: 0.249661
0.7819 --- loss_d: 0.228687
0.8600 --- loss_d: 0.436047
0.9382 --- loss_d: 0.530037
Epoch finished! Loss: 0.4329366036287443
Starting epoch 3/10.
0.0000 --- loss_d: 0.260067
0.0782 --- loss_d: 0.265622
0.1564 --- loss_d: 0.427180
0.2346 --- loss_d: 0.318947
0.3127 --- loss_d: 0.359408
0.3909 --- loss_d: 0.331977
0.4691 --- loss_d: 0.666632
0.5473 --- loss_d: 0.136626
0.6255 --- loss_d: 0.381059
0.7037 --- loss_d: 0.306339
0.7819 --- loss_d: 0.130166
0.8600 --- loss_d: 0.200965
0.9382 --- loss_d: 0.127919
Epoch finished! Loss: 0.2902351413068809
Starting epoch 4/10.
0.0000 --- loss_d: 0.042181
0.0782 --- loss_d: 0.061169
0.1564 --- loss_d: 0.149812
0.2346 --- loss_d: 0.071830
0.3127 --- loss_d: 0.238251
0.3909 --- loss_d: 0.131271
0.4691 --- loss_d: 0.083758
0.5473 --- loss_d: 0.270617
0.6255 --- loss_d: 0.116037
0.7037 --- loss_d: 0.088381
0.7819 --- loss_d: 0.058900
0.8600 --- loss_d: 0.722580
0.9382 --- loss_d: 0.149744
Epoch finished! Loss: 0.20632288333644547
Starting epoch 5/10.
0.0000 --- loss_d: 0.101798
0.0782 --- loss_d: 0.065840
0.1564 --- loss_d: 0.698428
0.2346 --- loss_d: 0.047405
0.3127 --- loss_d: 0.230655
0.3909 --- loss_d: 0.025777
0.4691 --- loss_d: 0.108081
0.5473 --- loss_d: 0.472775
0.6255 --- loss_d: 0.132356
0.7037 --- loss_d: 0.025556
0.7819 --- loss_d: 0.011813
0.8600 --- loss_d: 0.108507
0.9382 --- loss_d: 0.830999
Epoch finished! Loss: 0.17378471339282792
Starting epoch 6/10.
0.0000 --- loss_d: 0.134024
0.0782 --- loss_d: 0.047832
0.1564 --- loss_d: 0.013427
0.2346 --- loss_d: 0.024209
0.3127 --- loss_d: 0.104269
0.3909 --- loss_d: 0.074500
0.4691 --- loss_d: 0.290143
0.5473 --- loss_d: 0.010879
0.6255 --- loss_d: 0.021135
0.7037 --- loss_d: 0.502679
0.7819 --- loss_d: 0.025742
0.8600 --- loss_d: 0.575195
0.9382 --- loss_d: 0.157162
Epoch finished! Loss: 0.12569103059615558
Starting epoch 7/10.
0.0000 --- loss_d: 0.034800
0.0782 --- loss_d: 0.007682
0.1564 --- loss_d: 0.054938
0.2346 --- loss_d: 0.073754
0.3127 --- loss_d: 0.003913
0.3909 --- loss_d: 0.037808
0.4691 --- loss_d: 0.002920
0.5473 --- loss_d: 0.005598
0.6255 --- loss_d: 0.064053
0.7037 --- loss_d: 0.045074
0.7819 --- loss_d: 0.025758
0.8600 --- loss_d: 0.281232
0.9382 --- loss_d: 0.129191
Epoch finished! Loss: 0.05554332089973393
Starting epoch 8/10.
0.0000 --- loss_d: 0.006329
0.0782 --- loss_d: 0.133450
0.1564 --- loss_d: 0.044825
0.2346 --- loss_d: 0.485045
0.3127 --- loss_d: 0.008159
0.3909 --- loss_d: 0.012086
0.4691 --- loss_d: 0.106452
0.5473 --- loss_d: 0.210542
0.6255 --- loss_d: 0.140927
0.7037 --- loss_d: 0.063075
0.7819 --- loss_d: 0.042772
0.8600 --- loss_d: 0.006774
0.9382 --- loss_d: 0.007704
Epoch finished! Loss: 0.08332795475418936
Starting epoch 9/10.
0.0000 --- loss_d: 0.004114
0.0782 --- loss_d: 0.002956
0.1564 --- loss_d: 0.034367
0.2346 --- loss_d: 0.004201
0.3127 --- loss_d: 0.003104
0.3909 --- loss_d: 0.007406
0.4691 --- loss_d: 0.212281
0.5473 --- loss_d: 0.136390
0.6255 --- loss_d: 0.015001
0.7037 --- loss_d: 0.019761
0.7819 --- loss_d: 0.012880
0.8600 --- loss_d: 0.046074
0.9382 --- loss_d: 0.046879
Epoch finished! Loss: 0.060822850274743406
Starting epoch 10/10.
0.0000 --- loss_d: 0.002167
0.0782 --- loss_d: 0.348426
0.1564 --- loss_d: 0.012992
0.2346 --- loss_d: 0.232883
0.3127 --- loss_d: 0.009017
0.3909 --- loss_d: 0.002041
0.4691 --- loss_d: 0.006471
0.5473 --- loss_d: 0.035712
0.6255 --- loss_d: 0.010249
0.7037 --- loss_d: 0.031448
0.7819 --- loss_d: 0.000298
0.8600 --- loss_d: 0.001862
0.9382 --- loss_d: 0.002028
Epoch finished! Loss: 0.035214900546276386
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999988 1.         1.         1.         1.         1.
 1.         1.         1.         0.99999988 1.         1.
 1.         1.         1.         1.         1.         1.
 0.99951255 1.         1.        ]
pred: 0.9999767768950689, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp005-nsrr

=== Test on chp006-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.677135
0.0780 --- loss_d: 0.566571
0.1560 --- loss_d: 0.700977
0.2340 --- loss_d: 0.483928
0.3120 --- loss_d: 0.796544
0.3900 --- loss_d: 0.563202
0.4680 --- loss_d: 0.708210
0.5460 --- loss_d: 0.566823
0.6240 --- loss_d: 0.461880
0.7020 --- loss_d: 0.666842
0.7800 --- loss_d: 0.414896
0.8580 --- loss_d: 0.575406
0.9360 --- loss_d: 0.954704
Epoch finished! Loss: 0.6190180765697733
Starting epoch 2/10.
0.0000 --- loss_d: 0.619556
0.0780 --- loss_d: 0.523868
0.1560 --- loss_d: 0.618073
0.2340 --- loss_d: 0.301727
0.3120 --- loss_d: 0.509060
0.3900 --- loss_d: 0.323014
0.4680 --- loss_d: 0.421824
0.5460 --- loss_d: 0.220926
0.6240 --- loss_d: 0.460513
0.7020 --- loss_d: 0.399874
0.7800 --- loss_d: 0.365122
0.8580 --- loss_d: 0.457201
0.9360 --- loss_d: 0.212702
Epoch finished! Loss: 0.47631477226968855
Starting epoch 3/10.
0.0000 --- loss_d: 0.573276
0.0780 --- loss_d: 0.315670
0.1560 --- loss_d: 0.282164
0.2340 --- loss_d: 0.313455
0.3120 --- loss_d: 0.418866
0.3900 --- loss_d: 0.195047
0.4680 --- loss_d: 0.734384
0.5460 --- loss_d: 0.415948
0.6240 --- loss_d: 0.176376
0.7020 --- loss_d: 0.383853
0.7800 --- loss_d: 0.158601
0.8580 --- loss_d: 0.080565
0.9360 --- loss_d: 0.171373
Epoch finished! Loss: 0.31469300005119294
Starting epoch 4/10.
0.0000 --- loss_d: 0.628216
0.0780 --- loss_d: 0.124367
0.1560 --- loss_d: 0.210888
0.2340 --- loss_d: 0.358249
0.3120 --- loss_d: 0.037794
0.3900 --- loss_d: 0.221489
0.4680 --- loss_d: 0.074100
0.5460 --- loss_d: 0.107790
0.6240 --- loss_d: 0.200389
0.7020 --- loss_d: 0.026764
0.7800 --- loss_d: 0.297143
0.8580 --- loss_d: 0.248473
0.9360 --- loss_d: 0.215738
Epoch finished! Loss: 0.2430122826481238
Starting epoch 5/10.
0.0000 --- loss_d: 0.094145
0.0780 --- loss_d: 0.071558
0.1560 --- loss_d: 0.060579
0.2340 --- loss_d: 0.079222
0.3120 --- loss_d: 0.066923
0.3900 --- loss_d: 0.344658
0.4680 --- loss_d: 0.069845
0.5460 --- loss_d: 0.065000
0.6240 --- loss_d: 0.030307
0.7020 --- loss_d: 0.125500
0.7800 --- loss_d: 0.157142
0.8580 --- loss_d: 0.240843
0.9360 --- loss_d: 0.061618
Epoch finished! Loss: 0.22681613962049596
Starting epoch 6/10.
0.0000 --- loss_d: 0.117221
0.0780 --- loss_d: 0.067898
0.1560 --- loss_d: 0.242786
0.2340 --- loss_d: 0.139433
0.3120 --- loss_d: 0.099082
0.3900 --- loss_d: 0.208480
0.4680 --- loss_d: 0.036623
0.5460 --- loss_d: 0.096826
0.6240 --- loss_d: 0.234828
0.7020 --- loss_d: 0.068856
0.7800 --- loss_d: 0.678218
0.8580 --- loss_d: 0.624666
0.9360 --- loss_d: 0.028629
Epoch finished! Loss: 0.171370288124308
Starting epoch 7/10.
0.0000 --- loss_d: 0.185725
0.0780 --- loss_d: 0.058645
0.1560 --- loss_d: 0.052815
0.2340 --- loss_d: 0.159069
0.3120 --- loss_d: 0.140554
0.3900 --- loss_d: 0.072725
0.4680 --- loss_d: 0.047803
0.5460 --- loss_d: 0.178444
0.6240 --- loss_d: 0.086472
0.7020 --- loss_d: 0.254307
0.7800 --- loss_d: 0.186267
0.8580 --- loss_d: 0.124024
0.9360 --- loss_d: 0.424266
Epoch finished! Loss: 0.14855553986490122
Starting epoch 8/10.
0.0000 --- loss_d: 0.038639
0.0780 --- loss_d: 0.475970
0.1560 --- loss_d: 0.025012
0.2340 --- loss_d: 0.071135
0.3120 --- loss_d: 0.308693
0.3900 --- loss_d: 0.635645
0.4680 --- loss_d: 0.021296
0.5460 --- loss_d: 0.128201
0.6240 --- loss_d: 0.094458
0.7020 --- loss_d: 0.013320
0.7800 --- loss_d: 0.047491
0.8580 --- loss_d: 0.211144
0.9360 --- loss_d: 0.044745
Epoch finished! Loss: 0.09795043488702504
Starting epoch 9/10.
0.0000 --- loss_d: 0.022221
0.0780 --- loss_d: 0.453219
0.1560 --- loss_d: 0.308510
0.2340 --- loss_d: 0.218421
0.3120 --- loss_d: 0.331605
0.3900 --- loss_d: 0.217380
0.4680 --- loss_d: 0.212086
0.5460 --- loss_d: 0.046724
0.6240 --- loss_d: 0.072562
0.7020 --- loss_d: 0.252099
0.7800 --- loss_d: 0.528630
0.8580 --- loss_d: 0.137032
0.9360 --- loss_d: 0.426375
Epoch finished! Loss: 0.16631988203153014
Starting epoch 10/10.
0.0000 --- loss_d: 0.021238
0.0780 --- loss_d: 0.039567
0.1560 --- loss_d: 0.531831
0.2340 --- loss_d: 0.045290
0.3120 --- loss_d: 0.075873
0.3900 --- loss_d: 0.358826
0.4680 --- loss_d: 0.072218
0.5460 --- loss_d: 0.007977
0.6240 --- loss_d: 0.024210
0.7020 --- loss_d: 0.071901
0.7800 --- loss_d: 0.197213
0.8580 --- loss_d: 0.090110
0.9360 --- loss_d: 0.303290
Epoch finished! Loss: 0.0889026373042725
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999678 0.9985764  0.99998713 1.         1.         0.99999762
 0.99986172 0.99998677 1.         1.         0.99998093 1.
 0.99999988 0.9999907  0.99999404 1.         1.         0.99999225]
pred: 0.9999091227849325, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp006-nsrr

=== Test on chp007-nsrr. train_data(1281), test_data(19) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.712787
0.0781 --- loss_d: 0.665755
0.1561 --- loss_d: 0.677792
0.2342 --- loss_d: 0.717614
0.3123 --- loss_d: 0.695787
0.3903 --- loss_d: 0.538275
0.4684 --- loss_d: 0.541235
0.5464 --- loss_d: 0.363274
0.6245 --- loss_d: 0.627305
0.7026 --- loss_d: 0.440459
0.7806 --- loss_d: 0.462135
0.8587 --- loss_d: 0.559541
0.9368 --- loss_d: 0.435949
Epoch finished! Loss: 0.5905275419354439
Starting epoch 2/10.
0.0000 --- loss_d: 0.708401
0.0781 --- loss_d: 0.711634
0.1561 --- loss_d: 0.241166
0.2342 --- loss_d: 0.604032
0.3123 --- loss_d: 0.400468
0.3903 --- loss_d: 0.274214
0.4684 --- loss_d: 0.102199
0.5464 --- loss_d: 0.323435
0.6245 --- loss_d: 0.347518
0.7026 --- loss_d: 0.257632
0.7806 --- loss_d: 0.476873
0.8587 --- loss_d: 0.528997
0.9368 --- loss_d: 0.333951
Epoch finished! Loss: 0.41495558997849
Starting epoch 3/10.
0.0000 --- loss_d: 0.205799
0.0781 --- loss_d: 0.267404
0.1561 --- loss_d: 0.146224
0.2342 --- loss_d: 0.153704
0.3123 --- loss_d: 0.319099
0.3903 --- loss_d: 0.431959
0.4684 --- loss_d: 0.213917
0.5464 --- loss_d: 0.404965
0.6245 --- loss_d: 0.426511
0.7026 --- loss_d: 0.448551
0.7806 --- loss_d: 0.281415
0.8587 --- loss_d: 0.188353
0.9368 --- loss_d: 0.323585
Epoch finished! Loss: 0.2781536953552859
Starting epoch 4/10.
0.0000 --- loss_d: 0.133321
0.0781 --- loss_d: 0.225162
0.1561 --- loss_d: 0.175077
0.2342 --- loss_d: 0.104544
0.3123 --- loss_d: 0.139079
0.3903 --- loss_d: 0.270130
0.4684 --- loss_d: 0.049547
0.5464 --- loss_d: 0.147520
0.6245 --- loss_d: 0.156470
0.7026 --- loss_d: 0.460305
0.7806 --- loss_d: 0.154242
0.8587 --- loss_d: 0.116009
0.9368 --- loss_d: 0.175930
Epoch finished! Loss: 0.21767690301930998
Starting epoch 5/10.
0.0000 --- loss_d: 0.261838
0.0781 --- loss_d: 0.064189
0.1561 --- loss_d: 0.367622
0.2342 --- loss_d: 0.198532
0.3123 --- loss_d: 0.039111
0.3903 --- loss_d: 0.221712
0.4684 --- loss_d: 0.032760
0.5464 --- loss_d: 0.093656
0.6245 --- loss_d: 0.304989
0.7026 --- loss_d: 0.044159
0.7806 --- loss_d: 0.071569
0.8587 --- loss_d: 0.096207
0.9368 --- loss_d: 0.279438
Epoch finished! Loss: 0.17389811593602644
Starting epoch 6/10.
0.0000 --- loss_d: 0.153166
0.0781 --- loss_d: 0.046721
0.1561 --- loss_d: 0.348595
0.2342 --- loss_d: 0.025972
0.3123 --- loss_d: 0.087609
0.3903 --- loss_d: 0.010351
0.4684 --- loss_d: 0.256257
0.5464 --- loss_d: 0.027476
0.6245 --- loss_d: 0.020924
0.7026 --- loss_d: 0.075103
0.7806 --- loss_d: 0.092271
0.8587 --- loss_d: 0.264754
0.9368 --- loss_d: 0.047977
Epoch finished! Loss: 0.135402613588667
Starting epoch 7/10.
0.0000 --- loss_d: 0.283726
0.0781 --- loss_d: 0.532305
0.1561 --- loss_d: 0.020552
0.2342 --- loss_d: 0.014764
0.3123 --- loss_d: 0.045707
0.3903 --- loss_d: 0.031118
0.4684 --- loss_d: 0.076263
0.5464 --- loss_d: 0.026414
0.6245 --- loss_d: 0.028781
0.7026 --- loss_d: 0.047233
0.7806 --- loss_d: 0.052428
0.8587 --- loss_d: 0.132870
0.9368 --- loss_d: 0.294747
Epoch finished! Loss: 0.12274339618832641
Starting epoch 8/10.
0.0000 --- loss_d: 0.077289
0.0781 --- loss_d: 0.059930
0.1561 --- loss_d: 0.050238
0.2342 --- loss_d: 0.416392
0.3123 --- loss_d: 0.253359
0.3903 --- loss_d: 0.375546
0.4684 --- loss_d: 0.011554
0.5464 --- loss_d: 0.008228
0.6245 --- loss_d: 0.015923
0.7026 --- loss_d: 0.103753
0.7806 --- loss_d: 0.319402
0.8587 --- loss_d: 0.014372
0.9368 --- loss_d: 0.050089
Epoch finished! Loss: 0.08227269671556314
Starting epoch 9/10.
0.0000 --- loss_d: 0.022288
0.0781 --- loss_d: 0.432542
0.1561 --- loss_d: 0.018905
0.2342 --- loss_d: 0.020762
0.3123 --- loss_d: 0.031392
0.3903 --- loss_d: 0.529806
0.4684 --- loss_d: 0.030842
0.5464 --- loss_d: 0.050119
0.6245 --- loss_d: 0.145463
0.7026 --- loss_d: 0.085918
0.7806 --- loss_d: 0.017697
0.8587 --- loss_d: 0.017986
0.9368 --- loss_d: 0.307850
Epoch finished! Loss: 0.08651048871324818
Starting epoch 10/10.
0.0000 --- loss_d: 0.244377
0.0781 --- loss_d: 0.007634
0.1561 --- loss_d: 0.012671
0.2342 --- loss_d: 0.048626
0.3123 --- loss_d: 0.062250
0.3903 --- loss_d: 0.073769
0.4684 --- loss_d: 0.005696
0.5464 --- loss_d: 0.011635
0.6245 --- loss_d: 0.029474
0.7026 --- loss_d: 0.000185
0.7806 --- loss_d: 0.026255
0.8587 --- loss_d: 0.084329
0.9368 --- loss_d: 0.005437
Epoch finished! Loss: 0.049225139464397216
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99987316 0.999273   0.99999821 0.99985695 0.90777683 0.99998474
 0.99998987 0.99977821 0.9997794  0.9999752  0.99848926 0.9884221
 0.99996042 0.99981707 0.99961901 0.99917114 0.99913162 0.99867487
 0.99399877]
pred: 0.9938720966640272, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp007-nsrr

=== Test on chp008-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.684680
0.0778 --- loss_d: 0.566417
0.1556 --- loss_d: 0.674059
0.2335 --- loss_d: 0.683790
0.3113 --- loss_d: 0.438430
0.3891 --- loss_d: 0.603789
0.4669 --- loss_d: 0.423573
0.5447 --- loss_d: 0.465217
0.6226 --- loss_d: 0.591257
0.7004 --- loss_d: 0.619288
0.7782 --- loss_d: 0.564018
0.8560 --- loss_d: 0.644194
0.9339 --- loss_d: 0.715951
Epoch finished! Loss: 0.6084263811353594
Starting epoch 2/10.
0.0000 --- loss_d: 0.512272
0.0778 --- loss_d: 0.463306
0.1556 --- loss_d: 0.581811
0.2335 --- loss_d: 0.289882
0.3113 --- loss_d: 0.608140
0.3891 --- loss_d: 0.427660
0.4669 --- loss_d: 0.367269
0.5447 --- loss_d: 0.648344
0.6226 --- loss_d: 0.516006
0.7004 --- loss_d: 0.503273
0.7782 --- loss_d: 0.529053
0.8560 --- loss_d: 0.328342
0.9339 --- loss_d: 0.401534
Epoch finished! Loss: 0.5045647571096197
Starting epoch 3/10.
0.0000 --- loss_d: 0.318681
0.0778 --- loss_d: 0.324085
0.1556 --- loss_d: 0.231810
0.2335 --- loss_d: 0.295827
0.3113 --- loss_d: 0.443642
0.3891 --- loss_d: 0.291257
0.4669 --- loss_d: 0.178814
0.5447 --- loss_d: 0.093676
0.6226 --- loss_d: 0.377833
0.7004 --- loss_d: 0.102150
0.7782 --- loss_d: 0.333064
0.8560 --- loss_d: 0.234542
0.9339 --- loss_d: 0.325109
Epoch finished! Loss: 0.34368575422558933
Starting epoch 4/10.
0.0000 --- loss_d: 0.200008
0.0778 --- loss_d: 0.122052
0.1556 --- loss_d: 0.093512
0.2335 --- loss_d: 0.150878
0.3113 --- loss_d: 0.191585
0.3891 --- loss_d: 0.132987
0.4669 --- loss_d: 0.161039
0.5447 --- loss_d: 0.061910
0.6226 --- loss_d: 0.109711
0.7004 --- loss_d: 0.264977
0.7782 --- loss_d: 0.126311
0.8560 --- loss_d: 0.280650
0.9339 --- loss_d: 0.038341
Epoch finished! Loss: 0.2516784828621894
Starting epoch 5/10.
0.0000 --- loss_d: 0.164020
0.0778 --- loss_d: 0.066339
0.1556 --- loss_d: 0.044331
0.2335 --- loss_d: 0.045399
0.3113 --- loss_d: 0.095618
0.3891 --- loss_d: 0.096071
0.4669 --- loss_d: 0.040341
0.5447 --- loss_d: 0.200087
0.6226 --- loss_d: 0.124089
0.7004 --- loss_d: 0.086397
0.7782 --- loss_d: 0.073364
0.8560 --- loss_d: 0.292008
0.9339 --- loss_d: 0.302223
Epoch finished! Loss: 0.1761929774293094
Starting epoch 6/10.
0.0000 --- loss_d: 0.448722
0.0778 --- loss_d: 0.084696
0.1556 --- loss_d: 0.216101
0.2335 --- loss_d: 0.199686
0.3113 --- loss_d: 0.185534
0.3891 --- loss_d: 0.118810
0.4669 --- loss_d: 0.078839
0.5447 --- loss_d: 0.788037
0.6226 --- loss_d: 0.496601
0.7004 --- loss_d: 0.067170
0.7782 --- loss_d: 0.014997
0.8560 --- loss_d: 0.100611
0.9339 --- loss_d: 0.098455
Epoch finished! Loss: 0.13339342465769732
Starting epoch 7/10.
0.0000 --- loss_d: 0.072803
0.0778 --- loss_d: 0.350566
0.1556 --- loss_d: 0.406736
0.2335 --- loss_d: 0.017824
0.3113 --- loss_d: 0.017226
0.3891 --- loss_d: 0.009264
0.4669 --- loss_d: 0.134427
0.5447 --- loss_d: 0.024484
0.6226 --- loss_d: 0.007896
0.7004 --- loss_d: 0.022240
0.7782 --- loss_d: 0.104738
0.8560 --- loss_d: 0.528774
0.9339 --- loss_d: 0.412087
Epoch finished! Loss: 0.10285993524485093
Starting epoch 8/10.
0.0000 --- loss_d: 0.061154
0.0778 --- loss_d: 0.025106
0.1556 --- loss_d: 0.028588
0.2335 --- loss_d: 0.019713
0.3113 --- loss_d: 0.024630
0.3891 --- loss_d: 0.043096
0.4669 --- loss_d: 0.022930
0.5447 --- loss_d: 0.134164
0.6226 --- loss_d: 0.001092
0.7004 --- loss_d: 0.056904
0.7782 --- loss_d: 0.024569
0.8560 --- loss_d: 0.336512
0.9339 --- loss_d: 0.112053
Epoch finished! Loss: 0.08907205283139774
Starting epoch 9/10.
0.0000 --- loss_d: 0.046187
0.0778 --- loss_d: 0.074749
0.1556 --- loss_d: 0.016617
0.2335 --- loss_d: 0.043561
0.3113 --- loss_d: 0.006596
0.3891 --- loss_d: 0.025185
0.4669 --- loss_d: 0.003370
0.5447 --- loss_d: 0.013869
0.6226 --- loss_d: 0.093457
0.7004 --- loss_d: 0.004353
0.7782 --- loss_d: 0.063362
0.8560 --- loss_d: 0.021509
0.9339 --- loss_d: 0.049537
Epoch finished! Loss: 0.07018480082570022
Starting epoch 10/10.
0.0000 --- loss_d: 0.012312
0.0778 --- loss_d: 0.000558
0.1556 --- loss_d: 0.063738
0.2335 --- loss_d: 0.004858
0.3113 --- loss_d: 0.002283
0.3891 --- loss_d: 0.016729
0.4669 --- loss_d: 0.016141
0.5447 --- loss_d: 0.009224
0.6226 --- loss_d: 0.005853
0.7004 --- loss_d: 0.143960
0.7782 --- loss_d: 0.068506
0.8560 --- loss_d: 0.258072
0.9339 --- loss_d: 0.002245
Epoch finished! Loss: 0.054276194514841336
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99997902 0.96006    0.99998999 0.99736351 0.99999452 0.99998403
 0.99974865 0.99825555 0.66165829 0.99993896 0.99999404 0.99999654
 0.99997509 0.99985647 0.99994659]
pred: 0.9744494160016378, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp008-nsrr

=== Test on chp009-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.678859
0.0779 --- loss_d: 0.763629
0.1559 --- loss_d: 0.692863
0.2338 --- loss_d: 0.606722
0.3118 --- loss_d: 0.733856
0.3897 --- loss_d: 0.625275
0.4677 --- loss_d: 0.548300
0.5456 --- loss_d: 0.532915
0.6235 --- loss_d: 0.358366
0.7015 --- loss_d: 0.423972
0.7794 --- loss_d: 0.565078
0.8574 --- loss_d: 0.542637
0.9353 --- loss_d: 0.385075
Epoch finished! Loss: 0.5968347563175485
Starting epoch 2/10.
0.0000 --- loss_d: 0.245274
0.0779 --- loss_d: 0.442436
0.1559 --- loss_d: 0.310062
0.2338 --- loss_d: 0.181467
0.3118 --- loss_d: 0.425778
0.3897 --- loss_d: 0.191395
0.4677 --- loss_d: 0.268525
0.5456 --- loss_d: 0.406817
0.6235 --- loss_d: 0.300554
0.7015 --- loss_d: 0.159522
0.7794 --- loss_d: 0.283389
0.8574 --- loss_d: 0.568575
0.9353 --- loss_d: 0.215285
Epoch finished! Loss: 0.3883589110337198
Starting epoch 3/10.
0.0000 --- loss_d: 0.415739
0.0779 --- loss_d: 0.172446
0.1559 --- loss_d: 0.377089
0.2338 --- loss_d: 0.237212
0.3118 --- loss_d: 0.141552
0.3897 --- loss_d: 0.296475
0.4677 --- loss_d: 0.779763
0.5456 --- loss_d: 0.590717
0.6235 --- loss_d: 0.615196
0.7015 --- loss_d: 0.071721
0.7794 --- loss_d: 0.174867
0.8574 --- loss_d: 0.259896
0.9353 --- loss_d: 0.143862
Epoch finished! Loss: 0.29486665898002684
Starting epoch 4/10.
0.0000 --- loss_d: 0.386160
0.0779 --- loss_d: 0.079391
0.1559 --- loss_d: 0.139934
0.2338 --- loss_d: 0.566461
0.3118 --- loss_d: 0.163400
0.3897 --- loss_d: 0.295906
0.4677 --- loss_d: 0.475713
0.5456 --- loss_d: 0.076352
0.6235 --- loss_d: 0.186933
0.7015 --- loss_d: 0.898373
0.7794 --- loss_d: 0.035626
0.8574 --- loss_d: 0.196296
0.9353 --- loss_d: 0.446074
Epoch finished! Loss: 0.25301957793999463
Starting epoch 5/10.
0.0000 --- loss_d: 0.193939
0.0779 --- loss_d: 0.163634
0.1559 --- loss_d: 0.293588
0.2338 --- loss_d: 0.102985
0.3118 --- loss_d: 0.130873
0.3897 --- loss_d: 0.247601
0.4677 --- loss_d: 0.027762
0.5456 --- loss_d: 0.239526
0.6235 --- loss_d: 0.041275
0.7015 --- loss_d: 0.145919
0.7794 --- loss_d: 0.146202
0.8574 --- loss_d: 0.592083
0.9353 --- loss_d: 0.452656
Epoch finished! Loss: 0.20248394073132658
Starting epoch 6/10.
0.0000 --- loss_d: 0.071476
0.0779 --- loss_d: 0.235836
0.1559 --- loss_d: 0.117552
0.2338 --- loss_d: 0.096074
0.3118 --- loss_d: 0.163729
0.3897 --- loss_d: 0.040859
0.4677 --- loss_d: 0.026639
0.5456 --- loss_d: 0.206308
0.6235 --- loss_d: 0.204979
0.7015 --- loss_d: 0.136097
0.7794 --- loss_d: 0.026081
0.8574 --- loss_d: 0.044489
0.9353 --- loss_d: 0.120017
Epoch finished! Loss: 0.13610111538582714
Starting epoch 7/10.
0.0000 --- loss_d: 0.052785
0.0779 --- loss_d: 0.234128
0.1559 --- loss_d: 0.101620
0.2338 --- loss_d: 0.116997
0.3118 --- loss_d: 0.096125
0.3897 --- loss_d: 0.014707
0.4677 --- loss_d: 0.007118
0.5456 --- loss_d: 0.148601
0.6235 --- loss_d: 0.005506
0.7015 --- loss_d: 0.024587
0.7794 --- loss_d: 0.069913
0.8574 --- loss_d: 0.091036
0.9353 --- loss_d: 0.174735
Epoch finished! Loss: 0.12731015109238797
Starting epoch 8/10.
0.0000 --- loss_d: 0.152922
0.0779 --- loss_d: 0.047428
0.1559 --- loss_d: 0.021185
0.2338 --- loss_d: 0.013896
0.3118 --- loss_d: 0.013706
0.3897 --- loss_d: 0.020363
0.4677 --- loss_d: 0.008148
0.5456 --- loss_d: 0.003302
0.6235 --- loss_d: 0.684027
0.7015 --- loss_d: 0.052305
0.7794 --- loss_d: 0.007302
0.8574 --- loss_d: 0.133876
0.9353 --- loss_d: 0.001529
Epoch finished! Loss: 0.10160404107318755
Starting epoch 9/10.
0.0000 --- loss_d: 0.009145
0.0779 --- loss_d: 0.193083
0.1559 --- loss_d: 0.026006
0.2338 --- loss_d: 0.008402
0.3118 --- loss_d: 0.061766
0.3897 --- loss_d: 0.116264
0.4677 --- loss_d: 0.004000
0.5456 --- loss_d: 0.383314
0.6235 --- loss_d: 0.005452
0.7015 --- loss_d: 0.090485
0.7794 --- loss_d: 0.017321
0.8574 --- loss_d: 0.027326
0.9353 --- loss_d: 0.014548
Epoch finished! Loss: 0.04815911520290683
Starting epoch 10/10.
0.0000 --- loss_d: 0.019631
0.0779 --- loss_d: 0.017280
0.1559 --- loss_d: 0.057917
0.2338 --- loss_d: 0.010426
0.3118 --- loss_d: 0.309765
0.3897 --- loss_d: 0.010980
0.4677 --- loss_d: 0.077669
0.5456 --- loss_d: 0.001298
0.6235 --- loss_d: 0.051182
0.7015 --- loss_d: 0.003680
0.7794 --- loss_d: 0.003706
0.8574 --- loss_d: 0.197420
0.9353 --- loss_d: 0.168530
Epoch finished! Loss: 0.09681729321027888
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.9998455  1.         0.99999642 1.         1.         1.
 0.99999881 1.         0.99999988 1.         0.99999976 0.99999988
 0.99999964 1.         0.99999499 0.99998653 0.99999988]
pred: 0.9999894885455861, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp009-nsrr

=== Test on chp010-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.706156
0.0779 --- loss_d: 0.513174
0.1558 --- loss_d: 0.669559
0.2336 --- loss_d: 0.595550
0.3115 --- loss_d: 0.521286
0.3894 --- loss_d: 0.576611
0.4673 --- loss_d: 0.595051
0.5452 --- loss_d: 0.708321
0.6231 --- loss_d: 0.806962
0.7009 --- loss_d: 0.718678
0.7788 --- loss_d: 0.710388
0.8567 --- loss_d: 0.578659
0.9346 --- loss_d: 0.464928
Epoch finished! Loss: 0.6268023694865406
Starting epoch 2/10.
0.0000 --- loss_d: 0.643014
0.0779 --- loss_d: 0.523705
0.1558 --- loss_d: 0.633856
0.2336 --- loss_d: 0.824657
0.3115 --- loss_d: 0.374072
0.3894 --- loss_d: 0.472982
0.4673 --- loss_d: 0.109696
0.5452 --- loss_d: 0.766846
0.6231 --- loss_d: 0.460537
0.7009 --- loss_d: 0.623464
0.7788 --- loss_d: 0.287681
0.8567 --- loss_d: 0.341922
0.9346 --- loss_d: 0.272734
Epoch finished! Loss: 0.5016476123710163
Starting epoch 3/10.
0.0000 --- loss_d: 0.446560
0.0779 --- loss_d: 0.320712
0.1558 --- loss_d: 0.285471
0.2336 --- loss_d: 0.083826
0.3115 --- loss_d: 0.263007
0.3894 --- loss_d: 0.602025
0.4673 --- loss_d: 0.152055
0.5452 --- loss_d: 0.076228
0.6231 --- loss_d: 0.408460
0.7009 --- loss_d: 0.179580
0.7788 --- loss_d: 0.334823
0.8567 --- loss_d: 0.403824
0.9346 --- loss_d: 0.253966
Epoch finished! Loss: 0.35205963521730155
Starting epoch 4/10.
0.0000 --- loss_d: 0.272751
0.0779 --- loss_d: 0.213785
0.1558 --- loss_d: 0.114512
0.2336 --- loss_d: 0.374637
0.3115 --- loss_d: 0.329859
0.3894 --- loss_d: 0.070184
0.4673 --- loss_d: 0.211887
0.5452 --- loss_d: 0.194700
0.6231 --- loss_d: 0.142485
0.7009 --- loss_d: 0.169204
0.7788 --- loss_d: 0.157198
0.8567 --- loss_d: 0.331238
0.9346 --- loss_d: 0.330538
Epoch finished! Loss: 0.24999572614615317
Starting epoch 5/10.
0.0000 --- loss_d: 0.180343
0.0779 --- loss_d: 0.085870
0.1558 --- loss_d: 0.070843
0.2336 --- loss_d: 0.226273
0.3115 --- loss_d: 0.299795
0.3894 --- loss_d: 0.284781
0.4673 --- loss_d: 0.053654
0.5452 --- loss_d: 0.150696
0.6231 --- loss_d: 0.291534
0.7009 --- loss_d: 0.347422
0.7788 --- loss_d: 0.099910
0.8567 --- loss_d: 0.133714
0.9346 --- loss_d: 0.177590
Epoch finished! Loss: 0.17745099469902925
Starting epoch 6/10.
0.0000 --- loss_d: 0.512014
0.0779 --- loss_d: 0.107054
0.1558 --- loss_d: 0.112207
0.2336 --- loss_d: 0.100003
0.3115 --- loss_d: 0.011304
0.3894 --- loss_d: 0.033635
0.4673 --- loss_d: 0.011653
0.5452 --- loss_d: 0.061085
0.6231 --- loss_d: 0.081765
0.7009 --- loss_d: 0.012833
0.7788 --- loss_d: 0.215055
0.8567 --- loss_d: 0.054859
0.9346 --- loss_d: 0.018839
Epoch finished! Loss: 0.11228534112342459
Starting epoch 7/10.
0.0000 --- loss_d: 0.009304
0.0779 --- loss_d: 0.003153
0.1558 --- loss_d: 0.032136
0.2336 --- loss_d: 0.270140
0.3115 --- loss_d: 0.293807
0.3894 --- loss_d: 0.033560
0.4673 --- loss_d: 0.049571
0.5452 --- loss_d: 0.042626
0.6231 --- loss_d: 0.011303
0.7009 --- loss_d: 0.051840
0.7788 --- loss_d: 0.010364
0.8567 --- loss_d: 0.015427
0.9346 --- loss_d: 0.022397
Epoch finished! Loss: 0.08879860934121098
Starting epoch 8/10.
0.0000 --- loss_d: 0.021836
0.0779 --- loss_d: 0.008860
0.1558 --- loss_d: 0.010808
0.2336 --- loss_d: 0.472489
0.3115 --- loss_d: 0.008525
0.3894 --- loss_d: 0.098022
0.4673 --- loss_d: 0.023692
0.5452 --- loss_d: 0.095022
0.6231 --- loss_d: 0.053058
0.7009 --- loss_d: 0.338515
0.7788 --- loss_d: 0.078351
0.8567 --- loss_d: 0.020342
0.9346 --- loss_d: 0.057851
Epoch finished! Loss: 0.09558714592094475
Starting epoch 9/10.
0.0000 --- loss_d: 0.019326
0.0779 --- loss_d: 0.122996
0.1558 --- loss_d: 0.011012
0.2336 --- loss_d: 0.030281
0.3115 --- loss_d: 0.002219
0.3894 --- loss_d: 0.014077
0.4673 --- loss_d: 0.010795
0.5452 --- loss_d: 0.041875
0.6231 --- loss_d: 0.051682
0.7009 --- loss_d: 0.321613
0.7788 --- loss_d: 0.005057
0.8567 --- loss_d: 0.008125
0.9346 --- loss_d: 0.040870
Epoch finished! Loss: 0.06839091601068503
Starting epoch 10/10.
0.0000 --- loss_d: 0.036553
0.0779 --- loss_d: 0.019160
0.1558 --- loss_d: 0.008729
0.2336 --- loss_d: 0.207082
0.3115 --- loss_d: 0.005579
0.3894 --- loss_d: 0.012071
0.4673 --- loss_d: 0.007922
0.5452 --- loss_d: 0.269494
0.6231 --- loss_d: 0.114463
0.7009 --- loss_d: 0.135505
0.7788 --- loss_d: 0.037716
0.8567 --- loss_d: 0.009188
0.9346 --- loss_d: 0.007663
Epoch finished! Loss: 0.0720364190649434
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[1.         1.         0.99999988 1.         1.         1.
 0.99999797 0.99999893 1.         1.         1.         1.
 0.9999994  1.         0.99971837 1.        ]
pred: 0.9999821595847607, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp010-nsrr

=== Test on chp011-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.713785
0.0779 --- loss_d: 0.234664
0.1558 --- loss_d: 0.554478
0.2336 --- loss_d: 0.669463
0.3115 --- loss_d: 0.510292
0.3894 --- loss_d: 0.590868
0.4673 --- loss_d: 0.816657
0.5452 --- loss_d: 0.626494
0.6231 --- loss_d: 0.467904
0.7009 --- loss_d: 0.570893
0.7788 --- loss_d: 0.303007
0.8567 --- loss_d: 0.274686
0.9346 --- loss_d: 0.534630
Epoch finished! Loss: 0.5989101042505354
Starting epoch 2/10.
0.0000 --- loss_d: 0.527322
0.0779 --- loss_d: 0.582025
0.1558 --- loss_d: 0.270024
0.2336 --- loss_d: 0.571468
0.3115 --- loss_d: 0.448299
0.3894 --- loss_d: 0.173954
0.4673 --- loss_d: 0.597202
0.5452 --- loss_d: 0.349551
0.6231 --- loss_d: 0.243090
0.7009 --- loss_d: 0.179236
0.7788 --- loss_d: 0.408080
0.8567 --- loss_d: 0.137732
0.9346 --- loss_d: 0.354614
Epoch finished! Loss: 0.4022023126599379
Starting epoch 3/10.
0.0000 --- loss_d: 0.250003
0.0779 --- loss_d: 0.361130
0.1558 --- loss_d: 0.143042
0.2336 --- loss_d: 0.165826
0.3115 --- loss_d: 0.468465
0.3894 --- loss_d: 0.233021
0.4673 --- loss_d: 0.182542
0.5452 --- loss_d: 0.946525
0.6231 --- loss_d: 0.292085
0.7009 --- loss_d: 0.215414
0.7788 --- loss_d: 0.594909
0.8567 --- loss_d: 0.366012
0.9346 --- loss_d: 0.200893
Epoch finished! Loss: 0.2922773669997696
Starting epoch 4/10.
0.0000 --- loss_d: 0.288388
0.0779 --- loss_d: 0.083604
0.1558 --- loss_d: 0.159637
0.2336 --- loss_d: 0.218083
0.3115 --- loss_d: 0.046878
0.3894 --- loss_d: 0.052102
0.4673 --- loss_d: 0.123355
0.5452 --- loss_d: 0.033879
0.6231 --- loss_d: 0.278190
0.7009 --- loss_d: 0.285411
0.7788 --- loss_d: 0.102219
0.8567 --- loss_d: 0.426565
0.9346 --- loss_d: 0.056652
Epoch finished! Loss: 0.2027039578097174
Starting epoch 5/10.
0.0000 --- loss_d: 0.089019
0.0779 --- loss_d: 0.040989
0.1558 --- loss_d: 0.111633
0.2336 --- loss_d: 0.477623
0.3115 --- loss_d: 0.228930
0.3894 --- loss_d: 0.063715
0.4673 --- loss_d: 0.060558
0.5452 --- loss_d: 0.054344
0.6231 --- loss_d: 0.049156
0.7009 --- loss_d: 0.067741
0.7788 --- loss_d: 0.135416
0.8567 --- loss_d: 0.378755
0.9346 --- loss_d: 0.527444
Epoch finished! Loss: 0.15666072128078667
Starting epoch 6/10.
0.0000 --- loss_d: 0.208538
0.0779 --- loss_d: 0.202769
0.1558 --- loss_d: 0.157398
0.2336 --- loss_d: 0.048528
0.3115 --- loss_d: 0.010629
0.3894 --- loss_d: 0.024889
0.4673 --- loss_d: 0.026040
0.5452 --- loss_d: 0.014782
0.6231 --- loss_d: 0.034382
0.7009 --- loss_d: 0.230307
0.7788 --- loss_d: 0.012768
0.8567 --- loss_d: 0.071113
0.9346 --- loss_d: 0.182188
Epoch finished! Loss: 0.10780038653138035
Starting epoch 7/10.
0.0000 --- loss_d: 0.051278
0.0779 --- loss_d: 0.063624
0.1558 --- loss_d: 0.167004
0.2336 --- loss_d: 0.121163
0.3115 --- loss_d: 0.007719
0.3894 --- loss_d: 0.082068
0.4673 --- loss_d: 0.015454
0.5452 --- loss_d: 0.285204
0.6231 --- loss_d: 0.080169
0.7009 --- loss_d: 0.036031
0.7788 --- loss_d: 0.405290
0.8567 --- loss_d: 0.073830
0.9346 --- loss_d: 0.256410
Epoch finished! Loss: 0.11816857120356872
Starting epoch 8/10.
0.0000 --- loss_d: 0.068648
0.0779 --- loss_d: 0.017256
0.1558 --- loss_d: 0.013340
0.2336 --- loss_d: 0.020784
0.3115 --- loss_d: 0.009861
0.3894 --- loss_d: 0.007426
0.4673 --- loss_d: 0.663886
0.5452 --- loss_d: 0.146692
0.6231 --- loss_d: 0.210626
0.7009 --- loss_d: 0.038420
0.7788 --- loss_d: 0.140264
0.8567 --- loss_d: 0.001050
0.9346 --- loss_d: 0.092862
Epoch finished! Loss: 0.05373331851023977
Starting epoch 9/10.
0.0000 --- loss_d: 0.016643
0.0779 --- loss_d: 0.001833
0.1558 --- loss_d: 0.001926
0.2336 --- loss_d: 0.211623
0.3115 --- loss_d: 0.003823
0.3894 --- loss_d: 0.001389
0.4673 --- loss_d: 0.016315
0.5452 --- loss_d: 0.010942
0.6231 --- loss_d: 0.065676
0.7009 --- loss_d: 0.068144
0.7788 --- loss_d: 0.009304
0.8567 --- loss_d: 0.222260
0.9346 --- loss_d: 0.018392
Epoch finished! Loss: 0.05546958509307842
Starting epoch 10/10.
0.0000 --- loss_d: 0.100533
0.0779 --- loss_d: 0.006931
0.1558 --- loss_d: 0.018720
0.2336 --- loss_d: 0.036008
0.3115 --- loss_d: 0.163809
0.3894 --- loss_d: 0.002841
0.4673 --- loss_d: 0.027814
0.5452 --- loss_d: 0.026070
0.6231 --- loss_d: 0.006179
0.7009 --- loss_d: 0.023485
0.7788 --- loss_d: 0.016585
0.8567 --- loss_d: 0.020276
0.9346 --- loss_d: 0.004542
Epoch finished! Loss: 0.04003040507291189
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999988 1.         1.         1.         1.         1.
 0.99999976 0.99999988 1.         1.         1.         1.
 1.         1.         0.99999976 1.        ]
pred: 0.9999999552965164, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp011-nsrr

=== Test on chp012-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.796210
0.0780 --- loss_d: 0.400276
0.1560 --- loss_d: 0.642893
0.2340 --- loss_d: 0.626287
0.3120 --- loss_d: 0.484100
0.3900 --- loss_d: 0.821085
0.4680 --- loss_d: 0.889868
0.5460 --- loss_d: 0.575632
0.6240 --- loss_d: 0.477937
0.7020 --- loss_d: 0.730101
0.7800 --- loss_d: 0.698900
0.8580 --- loss_d: 0.432543
0.9360 --- loss_d: 0.532057
Epoch finished! Loss: 0.5959237606730312
Starting epoch 2/10.
0.0000 --- loss_d: 0.777166
0.0780 --- loss_d: 0.352752
0.1560 --- loss_d: 0.374279
0.2340 --- loss_d: 0.175701
0.3120 --- loss_d: 0.393233
0.3900 --- loss_d: 0.569805
0.4680 --- loss_d: 0.529138
0.5460 --- loss_d: 0.298474
0.6240 --- loss_d: 0.351885
0.7020 --- loss_d: 0.313985
0.7800 --- loss_d: 0.194332
0.8580 --- loss_d: 0.534516
0.9360 --- loss_d: 0.337754
Epoch finished! Loss: 0.47073867364088073
Starting epoch 3/10.
0.0000 --- loss_d: 0.279780
0.0780 --- loss_d: 0.609044
0.1560 --- loss_d: 0.238313
0.2340 --- loss_d: 0.136449
0.3120 --- loss_d: 0.114733
0.3900 --- loss_d: 0.197918
0.4680 --- loss_d: 0.239909
0.5460 --- loss_d: 0.241123
0.6240 --- loss_d: 0.204615
0.7020 --- loss_d: 0.047877
0.7800 --- loss_d: 0.157434
0.8580 --- loss_d: 0.219407
0.9360 --- loss_d: 0.353465
Epoch finished! Loss: 0.31509075785288587
Starting epoch 4/10.
0.0000 --- loss_d: 0.237950
0.0780 --- loss_d: 0.152057
0.1560 --- loss_d: 0.215189
0.2340 --- loss_d: 0.116958
0.3120 --- loss_d: 0.126363
0.3900 --- loss_d: 0.075447
0.4680 --- loss_d: 0.063674
0.5460 --- loss_d: 0.057890
0.6240 --- loss_d: 0.353398
0.7020 --- loss_d: 0.042654
0.7800 --- loss_d: 0.242137
0.8580 --- loss_d: 0.041991
0.9360 --- loss_d: 0.584654
Epoch finished! Loss: 0.20509912531269947
Starting epoch 5/10.
0.0000 --- loss_d: 0.389119
0.0780 --- loss_d: 0.120402
0.1560 --- loss_d: 0.023932
0.2340 --- loss_d: 0.117941
0.3120 --- loss_d: 0.078825
0.3900 --- loss_d: 0.023845
0.4680 --- loss_d: 0.248777
0.5460 --- loss_d: 0.061753
0.6240 --- loss_d: 0.174745
0.7020 --- loss_d: 0.128691
0.7800 --- loss_d: 0.057644
0.8580 --- loss_d: 0.173570
0.9360 --- loss_d: 0.018861
Epoch finished! Loss: 0.1624840317235794
Starting epoch 6/10.
0.0000 --- loss_d: 0.115535
0.0780 --- loss_d: 0.635356
0.1560 --- loss_d: 0.329552
0.2340 --- loss_d: 0.061516
0.3120 --- loss_d: 0.198989
0.3900 --- loss_d: 0.137166
0.4680 --- loss_d: 0.026364
0.5460 --- loss_d: 0.271144
0.6240 --- loss_d: 0.010919
0.7020 --- loss_d: 0.013925
0.7800 --- loss_d: 0.022058
0.8580 --- loss_d: 0.076529
0.9360 --- loss_d: 0.044805
Epoch finished! Loss: 0.13856945575025748
Starting epoch 7/10.
0.0000 --- loss_d: 0.019974
0.0780 --- loss_d: 0.029943
0.1560 --- loss_d: 0.007548
0.2340 --- loss_d: 0.035134
0.3120 --- loss_d: 0.003183
0.3900 --- loss_d: 0.003140
0.4680 --- loss_d: 0.046297
0.5460 --- loss_d: 0.005584
0.6240 --- loss_d: 0.085085
0.7020 --- loss_d: 0.007468
0.7800 --- loss_d: 0.158770
0.8580 --- loss_d: 0.003792
0.9360 --- loss_d: 0.503628
Epoch finished! Loss: 0.09750949047429458
Starting epoch 8/10.
0.0000 --- loss_d: 0.017300
0.0780 --- loss_d: 0.797281
0.1560 --- loss_d: 0.074241
0.2340 --- loss_d: 0.846265
0.3120 --- loss_d: 0.107308
0.3900 --- loss_d: 0.204433
0.4680 --- loss_d: 0.028007
0.5460 --- loss_d: 0.097132
0.6240 --- loss_d: 0.131170
0.7020 --- loss_d: 0.017542
0.7800 --- loss_d: 0.003459
0.8580 --- loss_d: 0.006278
0.9360 --- loss_d: 0.024343
Epoch finished! Loss: 0.12751467777707148
Starting epoch 9/10.
0.0000 --- loss_d: 0.005541
0.0780 --- loss_d: 0.014301
0.1560 --- loss_d: 0.008719
0.2340 --- loss_d: 0.073094
0.3120 --- loss_d: 0.284538
0.3900 --- loss_d: 0.020319
0.4680 --- loss_d: 0.001643
0.5460 --- loss_d: 0.003806
0.6240 --- loss_d: 0.014942
0.7020 --- loss_d: 0.009712
0.7800 --- loss_d: 0.009693
0.8580 --- loss_d: 0.649521
0.9360 --- loss_d: 0.045518
Epoch finished! Loss: 0.07732147441492998
Starting epoch 10/10.
0.0000 --- loss_d: 0.007823
0.0780 --- loss_d: 0.036484
0.1560 --- loss_d: 0.015524
0.2340 --- loss_d: 0.024323
0.3120 --- loss_d: 0.037981
0.3900 --- loss_d: 0.025264
0.4680 --- loss_d: 0.055280
0.5460 --- loss_d: 0.014339
0.6240 --- loss_d: 0.011598
0.7020 --- loss_d: 0.011532
0.7800 --- loss_d: 0.007183
0.8580 --- loss_d: 0.039033
0.9360 --- loss_d: 0.074426
Epoch finished! Loss: 0.08377515492611565
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999952 0.99890268 0.99828917 0.99998248 0.99999869 0.99996626
 0.99991906 0.9999969  0.99998665 0.99998081 0.99998534 0.99999988
 0.99999809 0.99998486 0.99992442 0.99999392 0.9999913  0.99999976]
pred: 0.9998277657561832, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp012-nsrr

=== Test on chp013-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.732173
0.0779 --- loss_d: 0.710295
0.1558 --- loss_d: 0.632113
0.2336 --- loss_d: 0.482739
0.3115 --- loss_d: 0.310305
0.3894 --- loss_d: 0.542605
0.4673 --- loss_d: 0.585105
0.5452 --- loss_d: 0.475917
0.6231 --- loss_d: 0.367751
0.7009 --- loss_d: 0.509257
0.7788 --- loss_d: 0.646131
0.8567 --- loss_d: 0.609845
0.9346 --- loss_d: 0.483730
Epoch finished! Loss: 0.5903781292727217
Starting epoch 2/10.
0.0000 --- loss_d: 0.308308
0.0779 --- loss_d: 0.287035
0.1558 --- loss_d: 0.714280
0.2336 --- loss_d: 0.387433
0.3115 --- loss_d: 0.390854
0.3894 --- loss_d: 0.231757
0.4673 --- loss_d: 0.389593
0.5452 --- loss_d: 1.231965
0.6231 --- loss_d: 0.689900
0.7009 --- loss_d: 0.291129
0.7788 --- loss_d: 0.248410
0.8567 --- loss_d: 0.342629
0.9346 --- loss_d: 0.371548
Epoch finished! Loss: 0.4253048247192055
Starting epoch 3/10.
0.0000 --- loss_d: 0.180512
0.0779 --- loss_d: 0.158327
0.1558 --- loss_d: 0.153820
0.2336 --- loss_d: 0.483665
0.3115 --- loss_d: 0.262082
0.3894 --- loss_d: 0.704238
0.4673 --- loss_d: 0.238454
0.5452 --- loss_d: 0.581227
0.6231 --- loss_d: 0.082557
0.7009 --- loss_d: 0.125268
0.7788 --- loss_d: 0.146294
0.8567 --- loss_d: 0.208608
0.9346 --- loss_d: 0.103374
Epoch finished! Loss: 0.2692572542873677
Starting epoch 4/10.
0.0000 --- loss_d: 0.093775
0.0779 --- loss_d: 0.500323
0.1558 --- loss_d: 0.085717
0.2336 --- loss_d: 0.699748
0.3115 --- loss_d: 0.092287
0.3894 --- loss_d: 0.294024
0.4673 --- loss_d: 0.089467
0.5452 --- loss_d: 0.082919
0.6231 --- loss_d: 0.114940
0.7009 --- loss_d: 0.055732
0.7788 --- loss_d: 0.037425
0.8567 --- loss_d: 0.203304
0.9346 --- loss_d: 0.207932
Epoch finished! Loss: 0.22138283512322232
Starting epoch 5/10.
0.0000 --- loss_d: 0.106171
0.0779 --- loss_d: 0.082147
0.1558 --- loss_d: 0.047403
0.2336 --- loss_d: 0.047187
0.3115 --- loss_d: 0.044415
0.3894 --- loss_d: 0.044515
0.4673 --- loss_d: 0.045456
0.5452 --- loss_d: 0.325021
0.6231 --- loss_d: 0.066731
0.7009 --- loss_d: 0.205394
0.7788 --- loss_d: 0.147807
0.8567 --- loss_d: 0.081018
0.9346 --- loss_d: 0.156455
Epoch finished! Loss: 0.19189900249330094
Starting epoch 6/10.
0.0000 --- loss_d: 0.209375
0.0779 --- loss_d: 0.051563
0.1558 --- loss_d: 0.053642
0.2336 --- loss_d: 0.026691
0.3115 --- loss_d: 0.068947
0.3894 --- loss_d: 0.285882
0.4673 --- loss_d: 0.067401
0.5452 --- loss_d: 0.156238
0.6231 --- loss_d: 0.085210
0.7009 --- loss_d: 0.141710
0.7788 --- loss_d: 0.012612
0.8567 --- loss_d: 0.318272
0.9346 --- loss_d: 0.178754
Epoch finished! Loss: 0.1479127565980889
Starting epoch 7/10.
0.0000 --- loss_d: 0.030106
0.0779 --- loss_d: 0.060977
0.1558 --- loss_d: 0.011835
0.2336 --- loss_d: 0.268759
0.3115 --- loss_d: 0.062682
0.3894 --- loss_d: 0.060618
0.4673 --- loss_d: 0.235984
0.5452 --- loss_d: 0.120805
0.6231 --- loss_d: 0.047676
0.7009 --- loss_d: 0.076147
0.7788 --- loss_d: 0.131806
0.8567 --- loss_d: 0.020142
0.9346 --- loss_d: 0.417376
Epoch finished! Loss: 0.09848239666462177
Starting epoch 8/10.
0.0000 --- loss_d: 0.004858
0.0779 --- loss_d: 0.144060
0.1558 --- loss_d: 0.117368
0.2336 --- loss_d: 0.007823
0.3115 --- loss_d: 0.005083
0.3894 --- loss_d: 0.016553
0.4673 --- loss_d: 0.018502
0.5452 --- loss_d: 0.087762
0.6231 --- loss_d: 0.053627
0.7009 --- loss_d: 0.010161
0.7788 --- loss_d: 0.132639
0.8567 --- loss_d: 0.485796
0.9346 --- loss_d: 0.095328
Epoch finished! Loss: 0.10406773450995388
Starting epoch 9/10.
0.0000 --- loss_d: 0.047042
0.0779 --- loss_d: 0.017122
0.1558 --- loss_d: 0.013694
0.2336 --- loss_d: 0.004497
0.3115 --- loss_d: 0.134194
0.3894 --- loss_d: 0.117864
0.4673 --- loss_d: 0.025831
0.5452 --- loss_d: 0.101302
0.6231 --- loss_d: 0.052769
0.7009 --- loss_d: 0.093510
0.7788 --- loss_d: 0.010760
0.8567 --- loss_d: 0.012897
0.9346 --- loss_d: 0.014105
Epoch finished! Loss: 0.06698144266738382
Starting epoch 10/10.
0.0000 --- loss_d: 0.006498
0.0779 --- loss_d: 0.039398
0.1558 --- loss_d: 0.308467
0.2336 --- loss_d: 0.003039
0.3115 --- loss_d: 0.001783
0.3894 --- loss_d: 0.018119
0.4673 --- loss_d: 0.204010
0.5452 --- loss_d: 0.012371
0.6231 --- loss_d: 0.008817
0.7009 --- loss_d: 0.023349
0.7788 --- loss_d: 0.004101
0.8567 --- loss_d: 0.016872
0.9346 --- loss_d: 0.015497
Epoch finished! Loss: 0.07019629618116596
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.9375
[0.66612577 0.24168071 0.9928872  0.9932335  0.99504304 0.99989891
 0.98832345 0.99833196 0.99994636 0.99962771 0.99998558 0.99984634
 0.9999938  0.99721318 0.99961472 0.99997056]
pred: 0.9294826742261648, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp013-nsrr

=== Test on chp014-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.695214
0.0779 --- loss_d: 0.613835
0.1558 --- loss_d: 0.686263
0.2336 --- loss_d: 0.618032
0.3115 --- loss_d: 0.617916
0.3894 --- loss_d: 0.304149
0.4673 --- loss_d: 0.532389
0.5452 --- loss_d: 0.750835
0.6231 --- loss_d: 0.676984
0.7009 --- loss_d: 0.467829
0.7788 --- loss_d: 0.457008
0.8567 --- loss_d: 0.593778
0.9346 --- loss_d: 0.899391
Epoch finished! Loss: 0.6010029102908447
Starting epoch 2/10.
0.0000 --- loss_d: 0.442794
0.0779 --- loss_d: 0.548022
0.1558 --- loss_d: 0.469906
0.2336 --- loss_d: 0.507873
0.3115 --- loss_d: 0.782190
0.3894 --- loss_d: 0.256390
0.4673 --- loss_d: 0.339592
0.5452 --- loss_d: 0.892804
0.6231 --- loss_d: 0.550973
0.7009 --- loss_d: 0.149721
0.7788 --- loss_d: 0.096862
0.8567 --- loss_d: 0.286852
0.9346 --- loss_d: 0.463477
Epoch finished! Loss: 0.4290422779158689
Starting epoch 3/10.
0.0000 --- loss_d: 0.183496
0.0779 --- loss_d: 0.699568
0.1558 --- loss_d: 0.236379
0.2336 --- loss_d: 0.363406
0.3115 --- loss_d: 0.280987
0.3894 --- loss_d: 0.260361
0.4673 --- loss_d: 0.501142
0.5452 --- loss_d: 0.261646
0.6231 --- loss_d: 0.405846
0.7009 --- loss_d: 0.148857
0.7788 --- loss_d: 0.393424
0.8567 --- loss_d: 0.408011
0.9346 --- loss_d: 0.228587
Epoch finished! Loss: 0.2988700154819526
Starting epoch 4/10.
0.0000 --- loss_d: 0.149283
0.0779 --- loss_d: 0.337533
0.1558 --- loss_d: 0.074531
0.2336 --- loss_d: 0.043127
0.3115 --- loss_d: 0.238380
0.3894 --- loss_d: 0.075703
0.4673 --- loss_d: 0.090205
0.5452 --- loss_d: 0.164834
0.6231 --- loss_d: 0.197404
0.7009 --- loss_d: 0.167936
0.7788 --- loss_d: 0.065323
0.8567 --- loss_d: 0.269619
0.9346 --- loss_d: 0.176709
Epoch finished! Loss: 0.24292222256190144
Starting epoch 5/10.
0.0000 --- loss_d: 0.134301
0.0779 --- loss_d: 0.101006
0.1558 --- loss_d: 0.086566
0.2336 --- loss_d: 0.224688
0.3115 --- loss_d: 0.136694
0.3894 --- loss_d: 0.319015
0.4673 --- loss_d: 0.020743
0.5452 --- loss_d: 0.154375
0.6231 --- loss_d: 0.291885
0.7009 --- loss_d: 0.184767
0.7788 --- loss_d: 0.026600
0.8567 --- loss_d: 0.063414
0.9346 --- loss_d: 0.237261
Epoch finished! Loss: 0.18135884199728025
Starting epoch 6/10.
0.0000 --- loss_d: 0.251162
0.0779 --- loss_d: 0.053803
0.1558 --- loss_d: 0.111957
0.2336 --- loss_d: 0.179782
0.3115 --- loss_d: 0.045600
0.3894 --- loss_d: 0.073677
0.4673 --- loss_d: 0.096655
0.5452 --- loss_d: 0.351479
0.6231 --- loss_d: 0.037591
0.7009 --- loss_d: 0.077049
0.7788 --- loss_d: 0.711052
0.8567 --- loss_d: 0.220057
0.9346 --- loss_d: 0.021935
Epoch finished! Loss: 0.16946325605385937
Starting epoch 7/10.
0.0000 --- loss_d: 0.053192
0.0779 --- loss_d: 0.071003
0.1558 --- loss_d: 0.068203
0.2336 --- loss_d: 0.053025
0.3115 --- loss_d: 0.014264
0.3894 --- loss_d: 0.080363
0.4673 --- loss_d: 0.531492
0.5452 --- loss_d: 0.100571
0.6231 --- loss_d: 0.004084
0.7009 --- loss_d: 0.084531
0.7788 --- loss_d: 0.192794
0.8567 --- loss_d: 0.005231
0.9346 --- loss_d: 0.006474
Epoch finished! Loss: 0.07562869682442397
Starting epoch 8/10.
0.0000 --- loss_d: 0.534823
0.0779 --- loss_d: 0.013635
0.1558 --- loss_d: 0.009233
0.2336 --- loss_d: 0.006650
0.3115 --- loss_d: 0.005114
0.3894 --- loss_d: 0.008628
0.4673 --- loss_d: 0.004429
0.5452 --- loss_d: 0.010700
0.6231 --- loss_d: 0.016448
0.7009 --- loss_d: 0.007226
0.7788 --- loss_d: 0.080180
0.8567 --- loss_d: 0.028389
0.9346 --- loss_d: 0.017055
Epoch finished! Loss: 0.07928735451423563
Starting epoch 9/10.
0.0000 --- loss_d: 0.083720
0.0779 --- loss_d: 0.361584
0.1558 --- loss_d: 0.017910
0.2336 --- loss_d: 0.109889
0.3115 --- loss_d: 0.025388
0.3894 --- loss_d: 0.017402
0.4673 --- loss_d: 0.429217
0.5452 --- loss_d: 0.014107
0.6231 --- loss_d: 0.356743
0.7009 --- loss_d: 0.297344
0.7788 --- loss_d: 0.244590
0.8567 --- loss_d: 0.005193
0.9346 --- loss_d: 0.136220
Epoch finished! Loss: 0.0911664510058472
Starting epoch 10/10.
0.0000 --- loss_d: 0.153813
0.0779 --- loss_d: 0.010021
0.1558 --- loss_d: 0.045313
0.2336 --- loss_d: 0.060695
0.3115 --- loss_d: 0.008609
0.3894 --- loss_d: 0.005992
0.4673 --- loss_d: 0.013156
0.5452 --- loss_d: 0.013363
0.6231 --- loss_d: 0.017744
0.7009 --- loss_d: 0.000960
0.7788 --- loss_d: 0.053169
0.8567 --- loss_d: 0.006195
0.9346 --- loss_d: 0.055205
Epoch finished! Loss: 0.062391760676746344
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999988 1.         1.         1.         1.         0.99999988
 0.99999952 1.         1.         1.         1.         0.9999702
 1.         0.99999988 0.99999511 1.        ]
pred: 0.9999977797269821, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp014-nsrr

=== Test on chp015-nsrr. train_data(1281), test_data(19) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.653313
0.0781 --- loss_d: 0.814031
0.1561 --- loss_d: 0.645082
0.2342 --- loss_d: 0.509955
0.3123 --- loss_d: 0.502531
0.3903 --- loss_d: 0.712460
0.4684 --- loss_d: 0.525437
0.5464 --- loss_d: 0.572491
0.6245 --- loss_d: 0.322370
0.7026 --- loss_d: 0.832987
0.7806 --- loss_d: 0.557463
0.8587 --- loss_d: 0.755299
0.9368 --- loss_d: 0.443017
Epoch finished! Loss: 0.6152093901764601
Starting epoch 2/10.
0.0000 --- loss_d: 0.355639
0.0781 --- loss_d: 0.475951
0.1561 --- loss_d: 0.582930
0.2342 --- loss_d: 0.637471
0.3123 --- loss_d: 0.585523
0.3903 --- loss_d: 0.332197
0.4684 --- loss_d: 0.387146
0.5464 --- loss_d: 0.382815
0.6245 --- loss_d: 0.375652
0.7026 --- loss_d: 0.372463
0.7806 --- loss_d: 0.538019
0.8587 --- loss_d: 0.644736
0.9368 --- loss_d: 0.398015
Epoch finished! Loss: 0.4752603395609185
Starting epoch 3/10.
0.0000 --- loss_d: 0.401580
0.0781 --- loss_d: 0.405014
0.1561 --- loss_d: 0.854727
0.2342 --- loss_d: 0.182773
0.3123 --- loss_d: 0.624814
0.3903 --- loss_d: 0.828204
0.4684 --- loss_d: 0.306991
0.5464 --- loss_d: 0.333701
0.6245 --- loss_d: 0.133489
0.7026 --- loss_d: 0.161502
0.7806 --- loss_d: 0.136772
0.8587 --- loss_d: 0.167045
0.9368 --- loss_d: 0.263433
Epoch finished! Loss: 0.3118099454586627
Starting epoch 4/10.
0.0000 --- loss_d: 0.088679
0.0781 --- loss_d: 0.166499
0.1561 --- loss_d: 0.026712
0.2342 --- loss_d: 0.034478
0.3123 --- loss_d: 0.060114
0.3903 --- loss_d: 0.293312
0.4684 --- loss_d: 0.139248
0.5464 --- loss_d: 0.072321
0.6245 --- loss_d: 0.287922
0.7026 --- loss_d: 0.310671
0.7806 --- loss_d: 0.174515
0.8587 --- loss_d: 0.214225
0.9368 --- loss_d: 0.054583
Epoch finished! Loss: 0.22867564463376766
Starting epoch 5/10.
0.0000 --- loss_d: 0.257377
0.0781 --- loss_d: 0.238906
0.1561 --- loss_d: 0.079768
0.2342 --- loss_d: 0.436441
0.3123 --- loss_d: 0.114528
0.3903 --- loss_d: 0.092076
0.4684 --- loss_d: 0.040438
0.5464 --- loss_d: 0.739319
0.6245 --- loss_d: 0.088729
0.7026 --- loss_d: 0.093570
0.7806 --- loss_d: 0.466227
0.8587 --- loss_d: 0.293510
0.9368 --- loss_d: 0.239176
Epoch finished! Loss: 0.18661483349569608
Starting epoch 6/10.
0.0000 --- loss_d: 0.026657
0.0781 --- loss_d: 0.029814
0.1561 --- loss_d: 0.021883
0.2342 --- loss_d: 0.107592
0.3123 --- loss_d: 0.352196
0.3903 --- loss_d: 0.244134
0.4684 --- loss_d: 0.149924
0.5464 --- loss_d: 0.130956
0.6245 --- loss_d: 0.565857
0.7026 --- loss_d: 0.250105
0.7806 --- loss_d: 0.103448
0.8587 --- loss_d: 0.019867
0.9368 --- loss_d: 0.005074
Epoch finished! Loss: 0.13067488838959207
Starting epoch 7/10.
0.0000 --- loss_d: 0.022973
0.0781 --- loss_d: 0.345715
0.1561 --- loss_d: 0.308292
0.2342 --- loss_d: 0.244051
0.3123 --- loss_d: 0.076572
0.3903 --- loss_d: 0.528606
0.4684 --- loss_d: 0.007016
0.5464 --- loss_d: 0.040738
0.6245 --- loss_d: 0.238615
0.7026 --- loss_d: 0.033461
0.7806 --- loss_d: 0.048307
0.8587 --- loss_d: 0.280447
0.9368 --- loss_d: 0.006698
Epoch finished! Loss: 0.11273406589498336
Starting epoch 8/10.
0.0000 --- loss_d: 0.059945
0.0781 --- loss_d: 0.018651
0.1561 --- loss_d: 0.022528
0.2342 --- loss_d: 0.071421
0.3123 --- loss_d: 0.018226
0.3903 --- loss_d: 0.008979
0.4684 --- loss_d: 0.041316
0.5464 --- loss_d: 0.036447
0.6245 --- loss_d: 0.054775
0.7026 --- loss_d: 0.028649
0.7806 --- loss_d: 0.114945
0.8587 --- loss_d: 0.427876
0.9368 --- loss_d: 0.655073
Epoch finished! Loss: 0.09632544938995125
Starting epoch 9/10.
0.0000 --- loss_d: 0.003876
0.0781 --- loss_d: 0.007349
0.1561 --- loss_d: 0.048147
0.2342 --- loss_d: 0.006340
0.3123 --- loss_d: 0.003784
0.3903 --- loss_d: 0.015096
0.4684 --- loss_d: 0.063120
0.5464 --- loss_d: 0.593344
0.6245 --- loss_d: 0.025689
0.7026 --- loss_d: 0.003621
0.7806 --- loss_d: 0.000740
0.8587 --- loss_d: 0.092290
0.9368 --- loss_d: 0.021281
Epoch finished! Loss: 0.053695890288196324
Starting epoch 10/10.
0.0000 --- loss_d: 0.003812
0.0781 --- loss_d: 0.163515
0.1561 --- loss_d: 0.012060
0.2342 --- loss_d: 0.008277
0.3123 --- loss_d: 0.039452
0.3903 --- loss_d: 0.032018
0.4684 --- loss_d: 0.014694
0.5464 --- loss_d: 0.329250
0.6245 --- loss_d: 0.052182
0.7026 --- loss_d: 0.043954
0.7806 --- loss_d: 0.020055
0.8587 --- loss_d: 0.002427
0.9368 --- loss_d: 0.016115
Epoch finished! Loss: 0.06556721132187704
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.999798   0.99996316 0.99998689 1.         0.99999917 0.99999988
 0.99894446 0.99758017 0.99999189 0.9999975  0.99953187 0.99998009
 0.99998903 0.99972123 0.99908864 0.99827588 0.96504074 0.99992108
 0.99999726]
pred: 0.9977793128866899, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp015-nsrr

=== Test on chp016-nsrr. train_data(1279), test_data(21) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.688463
0.0782 --- loss_d: 0.593066
0.1564 --- loss_d: 0.506723
0.2346 --- loss_d: 0.639496
0.3127 --- loss_d: 0.834604
0.3909 --- loss_d: 0.982338
0.4691 --- loss_d: 0.635436
0.5473 --- loss_d: 0.634909
0.6255 --- loss_d: 0.359445
0.7037 --- loss_d: 0.959894
0.7819 --- loss_d: 0.632097
0.8600 --- loss_d: 0.584348
0.9382 --- loss_d: 0.591055
Epoch finished! Loss: 0.6109767788507807
Starting epoch 2/10.
0.0000 --- loss_d: 0.586967
0.0782 --- loss_d: 0.345184
0.1564 --- loss_d: 0.490152
0.2346 --- loss_d: 0.357470
0.3127 --- loss_d: 0.427806
0.3909 --- loss_d: 0.551066
0.4691 --- loss_d: 0.373233
0.5473 --- loss_d: 0.384097
0.6255 --- loss_d: 0.403330
0.7037 --- loss_d: 0.373465
0.7819 --- loss_d: 0.413926
0.8600 --- loss_d: 0.231604
0.9382 --- loss_d: 0.238490
Epoch finished! Loss: 0.4554487439825779
Starting epoch 3/10.
0.0000 --- loss_d: 0.385159
0.0782 --- loss_d: 0.547152
0.1564 --- loss_d: 0.301251
0.2346 --- loss_d: 0.145485
0.3127 --- loss_d: 0.249915
0.3909 --- loss_d: 0.291522
0.4691 --- loss_d: 0.450492
0.5473 --- loss_d: 0.841683
0.6255 --- loss_d: 0.122255
0.7037 --- loss_d: 0.334157
0.7819 --- loss_d: 0.424367
0.8600 --- loss_d: 0.184227
0.9382 --- loss_d: 0.143709
Epoch finished! Loss: 0.30509388264943293
Starting epoch 4/10.
0.0000 --- loss_d: 0.101696
0.0782 --- loss_d: 0.156562
0.1564 --- loss_d: 0.117157
0.2346 --- loss_d: 0.251904
0.3127 --- loss_d: 0.099469
0.3909 --- loss_d: 0.281231
0.4691 --- loss_d: 0.088466
0.5473 --- loss_d: 0.501986
0.6255 --- loss_d: 0.980173
0.7037 --- loss_d: 0.224971
0.7819 --- loss_d: 0.108822
0.8600 --- loss_d: 0.046476
0.9382 --- loss_d: 0.186217
Epoch finished! Loss: 0.24713801953384257
Starting epoch 5/10.
0.0000 --- loss_d: 0.191246
0.0782 --- loss_d: 0.104937
0.1564 --- loss_d: 0.439393
0.2346 --- loss_d: 0.107167
0.3127 --- loss_d: 0.162552
0.3909 --- loss_d: 0.088545
0.4691 --- loss_d: 0.464983
0.5473 --- loss_d: 0.099112
0.6255 --- loss_d: 1.153413
0.7037 --- loss_d: 0.137904
0.7819 --- loss_d: 0.199979
0.8600 --- loss_d: 0.104515
0.9382 --- loss_d: 0.189726
Epoch finished! Loss: 0.20106905321847265
Starting epoch 6/10.
0.0000 --- loss_d: 0.087817
0.0782 --- loss_d: 0.146383
0.1564 --- loss_d: 0.066058
0.2346 --- loss_d: 0.112998
0.3127 --- loss_d: 0.053914
0.3909 --- loss_d: 0.053457
0.4691 --- loss_d: 0.025420
0.5473 --- loss_d: 0.051571
0.6255 --- loss_d: 0.003325
0.7037 --- loss_d: 0.060993
0.7819 --- loss_d: 0.045690
0.8600 --- loss_d: 0.129050
0.9382 --- loss_d: 0.121340
Epoch finished! Loss: 0.14564990590502486
Starting epoch 7/10.
0.0000 --- loss_d: 0.048906
0.0782 --- loss_d: 0.037876
0.1564 --- loss_d: 0.016371
0.2346 --- loss_d: 0.025539
0.3127 --- loss_d: 0.061621
0.3909 --- loss_d: 0.035673
0.4691 --- loss_d: 0.019139
0.5473 --- loss_d: 0.054386
0.6255 --- loss_d: 0.011939
0.7037 --- loss_d: 0.040382
0.7819 --- loss_d: 0.088438
0.8600 --- loss_d: 0.022866
0.9382 --- loss_d: 0.025556
Epoch finished! Loss: 0.08485012838028475
Starting epoch 8/10.
0.0000 --- loss_d: 0.324928
0.0782 --- loss_d: 0.467813
0.1564 --- loss_d: 0.017390
0.2346 --- loss_d: 0.181099
0.3127 --- loss_d: 0.079289
0.3909 --- loss_d: 0.062421
0.4691 --- loss_d: 0.062225
0.5473 --- loss_d: 0.017191
0.6255 --- loss_d: 0.345866
0.7037 --- loss_d: 0.091342
0.7819 --- loss_d: 0.047534
0.8600 --- loss_d: 0.016875
0.9382 --- loss_d: 0.005905
Epoch finished! Loss: 0.10901237368092352
Starting epoch 9/10.
0.0000 --- loss_d: 0.007171
0.0782 --- loss_d: 0.015183
0.1564 --- loss_d: 0.001737
0.2346 --- loss_d: 0.018829
0.3127 --- loss_d: 0.045348
0.3909 --- loss_d: 0.115036
0.4691 --- loss_d: 0.007855
0.5473 --- loss_d: 0.038266
0.6255 --- loss_d: 0.035912
0.7037 --- loss_d: 0.017050
0.7819 --- loss_d: 0.024274
0.8600 --- loss_d: 0.065177
0.9382 --- loss_d: 0.020969
Epoch finished! Loss: 0.08594965786988458
Starting epoch 10/10.
0.0000 --- loss_d: 0.023274
0.0782 --- loss_d: 0.009297
0.1564 --- loss_d: 0.150878
0.2346 --- loss_d: 0.007567
0.3127 --- loss_d: 0.288260
0.3909 --- loss_d: 0.048805
0.4691 --- loss_d: 0.026068
0.5473 --- loss_d: 0.074783
0.6255 --- loss_d: 0.009899
0.7037 --- loss_d: 0.051811
0.7819 --- loss_d: 0.021581
0.8600 --- loss_d: 0.021384
0.9382 --- loss_d: 0.086341
Epoch finished! Loss: 0.07193510690896486
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99995112 0.99934715 0.99996591 0.99999762 0.99999857 0.99996626
 0.99999905 0.99997866 0.99981982 0.99999893 0.99999952 0.99025679
 0.99990976 0.99913377 0.99998701 0.99998617 0.99999762 0.99999452
 0.99999666 0.99999344 0.99994671]
pred: 0.9994392877533322, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp016-nsrr

=== Test on chp017-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.720697
0.0779 --- loss_d: 0.412106
0.1558 --- loss_d: 0.924078
0.2336 --- loss_d: 0.657212
0.3115 --- loss_d: 0.471605
0.3894 --- loss_d: 0.484298
0.4673 --- loss_d: 0.611427
0.5452 --- loss_d: 0.553305
0.6231 --- loss_d: 0.728581
0.7009 --- loss_d: 0.761163
0.7788 --- loss_d: 0.454393
0.8567 --- loss_d: 0.297141
0.9346 --- loss_d: 0.681781
Epoch finished! Loss: 0.5963818407617509
Starting epoch 2/10.
0.0000 --- loss_d: 0.759533
0.0779 --- loss_d: 0.630983
0.1558 --- loss_d: 0.323093
0.2336 --- loss_d: 0.293627
0.3115 --- loss_d: 0.466088
0.3894 --- loss_d: 0.406853
0.4673 --- loss_d: 0.365969
0.5452 --- loss_d: 0.738116
0.6231 --- loss_d: 0.336405
0.7009 --- loss_d: 0.413029
0.7788 --- loss_d: 0.288953
0.8567 --- loss_d: 0.585692
0.9346 --- loss_d: 0.587570
Epoch finished! Loss: 0.45754188910359517
Starting epoch 3/10.
0.0000 --- loss_d: 0.148785
0.0779 --- loss_d: 0.344384
0.1558 --- loss_d: 0.981564
0.2336 --- loss_d: 0.135781
0.3115 --- loss_d: 0.377845
0.3894 --- loss_d: 0.323703
0.4673 --- loss_d: 0.150542
0.5452 --- loss_d: 0.310681
0.6231 --- loss_d: 0.484069
0.7009 --- loss_d: 0.186553
0.7788 --- loss_d: 0.389174
0.8567 --- loss_d: 0.283849
0.9346 --- loss_d: 0.112498
Epoch finished! Loss: 0.2595714550552657
Starting epoch 4/10.
0.0000 --- loss_d: 0.277945
0.0779 --- loss_d: 0.205596
0.1558 --- loss_d: 0.054305
0.2336 --- loss_d: 0.220150
0.3115 --- loss_d: 0.063632
0.3894 --- loss_d: 0.061314
0.4673 --- loss_d: 0.093248
0.5452 --- loss_d: 0.075678
0.6231 --- loss_d: 0.435790
0.7009 --- loss_d: 0.184661
0.7788 --- loss_d: 0.168999
0.8567 --- loss_d: 0.073284
0.9346 --- loss_d: 0.352034
Epoch finished! Loss: 0.2096932406857377
Starting epoch 5/10.
0.0000 --- loss_d: 0.489621
0.0779 --- loss_d: 0.086277
0.1558 --- loss_d: 0.024567
0.2336 --- loss_d: 0.020593
0.3115 --- loss_d: 0.233670
0.3894 --- loss_d: 0.087166
0.4673 --- loss_d: 0.325730
0.5452 --- loss_d: 0.028119
0.6231 --- loss_d: 0.017647
0.7009 --- loss_d: 0.243293
0.7788 --- loss_d: 0.258829
0.8567 --- loss_d: 0.096475
0.9346 --- loss_d: 0.109622
Epoch finished! Loss: 0.16768935175059596
Starting epoch 6/10.
0.0000 --- loss_d: 0.060743
0.0779 --- loss_d: 0.037765
0.1558 --- loss_d: 0.167091
0.2336 --- loss_d: 0.008380
0.3115 --- loss_d: 0.048127
0.3894 --- loss_d: 0.058449
0.4673 --- loss_d: 0.314608
0.5452 --- loss_d: 0.053544
0.6231 --- loss_d: 0.026759
0.7009 --- loss_d: 0.203880
0.7788 --- loss_d: 0.461158
0.8567 --- loss_d: 0.006879
0.9346 --- loss_d: 0.079388
Epoch finished! Loss: 0.12400689539390441
Starting epoch 7/10.
0.0000 --- loss_d: 0.017825
0.0779 --- loss_d: 0.171016
0.1558 --- loss_d: 0.140448
0.2336 --- loss_d: 0.044059
0.3115 --- loss_d: 0.010293
0.3894 --- loss_d: 0.009855
0.4673 --- loss_d: 0.238886
0.5452 --- loss_d: 0.220888
0.6231 --- loss_d: 0.267279
0.7009 --- loss_d: 0.064804
0.7788 --- loss_d: 0.003895
0.8567 --- loss_d: 0.694558
0.9346 --- loss_d: 0.029907
Epoch finished! Loss: 0.07760683616379538
Starting epoch 8/10.
0.0000 --- loss_d: 0.008381
0.0779 --- loss_d: 0.021381
0.1558 --- loss_d: 0.079186
0.2336 --- loss_d: 0.009488
0.3115 --- loss_d: 0.036109
0.3894 --- loss_d: 0.018995
0.4673 --- loss_d: 0.013326
0.5452 --- loss_d: 0.028698
0.6231 --- loss_d: 0.021652
0.7009 --- loss_d: 0.038389
0.7788 --- loss_d: 0.030063
0.8567 --- loss_d: 0.045132
0.9346 --- loss_d: 0.023887
Epoch finished! Loss: 0.08343233847836018
Starting epoch 9/10.
0.0000 --- loss_d: 0.021972
0.0779 --- loss_d: 0.010942
0.1558 --- loss_d: 0.011686
0.2336 --- loss_d: 0.224503
0.3115 --- loss_d: 0.001185
0.3894 --- loss_d: 0.001627
0.4673 --- loss_d: 0.011501
0.5452 --- loss_d: 0.007690
0.6231 --- loss_d: 0.000719
0.7009 --- loss_d: 0.005519
0.7788 --- loss_d: 0.022831
0.8567 --- loss_d: 0.072351
0.9346 --- loss_d: 0.264918
Epoch finished! Loss: 0.071778924568207
Starting epoch 10/10.
0.0000 --- loss_d: 0.050169
0.0779 --- loss_d: 0.268991
0.1558 --- loss_d: 0.348816
0.2336 --- loss_d: 0.075766
0.3115 --- loss_d: 0.326693
0.3894 --- loss_d: 0.022575
0.4673 --- loss_d: 0.020028
0.5452 --- loss_d: 0.028464
0.6231 --- loss_d: 0.036839
0.7009 --- loss_d: 0.025897
0.7788 --- loss_d: 0.048772
0.8567 --- loss_d: 0.009612
0.9346 --- loss_d: 0.057589
Epoch finished! Loss: 0.11652855910051585
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99881291 0.99969923 0.99980694 0.99948955 0.99676251 0.945746
 0.99026543 0.99999845 0.99999988 0.99660742 0.99997199 0.99973398
 0.99762064 0.93854415 0.97451651 0.99836558]
pred: 0.9897463247179985, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp017-nsrr

=== Test on chp018-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.644212
0.0780 --- loss_d: 0.817213
0.1560 --- loss_d: 0.495042
0.2340 --- loss_d: 0.602173
0.3120 --- loss_d: 0.574618
0.3900 --- loss_d: 0.548931
0.4680 --- loss_d: 0.788864
0.5460 --- loss_d: 0.764499
0.6240 --- loss_d: 0.870492
0.7020 --- loss_d: 0.621635
0.7800 --- loss_d: 0.342693
0.8580 --- loss_d: 0.525744
0.9360 --- loss_d: 0.346009
Epoch finished! Loss: 0.6046438673511147
Starting epoch 2/10.
0.0000 --- loss_d: 0.672347
0.0780 --- loss_d: 0.403449
0.1560 --- loss_d: 0.537503
0.2340 --- loss_d: 0.469001
0.3120 --- loss_d: 0.646399
0.3900 --- loss_d: 0.434823
0.4680 --- loss_d: 0.468011
0.5460 --- loss_d: 0.167641
0.6240 --- loss_d: 0.773245
0.7020 --- loss_d: 0.519355
0.7800 --- loss_d: 0.164403
0.8580 --- loss_d: 0.266710
0.9360 --- loss_d: 0.324126
Epoch finished! Loss: 0.455777496623341
Starting epoch 3/10.
0.0000 --- loss_d: 0.538203
0.0780 --- loss_d: 0.307916
0.1560 --- loss_d: 0.125161
0.2340 --- loss_d: 0.247736
0.3120 --- loss_d: 0.523004
0.3900 --- loss_d: 1.440742
0.4680 --- loss_d: 0.316683
0.5460 --- loss_d: 0.804232
0.6240 --- loss_d: 0.222626
0.7020 --- loss_d: 0.311043
0.7800 --- loss_d: 0.058344
0.8580 --- loss_d: 0.262248
0.9360 --- loss_d: 0.273915
Epoch finished! Loss: 0.2925983998866286
Starting epoch 4/10.
0.0000 --- loss_d: 0.354531
0.0780 --- loss_d: 0.129893
0.1560 --- loss_d: 0.332946
0.2340 --- loss_d: 0.128478
0.3120 --- loss_d: 0.086547
0.3900 --- loss_d: 0.196778
0.4680 --- loss_d: 0.076894
0.5460 --- loss_d: 0.102111
0.6240 --- loss_d: 0.316898
0.7020 --- loss_d: 0.386766
0.7800 --- loss_d: 0.125227
0.8580 --- loss_d: 0.233100
0.9360 --- loss_d: 0.213696
Epoch finished! Loss: 0.2255564168881392
Starting epoch 5/10.
0.0000 --- loss_d: 0.242558
0.0780 --- loss_d: 0.062979
0.1560 --- loss_d: 0.473988
0.2340 --- loss_d: 0.095054
0.3120 --- loss_d: 0.059830
0.3900 --- loss_d: 0.096665
0.4680 --- loss_d: 0.016977
0.5460 --- loss_d: 0.087266
0.6240 --- loss_d: 0.032971
0.7020 --- loss_d: 0.094964
0.7800 --- loss_d: 0.070007
0.8580 --- loss_d: 0.079563
0.9360 --- loss_d: 0.086367
Epoch finished! Loss: 0.17464813053811667
Starting epoch 6/10.
0.0000 --- loss_d: 0.019761
0.0780 --- loss_d: 0.146941
0.1560 --- loss_d: 0.042336
0.2340 --- loss_d: 0.480841
0.3120 --- loss_d: 0.132659
0.3900 --- loss_d: 0.182384
0.4680 --- loss_d: 0.061337
0.5460 --- loss_d: 0.030277
0.6240 --- loss_d: 0.186714
0.7020 --- loss_d: 0.031168
0.7800 --- loss_d: 0.091296
0.8580 --- loss_d: 0.694931
0.9360 --- loss_d: 0.020948
Epoch finished! Loss: 0.14875851109536598
Starting epoch 7/10.
0.0000 --- loss_d: 0.121988
0.0780 --- loss_d: 0.277168
0.1560 --- loss_d: 0.034331
0.2340 --- loss_d: 0.275116
0.3120 --- loss_d: 0.073481
0.3900 --- loss_d: 0.014008
0.4680 --- loss_d: 0.021537
0.5460 --- loss_d: 0.011304
0.6240 --- loss_d: 0.002975
0.7020 --- loss_d: 0.084922
0.7800 --- loss_d: 0.248381
0.8580 --- loss_d: 0.334881
0.9360 --- loss_d: 0.026062
Epoch finished! Loss: 0.11258617772364232
Starting epoch 8/10.
0.0000 --- loss_d: 0.041171
0.0780 --- loss_d: 0.055540
0.1560 --- loss_d: 0.019415
0.2340 --- loss_d: 0.019020
0.3120 --- loss_d: 0.353717
0.3900 --- loss_d: 0.198305
0.4680 --- loss_d: 0.002078
0.5460 --- loss_d: 0.025382
0.6240 --- loss_d: 0.020708
0.7020 --- loss_d: 0.077754
0.7800 --- loss_d: 0.618038
0.8580 --- loss_d: 0.148708
0.9360 --- loss_d: 0.029200
Epoch finished! Loss: 0.12932635640936496
Starting epoch 9/10.
0.0000 --- loss_d: 0.060732
0.0780 --- loss_d: 0.060135
0.1560 --- loss_d: 0.099683
0.2340 --- loss_d: 0.023729
0.3120 --- loss_d: 0.063544
0.3900 --- loss_d: 0.066340
0.4680 --- loss_d: 0.004260
0.5460 --- loss_d: 0.014584
0.6240 --- loss_d: 0.069773
0.7020 --- loss_d: 0.372188
0.7800 --- loss_d: 0.088434
0.8580 --- loss_d: 0.096331
0.9360 --- loss_d: 0.019252
Epoch finished! Loss: 0.09447361347702099
Starting epoch 10/10.
0.0000 --- loss_d: 0.410394
0.0780 --- loss_d: 0.017549
0.1560 --- loss_d: 0.036138
0.2340 --- loss_d: 0.272978
0.3120 --- loss_d: 0.004343
0.3900 --- loss_d: 0.016827
0.4680 --- loss_d: 0.009197
0.5460 --- loss_d: 0.007309
0.6240 --- loss_d: 0.004128
0.7020 --- loss_d: 0.002676
0.7800 --- loss_d: 0.041931
0.8580 --- loss_d: 0.001198
0.9360 --- loss_d: 0.001478
Epoch finished! Loss: 0.04619964999528747
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99987948 0.99999857 0.99997926 0.99983072 0.99999988 1.
 0.99999928 0.99998176 0.99982101 0.99999845 0.99999285 0.99998093
 0.99999845 0.99998713 1.         0.99999583 0.99998963 0.99813569]
pred: 0.9998649391863081, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp018-nsrr

=== Test on chp019-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.716662
0.0778 --- loss_d: 0.452333
0.1556 --- loss_d: 0.592758
0.2335 --- loss_d: 0.840582
0.3113 --- loss_d: 0.315693
0.3891 --- loss_d: 0.667962
0.4669 --- loss_d: 0.621239
0.5447 --- loss_d: 0.793137
0.6226 --- loss_d: 0.493725
0.7004 --- loss_d: 0.746382
0.7782 --- loss_d: 0.932787
0.8560 --- loss_d: 0.354521
0.9339 --- loss_d: 0.407891
Epoch finished! Loss: 0.6043556912336498
Starting epoch 2/10.
0.0000 --- loss_d: 0.430817
0.0778 --- loss_d: 0.629664
0.1556 --- loss_d: 0.654245
0.2335 --- loss_d: 0.390916
0.3113 --- loss_d: 0.297451
0.3891 --- loss_d: 0.294691
0.4669 --- loss_d: 0.565737
0.5447 --- loss_d: 0.442504
0.6226 --- loss_d: 0.506996
0.7004 --- loss_d: 0.454978
0.7782 --- loss_d: 0.240938
0.8560 --- loss_d: 0.502221
0.9339 --- loss_d: 0.427741
Epoch finished! Loss: 0.4336315292166546
Starting epoch 3/10.
0.0000 --- loss_d: 0.361257
0.0778 --- loss_d: 0.260264
0.1556 --- loss_d: 0.093731
0.2335 --- loss_d: 1.665690
0.3113 --- loss_d: 0.204018
0.3891 --- loss_d: 0.108049
0.4669 --- loss_d: 0.277498
0.5447 --- loss_d: 0.531910
0.6226 --- loss_d: 0.337656
0.7004 --- loss_d: 0.419791
0.7782 --- loss_d: 0.216074
0.8560 --- loss_d: 0.829941
0.9339 --- loss_d: 0.181715
Epoch finished! Loss: 0.29474360588938
Starting epoch 4/10.
0.0000 --- loss_d: 0.144825
0.0778 --- loss_d: 0.282518
0.1556 --- loss_d: 0.237185
0.2335 --- loss_d: 0.198236
0.3113 --- loss_d: 0.360764
0.3891 --- loss_d: 0.032134
0.4669 --- loss_d: 0.117008
0.5447 --- loss_d: 0.218858
0.6226 --- loss_d: 0.463243
0.7004 --- loss_d: 0.141516
0.7782 --- loss_d: 0.169238
0.8560 --- loss_d: 0.353769
0.9339 --- loss_d: 0.255718
Epoch finished! Loss: 0.21288165853184182
Starting epoch 5/10.
0.0000 --- loss_d: 0.036979
0.0778 --- loss_d: 0.335621
0.1556 --- loss_d: 0.240864
0.2335 --- loss_d: 0.488806
0.3113 --- loss_d: 0.682568
0.3891 --- loss_d: 0.120871
0.4669 --- loss_d: 0.976532
0.5447 --- loss_d: 0.194744
0.6226 --- loss_d: 0.184977
0.7004 --- loss_d: 0.085475
0.7782 --- loss_d: 0.266240
0.8560 --- loss_d: 0.174349
0.9339 --- loss_d: 0.084644
Epoch finished! Loss: 0.2058243559440598
Starting epoch 6/10.
0.0000 --- loss_d: 0.062119
0.0778 --- loss_d: 0.058120
0.1556 --- loss_d: 0.070307
0.2335 --- loss_d: 0.230879
0.3113 --- loss_d: 0.232831
0.3891 --- loss_d: 0.027130
0.4669 --- loss_d: 0.071988
0.5447 --- loss_d: 0.051198
0.6226 --- loss_d: 0.018941
0.7004 --- loss_d: 0.058283
0.7782 --- loss_d: 0.137317
0.8560 --- loss_d: 0.009806
0.9339 --- loss_d: 0.377024
Epoch finished! Loss: 0.11077621426011319
Starting epoch 7/10.
0.0000 --- loss_d: 0.291833
0.0778 --- loss_d: 0.073507
0.1556 --- loss_d: 0.087092
0.2335 --- loss_d: 0.084416
0.3113 --- loss_d: 0.027997
0.3891 --- loss_d: 0.086969
0.4669 --- loss_d: 0.011922
0.5447 --- loss_d: 0.043923
0.6226 --- loss_d: 0.021500
0.7004 --- loss_d: 0.018124
0.7782 --- loss_d: 0.017391
0.8560 --- loss_d: 0.327032
0.9339 --- loss_d: 0.048395
Epoch finished! Loss: 0.12271714449252613
Starting epoch 8/10.
0.0000 --- loss_d: 0.021303
0.0778 --- loss_d: 0.054942
0.1556 --- loss_d: 0.029818
0.2335 --- loss_d: 0.031081
0.3113 --- loss_d: 0.089588
0.3891 --- loss_d: 0.000974
0.4669 --- loss_d: 0.035487
0.5447 --- loss_d: 0.002128
0.6226 --- loss_d: 0.005743
0.7004 --- loss_d: 0.035533
0.7782 --- loss_d: 0.006513
0.8560 --- loss_d: 0.081259
0.9339 --- loss_d: 0.389961
Epoch finished! Loss: 0.07546409323958869
Starting epoch 9/10.
0.0000 --- loss_d: 0.003005
0.0778 --- loss_d: 0.006483
0.1556 --- loss_d: 0.100374
0.2335 --- loss_d: 0.032948
0.3113 --- loss_d: 0.037568
0.3891 --- loss_d: 0.065173
0.4669 --- loss_d: 0.293539
0.5447 --- loss_d: 0.017599
0.6226 --- loss_d: 0.003506
0.7004 --- loss_d: 0.044809
0.7782 --- loss_d: 0.184062
0.8560 --- loss_d: 0.010627
0.9339 --- loss_d: 0.005502
Epoch finished! Loss: 0.06393892563710324
Starting epoch 10/10.
0.0000 --- loss_d: 0.251125
0.0778 --- loss_d: 0.191882
0.1556 --- loss_d: 0.051291
0.2335 --- loss_d: 0.048463
0.3113 --- loss_d: 0.002677
0.3891 --- loss_d: 0.126307
0.4669 --- loss_d: 0.015598
0.5447 --- loss_d: 0.226346
0.6226 --- loss_d: 0.064478
0.7004 --- loss_d: 0.016452
0.7782 --- loss_d: 0.054606
0.8560 --- loss_d: 0.009969
0.9339 --- loss_d: 0.004187
Epoch finished! Loss: 0.08839979205481541
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.9333333333333333
[0.99975652 0.23161909 0.99965024 0.9998461  0.99959201 0.92031592
 0.99997568 0.99994421 0.99987161 0.99979812 0.99073493 0.99995244
 0.99999142 0.99995875 0.99997485]
pred: 0.9427321255207062, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp019-nsrr

=== Test on chp020-nsrr. train_data(1281), test_data(19) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.705537
0.0781 --- loss_d: 0.635153
0.1561 --- loss_d: 0.661883
0.2342 --- loss_d: 0.415985
0.3123 --- loss_d: 0.716505
0.3903 --- loss_d: 0.554268
0.4684 --- loss_d: 0.346237
0.5464 --- loss_d: 0.854976
0.6245 --- loss_d: 0.534141
0.7026 --- loss_d: 0.663871
0.7806 --- loss_d: 0.605605
0.8587 --- loss_d: 0.427916
0.9368 --- loss_d: 0.439643
Epoch finished! Loss: 0.6058192283380777
Starting epoch 2/10.
0.0000 --- loss_d: 0.663081
0.0781 --- loss_d: 0.563035
0.1561 --- loss_d: 0.427318
0.2342 --- loss_d: 0.331296
0.3123 --- loss_d: 0.519215
0.3903 --- loss_d: 0.284241
0.4684 --- loss_d: 0.429019
0.5464 --- loss_d: 0.404139
0.6245 --- loss_d: 0.297415
0.7026 --- loss_d: 0.337143
0.7806 --- loss_d: 0.496211
0.8587 --- loss_d: 0.419653
0.9368 --- loss_d: 0.385629
Epoch finished! Loss: 0.4696847332525067
Starting epoch 3/10.
0.0000 --- loss_d: 0.693352
0.0781 --- loss_d: 0.578039
0.1561 --- loss_d: 0.544992
0.2342 --- loss_d: 0.276066
0.3123 --- loss_d: 0.091089
0.3903 --- loss_d: 0.404064
0.4684 --- loss_d: 0.144082
0.5464 --- loss_d: 0.154897
0.6245 --- loss_d: 0.095308
0.7026 --- loss_d: 0.093181
0.7806 --- loss_d: 0.556851
0.8587 --- loss_d: 0.047238
0.9368 --- loss_d: 0.186031
Epoch finished! Loss: 0.28796419003629126
Starting epoch 4/10.
0.0000 --- loss_d: 0.294955
0.0781 --- loss_d: 0.600690
0.1561 --- loss_d: 0.076081
0.2342 --- loss_d: 0.254071
0.3123 --- loss_d: 0.105635
0.3903 --- loss_d: 0.087857
0.4684 --- loss_d: 0.213441
0.5464 --- loss_d: 0.667674
0.6245 --- loss_d: 0.238438
0.7026 --- loss_d: 0.066976
0.7806 --- loss_d: 0.340505
0.8587 --- loss_d: 0.021689
0.9368 --- loss_d: 0.108814
Epoch finished! Loss: 0.26233958461671136
Starting epoch 5/10.
0.0000 --- loss_d: 0.262805
0.0781 --- loss_d: 0.474222
0.1561 --- loss_d: 0.229882
0.2342 --- loss_d: 0.055265
0.3123 --- loss_d: 0.048171
0.3903 --- loss_d: 0.145990
0.4684 --- loss_d: 0.501972
0.5464 --- loss_d: 0.090382
0.6245 --- loss_d: 0.066078
0.7026 --- loss_d: 0.112988
0.7806 --- loss_d: 0.140477
0.8587 --- loss_d: 0.056022
0.9368 --- loss_d: 0.222588
Epoch finished! Loss: 0.21720426929823589
Starting epoch 6/10.
0.0000 --- loss_d: 0.077391
0.0781 --- loss_d: 0.026244
0.1561 --- loss_d: 0.224097
0.2342 --- loss_d: 0.142350
0.3123 --- loss_d: 0.039908
0.3903 --- loss_d: 0.056025
0.4684 --- loss_d: 0.027905
0.5464 --- loss_d: 0.045157
0.6245 --- loss_d: 0.058036
0.7026 --- loss_d: 0.179229
0.7806 --- loss_d: 0.254197
0.8587 --- loss_d: 0.023211
0.9368 --- loss_d: 0.662627
Epoch finished! Loss: 0.19805015534802806
Starting epoch 7/10.
0.0000 --- loss_d: 0.052366
0.0781 --- loss_d: 0.220010
0.1561 --- loss_d: 0.284798
0.2342 --- loss_d: 0.250069
0.3123 --- loss_d: 0.041534
0.3903 --- loss_d: 0.008671
0.4684 --- loss_d: 0.037940
0.5464 --- loss_d: 0.125113
0.6245 --- loss_d: 0.054020
0.7026 --- loss_d: 0.034157
0.7806 --- loss_d: 0.088198
0.8587 --- loss_d: 0.067773
0.9368 --- loss_d: 0.103310
Epoch finished! Loss: 0.16186502431810368
Starting epoch 8/10.
0.0000 --- loss_d: 0.218967
0.0781 --- loss_d: 0.311198
0.1561 --- loss_d: 0.035930
0.2342 --- loss_d: 0.021509
0.3123 --- loss_d: 0.039626
0.3903 --- loss_d: 0.138168
0.4684 --- loss_d: 0.206717
0.5464 --- loss_d: 0.083582
0.6245 --- loss_d: 0.052231
0.7026 --- loss_d: 0.146232
0.7806 --- loss_d: 0.050364
0.8587 --- loss_d: 0.156975
0.9368 --- loss_d: 0.020705
Epoch finished! Loss: 0.1508844679556205
Starting epoch 9/10.
0.0000 --- loss_d: 0.083650
0.0781 --- loss_d: 0.011920
0.1561 --- loss_d: 0.036181
0.2342 --- loss_d: 0.002398
0.3123 --- loss_d: 0.134300
0.3903 --- loss_d: 0.373095
0.4684 --- loss_d: 0.206842
0.5464 --- loss_d: 0.088767
0.6245 --- loss_d: 0.078435
0.7026 --- loss_d: 0.060058
0.7806 --- loss_d: 0.011059
0.8587 --- loss_d: 0.014721
0.9368 --- loss_d: 0.018720
Epoch finished! Loss: 0.0944956269731847
Starting epoch 10/10.
0.0000 --- loss_d: 0.005260
0.0781 --- loss_d: 0.012136
0.1561 --- loss_d: 0.022998
0.2342 --- loss_d: 0.027715
0.3123 --- loss_d: 0.024002
0.3903 --- loss_d: 0.095878
0.4684 --- loss_d: 0.003742
0.5464 --- loss_d: 0.010983
0.6245 --- loss_d: 0.006775
0.7026 --- loss_d: 0.001357
0.7806 --- loss_d: 0.003847
0.8587 --- loss_d: 0.002129
0.9368 --- loss_d: 0.004805
Epoch finished! Loss: 0.04574360317292303
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99996817 0.99998987 0.99997962 0.9999578  0.99999869 0.99999988
 1.         0.99999869 1.         1.         1.         0.99999964
 0.99999952 1.         1.         0.99999988 1.         1.
 1.        ]
pred: 0.9999943030507941, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp020-nsrr

=== Test on chp022-nsrr. train_data(1279), test_data(21) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.706298
0.0782 --- loss_d: 0.620746
0.1564 --- loss_d: 0.540434
0.2346 --- loss_d: 0.406605
0.3127 --- loss_d: 0.723219
0.3909 --- loss_d: 0.526334
0.4691 --- loss_d: 0.491793
0.5473 --- loss_d: 0.340262
0.6255 --- loss_d: 0.537208
0.7037 --- loss_d: 0.568493
0.7819 --- loss_d: 0.477742
0.8600 --- loss_d: 0.936917
0.9382 --- loss_d: 0.736861
Epoch finished! Loss: 0.6018962437712302
Starting epoch 2/10.
0.0000 --- loss_d: 0.373626
0.0782 --- loss_d: 0.304673
0.1564 --- loss_d: 0.775276
0.2346 --- loss_d: 0.574305
0.3127 --- loss_d: 0.358128
0.3909 --- loss_d: 0.247874
0.4691 --- loss_d: 0.180424
0.5473 --- loss_d: 0.277043
0.6255 --- loss_d: 0.471500
0.7037 --- loss_d: 0.386463
0.7819 --- loss_d: 0.400080
0.8600 --- loss_d: 0.225701
0.9382 --- loss_d: 0.382381
Epoch finished! Loss: 0.41067648549952845
Starting epoch 3/10.
0.0000 --- loss_d: 0.292284
0.0782 --- loss_d: 0.288063
0.1564 --- loss_d: 0.321379
0.2346 --- loss_d: 0.569573
0.3127 --- loss_d: 0.327979
0.3909 --- loss_d: 0.404464
0.4691 --- loss_d: 0.241958
0.5473 --- loss_d: 0.657062
0.6255 --- loss_d: 0.148387
0.7037 --- loss_d: 0.633733
0.7819 --- loss_d: 0.480896
0.8600 --- loss_d: 0.225075
0.9382 --- loss_d: 0.691647
Epoch finished! Loss: 0.2537365038475887
Starting epoch 4/10.
0.0000 --- loss_d: 0.180686
0.0782 --- loss_d: 0.487074
0.1564 --- loss_d: 0.056063
0.2346 --- loss_d: 0.105735
0.3127 --- loss_d: 0.595301
0.3909 --- loss_d: 0.062777
0.4691 --- loss_d: 0.248667
0.5473 --- loss_d: 0.211864
0.6255 --- loss_d: 0.220478
0.7037 --- loss_d: 0.336504
0.7819 --- loss_d: 0.055115
0.8600 --- loss_d: 0.241845
0.9382 --- loss_d: 0.316875
Epoch finished! Loss: 0.21504396153247263
Starting epoch 5/10.
0.0000 --- loss_d: 0.231870
0.0782 --- loss_d: 0.072770
0.1564 --- loss_d: 0.347851
0.2346 --- loss_d: 0.074277
0.3127 --- loss_d: 0.051738
0.3909 --- loss_d: 0.261478
0.4691 --- loss_d: 0.198208
0.5473 --- loss_d: 0.159953
0.6255 --- loss_d: 0.425783
0.7037 --- loss_d: 0.068304
0.7819 --- loss_d: 0.101594
0.8600 --- loss_d: 0.080691
0.9382 --- loss_d: 0.138783
Epoch finished! Loss: 0.16605623504220265
Starting epoch 6/10.
0.0000 --- loss_d: 0.150501
0.0782 --- loss_d: 0.086607
0.1564 --- loss_d: 0.032723
0.2346 --- loss_d: 0.017006
0.3127 --- loss_d: 0.053481
0.3909 --- loss_d: 0.089927
0.4691 --- loss_d: 0.028406
0.5473 --- loss_d: 0.004478
0.6255 --- loss_d: 0.815257
0.7037 --- loss_d: 0.190117
0.7819 --- loss_d: 0.132612
0.8600 --- loss_d: 0.017398
0.9382 --- loss_d: 0.541477
Epoch finished! Loss: 0.1038308813049656
Starting epoch 7/10.
0.0000 --- loss_d: 0.031601
0.0782 --- loss_d: 0.223490
0.1564 --- loss_d: 0.088406
0.2346 --- loss_d: 0.027828
0.3127 --- loss_d: 0.013176
0.3909 --- loss_d: 0.169512
0.4691 --- loss_d: 0.037498
0.5473 --- loss_d: 0.045778
0.6255 --- loss_d: 0.031184
0.7037 --- loss_d: 0.110943
0.7819 --- loss_d: 0.010673
0.8600 --- loss_d: 0.007882
0.9382 --- loss_d: 0.049365
Epoch finished! Loss: 0.10139191188064851
Starting epoch 8/10.
0.0000 --- loss_d: 0.011784
0.0782 --- loss_d: 0.053660
0.1564 --- loss_d: 0.014286
0.2346 --- loss_d: 0.190949
0.3127 --- loss_d: 0.010431
0.3909 --- loss_d: 0.030121
0.4691 --- loss_d: 0.057078
0.5473 --- loss_d: 0.027654
0.6255 --- loss_d: 0.105862
0.7037 --- loss_d: 0.011809
0.7819 --- loss_d: 0.005566
0.8600 --- loss_d: 0.074099
0.9382 --- loss_d: 0.033203
Epoch finished! Loss: 0.08790987657152087
Starting epoch 9/10.
0.0000 --- loss_d: 0.018998
0.0782 --- loss_d: 0.026559
0.1564 --- loss_d: 0.001442
0.2346 --- loss_d: 0.001606
0.3127 --- loss_d: 0.009122
0.3909 --- loss_d: 0.006370
0.4691 --- loss_d: 0.008516
0.5473 --- loss_d: 0.003318
0.6255 --- loss_d: 0.010443
0.7037 --- loss_d: 0.009368
0.7819 --- loss_d: 0.001449
0.8600 --- loss_d: 0.009127
0.9382 --- loss_d: 0.002390
Epoch finished! Loss: 0.04045521618461962
Starting epoch 10/10.
0.0000 --- loss_d: 0.154384
0.0782 --- loss_d: 0.000687
0.1564 --- loss_d: 0.444410
0.2346 --- loss_d: 0.001866
0.3127 --- loss_d: 0.002427
0.3909 --- loss_d: 0.001822
0.4691 --- loss_d: 0.002165
0.5473 --- loss_d: 0.169960
0.6255 --- loss_d: 0.022302
0.7037 --- loss_d: 0.038786
0.7819 --- loss_d: 0.003603
0.8600 --- loss_d: 0.007825
0.9382 --- loss_d: 0.014408
Epoch finished! Loss: 0.042479538687254584
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999845 0.99999833 1.         0.99999559 0.99999928 0.99999988
 1.         1.         1.         1.         1.         1.
 1.         0.99999988 1.         0.99999988 1.         1.
 1.         0.99999964 1.        ]
pred: 0.9999995685759044, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp022-nsrr

=== Test on chp024-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.640932
0.0780 --- loss_d: 0.607546
0.1560 --- loss_d: 0.915558
0.2340 --- loss_d: 0.505776
0.3120 --- loss_d: 0.828639
0.3900 --- loss_d: 0.566933
0.4680 --- loss_d: 0.711725
0.5460 --- loss_d: 0.536330
0.6240 --- loss_d: 0.528243
0.7020 --- loss_d: 0.245838
0.7800 --- loss_d: 0.563891
0.8580 --- loss_d: 0.477821
0.9360 --- loss_d: 0.418550
Epoch finished! Loss: 0.605535912909545
Starting epoch 2/10.
0.0000 --- loss_d: 0.571986
0.0780 --- loss_d: 0.805767
0.1560 --- loss_d: 0.456046
0.2340 --- loss_d: 0.318556
0.3120 --- loss_d: 0.619248
0.3900 --- loss_d: 0.448094
0.4680 --- loss_d: 0.566328
0.5460 --- loss_d: 0.294441
0.6240 --- loss_d: 0.523711
0.7020 --- loss_d: 0.313762
0.7800 --- loss_d: 0.601200
0.8580 --- loss_d: 0.635881
0.9360 --- loss_d: 0.158567
Epoch finished! Loss: 0.4198308897903189
Starting epoch 3/10.
0.0000 --- loss_d: 0.119076
0.0780 --- loss_d: 0.440547
0.1560 --- loss_d: 0.563829
0.2340 --- loss_d: 0.315166
0.3120 --- loss_d: 0.327161
0.3900 --- loss_d: 0.216921
0.4680 --- loss_d: 0.088619
0.5460 --- loss_d: 0.130326
0.6240 --- loss_d: 0.215309
0.7020 --- loss_d: 0.300233
0.7800 --- loss_d: 0.398287
0.8580 --- loss_d: 0.105296
0.9360 --- loss_d: 0.482246
Epoch finished! Loss: 0.3046555008040741
Starting epoch 4/10.
0.0000 --- loss_d: 0.208321
0.0780 --- loss_d: 0.475551
0.1560 --- loss_d: 0.271060
0.2340 --- loss_d: 0.224606
0.3120 --- loss_d: 0.316578
0.3900 --- loss_d: 0.226707
0.4680 --- loss_d: 0.305904
0.5460 --- loss_d: 0.189120
0.6240 --- loss_d: 0.422177
0.7020 --- loss_d: 0.449777
0.7800 --- loss_d: 0.117767
0.8580 --- loss_d: 0.679707
0.9360 --- loss_d: 0.214002
Epoch finished! Loss: 0.31107269346830435
Starting epoch 5/10.
0.0000 --- loss_d: 0.131173
0.0780 --- loss_d: 0.300877
0.1560 --- loss_d: 0.136250
0.2340 --- loss_d: 0.051295
0.3120 --- loss_d: 0.920738
0.3900 --- loss_d: 0.102827
0.4680 --- loss_d: 0.120359
0.5460 --- loss_d: 0.372478
0.6240 --- loss_d: 0.047364
0.7020 --- loss_d: 0.536067
0.7800 --- loss_d: 0.146619
0.8580 --- loss_d: 0.185578
0.9360 --- loss_d: 0.029441
Epoch finished! Loss: 0.2531736157689011
Starting epoch 6/10.
0.0000 --- loss_d: 0.059190
0.0780 --- loss_d: 0.098705
0.1560 --- loss_d: 0.059779
0.2340 --- loss_d: 0.073287
0.3120 --- loss_d: 0.026508
0.3900 --- loss_d: 0.205829
0.4680 --- loss_d: 0.020887
0.5460 --- loss_d: 0.199906
0.6240 --- loss_d: 0.652042
0.7020 --- loss_d: 0.102485
0.7800 --- loss_d: 0.080133
0.8580 --- loss_d: 0.096650
0.9360 --- loss_d: 0.189669
Epoch finished! Loss: 0.19559466336795595
Starting epoch 7/10.
0.0000 --- loss_d: 0.033478
0.0780 --- loss_d: 0.018510
0.1560 --- loss_d: 0.114638
0.2340 --- loss_d: 0.085534
0.3120 --- loss_d: 0.124417
0.3900 --- loss_d: 0.108016
0.4680 --- loss_d: 0.077986
0.5460 --- loss_d: 0.016215
0.6240 --- loss_d: 0.610348
0.7020 --- loss_d: 0.208041
0.7800 --- loss_d: 0.126476
0.8580 --- loss_d: 0.630807
0.9360 --- loss_d: 0.198308
Epoch finished! Loss: 0.13906978684099158
Starting epoch 8/10.
0.0000 --- loss_d: 0.011915
0.0780 --- loss_d: 0.136446
0.1560 --- loss_d: 0.108855
0.2340 --- loss_d: 0.068126
0.3120 --- loss_d: 0.110756
0.3900 --- loss_d: 0.110858
0.4680 --- loss_d: 0.048412
0.5460 --- loss_d: 0.076415
0.6240 --- loss_d: 1.363386
0.7020 --- loss_d: 0.018792
0.7800 --- loss_d: 0.031420
0.8580 --- loss_d: 0.036469
0.9360 --- loss_d: 0.004886
Epoch finished! Loss: 0.13239727135260182
Starting epoch 9/10.
0.0000 --- loss_d: 0.025992
0.0780 --- loss_d: 0.070820
0.1560 --- loss_d: 0.027372
0.2340 --- loss_d: 0.048251
0.3120 --- loss_d: 0.013231
0.3900 --- loss_d: 0.260111
0.4680 --- loss_d: 0.015012
0.5460 --- loss_d: 1.011299
0.6240 --- loss_d: 0.488538
0.7020 --- loss_d: 0.085215
0.7800 --- loss_d: 0.103369
0.8580 --- loss_d: 0.230280
0.9360 --- loss_d: 0.032475
Epoch finished! Loss: 0.10420044298552966
Starting epoch 10/10.
0.0000 --- loss_d: 0.055950
0.0780 --- loss_d: 0.002907
0.1560 --- loss_d: 0.068734
0.2340 --- loss_d: 0.062398
0.3120 --- loss_d: 0.079632
0.3900 --- loss_d: 0.058496
0.4680 --- loss_d: 0.032198
0.5460 --- loss_d: 0.029472
0.6240 --- loss_d: 0.023852
0.7020 --- loss_d: 0.022479
0.7800 --- loss_d: 0.007532
0.8580 --- loss_d: 0.014803
0.9360 --- loss_d: 0.094501
Epoch finished! Loss: 0.06586253951445542
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999893 0.99788696 0.99999833 0.99999976 0.99999988 0.99999964
 0.9999913  0.99999988 0.99664813 0.99999988 0.9999994  0.99999964
 1.         1.         0.99999738 0.99999988 0.99997377 0.99999976]
pred: 0.999694029490153, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp024-nsrr

=== Test on chp025-nsrr. train_data(1293), test_data(7) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.700537
0.0773 --- loss_d: 0.614389
0.1547 --- loss_d: 0.370436
0.2320 --- loss_d: 0.440611
0.3094 --- loss_d: 0.776226
0.3867 --- loss_d: 0.655850
0.4640 --- loss_d: 0.816062
0.5414 --- loss_d: 0.572030
0.6187 --- loss_d: 0.616949
0.6961 --- loss_d: 0.271272
0.7734 --- loss_d: 0.732782
0.8507 --- loss_d: 0.434582
0.9281 --- loss_d: 0.973817
Epoch finished! Loss: 0.6065059269583503
Starting epoch 2/10.
0.0000 --- loss_d: 0.401583
0.0773 --- loss_d: 0.463768
0.1547 --- loss_d: 0.412621
0.2320 --- loss_d: 0.776158
0.3094 --- loss_d: 0.474513
0.3867 --- loss_d: 0.249727
0.4640 --- loss_d: 0.494681
0.5414 --- loss_d: 0.323978
0.6187 --- loss_d: 0.936313
0.6961 --- loss_d: 0.462788
0.7734 --- loss_d: 0.336736
0.8507 --- loss_d: 0.185832
0.9281 --- loss_d: 0.357733
Epoch finished! Loss: 0.46220988150714903
Starting epoch 3/10.
0.0000 --- loss_d: 0.255554
0.0773 --- loss_d: 0.550030
0.1547 --- loss_d: 0.360193
0.2320 --- loss_d: 0.273841
0.3094 --- loss_d: 0.296309
0.3867 --- loss_d: 0.531286
0.4640 --- loss_d: 0.180178
0.5414 --- loss_d: 0.388549
0.6187 --- loss_d: 0.060555
0.6961 --- loss_d: 0.279128
0.7734 --- loss_d: 0.127151
0.8507 --- loss_d: 0.254668
0.9281 --- loss_d: 0.216416
Epoch finished! Loss: 0.2997393965028053
Starting epoch 4/10.
0.0000 --- loss_d: 0.156263
0.0773 --- loss_d: 0.190404
0.1547 --- loss_d: 0.879382
0.2320 --- loss_d: 0.232410
0.3094 --- loss_d: 0.102439
0.3867 --- loss_d: 0.176260
0.4640 --- loss_d: 0.164875
0.5414 --- loss_d: 0.204837
0.6187 --- loss_d: 0.286192
0.6961 --- loss_d: 0.326993
0.7734 --- loss_d: 0.323071
0.8507 --- loss_d: 0.169785
0.9281 --- loss_d: 0.103671
Epoch finished! Loss: 0.2517701016609059
Starting epoch 5/10.
0.0000 --- loss_d: 0.046898
0.0773 --- loss_d: 0.792973
0.1547 --- loss_d: 0.678370
0.2320 --- loss_d: 0.471017
0.3094 --- loss_d: 0.150309
0.3867 --- loss_d: 0.083554
0.4640 --- loss_d: 0.091693
0.5414 --- loss_d: 0.289709
0.6187 --- loss_d: 0.109368
0.6961 --- loss_d: 0.112930
0.7734 --- loss_d: 0.235413
0.8507 --- loss_d: 0.080023
0.9281 --- loss_d: 0.769364
Epoch finished! Loss: 0.23451095960976542
Starting epoch 6/10.
0.0000 --- loss_d: 0.257057
0.0773 --- loss_d: 0.301064
0.1547 --- loss_d: 0.055414
0.2320 --- loss_d: 0.014578
0.3094 --- loss_d: 0.563141
0.3867 --- loss_d: 0.525326
0.4640 --- loss_d: 0.108916
0.5414 --- loss_d: 0.039246
0.6187 --- loss_d: 0.364396
0.6961 --- loss_d: 0.148947
0.7734 --- loss_d: 0.183295
0.8507 --- loss_d: 0.038476
0.9281 --- loss_d: 0.263675
Epoch finished! Loss: 0.18522098323315844
Starting epoch 7/10.
0.0000 --- loss_d: 0.031183
0.0773 --- loss_d: 0.701660
0.1547 --- loss_d: 0.184727
0.2320 --- loss_d: 0.430064
0.3094 --- loss_d: 1.734854
0.3867 --- loss_d: 0.342750
0.4640 --- loss_d: 0.103323
0.5414 --- loss_d: 0.092940
0.6187 --- loss_d: 0.039030
0.6961 --- loss_d: 0.029409
0.7734 --- loss_d: 0.078994
0.8507 --- loss_d: 0.024516
0.9281 --- loss_d: 0.121031
Epoch finished! Loss: 0.12619834253564477
Starting epoch 8/10.
0.0000 --- loss_d: 0.092350
0.0773 --- loss_d: 0.007564
0.1547 --- loss_d: 0.143853
0.2320 --- loss_d: 0.056251
0.3094 --- loss_d: 0.044476
0.3867 --- loss_d: 0.345650
0.4640 --- loss_d: 0.055421
0.5414 --- loss_d: 0.018710
0.6187 --- loss_d: 0.209234
0.6961 --- loss_d: 0.033023
0.7734 --- loss_d: 0.007617
0.8507 --- loss_d: 0.025094
0.9281 --- loss_d: 0.002861
Epoch finished! Loss: 0.08930121372677674
Starting epoch 9/10.
0.0000 --- loss_d: 0.036551
0.0773 --- loss_d: 0.022519
0.1547 --- loss_d: 0.175314
0.2320 --- loss_d: 0.056549
0.3094 --- loss_d: 0.001277
0.3867 --- loss_d: 0.026334
0.4640 --- loss_d: 0.052195
0.5414 --- loss_d: 0.583155
0.6187 --- loss_d: 0.918647
0.6961 --- loss_d: 0.014352
0.7734 --- loss_d: 0.058803
0.8507 --- loss_d: 0.004738
0.9281 --- loss_d: 0.408589
Epoch finished! Loss: 0.09511931236689394
Starting epoch 10/10.
0.0000 --- loss_d: 0.074864
0.0773 --- loss_d: 0.018708
0.1547 --- loss_d: 0.037785
0.2320 --- loss_d: 0.008002
0.3094 --- loss_d: 0.043073
0.3867 --- loss_d: 0.030179
0.4640 --- loss_d: 0.000950
0.5414 --- loss_d: 0.035979
0.6187 --- loss_d: 0.014932
0.6961 --- loss_d: 0.008414
0.7734 --- loss_d: 0.004343
0.8507 --- loss_d: 0.013107
0.9281 --- loss_d: 0.034847
Epoch finished! Loss: 0.059639790778313655
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99874014 1.         1.         1.         1.         0.99999964
 1.        ]
pred: 0.9998199684279305, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp025-nsrr

=== Test on chp026-nsrr. train_data(1285), test_data(15) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.676115
0.0778 --- loss_d: 0.571356
0.1556 --- loss_d: 0.563053
0.2335 --- loss_d: 0.596041
0.3113 --- loss_d: 0.642270
0.3891 --- loss_d: 0.678825
0.4669 --- loss_d: 0.715449
0.5447 --- loss_d: 0.704908
0.6226 --- loss_d: 0.415889
0.7004 --- loss_d: 0.416854
0.7782 --- loss_d: 0.359927
0.8560 --- loss_d: 0.537898
0.9339 --- loss_d: 0.561016
Epoch finished! Loss: 0.5882560343015939
Starting epoch 2/10.
0.0000 --- loss_d: 0.404842
0.0778 --- loss_d: 0.593023
0.1556 --- loss_d: 0.498261
0.2335 --- loss_d: 0.335192
0.3113 --- loss_d: 0.231720
0.3891 --- loss_d: 0.306279
0.4669 --- loss_d: 0.246046
0.5447 --- loss_d: 0.354904
0.6226 --- loss_d: 0.532054
0.7004 --- loss_d: 0.638341
0.7782 --- loss_d: 0.678885
0.8560 --- loss_d: 0.172768
0.9339 --- loss_d: 0.169154
Epoch finished! Loss: 0.4216865560156293
Starting epoch 3/10.
0.0000 --- loss_d: 0.266757
0.0778 --- loss_d: 0.512585
0.1556 --- loss_d: 0.176991
0.2335 --- loss_d: 0.229867
0.3113 --- loss_d: 0.277890
0.3891 --- loss_d: 0.317191
0.4669 --- loss_d: 1.171568
0.5447 --- loss_d: 0.286406
0.6226 --- loss_d: 0.158698
0.7004 --- loss_d: 0.322225
0.7782 --- loss_d: 0.517758
0.8560 --- loss_d: 0.385473
0.9339 --- loss_d: 0.303318
Epoch finished! Loss: 0.29525628915871494
Starting epoch 4/10.
0.0000 --- loss_d: 0.056707
0.0778 --- loss_d: 0.181021
0.1556 --- loss_d: 0.166286
0.2335 --- loss_d: 0.502057
0.3113 --- loss_d: 0.372303
0.3891 --- loss_d: 0.356680
0.4669 --- loss_d: 0.219830
0.5447 --- loss_d: 0.280121
0.6226 --- loss_d: 0.188507
0.7004 --- loss_d: 0.137930
0.7782 --- loss_d: 0.183849
0.8560 --- loss_d: 0.127034
0.9339 --- loss_d: 0.239712
Epoch finished! Loss: 0.23866360241663642
Starting epoch 5/10.
0.0000 --- loss_d: 0.090743
0.0778 --- loss_d: 0.177299
0.1556 --- loss_d: 0.124130
0.2335 --- loss_d: 0.012576
0.3113 --- loss_d: 0.124187
0.3891 --- loss_d: 0.127150
0.4669 --- loss_d: 0.066596
0.5447 --- loss_d: 0.081409
0.6226 --- loss_d: 0.154238
0.7004 --- loss_d: 0.056790
0.7782 --- loss_d: 0.140827
0.8560 --- loss_d: 0.145931
0.9339 --- loss_d: 0.023135
Epoch finished! Loss: 0.19904221856995719
Starting epoch 6/10.
0.0000 --- loss_d: 0.082935
0.0778 --- loss_d: 0.232627
0.1556 --- loss_d: 0.111108
0.2335 --- loss_d: 0.490632
0.3113 --- loss_d: 0.036612
0.3891 --- loss_d: 0.022924
0.4669 --- loss_d: 0.080060
0.5447 --- loss_d: 0.029028
0.6226 --- loss_d: 0.078597
0.7004 --- loss_d: 0.107472
0.7782 --- loss_d: 0.058214
0.8560 --- loss_d: 0.013241
0.9339 --- loss_d: 0.110437
Epoch finished! Loss: 0.17881436954485252
Starting epoch 7/10.
0.0000 --- loss_d: 0.026532
0.0778 --- loss_d: 0.115942
0.1556 --- loss_d: 0.626946
0.2335 --- loss_d: 0.074167
0.3113 --- loss_d: 0.568338
0.3891 --- loss_d: 0.022512
0.4669 --- loss_d: 0.058145
0.5447 --- loss_d: 0.472364
0.6226 --- loss_d: 0.066180
0.7004 --- loss_d: 0.041009
0.7782 --- loss_d: 0.019904
0.8560 --- loss_d: 0.188924
0.9339 --- loss_d: 0.065730
Epoch finished! Loss: 0.1272277004100033
Starting epoch 8/10.
0.0000 --- loss_d: 0.010709
0.0778 --- loss_d: 0.007895
0.1556 --- loss_d: 0.014866
0.2335 --- loss_d: 0.016634
0.3113 --- loss_d: 0.041960
0.3891 --- loss_d: 0.017585
0.4669 --- loss_d: 0.013711
0.5447 --- loss_d: 0.027428
0.6226 --- loss_d: 0.027086
0.7004 --- loss_d: 0.331430
0.7782 --- loss_d: 0.403165
0.8560 --- loss_d: 0.057351
0.9339 --- loss_d: 0.051346
Epoch finished! Loss: 0.12972212469503575
Starting epoch 9/10.
0.0000 --- loss_d: 0.089406
0.0778 --- loss_d: 0.240400
0.1556 --- loss_d: 0.009027
0.2335 --- loss_d: 0.006904
0.3113 --- loss_d: 0.018904
0.3891 --- loss_d: 0.118238
0.4669 --- loss_d: 0.023725
0.5447 --- loss_d: 0.028638
0.6226 --- loss_d: 0.021290
0.7004 --- loss_d: 0.029317
0.7782 --- loss_d: 0.018973
0.8560 --- loss_d: 0.075000
0.9339 --- loss_d: 0.048606
Epoch finished! Loss: 0.08126631348295632
Starting epoch 10/10.
0.0000 --- loss_d: 0.009726
0.0778 --- loss_d: 0.026465
0.1556 --- loss_d: 0.037059
0.2335 --- loss_d: 0.018910
0.3113 --- loss_d: 0.007362
0.3891 --- loss_d: 0.019683
0.4669 --- loss_d: 0.037891
0.5447 --- loss_d: 0.016298
0.6226 --- loss_d: 0.003024
0.7004 --- loss_d: 0.214989
0.7782 --- loss_d: 0.001552
0.8560 --- loss_d: 0.014711
0.9339 --- loss_d: 0.164468
Epoch finished! Loss: 0.05727659196600143
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999905 0.99998307 0.99994159 0.99907076 0.9999969  0.99999416
 0.99999475 0.99998379 0.99999368 0.99997878 0.99999189 0.99987805
 0.99998593 0.99933738 0.99992371]
pred: 0.999870232741038, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp026-nsrr

=== Test on chp028-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.686099
0.0779 --- loss_d: 0.900996
0.1559 --- loss_d: 0.666714
0.2338 --- loss_d: 0.428775
0.3118 --- loss_d: 0.757777
0.3897 --- loss_d: 0.612756
0.4677 --- loss_d: 0.446467
0.5456 --- loss_d: 0.505586
0.6235 --- loss_d: 0.409058
0.7015 --- loss_d: 0.448293
0.7794 --- loss_d: 0.419260
0.8574 --- loss_d: 0.844601
0.9353 --- loss_d: 0.765273
Epoch finished! Loss: 0.6101197893731296
Starting epoch 2/10.
0.0000 --- loss_d: 0.658460
0.0779 --- loss_d: 0.547930
0.1559 --- loss_d: 0.475192
0.2338 --- loss_d: 0.740622
0.3118 --- loss_d: 0.528197
0.3897 --- loss_d: 0.430239
0.4677 --- loss_d: 0.499430
0.5456 --- loss_d: 0.302483
0.6235 --- loss_d: 0.650425
0.7015 --- loss_d: 0.395310
0.7794 --- loss_d: 0.317250
0.8574 --- loss_d: 0.367594
0.9353 --- loss_d: 0.764414
Epoch finished! Loss: 0.5152115026721731
Starting epoch 3/10.
0.0000 --- loss_d: 0.236398
0.0779 --- loss_d: 0.395527
0.1559 --- loss_d: 0.368037
0.2338 --- loss_d: 0.279477
0.3118 --- loss_d: 0.205792
0.3897 --- loss_d: 0.341133
0.4677 --- loss_d: 0.623162
0.5456 --- loss_d: 0.339679
0.6235 --- loss_d: 0.275780
0.7015 --- loss_d: 0.130051
0.7794 --- loss_d: 0.095176
0.8574 --- loss_d: 0.613033
0.9353 --- loss_d: 0.092853
Epoch finished! Loss: 0.32768803753424436
Starting epoch 4/10.
0.0000 --- loss_d: 0.083193
0.0779 --- loss_d: 0.452562
0.1559 --- loss_d: 0.157920
0.2338 --- loss_d: 0.192142
0.3118 --- loss_d: 0.159137
0.3897 --- loss_d: 0.333282
0.4677 --- loss_d: 0.173425
0.5456 --- loss_d: 0.097251
0.6235 --- loss_d: 0.048155
0.7015 --- loss_d: 0.111587
0.7794 --- loss_d: 0.049341
0.8574 --- loss_d: 0.385082
0.9353 --- loss_d: 0.452934
Epoch finished! Loss: 0.24073587352177128
Starting epoch 5/10.
0.0000 --- loss_d: 0.060331
0.0779 --- loss_d: 0.153956
0.1559 --- loss_d: 0.295321
0.2338 --- loss_d: 0.116686
0.3118 --- loss_d: 0.010033
0.3897 --- loss_d: 1.085744
0.4677 --- loss_d: 0.102336
0.5456 --- loss_d: 0.394536
0.6235 --- loss_d: 0.037133
0.7015 --- loss_d: 0.105233
0.7794 --- loss_d: 0.395107
0.8574 --- loss_d: 0.039523
0.9353 --- loss_d: 0.196647
Epoch finished! Loss: 0.1589348026245716
Starting epoch 6/10.
0.0000 --- loss_d: 0.009795
0.0779 --- loss_d: 0.040955
0.1559 --- loss_d: 0.008853
0.2338 --- loss_d: 0.196146
0.3118 --- loss_d: 0.013260
0.3897 --- loss_d: 0.212682
0.4677 --- loss_d: 0.067819
0.5456 --- loss_d: 0.048305
0.6235 --- loss_d: 0.026733
0.7015 --- loss_d: 0.084393
0.7794 --- loss_d: 0.010387
0.8574 --- loss_d: 0.009170
0.9353 --- loss_d: 0.157798
Epoch finished! Loss: 0.1321800946152507
Starting epoch 7/10.
0.0000 --- loss_d: 0.052602
0.0779 --- loss_d: 0.059643
0.1559 --- loss_d: 0.018854
0.2338 --- loss_d: 0.022654
0.3118 --- loss_d: 0.018545
0.3897 --- loss_d: 0.590414
0.4677 --- loss_d: 0.130018
0.5456 --- loss_d: 0.036218
0.6235 --- loss_d: 0.020086
0.7015 --- loss_d: 0.103629
0.7794 --- loss_d: 0.073132
0.8574 --- loss_d: 0.009488
0.9353 --- loss_d: 0.031005
Epoch finished! Loss: 0.09337326357854181
Starting epoch 8/10.
0.0000 --- loss_d: 0.005589
0.0779 --- loss_d: 0.264296
0.1559 --- loss_d: 0.006207
0.2338 --- loss_d: 0.003665
0.3118 --- loss_d: 0.052307
0.3897 --- loss_d: 0.103142
0.4677 --- loss_d: 0.001812
0.5456 --- loss_d: 0.163499
0.6235 --- loss_d: 0.001550
0.7015 --- loss_d: 0.001700
0.7794 --- loss_d: 0.239612
0.8574 --- loss_d: 0.026458
0.9353 --- loss_d: 0.178097
Epoch finished! Loss: 0.05720919089867493
Starting epoch 9/10.
0.0000 --- loss_d: 0.004823
0.0779 --- loss_d: 0.022096
0.1559 --- loss_d: 0.010815
0.2338 --- loss_d: 0.028397
0.3118 --- loss_d: 0.002806
0.3897 --- loss_d: 0.010383
0.4677 --- loss_d: 0.061143
0.5456 --- loss_d: 0.009453
0.6235 --- loss_d: 0.066522
0.7015 --- loss_d: 0.006534
0.7794 --- loss_d: 0.007068
0.8574 --- loss_d: 0.090292
0.9353 --- loss_d: 0.018122
Epoch finished! Loss: 0.08030816141490504
Starting epoch 10/10.
0.0000 --- loss_d: 0.006012
0.0779 --- loss_d: 0.321539
0.1559 --- loss_d: 0.009503
0.2338 --- loss_d: 0.005869
0.3118 --- loss_d: 0.307361
0.3897 --- loss_d: 0.000593
0.4677 --- loss_d: 0.001593
0.5456 --- loss_d: 0.003335
0.6235 --- loss_d: 0.004916
0.7015 --- loss_d: 0.003066
0.7794 --- loss_d: 0.009736
0.8574 --- loss_d: 0.019422
0.9353 --- loss_d: 0.003252
Epoch finished! Loss: 0.0381825010861121
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.85239226 1.         0.99999988 0.99995923 0.99999821 0.99999988
 0.99999976 0.99996305 0.99999511 0.99999321 0.99999988 0.99998403
 0.99996221 0.99999917 0.9999994  0.70728922 0.99998152]
pred: 0.9740891772158006, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp028-nsrr

=== Test on chp029-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.756925
0.0779 --- loss_d: 0.844105
0.1559 --- loss_d: 0.711747
0.2338 --- loss_d: 0.565152
0.3118 --- loss_d: 0.890466
0.3897 --- loss_d: 0.680195
0.4677 --- loss_d: 0.738470
0.5456 --- loss_d: 0.651943
0.6235 --- loss_d: 0.511675
0.7015 --- loss_d: 0.366896
0.7794 --- loss_d: 0.302599
0.8574 --- loss_d: 0.684908
0.9353 --- loss_d: 0.516190
Epoch finished! Loss: 0.6021770898951218
Starting epoch 2/10.
0.0000 --- loss_d: 0.748235
0.0779 --- loss_d: 0.355896
0.1559 --- loss_d: 0.419855
0.2338 --- loss_d: 0.315133
0.3118 --- loss_d: 0.538933
0.3897 --- loss_d: 0.346424
0.4677 --- loss_d: 0.853474
0.5456 --- loss_d: 0.301810
0.6235 --- loss_d: 0.557029
0.7015 --- loss_d: 0.789657
0.7794 --- loss_d: 0.493415
0.8574 --- loss_d: 0.389461
0.9353 --- loss_d: 0.316107
Epoch finished! Loss: 0.43927284446544945
Starting epoch 3/10.
0.0000 --- loss_d: 0.402262
0.0779 --- loss_d: 0.238791
0.1559 --- loss_d: 0.310138
0.2338 --- loss_d: 0.457170
0.3118 --- loss_d: 0.184488
0.3897 --- loss_d: 0.562873
0.4677 --- loss_d: 0.266051
0.5456 --- loss_d: 0.365390
0.6235 --- loss_d: 0.182575
0.7015 --- loss_d: 0.748580
0.7794 --- loss_d: 0.236918
0.8574 --- loss_d: 0.781486
0.9353 --- loss_d: 0.250956
Epoch finished! Loss: 0.32731393989524804
Starting epoch 4/10.
0.0000 --- loss_d: 0.161071
0.0779 --- loss_d: 0.664157
0.1559 --- loss_d: 0.217983
0.2338 --- loss_d: 0.292990
0.3118 --- loss_d: 0.238868
0.3897 --- loss_d: 0.084219
0.4677 --- loss_d: 0.154163
0.5456 --- loss_d: 0.108517
0.6235 --- loss_d: 0.077191
0.7015 --- loss_d: 0.799515
0.7794 --- loss_d: 0.220128
0.8574 --- loss_d: 0.201246
0.9353 --- loss_d: 0.078422
Epoch finished! Loss: 0.2241516570938984
Starting epoch 5/10.
0.0000 --- loss_d: 0.151523
0.0779 --- loss_d: 0.433222
0.1559 --- loss_d: 0.039764
0.2338 --- loss_d: 0.254491
0.3118 --- loss_d: 0.190199
0.3897 --- loss_d: 0.260231
0.4677 --- loss_d: 0.036836
0.5456 --- loss_d: 0.321847
0.6235 --- loss_d: 0.023577
0.7015 --- loss_d: 0.198500
0.7794 --- loss_d: 0.139469
0.8574 --- loss_d: 0.161336
0.9353 --- loss_d: 0.072974
Epoch finished! Loss: 0.18997334150481038
Starting epoch 6/10.
0.0000 --- loss_d: 0.052087
0.0779 --- loss_d: 0.153865
0.1559 --- loss_d: 0.083914
0.2338 --- loss_d: 0.209252
0.3118 --- loss_d: 0.049532
0.3897 --- loss_d: 0.319335
0.4677 --- loss_d: 0.057158
0.5456 --- loss_d: 0.019278
0.6235 --- loss_d: 0.128277
0.7015 --- loss_d: 0.198640
0.7794 --- loss_d: 0.145138
0.8574 --- loss_d: 0.097877
0.9353 --- loss_d: 0.098042
Epoch finished! Loss: 0.13630005328013794
Starting epoch 7/10.
0.0000 --- loss_d: 0.176100
0.0779 --- loss_d: 0.013261
0.1559 --- loss_d: 0.131471
0.2338 --- loss_d: 0.055393
0.3118 --- loss_d: 0.172876
0.3897 --- loss_d: 0.027646
0.4677 --- loss_d: 0.041497
0.5456 --- loss_d: 0.019163
0.6235 --- loss_d: 0.057990
0.7015 --- loss_d: 0.010106
0.7794 --- loss_d: 0.054640
0.8574 --- loss_d: 0.007139
0.9353 --- loss_d: 0.338946
Epoch finished! Loss: 0.11857113561200094
Starting epoch 8/10.
0.0000 --- loss_d: 0.004975
0.0779 --- loss_d: 0.056024
0.1559 --- loss_d: 0.008549
0.2338 --- loss_d: 0.007152
0.3118 --- loss_d: 0.067534
0.3897 --- loss_d: 0.006888
0.4677 --- loss_d: 0.052660
0.5456 --- loss_d: 0.012963
0.6235 --- loss_d: 0.011063
0.7015 --- loss_d: 0.113183
0.7794 --- loss_d: 0.067379
0.8574 --- loss_d: 0.006285
0.9353 --- loss_d: 0.027055
Epoch finished! Loss: 0.08407635821822623
Starting epoch 9/10.
0.0000 --- loss_d: 0.034854
0.0779 --- loss_d: 0.000686
0.1559 --- loss_d: 0.389076
0.2338 --- loss_d: 0.022350
0.3118 --- loss_d: 0.003283
0.3897 --- loss_d: 0.059157
0.4677 --- loss_d: 0.026413
0.5456 --- loss_d: 0.149333
0.6235 --- loss_d: 0.147318
0.7015 --- loss_d: 0.049618
0.7794 --- loss_d: 0.060308
0.8574 --- loss_d: 0.361461
0.9353 --- loss_d: 0.002270
Epoch finished! Loss: 0.08160293659057061
Starting epoch 10/10.
0.0000 --- loss_d: 0.020255
0.0779 --- loss_d: 0.014445
0.1559 --- loss_d: 0.041537
0.2338 --- loss_d: 0.010916
0.3118 --- loss_d: 0.016547
0.3897 --- loss_d: 0.014640
0.4677 --- loss_d: 0.066318
0.5456 --- loss_d: 0.015174
0.6235 --- loss_d: 0.014673
0.7015 --- loss_d: 0.068589
0.7794 --- loss_d: 0.014168
0.8574 --- loss_d: 0.036809
0.9353 --- loss_d: 0.127630
Epoch finished! Loss: 0.07373421044712813
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99887329 0.9999547  0.9999963  0.9999814  0.99992025 0.99893647
 0.99976462 0.99999392 0.99997282 0.99963486 0.99942964 0.99998987
 0.9998337  0.99999237 0.99944657 0.99668831 0.99995887]
pred: 0.9995510578155518, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp029-nsrr

=== Test on chp030-nsrr. train_data(1280), test_data(20) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.698413
0.0781 --- loss_d: 0.612254
0.1562 --- loss_d: 0.447779
0.2344 --- loss_d: 0.461676
0.3125 --- loss_d: 0.543001
0.3906 --- loss_d: 0.868088
0.4688 --- loss_d: 0.562832
0.5469 --- loss_d: 0.654302
0.6250 --- loss_d: 0.402217
0.7031 --- loss_d: 0.315046
0.7812 --- loss_d: 0.570997
0.8594 --- loss_d: 0.526612
0.9375 --- loss_d: 0.389345
Epoch finished! Loss: 0.5884418511015224
Starting epoch 2/10.
0.0000 --- loss_d: 0.437512
0.0781 --- loss_d: 0.497044
0.1562 --- loss_d: 0.325439
0.2344 --- loss_d: 0.223109
0.3125 --- loss_d: 0.813727
0.3906 --- loss_d: 0.323629
0.4688 --- loss_d: 0.334411
0.5469 --- loss_d: 1.204448
0.6250 --- loss_d: 0.501791
0.7031 --- loss_d: 0.459530
0.7812 --- loss_d: 0.427116
0.8594 --- loss_d: 0.919675
0.9375 --- loss_d: 0.441118
Epoch finished! Loss: 0.4628786743860545
Starting epoch 3/10.
0.0000 --- loss_d: 0.359171
0.0781 --- loss_d: 0.205107
0.1562 --- loss_d: 0.514409
0.2344 --- loss_d: 0.224395
0.3125 --- loss_d: 0.517857
0.3906 --- loss_d: 0.433604
0.4688 --- loss_d: 0.424393
0.5469 --- loss_d: 0.268326
0.6250 --- loss_d: 0.450050
0.7031 --- loss_d: 0.384292
0.7812 --- loss_d: 0.162428
0.8594 --- loss_d: 0.110815
0.9375 --- loss_d: 0.320708
Epoch finished! Loss: 0.3269863354526167
Starting epoch 4/10.
0.0000 --- loss_d: 0.672522
0.0781 --- loss_d: 0.495053
0.1562 --- loss_d: 0.327388
0.2344 --- loss_d: 0.087947
0.3125 --- loss_d: 0.048278
0.3906 --- loss_d: 0.076202
0.4688 --- loss_d: 0.110803
0.5469 --- loss_d: 0.049765
0.6250 --- loss_d: 0.397468
0.7031 --- loss_d: 0.215532
0.7812 --- loss_d: 0.057845
0.8594 --- loss_d: 0.361645
0.9375 --- loss_d: 0.068288
Epoch finished! Loss: 0.24077679496991822
Starting epoch 5/10.
0.0000 --- loss_d: 0.146762
0.0781 --- loss_d: 0.168640
0.1562 --- loss_d: 0.110968
0.2344 --- loss_d: 0.084529
0.3125 --- loss_d: 0.010846
0.3906 --- loss_d: 0.186122
0.4688 --- loss_d: 0.338967
0.5469 --- loss_d: 0.181765
0.6250 --- loss_d: 0.213495
0.7031 --- loss_d: 0.065172
0.7812 --- loss_d: 0.175676
0.8594 --- loss_d: 0.120581
0.9375 --- loss_d: 0.139028
Epoch finished! Loss: 0.18297847666169012
Starting epoch 6/10.
0.0000 --- loss_d: 0.033769
0.0781 --- loss_d: 0.504261
0.1562 --- loss_d: 0.047201
0.2344 --- loss_d: 0.085492
0.3125 --- loss_d: 0.191662
0.3906 --- loss_d: 0.024577
0.4688 --- loss_d: 0.009889
0.5469 --- loss_d: 0.088475
0.6250 --- loss_d: 0.027584
0.7031 --- loss_d: 0.220633
0.7812 --- loss_d: 0.065871
0.8594 --- loss_d: 0.049061
0.9375 --- loss_d: 0.312210
Epoch finished! Loss: 0.10942366290067536
Starting epoch 7/10.
0.0000 --- loss_d: 0.034462
0.0781 --- loss_d: 0.021327
0.1562 --- loss_d: 0.083741
0.2344 --- loss_d: 0.013539
0.3125 --- loss_d: 0.002525
0.3906 --- loss_d: 0.002437
0.4688 --- loss_d: 0.008744
0.5469 --- loss_d: 0.111682
0.6250 --- loss_d: 0.017070
0.7031 --- loss_d: 0.006305
0.7812 --- loss_d: 0.038516
0.8594 --- loss_d: 0.046808
0.9375 --- loss_d: 0.001456
Epoch finished! Loss: 0.07491863876174197
Starting epoch 8/10.
0.0000 --- loss_d: 0.164434
0.0781 --- loss_d: 0.043449
0.1562 --- loss_d: 0.001450
0.2344 --- loss_d: 0.016178
0.3125 --- loss_d: 0.006282
0.3906 --- loss_d: 0.283433
0.4688 --- loss_d: 0.003993
0.5469 --- loss_d: 0.065153
0.6250 --- loss_d: 0.072267
0.7031 --- loss_d: 0.012099
0.7812 --- loss_d: 0.016667
0.8594 --- loss_d: 0.089410
0.9375 --- loss_d: 0.003029
Epoch finished! Loss: 0.06109397276212997
Starting epoch 9/10.
0.0000 --- loss_d: 0.024447
0.0781 --- loss_d: 0.009123
0.1562 --- loss_d: 0.001540
0.2344 --- loss_d: 0.005505
0.3125 --- loss_d: 0.002443
0.3906 --- loss_d: 0.000941
0.4688 --- loss_d: 0.003813
0.5469 --- loss_d: 0.020713
0.6250 --- loss_d: 0.021334
0.7031 --- loss_d: 0.010188
0.7812 --- loss_d: 0.006855
0.8594 --- loss_d: 0.132002
0.9375 --- loss_d: 0.022139
Epoch finished! Loss: 0.0741985886303642
Starting epoch 10/10.
0.0000 --- loss_d: 0.006347
0.0781 --- loss_d: 0.106362
0.1562 --- loss_d: 0.028013
0.2344 --- loss_d: 0.027289
0.3125 --- loss_d: 0.027138
0.3906 --- loss_d: 0.035107
0.4688 --- loss_d: 0.023075
0.5469 --- loss_d: 0.111153
0.6250 --- loss_d: 0.026497
0.7031 --- loss_d: 0.066596
0.7812 --- loss_d: 0.005597
0.8594 --- loss_d: 0.077298
0.9375 --- loss_d: 0.005768
Epoch finished! Loss: 0.07563233367482743
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99627268 0.99969566 1.         0.99999964 0.99966276 0.99364555
 0.99974817 1.         0.99652833 0.99999547 1.         0.99999964
 0.99999344 0.877949   0.99841416 0.99439007 0.99997151 0.9996537
 0.99996424 0.99999857]
pred: 0.9927941292524338, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp030-nsrr

=== Test on chp031-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.655835
0.0780 --- loss_d: 0.475412
0.1560 --- loss_d: 0.802505
0.2340 --- loss_d: 0.671251
0.3120 --- loss_d: 0.481870
0.3900 --- loss_d: 0.861565
0.4680 --- loss_d: 0.509227
0.5460 --- loss_d: 0.772743
0.6240 --- loss_d: 0.789851
0.7020 --- loss_d: 0.907046
0.7800 --- loss_d: 0.547855
0.8580 --- loss_d: 0.630529
0.9360 --- loss_d: 0.635988
Epoch finished! Loss: 0.6117553971707821
Starting epoch 2/10.
0.0000 --- loss_d: 0.352364
0.0780 --- loss_d: 0.545815
0.1560 --- loss_d: 0.765937
0.2340 --- loss_d: 0.424434
0.3120 --- loss_d: 0.860279
0.3900 --- loss_d: 0.452865
0.4680 --- loss_d: 0.770903
0.5460 --- loss_d: 1.037271
0.6240 --- loss_d: 0.451233
0.7020 --- loss_d: 0.617405
0.7800 --- loss_d: 1.245365
0.8580 --- loss_d: 0.772705
0.9360 --- loss_d: 0.354396
Epoch finished! Loss: 0.4737612217431888
Starting epoch 3/10.
0.0000 --- loss_d: 0.517272
0.0780 --- loss_d: 0.393040
0.1560 --- loss_d: 0.118288
0.2340 --- loss_d: 0.308027
0.3120 --- loss_d: 0.287541
0.3900 --- loss_d: 0.236514
0.4680 --- loss_d: 0.039355
0.5460 --- loss_d: 0.189397
0.6240 --- loss_d: 0.186228
0.7020 --- loss_d: 0.251378
0.7800 --- loss_d: 0.242497
0.8580 --- loss_d: 0.291234
0.9360 --- loss_d: 0.522672
Epoch finished! Loss: 0.30734695825958624
Starting epoch 4/10.
0.0000 --- loss_d: 0.178429
0.0780 --- loss_d: 0.464445
0.1560 --- loss_d: 0.100465
0.2340 --- loss_d: 0.083803
0.3120 --- loss_d: 0.165657
0.3900 --- loss_d: 0.024658
0.4680 --- loss_d: 0.007322
0.5460 --- loss_d: 0.342257
0.6240 --- loss_d: 0.084154
0.7020 --- loss_d: 0.056142
0.7800 --- loss_d: 0.319027
0.8580 --- loss_d: 0.124618
0.9360 --- loss_d: 0.085937
Epoch finished! Loss: 0.19092495060249348
Starting epoch 5/10.
0.0000 --- loss_d: 0.052882
0.0780 --- loss_d: 0.003484
0.1560 --- loss_d: 0.120503
0.2340 --- loss_d: 0.065881
0.3120 --- loss_d: 0.027625
0.3900 --- loss_d: 0.063579
0.4680 --- loss_d: 0.321963
0.5460 --- loss_d: 0.021121
0.6240 --- loss_d: 0.016677
0.7020 --- loss_d: 0.092212
0.7800 --- loss_d: 0.128422
0.8580 --- loss_d: 0.028216
0.9360 --- loss_d: 0.278309
Epoch finished! Loss: 0.15308739856664033
Starting epoch 6/10.
0.0000 --- loss_d: 0.030734
0.0780 --- loss_d: 0.072541
0.1560 --- loss_d: 0.127266
0.2340 --- loss_d: 0.025134
0.3120 --- loss_d: 0.015626
0.3900 --- loss_d: 0.368621
0.4680 --- loss_d: 0.097517
0.5460 --- loss_d: 0.005681
0.6240 --- loss_d: 0.247046
0.7020 --- loss_d: 0.047561
0.7800 --- loss_d: 0.114758
0.8580 --- loss_d: 0.347479
0.9360 --- loss_d: 0.159505
Epoch finished! Loss: 0.13077155615246738
Starting epoch 7/10.
0.0000 --- loss_d: 0.023116
0.0780 --- loss_d: 0.044300
0.1560 --- loss_d: 0.031652
0.2340 --- loss_d: 0.005279
0.3120 --- loss_d: 0.046755
0.3900 --- loss_d: 0.390934
0.4680 --- loss_d: 0.016913
0.5460 --- loss_d: 0.013154
0.6240 --- loss_d: 0.237589
0.7020 --- loss_d: 0.015397
0.7800 --- loss_d: 0.017442
0.8580 --- loss_d: 0.133211
0.9360 --- loss_d: 0.030758
Epoch finished! Loss: 0.08356064370400418
Starting epoch 8/10.
0.0000 --- loss_d: 0.027745
0.0780 --- loss_d: 0.010113
0.1560 --- loss_d: 0.020752
0.2340 --- loss_d: 0.010110
0.3120 --- loss_d: 0.022730
0.3900 --- loss_d: 0.008580
0.4680 --- loss_d: 0.013617
0.5460 --- loss_d: 0.005062
0.6240 --- loss_d: 0.001895
0.7020 --- loss_d: 0.015761
0.7800 --- loss_d: 0.003658
0.8580 --- loss_d: 0.000677
0.9360 --- loss_d: 0.009969
Epoch finished! Loss: 0.038213862506609075
Starting epoch 9/10.
0.0000 --- loss_d: 0.002789
0.0780 --- loss_d: 0.007376
0.1560 --- loss_d: 0.091653
0.2340 --- loss_d: 0.006766
0.3120 --- loss_d: 0.122447
0.3900 --- loss_d: 0.014727
0.4680 --- loss_d: 0.136775
0.5460 --- loss_d: 0.007047
0.6240 --- loss_d: 0.003634
0.7020 --- loss_d: 0.014787
0.7800 --- loss_d: 0.005730
0.8580 --- loss_d: 0.047545
0.9360 --- loss_d: 0.001990
Epoch finished! Loss: 0.0578618790946166
Starting epoch 10/10.
0.0000 --- loss_d: 0.042006
0.0780 --- loss_d: 0.000834
0.1560 --- loss_d: 0.018200
0.2340 --- loss_d: 0.007058
0.3120 --- loss_d: 0.007060
0.3900 --- loss_d: 0.013360
0.4680 --- loss_d: 0.057897
0.5460 --- loss_d: 0.003538
0.6240 --- loss_d: 0.189564
0.7020 --- loss_d: 0.096442
0.7800 --- loss_d: 0.060970
0.8580 --- loss_d: 0.001594
0.9360 --- loss_d: 0.000258
Epoch finished! Loss: 0.03880605192546227
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99992836 0.99987805 0.98003483 0.97819054 0.99471152 0.99960929
 0.99966037 0.9999727  0.99901855 0.99994969 0.98594046 0.99999678
 0.99815565 0.99994075 0.99998391 0.99996758 0.99783593 0.99993837]
pred: 0.9962618516551124, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp031-nsrr

=== Test on chp032-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.686396
0.0779 --- loss_d: 0.687040
0.1559 --- loss_d: 0.624342
0.2338 --- loss_d: 0.602028
0.3118 --- loss_d: 0.622724
0.3897 --- loss_d: 0.553004
0.4677 --- loss_d: 0.442523
0.5456 --- loss_d: 0.695803
0.6235 --- loss_d: 0.469175
0.7015 --- loss_d: 0.523627
0.7794 --- loss_d: 0.501393
0.8574 --- loss_d: 0.520801
0.9353 --- loss_d: 0.462819
Epoch finished! Loss: 0.5912678048480302
Starting epoch 2/10.
0.0000 --- loss_d: 0.535799
0.0779 --- loss_d: 0.466901
0.1559 --- loss_d: 0.324476
0.2338 --- loss_d: 0.517787
0.3118 --- loss_d: 0.543372
0.3897 --- loss_d: 0.175919
0.4677 --- loss_d: 0.466788
0.5456 --- loss_d: 0.377986
0.6235 --- loss_d: 0.534541
0.7015 --- loss_d: 0.377124
0.7794 --- loss_d: 0.279240
0.8574 --- loss_d: 0.178985
0.9353 --- loss_d: 0.209129
Epoch finished! Loss: 0.407028382003773
Starting epoch 3/10.
0.0000 --- loss_d: 0.275523
0.0779 --- loss_d: 0.132338
0.1559 --- loss_d: 0.560713
0.2338 --- loss_d: 0.272233
0.3118 --- loss_d: 0.256173
0.3897 --- loss_d: 0.437327
0.4677 --- loss_d: 0.158419
0.5456 --- loss_d: 0.663367
0.6235 --- loss_d: 0.180209
0.7015 --- loss_d: 0.150372
0.7794 --- loss_d: 0.264207
0.8574 --- loss_d: 0.757554
0.9353 --- loss_d: 0.261067
Epoch finished! Loss: 0.33650326216593385
Starting epoch 4/10.
0.0000 --- loss_d: 0.339038
0.0779 --- loss_d: 0.348290
0.1559 --- loss_d: 0.242362
0.2338 --- loss_d: 0.173212
0.3118 --- loss_d: 0.263085
0.3897 --- loss_d: 0.456229
0.4677 --- loss_d: 0.274789
0.5456 --- loss_d: 0.292843
0.6235 --- loss_d: 0.027975
0.7015 --- loss_d: 0.085891
0.7794 --- loss_d: 0.395736
0.8574 --- loss_d: 0.105235
0.9353 --- loss_d: 0.211573
Epoch finished! Loss: 0.21109562886704225
Starting epoch 5/10.
0.0000 --- loss_d: 0.044982
0.0779 --- loss_d: 0.271892
0.1559 --- loss_d: 0.107611
0.2338 --- loss_d: 0.444209
0.3118 --- loss_d: 0.223335
0.3897 --- loss_d: 0.806943
0.4677 --- loss_d: 0.169215
0.5456 --- loss_d: 0.570219
0.6235 --- loss_d: 0.092693
0.7015 --- loss_d: 0.093583
0.7794 --- loss_d: 0.141381
0.8574 --- loss_d: 0.123372
0.9353 --- loss_d: 0.017405
Epoch finished! Loss: 0.17946834804752143
Starting epoch 6/10.
0.0000 --- loss_d: 0.380606
0.0779 --- loss_d: 0.157037
0.1559 --- loss_d: 0.163180
0.2338 --- loss_d: 0.043701
0.3118 --- loss_d: 0.034176
0.3897 --- loss_d: 0.044344
0.4677 --- loss_d: 0.086973
0.5456 --- loss_d: 0.010752
0.6235 --- loss_d: 0.066829
0.7015 --- loss_d: 0.016119
0.7794 --- loss_d: 0.295220
0.8574 --- loss_d: 0.344943
0.9353 --- loss_d: 0.033043
Epoch finished! Loss: 0.14397457856102847
Starting epoch 7/10.
0.0000 --- loss_d: 0.167717
0.0779 --- loss_d: 0.304502
0.1559 --- loss_d: 0.070055
0.2338 --- loss_d: 0.034609
0.3118 --- loss_d: 0.096716
0.3897 --- loss_d: 0.058854
0.4677 --- loss_d: 0.033313
0.5456 --- loss_d: 0.078153
0.6235 --- loss_d: 0.246332
0.7015 --- loss_d: 0.122326
0.7794 --- loss_d: 0.087071
0.8574 --- loss_d: 0.022074
0.9353 --- loss_d: 0.021696
Epoch finished! Loss: 0.11658885948781972
Starting epoch 8/10.
0.0000 --- loss_d: 0.011374
0.0779 --- loss_d: 0.005516
0.1559 --- loss_d: 0.009842
0.2338 --- loss_d: 0.012483
0.3118 --- loss_d: 0.011050
0.3897 --- loss_d: 0.006611
0.4677 --- loss_d: 0.069715
0.5456 --- loss_d: 0.023210
0.6235 --- loss_d: 0.099477
0.7015 --- loss_d: 0.011078
0.7794 --- loss_d: 0.017450
0.8574 --- loss_d: 0.055249
0.9353 --- loss_d: 0.009497
Epoch finished! Loss: 0.07442784783779643
Starting epoch 9/10.
0.0000 --- loss_d: 0.218152
0.0779 --- loss_d: 0.192192
0.1559 --- loss_d: 0.017305
0.2338 --- loss_d: 0.010727
0.3118 --- loss_d: 0.003168
0.3897 --- loss_d: 0.001361
0.4677 --- loss_d: 0.005842
0.5456 --- loss_d: 0.081061
0.6235 --- loss_d: 0.045484
0.7015 --- loss_d: 0.028128
0.7794 --- loss_d: 0.008507
0.8574 --- loss_d: 0.001908
0.9353 --- loss_d: 0.057515
Epoch finished! Loss: 0.054626810746867704
Starting epoch 10/10.
0.0000 --- loss_d: 0.024769
0.0779 --- loss_d: 0.001873
0.1559 --- loss_d: 0.002485
0.2338 --- loss_d: 0.059393
0.3118 --- loss_d: 0.027999
0.3897 --- loss_d: 0.003002
0.4677 --- loss_d: 0.003299
0.5456 --- loss_d: 0.590593
0.6235 --- loss_d: 0.018461
0.7015 --- loss_d: 0.001958
0.7794 --- loss_d: 0.056213
0.8574 --- loss_d: 0.052152
0.9353 --- loss_d: 0.036765
Epoch finished! Loss: 0.04422388619752837
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99984109 0.84687817 0.89145303 0.99979264 0.99941635 0.99535936
 0.99999499 0.9929201  0.99899668 0.99999964 0.99993777 0.99999762
 0.99987328 0.99935752 0.99983668 0.99999952 0.99999821]
pred: 0.9837442741674536, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp032-nsrr

=== Test on chp033-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.658866
0.0779 --- loss_d: 0.647895
0.1558 --- loss_d: 0.353711
0.2336 --- loss_d: 0.527058
0.3115 --- loss_d: 0.463311
0.3894 --- loss_d: 0.574300
0.4673 --- loss_d: 0.506817
0.5452 --- loss_d: 0.742209
0.6231 --- loss_d: 0.495475
0.7009 --- loss_d: 0.647345
0.7788 --- loss_d: 0.762102
0.8567 --- loss_d: 0.553058
0.9346 --- loss_d: 0.581066
Epoch finished! Loss: 0.6008828720077872
Starting epoch 2/10.
0.0000 --- loss_d: 0.677633
0.0779 --- loss_d: 0.397556
0.1558 --- loss_d: 0.342235
0.2336 --- loss_d: 0.609988
0.3115 --- loss_d: 0.498547
0.3894 --- loss_d: 0.529625
0.4673 --- loss_d: 0.287978
0.5452 --- loss_d: 0.352734
0.6231 --- loss_d: 0.357606
0.7009 --- loss_d: 0.550018
0.7788 --- loss_d: 0.490993
0.8567 --- loss_d: 0.195704
0.9346 --- loss_d: 0.596698
Epoch finished! Loss: 0.40752590383635834
Starting epoch 3/10.
0.0000 --- loss_d: 0.336265
0.0779 --- loss_d: 0.339570
0.1558 --- loss_d: 0.095448
0.2336 --- loss_d: 0.426978
0.3115 --- loss_d: 0.078831
0.3894 --- loss_d: 0.107821
0.4673 --- loss_d: 0.378542
0.5452 --- loss_d: 0.927712
0.6231 --- loss_d: 0.076400
0.7009 --- loss_d: 0.298443
0.7788 --- loss_d: 0.096492
0.8567 --- loss_d: 0.405123
0.9346 --- loss_d: 0.269387
Epoch finished! Loss: 0.284220304019982
Starting epoch 4/10.
0.0000 --- loss_d: 0.489901
0.0779 --- loss_d: 0.114744
0.1558 --- loss_d: 0.029642
0.2336 --- loss_d: 0.085048
0.3115 --- loss_d: 0.012491
0.3894 --- loss_d: 0.132144
0.4673 --- loss_d: 0.019829
0.5452 --- loss_d: 0.017633
0.6231 --- loss_d: 0.010509
0.7009 --- loss_d: 0.227002
0.7788 --- loss_d: 0.228342
0.8567 --- loss_d: 0.315028
0.9346 --- loss_d: 0.261726
Epoch finished! Loss: 0.18669453038455686
Starting epoch 5/10.
0.0000 --- loss_d: 0.052750
0.0779 --- loss_d: 0.110131
0.1558 --- loss_d: 0.625984
0.2336 --- loss_d: 0.099494
0.3115 --- loss_d: 0.340778
0.3894 --- loss_d: 0.124254
0.4673 --- loss_d: 0.064881
0.5452 --- loss_d: 0.024222
0.6231 --- loss_d: 0.144974
0.7009 --- loss_d: 0.073713
0.7788 --- loss_d: 0.105347
0.8567 --- loss_d: 0.017125
0.9346 --- loss_d: 0.021175
Epoch finished! Loss: 0.14529320076690055
Starting epoch 6/10.
0.0000 --- loss_d: 0.245847
0.0779 --- loss_d: 0.070007
0.1558 --- loss_d: 0.081572
0.2336 --- loss_d: 0.060947
0.3115 --- loss_d: 0.449902
0.3894 --- loss_d: 0.007628
0.4673 --- loss_d: 0.013608
0.5452 --- loss_d: 0.145766
0.6231 --- loss_d: 0.486379
0.7009 --- loss_d: 0.014505
0.7788 --- loss_d: 0.156057
0.8567 --- loss_d: 0.037467
0.9346 --- loss_d: 0.023883
Epoch finished! Loss: 0.13341945285901602
Starting epoch 7/10.
0.0000 --- loss_d: 0.110548
0.0779 --- loss_d: 0.092249
0.1558 --- loss_d: 0.017046
0.2336 --- loss_d: 0.054103
0.3115 --- loss_d: 0.010897
0.3894 --- loss_d: 0.383137
0.4673 --- loss_d: 0.071317
0.5452 --- loss_d: 0.015388
0.6231 --- loss_d: 0.005520
0.7009 --- loss_d: 0.023799
0.7788 --- loss_d: 0.308992
0.8567 --- loss_d: 0.315215
0.9346 --- loss_d: 0.001140
Epoch finished! Loss: 0.062405212725025194
Starting epoch 8/10.
0.0000 --- loss_d: 0.010432
0.0779 --- loss_d: 0.117827
0.1558 --- loss_d: 0.046220
0.2336 --- loss_d: 0.005203
0.3115 --- loss_d: 0.031765
0.3894 --- loss_d: 0.005340
0.4673 --- loss_d: 0.590699
0.5452 --- loss_d: 0.096083
0.6231 --- loss_d: 0.071900
0.7009 --- loss_d: 0.019563
0.7788 --- loss_d: 0.060026
0.8567 --- loss_d: 0.008096
0.9346 --- loss_d: 0.509308
Epoch finished! Loss: 0.07971511193318292
Starting epoch 9/10.
0.0000 --- loss_d: 0.005007
0.0779 --- loss_d: 0.016975
0.1558 --- loss_d: 0.068769
0.2336 --- loss_d: 0.020877
0.3115 --- loss_d: 0.023939
0.3894 --- loss_d: 0.002167
0.4673 --- loss_d: 0.007716
0.5452 --- loss_d: 0.175622
0.6231 --- loss_d: 0.000747
0.7009 --- loss_d: 0.126061
0.7788 --- loss_d: 0.046674
0.8567 --- loss_d: 0.003319
0.9346 --- loss_d: 0.010089
Epoch finished! Loss: 0.055591865357428105
Starting epoch 10/10.
0.0000 --- loss_d: 0.002444
0.0779 --- loss_d: 0.093354
0.1558 --- loss_d: 0.005680
0.2336 --- loss_d: 0.084208
0.3115 --- loss_d: 0.000921
0.3894 --- loss_d: 0.004953
0.4673 --- loss_d: 0.014862
0.5452 --- loss_d: 0.013416
0.6231 --- loss_d: 0.003959
0.7009 --- loss_d: 0.002028
0.7788 --- loss_d: 0.004949
0.8567 --- loss_d: 0.001711
0.9346 --- loss_d: 0.015393
Epoch finished! Loss: 0.04505897071715026
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999285 0.99981946 1.         1.         1.         1.
 1.         0.99999666 0.99998665 1.         1.         1.
 1.         1.         0.99995482 1.        ]
pred: 0.9999844022095203, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp033-nsrr

=== Test on chp034-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.709258
0.0779 --- loss_d: 0.898309
0.1559 --- loss_d: 0.608540
0.2338 --- loss_d: 0.265323
0.3118 --- loss_d: 0.719299
0.3897 --- loss_d: 0.641346
0.4677 --- loss_d: 0.485153
0.5456 --- loss_d: 0.447865
0.6235 --- loss_d: 0.563969
0.7015 --- loss_d: 0.713879
0.7794 --- loss_d: 0.457541
0.8574 --- loss_d: 0.594367
0.9353 --- loss_d: 0.681045
Epoch finished! Loss: 0.6034355857409537
Starting epoch 2/10.
0.0000 --- loss_d: 0.592114
0.0779 --- loss_d: 0.409397
0.1559 --- loss_d: 0.496283
0.2338 --- loss_d: 0.320958
0.3118 --- loss_d: 0.321805
0.3897 --- loss_d: 0.294957
0.4677 --- loss_d: 0.291885
0.5456 --- loss_d: 0.381722
0.6235 --- loss_d: 0.679888
0.7015 --- loss_d: 0.311777
0.7794 --- loss_d: 0.658483
0.8574 --- loss_d: 0.242709
0.9353 --- loss_d: 0.232628
Epoch finished! Loss: 0.3981827977113426
Starting epoch 3/10.
0.0000 --- loss_d: 0.262851
0.0779 --- loss_d: 0.186134
0.1559 --- loss_d: 0.461379
0.2338 --- loss_d: 0.166099
0.3118 --- loss_d: 0.421014
0.3897 --- loss_d: 0.293190
0.4677 --- loss_d: 0.184618
0.5456 --- loss_d: 0.177628
0.6235 --- loss_d: 0.225891
0.7015 --- loss_d: 0.166911
0.7794 --- loss_d: 0.480841
0.8574 --- loss_d: 0.222806
0.9353 --- loss_d: 0.121063
Epoch finished! Loss: 0.2992877697106451
Starting epoch 4/10.
0.0000 --- loss_d: 0.958685
0.0779 --- loss_d: 0.146881
0.1559 --- loss_d: 0.123477
0.2338 --- loss_d: 0.084246
0.3118 --- loss_d: 0.156679
0.3897 --- loss_d: 0.488100
0.4677 --- loss_d: 0.316119
0.5456 --- loss_d: 0.152234
0.6235 --- loss_d: 0.241173
0.7015 --- loss_d: 0.060994
0.7794 --- loss_d: 0.185815
0.8574 --- loss_d: 0.038655
0.9353 --- loss_d: 0.082803
Epoch finished! Loss: 0.2409344429252087
Starting epoch 5/10.
0.0000 --- loss_d: 0.215730
0.0779 --- loss_d: 0.121925
0.1559 --- loss_d: 0.210453
0.2338 --- loss_d: 0.063540
0.3118 --- loss_d: 0.032878
0.3897 --- loss_d: 0.006642
0.4677 --- loss_d: 0.217662
0.5456 --- loss_d: 0.155182
0.6235 --- loss_d: 0.019796
0.7015 --- loss_d: 0.030589
0.7794 --- loss_d: 0.227563
0.8574 --- loss_d: 0.459110
0.9353 --- loss_d: 0.137883
Epoch finished! Loss: 0.18155321014273795
Starting epoch 6/10.
0.0000 --- loss_d: 0.369323
0.0779 --- loss_d: 0.164109
0.1559 --- loss_d: 0.101307
0.2338 --- loss_d: 0.099709
0.3118 --- loss_d: 0.054174
0.3897 --- loss_d: 0.086271
0.4677 --- loss_d: 0.257184
0.5456 --- loss_d: 0.033703
0.6235 --- loss_d: 0.015516
0.7015 --- loss_d: 0.089668
0.7794 --- loss_d: 0.160488
0.8574 --- loss_d: 0.366445
0.9353 --- loss_d: 0.016351
Epoch finished! Loss: 0.15471919982883264
Starting epoch 7/10.
0.0000 --- loss_d: 0.374235
0.0779 --- loss_d: 0.326393
0.1559 --- loss_d: 0.080259
0.2338 --- loss_d: 0.054053
0.3118 --- loss_d: 0.029775
0.3897 --- loss_d: 0.038310
0.4677 --- loss_d: 0.101143
0.5456 --- loss_d: 0.118697
0.6235 --- loss_d: 0.008333
0.7015 --- loss_d: 0.160209
0.7794 --- loss_d: 0.011623
0.8574 --- loss_d: 0.063050
0.9353 --- loss_d: 0.043657
Epoch finished! Loss: 0.09669455599487264
Starting epoch 8/10.
0.0000 --- loss_d: 0.005299
0.0779 --- loss_d: 0.045211
0.1559 --- loss_d: 0.090759
0.2338 --- loss_d: 0.012496
0.3118 --- loss_d: 0.017455
0.3897 --- loss_d: 0.035096
0.4677 --- loss_d: 0.105333
0.5456 --- loss_d: 0.004739
0.6235 --- loss_d: 0.038023
0.7015 --- loss_d: 0.172608
0.7794 --- loss_d: 0.141356
0.8574 --- loss_d: 0.021297
0.9353 --- loss_d: 0.010087
Epoch finished! Loss: 0.12837131835431137
Starting epoch 9/10.
0.0000 --- loss_d: 0.047601
0.0779 --- loss_d: 0.040525
0.1559 --- loss_d: 0.010623
0.2338 --- loss_d: 0.011101
0.3118 --- loss_d: 0.137562
0.3897 --- loss_d: 0.073291
0.4677 --- loss_d: 0.158512
0.5456 --- loss_d: 0.136542
0.6235 --- loss_d: 0.261416
0.7015 --- loss_d: 0.032079
0.7794 --- loss_d: 0.006408
0.8574 --- loss_d: 0.007198
0.9353 --- loss_d: 0.010382
Epoch finished! Loss: 0.09020057339694176
Starting epoch 10/10.
0.0000 --- loss_d: 0.006878
0.0779 --- loss_d: 0.002146
0.1559 --- loss_d: 0.278361
0.2338 --- loss_d: 0.010567
0.3118 --- loss_d: 0.002323
0.3897 --- loss_d: 0.004806
0.4677 --- loss_d: 0.014579
0.5456 --- loss_d: 0.114317
0.6235 --- loss_d: 0.010333
0.7015 --- loss_d: 0.017711
0.7794 --- loss_d: 0.013447
0.8574 --- loss_d: 0.019587
0.9353 --- loss_d: 0.016644
Epoch finished! Loss: 0.055630008291700506
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.9411764705882353
[0.38575545 0.96308732 0.75365365 0.9462378  0.96970403 1.
 0.68271971 0.81179529 0.58732659 0.97708446 0.90135908 0.92620194
 0.98175228 0.9058845  0.98933756 0.87705314 0.96151555]
pred: 0.8600275498979232, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp034-nsrr

=== Test on chp036-nsrr. train_data(1279), test_data(21) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.658549
0.0782 --- loss_d: 0.329626
0.1564 --- loss_d: 0.919755
0.2346 --- loss_d: 0.741078
0.3127 --- loss_d: 0.731068
0.3909 --- loss_d: 0.439787
0.4691 --- loss_d: 0.835204
0.5473 --- loss_d: 0.510000
0.6255 --- loss_d: 0.504194
0.7037 --- loss_d: 0.609578
0.7819 --- loss_d: 0.366696
0.8600 --- loss_d: 0.815575
0.9382 --- loss_d: 0.529683
Epoch finished! Loss: 0.6013076554133198
Starting epoch 2/10.
0.0000 --- loss_d: 0.324056
0.0782 --- loss_d: 0.341136
0.1564 --- loss_d: 0.465645
0.2346 --- loss_d: 0.444849
0.3127 --- loss_d: 0.830774
0.3909 --- loss_d: 0.589918
0.4691 --- loss_d: 0.208499
0.5473 --- loss_d: 0.735865
0.6255 --- loss_d: 0.590769
0.7037 --- loss_d: 0.597195
0.7819 --- loss_d: 0.219667
0.8600 --- loss_d: 0.436639
0.9382 --- loss_d: 0.143030
Epoch finished! Loss: 0.38618409152575367
Starting epoch 3/10.
0.0000 --- loss_d: 0.309997
0.0782 --- loss_d: 0.173928
0.1564 --- loss_d: 0.291362
0.2346 --- loss_d: 0.321470
0.3127 --- loss_d: 0.208000
0.3909 --- loss_d: 0.100162
0.4691 --- loss_d: 0.540864
0.5473 --- loss_d: 0.172962
0.6255 --- loss_d: 0.508429
0.7037 --- loss_d: 0.172568
0.7819 --- loss_d: 0.095325
0.8600 --- loss_d: 0.147017
0.9382 --- loss_d: 0.233770
Epoch finished! Loss: 0.2748202121207916
Starting epoch 4/10.
0.0000 --- loss_d: 0.130523
0.0782 --- loss_d: 0.235043
0.1564 --- loss_d: 0.109060
0.2346 --- loss_d: 0.151522
0.3127 --- loss_d: 0.264119
0.3909 --- loss_d: 0.032301
0.4691 --- loss_d: 0.078440
0.5473 --- loss_d: 0.124541
0.6255 --- loss_d: 0.237162
0.7037 --- loss_d: 0.385307
0.7819 --- loss_d: 0.048038
0.8600 --- loss_d: 0.357905
0.9382 --- loss_d: 0.469350
Epoch finished! Loss: 0.20786330624534857
Starting epoch 5/10.
0.0000 --- loss_d: 0.085829
0.0782 --- loss_d: 0.092740
0.1564 --- loss_d: 0.801899
0.2346 --- loss_d: 0.290156
0.3127 --- loss_d: 0.026899
0.3909 --- loss_d: 0.043904
0.4691 --- loss_d: 0.053682
0.5473 --- loss_d: 0.045451
0.6255 --- loss_d: 0.348321
0.7037 --- loss_d: 0.068384
0.7819 --- loss_d: 0.017276
0.8600 --- loss_d: 0.129443
0.9382 --- loss_d: 0.023144
Epoch finished! Loss: 0.1595591439088205
Starting epoch 6/10.
0.0000 --- loss_d: 0.257607
0.0782 --- loss_d: 0.068069
0.1564 --- loss_d: 0.007932
0.2346 --- loss_d: 0.013206
0.3127 --- loss_d: 0.302803
0.3909 --- loss_d: 0.038719
0.4691 --- loss_d: 0.030560
0.5473 --- loss_d: 0.161293
0.6255 --- loss_d: 0.032923
0.7037 --- loss_d: 0.184991
0.7819 --- loss_d: 0.204054
0.8600 --- loss_d: 0.024782
0.9382 --- loss_d: 0.037703
Epoch finished! Loss: 0.11830473402111726
Starting epoch 7/10.
0.0000 --- loss_d: 0.133404
0.0782 --- loss_d: 0.073791
0.1564 --- loss_d: 0.158803
0.2346 --- loss_d: 0.044803
0.3127 --- loss_d: 0.287634
0.3909 --- loss_d: 0.017159
0.4691 --- loss_d: 0.020217
0.5473 --- loss_d: 0.020485
0.6255 --- loss_d: 0.006560
0.7037 --- loss_d: 0.045728
0.7819 --- loss_d: 0.006698
0.8600 --- loss_d: 0.011472
0.9382 --- loss_d: 0.079017
Epoch finished! Loss: 0.10438864994757464
Starting epoch 8/10.
0.0000 --- loss_d: 0.019826
0.0782 --- loss_d: 0.054091
0.1564 --- loss_d: 0.263436
0.2346 --- loss_d: 0.014733
0.3127 --- loss_d: 0.043189
0.3909 --- loss_d: 0.005892
0.4691 --- loss_d: 0.015226
0.5473 --- loss_d: 0.266709
0.6255 --- loss_d: 0.277523
0.7037 --- loss_d: 0.062371
0.7819 --- loss_d: 0.088053
0.8600 --- loss_d: 0.369743
0.9382 --- loss_d: 0.062078
Epoch finished! Loss: 0.09239610983700469
Starting epoch 9/10.
0.0000 --- loss_d: 0.038680
0.0782 --- loss_d: 0.006361
0.1564 --- loss_d: 1.070025
0.2346 --- loss_d: 0.229864
0.3127 --- loss_d: 0.548091
0.3909 --- loss_d: 0.067344
0.4691 --- loss_d: 0.066602
0.5473 --- loss_d: 0.669653
0.6255 --- loss_d: 0.012736
0.7037 --- loss_d: 0.326407
0.7819 --- loss_d: 0.103570
0.8600 --- loss_d: 0.076934
0.9382 --- loss_d: 0.020806
Epoch finished! Loss: 0.0936109103394423
Starting epoch 10/10.
0.0000 --- loss_d: 0.005960
0.0782 --- loss_d: 0.230654
0.1564 --- loss_d: 0.015884
0.2346 --- loss_d: 0.001898
0.3127 --- loss_d: 0.005426
0.3909 --- loss_d: 0.002956
0.4691 --- loss_d: 0.018685
0.5473 --- loss_d: 0.014405
0.6255 --- loss_d: 0.001337
0.7037 --- loss_d: 0.002289
0.7819 --- loss_d: 0.092517
0.8600 --- loss_d: 0.089467
0.9382 --- loss_d: 0.002131
Epoch finished! Loss: 0.05006097859861586
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[1.         0.99999988 1.         0.99999905 1.         0.99999774
 0.99998808 0.99999273 0.99999774 0.99996614 1.         1.
 0.99999642 0.99999869 0.99999535 0.99999857 1.         0.99999809
 0.99999642 0.99998474 0.99999869]
pred: 0.9999956346693493, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp036-nsrr

=== Test on chp037-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.684400
0.0779 --- loss_d: 1.088230
0.1559 --- loss_d: 0.502075
0.2338 --- loss_d: 0.611175
0.3118 --- loss_d: 0.672860
0.3897 --- loss_d: 0.940967
0.4677 --- loss_d: 0.554606
0.5456 --- loss_d: 0.502177
0.6235 --- loss_d: 0.704058
0.7015 --- loss_d: 0.318283
0.7794 --- loss_d: 0.737524
0.8574 --- loss_d: 0.336971
0.9353 --- loss_d: 0.415479
Epoch finished! Loss: 0.6072205537930131
Starting epoch 2/10.
0.0000 --- loss_d: 0.429348
0.0779 --- loss_d: 0.558323
0.1559 --- loss_d: 0.332268
0.2338 --- loss_d: 0.371384
0.3118 --- loss_d: 0.717570
0.3897 --- loss_d: 0.468097
0.4677 --- loss_d: 0.322831
0.5456 --- loss_d: 0.629250
0.6235 --- loss_d: 0.361068
0.7015 --- loss_d: 0.430483
0.7794 --- loss_d: 0.527564
0.8574 --- loss_d: 0.326920
0.9353 --- loss_d: 0.355925
Epoch finished! Loss: 0.4579709701356478
Starting epoch 3/10.
0.0000 --- loss_d: 0.313481
0.0779 --- loss_d: 0.037347
0.1559 --- loss_d: 0.169626
0.2338 --- loss_d: 0.321482
0.3118 --- loss_d: 0.406344
0.3897 --- loss_d: 0.293888
0.4677 --- loss_d: 0.075734
0.5456 --- loss_d: 0.233799
0.6235 --- loss_d: 0.283593
0.7015 --- loss_d: 0.200261
0.7794 --- loss_d: 0.184690
0.8574 --- loss_d: 0.120465
0.9353 --- loss_d: 0.461621
Epoch finished! Loss: 0.3185010212182533
Starting epoch 4/10.
0.0000 --- loss_d: 0.160478
0.0779 --- loss_d: 0.182589
0.1559 --- loss_d: 0.057971
0.2338 --- loss_d: 0.188886
0.3118 --- loss_d: 0.390914
0.3897 --- loss_d: 0.108544
0.4677 --- loss_d: 0.457622
0.5456 --- loss_d: 0.233563
0.6235 --- loss_d: 0.410808
0.7015 --- loss_d: 0.299116
0.7794 --- loss_d: 0.151226
0.8574 --- loss_d: 1.362714
0.9353 --- loss_d: 0.292898
Epoch finished! Loss: 0.25300053288810886
Starting epoch 5/10.
0.0000 --- loss_d: 0.200093
0.0779 --- loss_d: 0.107209
0.1559 --- loss_d: 0.422982
0.2338 --- loss_d: 0.110881
0.3118 --- loss_d: 0.078765
0.3897 --- loss_d: 0.372468
0.4677 --- loss_d: 0.042377
0.5456 --- loss_d: 0.336292
0.6235 --- loss_d: 0.239767
0.7015 --- loss_d: 0.154581
0.7794 --- loss_d: 0.255811
0.8574 --- loss_d: 0.359431
0.9353 --- loss_d: 0.746289
Epoch finished! Loss: 0.23308042094868142
Starting epoch 6/10.
0.0000 --- loss_d: 0.101822
0.0779 --- loss_d: 0.191982
0.1559 --- loss_d: 0.146716
0.2338 --- loss_d: 0.072383
0.3118 --- loss_d: 0.295884
0.3897 --- loss_d: 0.386857
0.4677 --- loss_d: 0.594956
0.5456 --- loss_d: 0.078232
0.6235 --- loss_d: 0.056960
0.7015 --- loss_d: 0.025911
0.7794 --- loss_d: 0.042762
0.8574 --- loss_d: 0.014232
0.9353 --- loss_d: 0.125542
Epoch finished! Loss: 0.1536179467693728
Starting epoch 7/10.
0.0000 --- loss_d: 0.122394
0.0779 --- loss_d: 0.052510
0.1559 --- loss_d: 0.115083
0.2338 --- loss_d: 0.033809
0.3118 --- loss_d: 0.004473
0.3897 --- loss_d: 0.009576
0.4677 --- loss_d: 0.043639
0.5456 --- loss_d: 0.019099
0.6235 --- loss_d: 0.030652
0.7015 --- loss_d: 0.145067
0.7794 --- loss_d: 0.708233
0.8574 --- loss_d: 0.112144
0.9353 --- loss_d: 0.058242
Epoch finished! Loss: 0.09944518697739113
Starting epoch 8/10.
0.0000 --- loss_d: 0.092456
0.0779 --- loss_d: 0.087132
0.1559 --- loss_d: 0.012837
0.2338 --- loss_d: 0.019849
0.3118 --- loss_d: 0.061286
0.3897 --- loss_d: 0.328949
0.4677 --- loss_d: 0.009113
0.5456 --- loss_d: 0.007844
0.6235 --- loss_d: 0.002031
0.7015 --- loss_d: 0.063889
0.7794 --- loss_d: 0.135907
0.8574 --- loss_d: 0.023054
0.9353 --- loss_d: 0.045705
Epoch finished! Loss: 0.09815534881636268
Starting epoch 9/10.
0.0000 --- loss_d: 0.103199
0.0779 --- loss_d: 0.004528
0.1559 --- loss_d: 0.123563
0.2338 --- loss_d: 0.009805
0.3118 --- loss_d: 0.331325
0.3897 --- loss_d: 0.006897
0.4677 --- loss_d: 0.028234
0.5456 --- loss_d: 0.004745
0.6235 --- loss_d: 0.011919
0.7015 --- loss_d: 0.328881
0.7794 --- loss_d: 0.006358
0.8574 --- loss_d: 0.162950
0.9353 --- loss_d: 0.057165
Epoch finished! Loss: 0.0819761245418249
Starting epoch 10/10.
0.0000 --- loss_d: 0.007761
0.0779 --- loss_d: 0.173206
0.1559 --- loss_d: 0.020108
0.2338 --- loss_d: 0.015257
0.3118 --- loss_d: 0.024896
0.3897 --- loss_d: 0.040967
0.4677 --- loss_d: 0.002284
0.5456 --- loss_d: 0.033497
0.6235 --- loss_d: 0.003093
0.7015 --- loss_d: 0.002876
0.7794 --- loss_d: 0.002570
0.8574 --- loss_d: 0.151655
0.9353 --- loss_d: 0.019217
Epoch finished! Loss: 0.06068608932673669
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999869 0.99050939 1.         1.         1.         1.
 0.99999988 0.99999988 0.98111469 0.99999797 0.99999845 0.99999774
 0.99999952 0.99999988 0.99997211 0.99999988 0.99999964]
pred: 0.9983286892666536, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp037-nsrr

=== Test on chp038-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.660218
0.0779 --- loss_d: 0.361557
0.1559 --- loss_d: 0.543920
0.2338 --- loss_d: 0.433064
0.3118 --- loss_d: 1.039487
0.3897 --- loss_d: 0.851122
0.4677 --- loss_d: 0.668976
0.5456 --- loss_d: 0.500570
0.6235 --- loss_d: 0.364509
0.7015 --- loss_d: 0.196636
0.7794 --- loss_d: 0.355010
0.8574 --- loss_d: 0.489363
0.9353 --- loss_d: 0.563323
Epoch finished! Loss: 0.6014412916265428
Starting epoch 2/10.
0.0000 --- loss_d: 0.393527
0.0779 --- loss_d: 0.486866
0.1559 --- loss_d: 0.499971
0.2338 --- loss_d: 0.526562
0.3118 --- loss_d: 0.555003
0.3897 --- loss_d: 0.490615
0.4677 --- loss_d: 0.252697
0.5456 --- loss_d: 0.184823
0.6235 --- loss_d: 0.485433
0.7015 --- loss_d: 0.587402
0.7794 --- loss_d: 0.439584
0.8574 --- loss_d: 0.278100
0.9353 --- loss_d: 0.412261
Epoch finished! Loss: 0.502879818319343
Starting epoch 3/10.
0.0000 --- loss_d: 0.396963
0.0779 --- loss_d: 0.441971
0.1559 --- loss_d: 0.462964
0.2338 --- loss_d: 0.352328
0.3118 --- loss_d: 0.235185
0.3897 --- loss_d: 0.292589
0.4677 --- loss_d: 0.454913
0.5456 --- loss_d: 0.325713
0.6235 --- loss_d: 0.128112
0.7015 --- loss_d: 0.125598
0.7794 --- loss_d: 0.492063
0.8574 --- loss_d: 0.094896
0.9353 --- loss_d: 0.327083
Epoch finished! Loss: 0.32711755388299935
Starting epoch 4/10.
0.0000 --- loss_d: 0.293659
0.0779 --- loss_d: 0.102849
0.1559 --- loss_d: 0.221769
0.2338 --- loss_d: 0.149223
0.3118 --- loss_d: 0.408246
0.3897 --- loss_d: 0.391461
0.4677 --- loss_d: 0.752532
0.5456 --- loss_d: 0.293663
0.6235 --- loss_d: 0.094419
0.7015 --- loss_d: 0.431042
0.7794 --- loss_d: 0.246971
0.8574 --- loss_d: 0.189171
0.9353 --- loss_d: 0.068568
Epoch finished! Loss: 0.26795995004067663
Starting epoch 5/10.
0.0000 --- loss_d: 0.142354
0.0779 --- loss_d: 0.173747
0.1559 --- loss_d: 0.231187
0.2338 --- loss_d: 0.235618
0.3118 --- loss_d: 0.162249
0.3897 --- loss_d: 0.041419
0.4677 --- loss_d: 0.085720
0.5456 --- loss_d: 0.024105
0.6235 --- loss_d: 0.399612
0.7015 --- loss_d: 0.059598
0.7794 --- loss_d: 0.206164
0.8574 --- loss_d: 0.216627
0.9353 --- loss_d: 0.131172
Epoch finished! Loss: 0.22095320901280502
Starting epoch 6/10.
0.0000 --- loss_d: 0.055313
0.0779 --- loss_d: 0.353555
0.1559 --- loss_d: 0.129352
0.2338 --- loss_d: 0.121066
0.3118 --- loss_d: 0.055423
0.3897 --- loss_d: 0.053536
0.4677 --- loss_d: 0.655898
0.5456 --- loss_d: 0.375789
0.6235 --- loss_d: 0.070486
0.7015 --- loss_d: 0.089960
0.7794 --- loss_d: 0.160796
0.8574 --- loss_d: 0.033072
0.9353 --- loss_d: 0.048379
Epoch finished! Loss: 0.1783216265248484
Starting epoch 7/10.
0.0000 --- loss_d: 0.099083
0.0779 --- loss_d: 0.065055
0.1559 --- loss_d: 0.047105
0.2338 --- loss_d: 0.013667
0.3118 --- loss_d: 0.235705
0.3897 --- loss_d: 0.018671
0.4677 --- loss_d: 0.020563
0.5456 --- loss_d: 0.011308
0.6235 --- loss_d: 0.023163
0.7015 --- loss_d: 0.026692
0.7794 --- loss_d: 0.147601
0.8574 --- loss_d: 0.135122
0.9353 --- loss_d: 0.014993
Epoch finished! Loss: 0.1350193249345466
Starting epoch 8/10.
0.0000 --- loss_d: 0.064436
0.0779 --- loss_d: 0.092847
0.1559 --- loss_d: 0.205465
0.2338 --- loss_d: 0.005929
0.3118 --- loss_d: 0.010639
0.3897 --- loss_d: 0.105694
0.4677 --- loss_d: 0.023480
0.5456 --- loss_d: 0.018021
0.6235 --- loss_d: 0.008057
0.7015 --- loss_d: 0.132194
0.7794 --- loss_d: 0.022584
0.8574 --- loss_d: 0.013275
0.9353 --- loss_d: 0.257871
Epoch finished! Loss: 0.12312047134946624
Starting epoch 9/10.
0.0000 --- loss_d: 0.011992
0.0779 --- loss_d: 0.023970
0.1559 --- loss_d: 0.008408
0.2338 --- loss_d: 0.011148
0.3118 --- loss_d: 0.008819
0.3897 --- loss_d: 0.016114
0.4677 --- loss_d: 0.047454
0.5456 --- loss_d: 0.005549
0.6235 --- loss_d: 0.011819
0.7015 --- loss_d: 0.055046
0.7794 --- loss_d: 0.024301
0.8574 --- loss_d: 0.189400
0.9353 --- loss_d: 0.032506
Epoch finished! Loss: 0.07414850094482972
Starting epoch 10/10.
0.0000 --- loss_d: 0.004831
0.0779 --- loss_d: 0.152845
0.1559 --- loss_d: 0.061625
0.2338 --- loss_d: 0.014603
0.3118 --- loss_d: 0.010852
0.3897 --- loss_d: 0.029516
0.4677 --- loss_d: 0.001469
0.5456 --- loss_d: 0.283742
0.6235 --- loss_d: 0.019477
0.7015 --- loss_d: 0.008423
0.7794 --- loss_d: 0.005723
0.8574 --- loss_d: 0.048726
0.9353 --- loss_d: 0.009245
Epoch finished! Loss: 0.0709200652340769
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99954176 0.9974584  0.99991369 0.99989486 0.99996889 0.99992168
 0.99989617 0.99674523 0.99961048 0.99997759 0.99997723 0.99988413
 0.99891222 0.99999952 0.99991786 0.99987817 0.9997831 ]
pred: 0.9994871160563301, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp038-nsrr

=== Test on chp039-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.679629
0.0780 --- loss_d: 0.515132
0.1560 --- loss_d: 0.653191
0.2340 --- loss_d: 1.196638
0.3120 --- loss_d: 0.580579
0.3900 --- loss_d: 0.693806
0.4680 --- loss_d: 0.485987
0.5460 --- loss_d: 0.589949
0.6240 --- loss_d: 0.729036
0.7020 --- loss_d: 0.583481
0.7800 --- loss_d: 0.470791
0.8580 --- loss_d: 0.578743
0.9360 --- loss_d: 0.354037
Epoch finished! Loss: 0.5852226469432935
Starting epoch 2/10.
0.0000 --- loss_d: 0.410936
0.0780 --- loss_d: 0.208909
0.1560 --- loss_d: 0.233332
0.2340 --- loss_d: 0.486681
0.3120 --- loss_d: 0.557424
0.3900 --- loss_d: 0.459411
0.4680 --- loss_d: 0.544994
0.5460 --- loss_d: 0.185324
0.6240 --- loss_d: 0.528918
0.7020 --- loss_d: 0.372818
0.7800 --- loss_d: 0.387972
0.8580 --- loss_d: 0.330548
0.9360 --- loss_d: 0.319590
Epoch finished! Loss: 0.41380751074757427
Starting epoch 3/10.
0.0000 --- loss_d: 0.228639
0.0780 --- loss_d: 0.469594
0.1560 --- loss_d: 0.287638
0.2340 --- loss_d: 0.197203
0.3120 --- loss_d: 0.576746
0.3900 --- loss_d: 0.044405
0.4680 --- loss_d: 0.386810
0.5460 --- loss_d: 0.799665
0.6240 --- loss_d: 0.366355
0.7020 --- loss_d: 0.137895
0.7800 --- loss_d: 0.147365
0.8580 --- loss_d: 0.593955
0.9360 --- loss_d: 0.149636
Epoch finished! Loss: 0.28680975575116463
Starting epoch 4/10.
0.0000 --- loss_d: 0.369635
0.0780 --- loss_d: 0.330950
0.1560 --- loss_d: 0.155048
0.2340 --- loss_d: 0.213633
0.3120 --- loss_d: 0.084055
0.3900 --- loss_d: 0.717307
0.4680 --- loss_d: 0.273699
0.5460 --- loss_d: 0.503615
0.6240 --- loss_d: 0.344756
0.7020 --- loss_d: 1.461080
0.7800 --- loss_d: 0.376051
0.8580 --- loss_d: 0.082314
0.9360 --- loss_d: 0.190883
Epoch finished! Loss: 0.2838479488855228
Starting epoch 5/10.
0.0000 --- loss_d: 0.072813
0.0780 --- loss_d: 0.190515
0.1560 --- loss_d: 0.412534
0.2340 --- loss_d: 0.092199
0.3120 --- loss_d: 0.194563
0.3900 --- loss_d: 0.204321
0.4680 --- loss_d: 0.080088
0.5460 --- loss_d: 0.059499
0.6240 --- loss_d: 0.194730
0.7020 --- loss_d: 0.063542
0.7800 --- loss_d: 0.139620
0.8580 --- loss_d: 0.844710
0.9360 --- loss_d: 0.056822
Epoch finished! Loss: 0.18561831187980715
Starting epoch 6/10.
0.0000 --- loss_d: 0.052520
0.0780 --- loss_d: 0.171073
0.1560 --- loss_d: 0.148626
0.2340 --- loss_d: 0.105753
0.3120 --- loss_d: 0.100815
0.3900 --- loss_d: 0.017273
0.4680 --- loss_d: 0.008226
0.5460 --- loss_d: 0.068133
0.6240 --- loss_d: 0.092063
0.7020 --- loss_d: 0.079145
0.7800 --- loss_d: 0.145487
0.8580 --- loss_d: 0.589528
0.9360 --- loss_d: 0.162941
Epoch finished! Loss: 0.15525459180753387
Starting epoch 7/10.
0.0000 --- loss_d: 0.043712
0.0780 --- loss_d: 0.072255
0.1560 --- loss_d: 0.276312
0.2340 --- loss_d: 0.019823
0.3120 --- loss_d: 0.068085
0.3900 --- loss_d: 0.631530
0.4680 --- loss_d: 0.115666
0.5460 --- loss_d: 0.257006
0.6240 --- loss_d: 0.013040
0.7020 --- loss_d: 0.094313
0.7800 --- loss_d: 0.135773
0.8580 --- loss_d: 0.160588
0.9360 --- loss_d: 0.010888
Epoch finished! Loss: 0.1252699612032302
Starting epoch 8/10.
0.0000 --- loss_d: 0.301272
0.0780 --- loss_d: 0.016804
0.1560 --- loss_d: 0.207757
0.2340 --- loss_d: 0.029208
0.3120 --- loss_d: 0.128631
0.3900 --- loss_d: 0.037613
0.4680 --- loss_d: 0.424791
0.5460 --- loss_d: 0.034656
0.6240 --- loss_d: 0.032761
0.7020 --- loss_d: 0.951744
0.7800 --- loss_d: 0.402989
0.8580 --- loss_d: 0.139014
0.9360 --- loss_d: 0.015365
Epoch finished! Loss: 0.11727252742457495
Starting epoch 9/10.
0.0000 --- loss_d: 0.205510
0.0780 --- loss_d: 0.179211
0.1560 --- loss_d: 0.017298
0.2340 --- loss_d: 0.012302
0.3120 --- loss_d: 0.009570
0.3900 --- loss_d: 0.060029
0.4680 --- loss_d: 0.124424
0.5460 --- loss_d: 0.120524
0.6240 --- loss_d: 0.023527
0.7020 --- loss_d: 0.021577
0.7800 --- loss_d: 0.008849
0.8580 --- loss_d: 0.085487
0.9360 --- loss_d: 0.023878
Epoch finished! Loss: 0.06971945214263542
Starting epoch 10/10.
0.0000 --- loss_d: 0.010533
0.0780 --- loss_d: 0.500798
0.1560 --- loss_d: 0.123066
0.2340 --- loss_d: 0.007254
0.3120 --- loss_d: 0.009712
0.3900 --- loss_d: 0.019062
0.4680 --- loss_d: 0.002495
0.5460 --- loss_d: 0.037928
0.6240 --- loss_d: 0.494441
0.7020 --- loss_d: 0.017483
0.7800 --- loss_d: 0.021576
0.8580 --- loss_d: 0.108881
0.9360 --- loss_d: 0.008481
Epoch finished! Loss: 0.10765130200070416
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999988 0.99993753 0.99999928 0.99999976 0.99999893 0.99999952
 0.99998701 0.99999666 0.99982929 0.9999975  0.99878556 0.9999907
 0.99998319 0.99999881 0.99998283 0.99999869 0.99999285 0.99930489]
pred: 0.9998768270015717, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp039-nsrr

=== Test on chp040-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.830468
0.0779 --- loss_d: 0.352495
0.1559 --- loss_d: 0.644281
0.2338 --- loss_d: 0.526384
0.3118 --- loss_d: 0.440315
0.3897 --- loss_d: 0.461238
0.4677 --- loss_d: 0.681801
0.5456 --- loss_d: 0.753568
0.6235 --- loss_d: 0.835232
0.7015 --- loss_d: 0.663081
0.7794 --- loss_d: 0.781846
0.8574 --- loss_d: 0.415571
0.9353 --- loss_d: 0.869544
Epoch finished! Loss: 0.6107748658396304
Starting epoch 2/10.
0.0000 --- loss_d: 0.476319
0.0779 --- loss_d: 0.883528
0.1559 --- loss_d: 0.413273
0.2338 --- loss_d: 0.501177
0.3118 --- loss_d: 0.330785
0.3897 --- loss_d: 0.433854
0.4677 --- loss_d: 0.503686
0.5456 --- loss_d: 0.405307
0.6235 --- loss_d: 0.834231
0.7015 --- loss_d: 0.451888
0.7794 --- loss_d: 0.439870
0.8574 --- loss_d: 0.201584
0.9353 --- loss_d: 0.544994
Epoch finished! Loss: 0.5118471581954509
Starting epoch 3/10.
0.0000 --- loss_d: 0.522017
0.0779 --- loss_d: 0.266912
0.1559 --- loss_d: 0.357964
0.2338 --- loss_d: 0.694826
0.3118 --- loss_d: 0.437506
0.3897 --- loss_d: 0.496757
0.4677 --- loss_d: 0.379999
0.5456 --- loss_d: 0.179149
0.6235 --- loss_d: 0.612310
0.7015 --- loss_d: 0.218407
0.7794 --- loss_d: 0.334064
0.8574 --- loss_d: 0.279651
0.9353 --- loss_d: 0.221255
Epoch finished! Loss: 0.369926485553151
Starting epoch 4/10.
0.0000 --- loss_d: 0.309438
0.0779 --- loss_d: 0.297931
0.1559 --- loss_d: 0.147853
0.2338 --- loss_d: 0.041761
0.3118 --- loss_d: 0.072893
0.3897 --- loss_d: 0.350309
0.4677 --- loss_d: 0.266871
0.5456 --- loss_d: 0.035598
0.6235 --- loss_d: 0.190054
0.7015 --- loss_d: 0.588939
0.7794 --- loss_d: 0.319197
0.8574 --- loss_d: 0.201616
0.9353 --- loss_d: 0.150279
Epoch finished! Loss: 0.24873703729826957
Starting epoch 5/10.
0.0000 --- loss_d: 0.182860
0.0779 --- loss_d: 0.089892
0.1559 --- loss_d: 0.088407
0.2338 --- loss_d: 0.114765
0.3118 --- loss_d: 0.089270
0.3897 --- loss_d: 0.057244
0.4677 --- loss_d: 0.195447
0.5456 --- loss_d: 0.115161
0.6235 --- loss_d: 0.090243
0.7015 --- loss_d: 0.413824
0.7794 --- loss_d: 0.086939
0.8574 --- loss_d: 0.208533
0.9353 --- loss_d: 0.058837
Epoch finished! Loss: 0.19029092058190145
Starting epoch 6/10.
0.0000 --- loss_d: 0.052888
0.0779 --- loss_d: 0.047057
0.1559 --- loss_d: 0.019194
0.2338 --- loss_d: 0.011365
0.3118 --- loss_d: 0.080211
0.3897 --- loss_d: 0.046094
0.4677 --- loss_d: 0.055633
0.5456 --- loss_d: 0.186695
0.6235 --- loss_d: 0.168756
0.7015 --- loss_d: 0.079393
0.7794 --- loss_d: 0.214535
0.8574 --- loss_d: 0.016177
0.9353 --- loss_d: 0.261294
Epoch finished! Loss: 0.13500816161104012
Starting epoch 7/10.
0.0000 --- loss_d: 0.084616
0.0779 --- loss_d: 0.058426
0.1559 --- loss_d: 0.083657
0.2338 --- loss_d: 0.230208
0.3118 --- loss_d: 0.014715
0.3897 --- loss_d: 0.009907
0.4677 --- loss_d: 0.388850
0.5456 --- loss_d: 0.191046
0.6235 --- loss_d: 0.274269
0.7015 --- loss_d: 0.423369
0.7794 --- loss_d: 0.078626
0.8574 --- loss_d: 0.082767
0.9353 --- loss_d: 0.015006
Epoch finished! Loss: 0.13097293697137502
Starting epoch 8/10.
0.0000 --- loss_d: 0.070211
0.0779 --- loss_d: 0.012537
0.1559 --- loss_d: 0.021822
0.2338 --- loss_d: 0.031581
0.3118 --- loss_d: 0.008379
0.3897 --- loss_d: 0.022612
0.4677 --- loss_d: 0.008584
0.5456 --- loss_d: 0.003898
0.6235 --- loss_d: 0.017009
0.7015 --- loss_d: 0.407790
0.7794 --- loss_d: 0.004410
0.8574 --- loss_d: 0.018990
0.9353 --- loss_d: 0.017366
Epoch finished! Loss: 0.07569291496361075
Starting epoch 9/10.
0.0000 --- loss_d: 0.163614
0.0779 --- loss_d: 0.014070
0.1559 --- loss_d: 0.022771
0.2338 --- loss_d: 0.258519
0.3118 --- loss_d: 0.024099
0.3897 --- loss_d: 0.005352
0.4677 --- loss_d: 0.085075
0.5456 --- loss_d: 0.036841
0.6235 --- loss_d: 0.117850
0.7015 --- loss_d: 0.296841
0.7794 --- loss_d: 0.028584
0.8574 --- loss_d: 0.030045
0.9353 --- loss_d: 0.040151
Epoch finished! Loss: 0.07873556502454448
Starting epoch 10/10.
0.0000 --- loss_d: 0.003431
0.0779 --- loss_d: 0.047994
0.1559 --- loss_d: 0.280611
0.2338 --- loss_d: 0.017148
0.3118 --- loss_d: 0.016951
0.3897 --- loss_d: 0.010052
0.4677 --- loss_d: 0.072486
0.5456 --- loss_d: 0.000794
0.6235 --- loss_d: 0.003733
0.7015 --- loss_d: 0.008388
0.7794 --- loss_d: 0.006855
0.8574 --- loss_d: 0.001429
0.9353 --- loss_d: 0.005366
Epoch finished! Loss: 0.056660219810737544
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99988687 0.99999988 1.         0.99999917 1.         1.
 0.99999988 0.99999988 0.99999964 0.99999762 1.         1.
 0.99998701 0.99999976 0.99999988 0.99999869 0.99999988]
pred: 0.999992244383868, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp040-nsrr

=== Test on chp041-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.673809
0.0780 --- loss_d: 0.762481
0.1560 --- loss_d: 0.531087
0.2340 --- loss_d: 1.348034
0.3120 --- loss_d: 0.764649
0.3900 --- loss_d: 0.646594
0.4680 --- loss_d: 0.671977
0.5460 --- loss_d: 0.656444
0.6240 --- loss_d: 0.485356
0.7020 --- loss_d: 0.404357
0.7800 --- loss_d: 0.621563
0.8580 --- loss_d: 0.683118
0.9360 --- loss_d: 0.633086
Epoch finished! Loss: 0.602575511788018
Starting epoch 2/10.
0.0000 --- loss_d: 0.692134
0.0780 --- loss_d: 0.253947
0.1560 --- loss_d: 0.634633
0.2340 --- loss_d: 0.359977
0.3120 --- loss_d: 0.406455
0.3900 --- loss_d: 0.820844
0.4680 --- loss_d: 0.352244
0.5460 --- loss_d: 0.366177
0.6240 --- loss_d: 0.638399
0.7020 --- loss_d: 0.371132
0.7800 --- loss_d: 0.321066
0.8580 --- loss_d: 0.559801
0.9360 --- loss_d: 0.485944
Epoch finished! Loss: 0.50060634536203
Starting epoch 3/10.
0.0000 --- loss_d: 0.174925
0.0780 --- loss_d: 0.486026
0.1560 --- loss_d: 0.369609
0.2340 --- loss_d: 0.479453
0.3120 --- loss_d: 0.346623
0.3900 --- loss_d: 0.146833
0.4680 --- loss_d: 0.286691
0.5460 --- loss_d: 0.271223
0.6240 --- loss_d: 0.209693
0.7020 --- loss_d: 0.333122
0.7800 --- loss_d: 0.389142
0.8580 --- loss_d: 0.357430
0.9360 --- loss_d: 0.204119
Epoch finished! Loss: 0.33099483948899433
Starting epoch 4/10.
0.0000 --- loss_d: 0.066101
0.0780 --- loss_d: 0.630131
0.1560 --- loss_d: 0.166447
0.2340 --- loss_d: 0.082107
0.3120 --- loss_d: 0.041030
0.3900 --- loss_d: 0.262910
0.4680 --- loss_d: 0.046693
0.5460 --- loss_d: 0.273401
0.6240 --- loss_d: 0.092170
0.7020 --- loss_d: 0.281823
0.7800 --- loss_d: 0.153647
0.8580 --- loss_d: 0.730279
0.9360 --- loss_d: 0.190415
Epoch finished! Loss: 0.2125093973299954
Starting epoch 5/10.
0.0000 --- loss_d: 0.314250
0.0780 --- loss_d: 0.034797
0.1560 --- loss_d: 0.107421
0.2340 --- loss_d: 0.087725
0.3120 --- loss_d: 0.028558
0.3900 --- loss_d: 0.163702
0.4680 --- loss_d: 0.084034
0.5460 --- loss_d: 0.094117
0.6240 --- loss_d: 0.026485
0.7020 --- loss_d: 0.057849
0.7800 --- loss_d: 0.270817
0.8580 --- loss_d: 0.072255
0.9360 --- loss_d: 0.014018
Epoch finished! Loss: 0.11170292007227545
Starting epoch 6/10.
0.0000 --- loss_d: 0.238710
0.0780 --- loss_d: 0.013681
0.1560 --- loss_d: 0.034562
0.2340 --- loss_d: 0.013607
0.3120 --- loss_d: 0.058084
0.3900 --- loss_d: 0.194379
0.4680 --- loss_d: 0.124058
0.5460 --- loss_d: 0.324545
0.6240 --- loss_d: 0.092420
0.7020 --- loss_d: 0.187218
0.7800 --- loss_d: 0.010554
0.8580 --- loss_d: 0.100471
0.9360 --- loss_d: 0.098222
Epoch finished! Loss: 0.12393319325474295
Starting epoch 7/10.
0.0000 --- loss_d: 0.119760
0.0780 --- loss_d: 0.219892
0.1560 --- loss_d: 0.050767
0.2340 --- loss_d: 0.018635
0.3120 --- loss_d: 0.008275
0.3900 --- loss_d: 0.026629
0.4680 --- loss_d: 0.034976
0.5460 --- loss_d: 0.026219
0.6240 --- loss_d: 0.152387
0.7020 --- loss_d: 0.065427
0.7800 --- loss_d: 0.057244
0.8580 --- loss_d: 0.081896
0.9360 --- loss_d: 0.399226
Epoch finished! Loss: 0.09919117854224169
Starting epoch 8/10.
0.0000 --- loss_d: 0.020330
0.0780 --- loss_d: 0.010194
0.1560 --- loss_d: 0.063141
0.2340 --- loss_d: 0.003444
0.3120 --- loss_d: 0.003376
0.3900 --- loss_d: 0.004409
0.4680 --- loss_d: 0.093585
0.5460 --- loss_d: 0.000968
0.6240 --- loss_d: 0.033336
0.7020 --- loss_d: 0.036523
0.7800 --- loss_d: 0.260960
0.8580 --- loss_d: 0.085909
0.9360 --- loss_d: 0.004654
Epoch finished! Loss: 0.05458247725982801
Starting epoch 9/10.
0.0000 --- loss_d: 0.008060
0.0780 --- loss_d: 0.012906
0.1560 --- loss_d: 0.031873
0.2340 --- loss_d: 0.017329
0.3120 --- loss_d: 0.001357
0.3900 --- loss_d: 0.000999
0.4680 --- loss_d: 0.001601
0.5460 --- loss_d: 0.162124
0.6240 --- loss_d: 0.091921
0.7020 --- loss_d: 0.010609
0.7800 --- loss_d: 0.016764
0.8580 --- loss_d: 0.015095
0.9360 --- loss_d: 0.005032
Epoch finished! Loss: 0.052310342861346726
Starting epoch 10/10.
0.0000 --- loss_d: 0.007213
0.0780 --- loss_d: 0.007306
0.1560 --- loss_d: 0.003639
0.2340 --- loss_d: 0.004791
0.3120 --- loss_d: 0.006243
0.3900 --- loss_d: 0.003157
0.4680 --- loss_d: 0.002077
0.5460 --- loss_d: 0.002045
0.6240 --- loss_d: 0.000976
0.7020 --- loss_d: 0.004672
0.7800 --- loss_d: 0.009603
0.8580 --- loss_d: 0.060002
0.9360 --- loss_d: 0.006784
Epoch finished! Loss: 0.03461662166921542
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99894863 0.99998963 0.98625851 0.99999976 1.         0.99933332
 0.99999928 0.99999678 0.99985135 0.99999869 0.99999642 0.99999845
 0.99999928 0.99999964 0.99999964 0.99914646 0.99985421 0.99999487]
pred: 0.9990758299827576, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp041-nsrr

=== Test on chp042-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.734786
0.0780 --- loss_d: 1.364454
0.1560 --- loss_d: 0.409907
0.2340 --- loss_d: 0.941514
0.3120 --- loss_d: 0.674844
0.3900 --- loss_d: 0.613156
0.4680 --- loss_d: 0.510860
0.5460 --- loss_d: 0.914174
0.6240 --- loss_d: 0.596735
0.7020 --- loss_d: 1.048740
0.7800 --- loss_d: 0.741894
0.8580 --- loss_d: 0.507925
0.9360 --- loss_d: 0.369594
Epoch finished! Loss: 0.6110907413531095
Starting epoch 2/10.
0.0000 --- loss_d: 0.492319
0.0780 --- loss_d: 0.705983
0.1560 --- loss_d: 0.131356
0.2340 --- loss_d: 0.799833
0.3120 --- loss_d: 0.575023
0.3900 --- loss_d: 0.370497
0.4680 --- loss_d: 0.656187
0.5460 --- loss_d: 0.896661
0.6240 --- loss_d: 0.315298
0.7020 --- loss_d: 0.230542
0.7800 --- loss_d: 0.334270
0.8580 --- loss_d: 0.324190
0.9360 --- loss_d: 0.452890
Epoch finished! Loss: 0.45557586662471294
Starting epoch 3/10.
0.0000 --- loss_d: 0.490550
0.0780 --- loss_d: 0.468846
0.1560 --- loss_d: 0.204363
0.2340 --- loss_d: 0.257168
0.3120 --- loss_d: 0.279008
0.3900 --- loss_d: 0.465313
0.4680 --- loss_d: 0.601536
0.5460 --- loss_d: 0.209869
0.6240 --- loss_d: 0.205752
0.7020 --- loss_d: 0.239450
0.7800 --- loss_d: 0.311612
0.8580 --- loss_d: 0.155405
0.9360 --- loss_d: 1.073206
Epoch finished! Loss: 0.3170821374224033
Starting epoch 4/10.
0.0000 --- loss_d: 0.172350
0.0780 --- loss_d: 0.295195
0.1560 --- loss_d: 0.136606
0.2340 --- loss_d: 0.144972
0.3120 --- loss_d: 0.220348
0.3900 --- loss_d: 0.121895
0.4680 --- loss_d: 0.039829
0.5460 --- loss_d: 0.118285
0.6240 --- loss_d: 0.553183
0.7020 --- loss_d: 0.196571
0.7800 --- loss_d: 0.179978
0.8580 --- loss_d: 0.103037
0.9360 --- loss_d: 0.325658
Epoch finished! Loss: 0.22578796747257002
Starting epoch 5/10.
0.0000 --- loss_d: 0.021948
0.0780 --- loss_d: 0.042204
0.1560 --- loss_d: 0.097539
0.2340 --- loss_d: 0.248261
0.3120 --- loss_d: 0.142648
0.3900 --- loss_d: 0.082443
0.4680 --- loss_d: 0.038566
0.5460 --- loss_d: 0.126860
0.6240 --- loss_d: 0.254863
0.7020 --- loss_d: 0.603040
0.7800 --- loss_d: 0.086313
0.8580 --- loss_d: 0.070815
0.9360 --- loss_d: 0.014436
Epoch finished! Loss: 0.16209123855514918
Starting epoch 6/10.
0.0000 --- loss_d: 0.533255
0.0780 --- loss_d: 0.034893
0.1560 --- loss_d: 0.334383
0.2340 --- loss_d: 0.117976
0.3120 --- loss_d: 0.054996
0.3900 --- loss_d: 0.293397
0.4680 --- loss_d: 0.023334
0.5460 --- loss_d: 0.334343
0.6240 --- loss_d: 0.151776
0.7020 --- loss_d: 0.147476
0.7800 --- loss_d: 0.012281
0.8580 --- loss_d: 0.035734
0.9360 --- loss_d: 0.064121
Epoch finished! Loss: 0.1571099993379903
Starting epoch 7/10.
0.0000 --- loss_d: 0.100402
0.0780 --- loss_d: 0.071663
0.1560 --- loss_d: 0.073644
0.2340 --- loss_d: 0.375311
0.3120 --- loss_d: 0.013670
0.3900 --- loss_d: 0.014596
0.4680 --- loss_d: 0.156156
0.5460 --- loss_d: 0.280672
0.6240 --- loss_d: 0.113604
0.7020 --- loss_d: 0.133837
0.7800 --- loss_d: 0.361250
0.8580 --- loss_d: 0.003308
0.9360 --- loss_d: 0.382831
Epoch finished! Loss: 0.09790434079332044
Starting epoch 8/10.
0.0000 --- loss_d: 0.160827
0.0780 --- loss_d: 0.010233
0.1560 --- loss_d: 0.066262
0.2340 --- loss_d: 0.008741
0.3120 --- loss_d: 0.007408
0.3900 --- loss_d: 0.054806
0.4680 --- loss_d: 0.038034
0.5460 --- loss_d: 0.048364
0.6240 --- loss_d: 0.184413
0.7020 --- loss_d: 0.016355
0.7800 --- loss_d: 0.270690
0.8580 --- loss_d: 0.020627
0.9360 --- loss_d: 0.010372
Epoch finished! Loss: 0.11490358500577713
Starting epoch 9/10.
0.0000 --- loss_d: 0.095722
0.0780 --- loss_d: 0.189976
0.1560 --- loss_d: 0.186385
0.2340 --- loss_d: 0.020235
0.3120 --- loss_d: 0.203249
0.3900 --- loss_d: 0.003026
0.4680 --- loss_d: 0.218495
0.5460 --- loss_d: 0.005452
0.6240 --- loss_d: 0.026044
0.7020 --- loss_d: 0.006332
0.7800 --- loss_d: 0.004795
0.8580 --- loss_d: 0.004967
0.9360 --- loss_d: 0.002204
Epoch finished! Loss: 0.08400035520662641
Starting epoch 10/10.
0.0000 --- loss_d: 0.015212
0.0780 --- loss_d: 0.231146
0.1560 --- loss_d: 0.000724
0.2340 --- loss_d: 0.033602
0.3120 --- loss_d: 0.002422
0.3900 --- loss_d: 0.009975
0.4680 --- loss_d: 0.077283
0.5460 --- loss_d: 0.009292
0.6240 --- loss_d: 0.001336
0.7020 --- loss_d: 0.003750
0.7800 --- loss_d: 0.059592
0.8580 --- loss_d: 0.029849
0.9360 --- loss_d: 0.003636
Epoch finished! Loss: 0.03066480506959124
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.93663895 0.99999452 0.99999368 0.99999976 1.         0.99999988
 0.99999988 1.         1.         1.         1.         0.99999714
 0.9999969  1.         1.         1.         0.99999821 0.99999988]
pred: 0.9964788224962022, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp042-nsrr

=== Test on chp043-nsrr. train_data(1280), test_data(20) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.732506
0.0781 --- loss_d: 0.609672
0.1562 --- loss_d: 0.594062
0.2344 --- loss_d: 0.651496
0.3125 --- loss_d: 0.355951
0.3906 --- loss_d: 0.688077
0.4688 --- loss_d: 0.585279
0.5469 --- loss_d: 0.320574
0.6250 --- loss_d: 0.456957
0.7031 --- loss_d: 0.518192
0.7812 --- loss_d: 0.556110
0.8594 --- loss_d: 0.436520
0.9375 --- loss_d: 0.305406
Epoch finished! Loss: 0.5926643316670666
Starting epoch 2/10.
0.0000 --- loss_d: 0.548396
0.0781 --- loss_d: 0.360037
0.1562 --- loss_d: 0.797319
0.2344 --- loss_d: 0.354359
0.3125 --- loss_d: 0.372774
0.3906 --- loss_d: 0.309406
0.4688 --- loss_d: 0.444292
0.5469 --- loss_d: 0.156726
0.6250 --- loss_d: 0.117574
0.7031 --- loss_d: 0.451101
0.7812 --- loss_d: 0.308771
0.8594 --- loss_d: 0.402905
0.9375 --- loss_d: 0.259908
Epoch finished! Loss: 0.41089240995448406
Starting epoch 3/10.
0.0000 --- loss_d: 0.563201
0.0781 --- loss_d: 0.210774
0.1562 --- loss_d: 0.215525
0.2344 --- loss_d: 0.206836
0.3125 --- loss_d: 0.196362
0.3906 --- loss_d: 0.555819
0.4688 --- loss_d: 0.327427
0.5469 --- loss_d: 0.788415
0.6250 --- loss_d: 0.342915
0.7031 --- loss_d: 0.175268
0.7812 --- loss_d: 0.191911
0.8594 --- loss_d: 0.130285
0.9375 --- loss_d: 0.060398
Epoch finished! Loss: 0.28391426766481925
Starting epoch 4/10.
0.0000 --- loss_d: 0.121409
0.0781 --- loss_d: 0.379299
0.1562 --- loss_d: 0.219994
0.2344 --- loss_d: 0.108167
0.3125 --- loss_d: 0.189448
0.3906 --- loss_d: 0.636045
0.4688 --- loss_d: 0.130451
0.5469 --- loss_d: 0.245368
0.6250 --- loss_d: 0.143609
0.7031 --- loss_d: 0.121204
0.7812 --- loss_d: 0.133513
0.8594 --- loss_d: 0.300137
0.9375 --- loss_d: 0.115604
Epoch finished! Loss: 0.26006452073379765
Starting epoch 5/10.
0.0000 --- loss_d: 0.510052
0.0781 --- loss_d: 0.191524
0.1562 --- loss_d: 0.132153
0.2344 --- loss_d: 0.143921
0.3125 --- loss_d: 0.083750
0.3906 --- loss_d: 0.027296
0.4688 --- loss_d: 0.194859
0.5469 --- loss_d: 0.067229
0.6250 --- loss_d: 0.155750
0.7031 --- loss_d: 0.050666
0.7812 --- loss_d: 0.079515
0.8594 --- loss_d: 0.508828
0.9375 --- loss_d: 0.063716
Epoch finished! Loss: 0.19797555641747835
Starting epoch 6/10.
0.0000 --- loss_d: 0.587462
0.0781 --- loss_d: 0.359158
0.1562 --- loss_d: 0.077307
0.2344 --- loss_d: 0.053599
0.3125 --- loss_d: 0.101481
0.3906 --- loss_d: 0.024298
0.4688 --- loss_d: 0.044208
0.5469 --- loss_d: 0.106402
0.6250 --- loss_d: 0.103500
0.7031 --- loss_d: 0.045766
0.7812 --- loss_d: 0.128866
0.8594 --- loss_d: 0.273228
0.9375 --- loss_d: 0.337316
Epoch finished! Loss: 0.1562882235537716
Starting epoch 7/10.
0.0000 --- loss_d: 0.076698
0.0781 --- loss_d: 0.033772
0.1562 --- loss_d: 0.096113
0.2344 --- loss_d: 0.093558
0.3125 --- loss_d: 0.184142
0.3906 --- loss_d: 0.016158
0.4688 --- loss_d: 0.073823
0.5469 --- loss_d: 0.036079
0.6250 --- loss_d: 0.016920
0.7031 --- loss_d: 0.114187
0.7812 --- loss_d: 0.090956
0.8594 --- loss_d: 0.101237
0.9375 --- loss_d: 0.325371
Epoch finished! Loss: 0.13863498001638067
Starting epoch 8/10.
0.0000 --- loss_d: 0.019163
0.0781 --- loss_d: 0.068709
0.1562 --- loss_d: 0.028809
0.2344 --- loss_d: 0.036927
0.3125 --- loss_d: 0.029209
0.3906 --- loss_d: 0.015096
0.4688 --- loss_d: 0.029760
0.5469 --- loss_d: 0.258066
0.6250 --- loss_d: 0.010651
0.7031 --- loss_d: 0.122871
0.7812 --- loss_d: 0.182376
0.8594 --- loss_d: 0.049750
0.9375 --- loss_d: 0.018818
Epoch finished! Loss: 0.12383903139527505
Starting epoch 9/10.
0.0000 --- loss_d: 0.014691
0.0781 --- loss_d: 0.004568
0.1562 --- loss_d: 0.008605
0.2344 --- loss_d: 0.048727
0.3125 --- loss_d: 0.097351
0.3906 --- loss_d: 0.017966
0.4688 --- loss_d: 0.071264
0.5469 --- loss_d: 0.021705
0.6250 --- loss_d: 0.031986
0.7031 --- loss_d: 0.013104
0.7812 --- loss_d: 0.032173
0.8594 --- loss_d: 0.002374
0.9375 --- loss_d: 0.084165
Epoch finished! Loss: 0.07504574172143773
Starting epoch 10/10.
0.0000 --- loss_d: 0.028783
0.0781 --- loss_d: 0.072669
0.1562 --- loss_d: 0.054849
0.2344 --- loss_d: 0.010375
0.3125 --- loss_d: 0.002021
0.3906 --- loss_d: 0.023764
0.4688 --- loss_d: 0.047329
0.5469 --- loss_d: 0.021335
0.6250 --- loss_d: 0.008181
0.7031 --- loss_d: 0.024693
0.7812 --- loss_d: 0.028981
0.8594 --- loss_d: 0.044779
0.9375 --- loss_d: 0.025865
Epoch finished! Loss: 0.08951003996790094
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99994361 0.99175125 0.9991222  0.99967706 0.99998331 0.99682176
 0.99970466 0.99992883 0.99999917 0.99998629 0.99985874 0.99999595
 0.99999988 0.9973501  0.99976939 0.99998808 0.99999726 0.99984145
 0.9999944  0.99995685]
pred: 0.9991835117340088, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp043-nsrr

=== Test on chp044-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.605920
0.0779 --- loss_d: 0.580858
0.1559 --- loss_d: 0.629330
0.2338 --- loss_d: 0.712946
0.3118 --- loss_d: 0.657072
0.3897 --- loss_d: 0.460174
0.4677 --- loss_d: 0.513707
0.5456 --- loss_d: 0.647216
0.6235 --- loss_d: 0.650279
0.7015 --- loss_d: 0.687115
0.7794 --- loss_d: 0.478997
0.8574 --- loss_d: 0.409494
0.9353 --- loss_d: 0.681104
Epoch finished! Loss: 0.596552248345688
Starting epoch 2/10.
0.0000 --- loss_d: 0.462535
0.0779 --- loss_d: 0.695811
0.1559 --- loss_d: 0.644500
0.2338 --- loss_d: 0.433553
0.3118 --- loss_d: 0.584147
0.3897 --- loss_d: 0.798468
0.4677 --- loss_d: 0.478028
0.5456 --- loss_d: 0.850676
0.6235 --- loss_d: 0.631591
0.7015 --- loss_d: 0.388502
0.7794 --- loss_d: 0.257202
0.8574 --- loss_d: 0.529321
0.9353 --- loss_d: 0.188987
Epoch finished! Loss: 0.49493723560590297
Starting epoch 3/10.
0.0000 --- loss_d: 0.136574
0.0779 --- loss_d: 0.093981
0.1559 --- loss_d: 0.089163
0.2338 --- loss_d: 0.907437
0.3118 --- loss_d: 0.531018
0.3897 --- loss_d: 0.175967
0.4677 --- loss_d: 0.415933
0.5456 --- loss_d: 0.122576
0.6235 --- loss_d: 0.591495
0.7015 --- loss_d: 0.204767
0.7794 --- loss_d: 0.269979
0.8574 --- loss_d: 0.920797
0.9353 --- loss_d: 0.429052
Epoch finished! Loss: 0.3377660197438672
Starting epoch 4/10.
0.0000 --- loss_d: 0.249393
0.0779 --- loss_d: 0.216076
0.1559 --- loss_d: 0.221122
0.2338 --- loss_d: 0.244267
0.3118 --- loss_d: 0.167766
0.3897 --- loss_d: 0.053386
0.4677 --- loss_d: 0.168109
0.5456 --- loss_d: 0.555757
0.6235 --- loss_d: 0.161082
0.7015 --- loss_d: 0.364131
0.7794 --- loss_d: 0.047698
0.8574 --- loss_d: 0.259965
0.9353 --- loss_d: 0.237409
Epoch finished! Loss: 0.2583772426878568
Starting epoch 5/10.
0.0000 --- loss_d: 0.230015
0.0779 --- loss_d: 0.203455
0.1559 --- loss_d: 0.513152
0.2338 --- loss_d: 0.155516
0.3118 --- loss_d: 0.025772
0.3897 --- loss_d: 0.127149
0.4677 --- loss_d: 0.073753
0.5456 --- loss_d: 0.049773
0.6235 --- loss_d: 0.181438
0.7015 --- loss_d: 0.639826
0.7794 --- loss_d: 0.187757
0.8574 --- loss_d: 0.339959
0.9353 --- loss_d: 0.075201
Epoch finished! Loss: 0.22415570165321697
Starting epoch 6/10.
0.0000 --- loss_d: 0.060433
0.0779 --- loss_d: 0.088989
0.1559 --- loss_d: 0.528757
0.2338 --- loss_d: 0.079303
0.3118 --- loss_d: 0.034722
0.3897 --- loss_d: 0.092244
0.4677 --- loss_d: 0.099885
0.5456 --- loss_d: 0.137139
0.6235 --- loss_d: 0.025802
0.7015 --- loss_d: 0.085323
0.7794 --- loss_d: 0.353521
0.8574 --- loss_d: 0.062570
0.9353 --- loss_d: 0.026486
Epoch finished! Loss: 0.17625506941840285
Starting epoch 7/10.
0.0000 --- loss_d: 0.026460
0.0779 --- loss_d: 0.097214
0.1559 --- loss_d: 0.121985
0.2338 --- loss_d: 0.118617
0.3118 --- loss_d: 0.250007
0.3897 --- loss_d: 0.089744
0.4677 --- loss_d: 0.144928
0.5456 --- loss_d: 0.109403
0.6235 --- loss_d: 0.326730
0.7015 --- loss_d: 0.059944
0.7794 --- loss_d: 0.070080
0.8574 --- loss_d: 0.038512
0.9353 --- loss_d: 0.388347
Epoch finished! Loss: 0.15889248312851123
Starting epoch 8/10.
0.0000 --- loss_d: 0.028482
0.0779 --- loss_d: 0.007537
0.1559 --- loss_d: 0.043728
0.2338 --- loss_d: 0.008865
0.3118 --- loss_d: 0.293372
0.3897 --- loss_d: 0.120175
0.4677 --- loss_d: 0.055481
0.5456 --- loss_d: 0.013282
0.6235 --- loss_d: 0.037112
0.7015 --- loss_d: 0.242999
0.7794 --- loss_d: 0.012571
0.8574 --- loss_d: 0.253587
0.9353 --- loss_d: 0.014183
Epoch finished! Loss: 0.09616345685572014
Starting epoch 9/10.
0.0000 --- loss_d: 0.118597
0.0779 --- loss_d: 0.030743
0.1559 --- loss_d: 0.004955
0.2338 --- loss_d: 0.031788
0.3118 --- loss_d: 0.183517
0.3897 --- loss_d: 0.173789
0.4677 --- loss_d: 0.191739
0.5456 --- loss_d: 0.025398
0.6235 --- loss_d: 0.005686
0.7015 --- loss_d: 0.288814
0.7794 --- loss_d: 0.015121
0.8574 --- loss_d: 0.089299
0.9353 --- loss_d: 0.033948
Epoch finished! Loss: 0.08897773902299377
Starting epoch 10/10.
0.0000 --- loss_d: 0.036533
0.0779 --- loss_d: 0.021891
0.1559 --- loss_d: 0.151438
0.2338 --- loss_d: 0.035318
0.3118 --- loss_d: 0.014668
0.3897 --- loss_d: 0.089692
0.4677 --- loss_d: 0.011637
0.5456 --- loss_d: 0.110261
0.6235 --- loss_d: 0.012698
0.7015 --- loss_d: 0.032533
0.7794 --- loss_d: 0.126561
0.8574 --- loss_d: 0.027078
0.9353 --- loss_d: 0.047387
Epoch finished! Loss: 0.09903927865639162
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[1.         0.99880922 0.99999988 1.         0.99999964 1.
 0.99999988 0.99999154 0.99721342 0.99999964 0.99999976 0.99999928
 0.99999964 0.99999988 0.99999952 1.         0.99999619]
pred: 0.9997651471811182, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp044-nsrr

=== Test on chp045-nsrr. train_data(1280), test_data(20) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.682894
0.0781 --- loss_d: 0.703285
0.1562 --- loss_d: 0.478122
0.2344 --- loss_d: 0.494480
0.3125 --- loss_d: 0.717012
0.3906 --- loss_d: 0.548259
0.4688 --- loss_d: 0.571534
0.5469 --- loss_d: 0.551327
0.6250 --- loss_d: 0.432907
0.7031 --- loss_d: 0.375761
0.7812 --- loss_d: 0.722267
0.8594 --- loss_d: 0.860684
0.9375 --- loss_d: 0.639868
Epoch finished! Loss: 0.6019905955772701
Starting epoch 2/10.
0.0000 --- loss_d: 0.442449
0.0781 --- loss_d: 0.416421
0.1562 --- loss_d: 0.456103
0.2344 --- loss_d: 0.514763
0.3125 --- loss_d: 0.785104
0.3906 --- loss_d: 0.486708
0.4688 --- loss_d: 0.661863
0.5469 --- loss_d: 0.446472
0.6250 --- loss_d: 0.366776
0.7031 --- loss_d: 0.283342
0.7812 --- loss_d: 0.234487
0.8594 --- loss_d: 0.743310
0.9375 --- loss_d: 0.239105
Epoch finished! Loss: 0.4881802441801612
Starting epoch 3/10.
0.0000 --- loss_d: 0.288201
0.0781 --- loss_d: 0.415509
0.1562 --- loss_d: 0.114138
0.2344 --- loss_d: 0.246559
0.3125 --- loss_d: 0.149977
0.3906 --- loss_d: 0.146368
0.4688 --- loss_d: 0.298209
0.5469 --- loss_d: 0.121116
0.6250 --- loss_d: 0.168359
0.7031 --- loss_d: 0.527244
0.7812 --- loss_d: 0.411405
0.8594 --- loss_d: 0.210113
0.9375 --- loss_d: 0.225122
Epoch finished! Loss: 0.3085520771720747
Starting epoch 4/10.
0.0000 --- loss_d: 0.132701
0.0781 --- loss_d: 0.159140
0.1562 --- loss_d: 0.195946
0.2344 --- loss_d: 0.110331
0.3125 --- loss_d: 0.478339
0.3906 --- loss_d: 0.139985
0.4688 --- loss_d: 0.462362
0.5469 --- loss_d: 0.111603
0.6250 --- loss_d: 0.377852
0.7031 --- loss_d: 0.071885
0.7812 --- loss_d: 0.449483
0.8594 --- loss_d: 0.307347
0.9375 --- loss_d: 0.037890
Epoch finished! Loss: 0.2560427424710567
Starting epoch 5/10.
0.0000 --- loss_d: 0.023751
0.0781 --- loss_d: 0.108083
0.1562 --- loss_d: 0.033519
0.2344 --- loss_d: 0.105201
0.3125 --- loss_d: 0.075150
0.3906 --- loss_d: 0.030622
0.4688 --- loss_d: 0.414993
0.5469 --- loss_d: 0.437323
0.6250 --- loss_d: 0.148097
0.7031 --- loss_d: 0.076268
0.7812 --- loss_d: 0.284867
0.8594 --- loss_d: 0.148235
0.9375 --- loss_d: 0.084040
Epoch finished! Loss: 0.21916321962778493
Starting epoch 6/10.
0.0000 --- loss_d: 0.039681
0.0781 --- loss_d: 0.018288
0.1562 --- loss_d: 0.007365
0.2344 --- loss_d: 0.202512
0.3125 --- loss_d: 0.148527
0.3906 --- loss_d: 0.044405
0.4688 --- loss_d: 0.041190
0.5469 --- loss_d: 0.047701
0.6250 --- loss_d: 0.410824
0.7031 --- loss_d: 0.027211
0.7812 --- loss_d: 0.093365
0.8594 --- loss_d: 0.187118
0.9375 --- loss_d: 0.033989
Epoch finished! Loss: 0.1498838642531434
Starting epoch 7/10.
0.0000 --- loss_d: 0.041605
0.0781 --- loss_d: 0.276995
0.1562 --- loss_d: 0.167740
0.2344 --- loss_d: 0.103694
0.3125 --- loss_d: 0.017620
0.3906 --- loss_d: 0.274620
0.4688 --- loss_d: 0.271920
0.5469 --- loss_d: 0.258052
0.6250 --- loss_d: 0.055754
0.7031 --- loss_d: 0.304601
0.7812 --- loss_d: 0.062205
0.8594 --- loss_d: 0.028814
0.9375 --- loss_d: 0.313274
Epoch finished! Loss: 0.12631468400249155
Starting epoch 8/10.
0.0000 --- loss_d: 0.007341
0.0781 --- loss_d: 0.027229
0.1562 --- loss_d: 0.207508
0.2344 --- loss_d: 0.077306
0.3125 --- loss_d: 0.027936
0.3906 --- loss_d: 0.056591
0.4688 --- loss_d: 0.008239
0.5469 --- loss_d: 0.011345
0.6250 --- loss_d: 0.007012
0.7031 --- loss_d: 0.029933
0.7812 --- loss_d: 0.285366
0.8594 --- loss_d: 0.013562
0.9375 --- loss_d: 0.002674
Epoch finished! Loss: 0.1045909058467639
Starting epoch 9/10.
0.0000 --- loss_d: 0.010126
0.0781 --- loss_d: 0.021869
0.1562 --- loss_d: 0.010842
0.2344 --- loss_d: 0.004038
0.3125 --- loss_d: 0.003962
0.3906 --- loss_d: 0.033468
0.4688 --- loss_d: 0.043169
0.5469 --- loss_d: 0.071554
0.6250 --- loss_d: 0.484795
0.7031 --- loss_d: 0.035797
0.7812 --- loss_d: 0.031439
0.8594 --- loss_d: 0.180955
0.9375 --- loss_d: 0.029529
Epoch finished! Loss: 0.08705297068832075
Starting epoch 10/10.
0.0000 --- loss_d: 0.084873
0.0781 --- loss_d: 0.002244
0.1562 --- loss_d: 0.009805
0.2344 --- loss_d: 0.020525
0.3125 --- loss_d: 0.013853
0.3906 --- loss_d: 0.094414
0.4688 --- loss_d: 0.003518
0.5469 --- loss_d: 0.580571
0.6250 --- loss_d: 0.209000
0.7031 --- loss_d: 0.259321
0.7812 --- loss_d: 0.034583
0.8594 --- loss_d: 0.004590
0.9375 --- loss_d: 0.014249
Epoch finished! Loss: 0.0713606661292871
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99995232 0.99999976 0.99998927 0.99999738 0.99999726 1.
 0.99997663 0.99999404 0.99970978 0.99977297 0.99999952 0.99986517
 0.99999774 0.99977416 0.99996245 0.99998498 0.99998224 0.99993777
 0.99755716 1.        ]
pred: 0.9998225301504136, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp045-nsrr

=== Test on chp046-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.742715
0.0780 --- loss_d: 0.738418
0.1560 --- loss_d: 0.694549
0.2340 --- loss_d: 0.522187
0.3120 --- loss_d: 0.655880
0.3900 --- loss_d: 0.434794
0.4680 --- loss_d: 0.371108
0.5460 --- loss_d: 0.742410
0.6240 --- loss_d: 0.476142
0.7020 --- loss_d: 0.762516
0.7800 --- loss_d: 0.657646
0.8580 --- loss_d: 0.568752
0.9360 --- loss_d: 0.217797
Epoch finished! Loss: 0.6036410346860066
Starting epoch 2/10.
0.0000 --- loss_d: 0.999607
0.0780 --- loss_d: 0.236898
0.1560 --- loss_d: 0.494287
0.2340 --- loss_d: 0.424772
0.3120 --- loss_d: 0.215118
0.3900 --- loss_d: 0.344038
0.4680 --- loss_d: 0.510131
0.5460 --- loss_d: 1.069742
0.6240 --- loss_d: 0.642802
0.7020 --- loss_d: 0.376808
0.7800 --- loss_d: 0.399579
0.8580 --- loss_d: 0.509098
0.9360 --- loss_d: 0.372731
Epoch finished! Loss: 0.4912521651131101
Starting epoch 3/10.
0.0000 --- loss_d: 0.627058
0.0780 --- loss_d: 0.290009
0.1560 --- loss_d: 0.245641
0.2340 --- loss_d: 0.684969
0.3120 --- loss_d: 0.115860
0.3900 --- loss_d: 0.154624
0.4680 --- loss_d: 0.223905
0.5460 --- loss_d: 0.243945
0.6240 --- loss_d: 0.169451
0.7020 --- loss_d: 0.057571
0.7800 --- loss_d: 0.040200
0.8580 --- loss_d: 0.069636
0.9360 --- loss_d: 0.381625
Epoch finished! Loss: 0.2874642356473487
Starting epoch 4/10.
0.0000 --- loss_d: 0.231175
0.0780 --- loss_d: 0.350650
0.1560 --- loss_d: 0.141424
0.2340 --- loss_d: 0.305727
0.3120 --- loss_d: 0.202210
0.3900 --- loss_d: 0.045519
0.4680 --- loss_d: 0.131407
0.5460 --- loss_d: 0.257918
0.6240 --- loss_d: 0.476677
0.7020 --- loss_d: 0.062645
0.7800 --- loss_d: 0.098567
0.8580 --- loss_d: 0.310066
0.9360 --- loss_d: 0.352919
Epoch finished! Loss: 0.21783865347970277
Starting epoch 5/10.
0.0000 --- loss_d: 0.440608
0.0780 --- loss_d: 0.381364
0.1560 --- loss_d: 0.184773
0.2340 --- loss_d: 0.091758
0.3120 --- loss_d: 0.082904
0.3900 --- loss_d: 0.037788
0.4680 --- loss_d: 0.035161
0.5460 --- loss_d: 0.010370
0.6240 --- loss_d: 0.124394
0.7020 --- loss_d: 0.066458
0.7800 --- loss_d: 0.032629
0.8580 --- loss_d: 0.054438
0.9360 --- loss_d: 0.224701
Epoch finished! Loss: 0.15340921137612895
Starting epoch 6/10.
0.0000 --- loss_d: 0.010983
0.0780 --- loss_d: 0.096419
0.1560 --- loss_d: 0.046305
0.2340 --- loss_d: 0.052198
0.3120 --- loss_d: 0.004559
0.3900 --- loss_d: 0.084821
0.4680 --- loss_d: 0.110501
0.5460 --- loss_d: 0.286209
0.6240 --- loss_d: 0.093264
0.7020 --- loss_d: 0.024469
0.7800 --- loss_d: 0.018789
0.8580 --- loss_d: 0.046849
0.9360 --- loss_d: 0.032681
Epoch finished! Loss: 0.11629380926933663
Starting epoch 7/10.
0.0000 --- loss_d: 0.023273
0.0780 --- loss_d: 0.355098
0.1560 --- loss_d: 0.063901
0.2340 --- loss_d: 0.048310
0.3120 --- loss_d: 0.055801
0.3900 --- loss_d: 0.019531
0.4680 --- loss_d: 0.402814
0.5460 --- loss_d: 0.222669
0.6240 --- loss_d: 1.105017
0.7020 --- loss_d: 0.204543
0.7800 --- loss_d: 0.008981
0.8580 --- loss_d: 0.019448
0.9360 --- loss_d: 0.143514
Epoch finished! Loss: 0.08715521527756209
Starting epoch 8/10.
0.0000 --- loss_d: 0.079780
0.0780 --- loss_d: 0.005469
0.1560 --- loss_d: 0.006917
0.2340 --- loss_d: 0.074830
0.3120 --- loss_d: 0.035019
0.3900 --- loss_d: 0.021038
0.4680 --- loss_d: 1.021685
0.5460 --- loss_d: 0.199345
0.6240 --- loss_d: 0.100555
0.7020 --- loss_d: 0.045279
0.7800 --- loss_d: 0.003075
0.8580 --- loss_d: 0.006838
0.9360 --- loss_d: 0.007561
Epoch finished! Loss: 0.07317191289621405
Starting epoch 9/10.
0.0000 --- loss_d: 0.005041
0.0780 --- loss_d: 0.003903
0.1560 --- loss_d: 0.029783
0.2340 --- loss_d: 0.001474
0.3120 --- loss_d: 0.023807
0.3900 --- loss_d: 0.075825
0.4680 --- loss_d: 0.016486
0.5460 --- loss_d: 0.029823
0.6240 --- loss_d: 0.003537
0.7020 --- loss_d: 0.038867
0.7800 --- loss_d: 0.004132
0.8580 --- loss_d: 0.004607
0.9360 --- loss_d: 0.044414
Epoch finished! Loss: 0.04178808881943041
Starting epoch 10/10.
0.0000 --- loss_d: 0.045583
0.0780 --- loss_d: 0.133718
0.1560 --- loss_d: 0.001190
0.2340 --- loss_d: 0.006390
0.3120 --- loss_d: 0.136271
0.3900 --- loss_d: 0.009744
0.4680 --- loss_d: 0.030096
0.5460 --- loss_d: 0.001864
0.6240 --- loss_d: 0.017907
0.7020 --- loss_d: 0.038822
0.7800 --- loss_d: 0.046446
0.8580 --- loss_d: 0.032794
0.9360 --- loss_d: 0.346479
Epoch finished! Loss: 0.022609551971868314
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99989772 0.99979073 0.99999762 0.99998939 0.99999285 0.99998713
 0.99999726 0.99999845 0.99999905 1.         0.99999607 1.
 1.         0.99997187 0.99999952 0.99997878 0.9999994  0.99999976]
pred: 0.9999775323602889, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp046-nsrr

=== Test on chp047-nsrr. train_data(1286), test_data(14) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.675567
0.0778 --- loss_d: 0.541322
0.1555 --- loss_d: 0.629619
0.2333 --- loss_d: 0.796492
0.3110 --- loss_d: 0.780317
0.3888 --- loss_d: 0.474133
0.4666 --- loss_d: 0.579705
0.5443 --- loss_d: 0.502322
0.6221 --- loss_d: 0.457084
0.6998 --- loss_d: 0.378483
0.7776 --- loss_d: 0.701454
0.8554 --- loss_d: 0.742763
0.9331 --- loss_d: 0.507047
Epoch finished! Loss: 0.5958408310543746
Starting epoch 2/10.
0.0000 --- loss_d: 0.337404
0.0778 --- loss_d: 0.336956
0.1555 --- loss_d: 0.440506
0.2333 --- loss_d: 0.358557
0.3110 --- loss_d: 0.397076
0.3888 --- loss_d: 0.975557
0.4666 --- loss_d: 0.331899
0.5443 --- loss_d: 0.346835
0.6221 --- loss_d: 0.197204
0.6998 --- loss_d: 0.188805
0.7776 --- loss_d: 0.192212
0.8554 --- loss_d: 0.970575
0.9331 --- loss_d: 0.523386
Epoch finished! Loss: 0.4515181590686552
Starting epoch 3/10.
0.0000 --- loss_d: 0.148136
0.0778 --- loss_d: 0.116796
0.1555 --- loss_d: 0.202847
0.2333 --- loss_d: 0.357866
0.3110 --- loss_d: 0.257618
0.3888 --- loss_d: 0.539528
0.4666 --- loss_d: 0.299648
0.5443 --- loss_d: 0.123183
0.6221 --- loss_d: 0.505859
0.6998 --- loss_d: 0.177773
0.7776 --- loss_d: 0.297249
0.8554 --- loss_d: 0.606283
0.9331 --- loss_d: 0.147408
Epoch finished! Loss: 0.3016434417513665
Starting epoch 4/10.
0.0000 --- loss_d: 0.229278
0.0778 --- loss_d: 0.405006
0.1555 --- loss_d: 0.194927
0.2333 --- loss_d: 0.129001
0.3110 --- loss_d: 0.334561
0.3888 --- loss_d: 0.183233
0.4666 --- loss_d: 0.447432
0.5443 --- loss_d: 0.238007
0.6221 --- loss_d: 0.046241
0.6998 --- loss_d: 0.540263
0.7776 --- loss_d: 1.243335
0.8554 --- loss_d: 0.077614
0.9331 --- loss_d: 0.216349
Epoch finished! Loss: 0.22904894064413384
Starting epoch 5/10.
0.0000 --- loss_d: 0.045461
0.0778 --- loss_d: 0.053404
0.1555 --- loss_d: 0.072560
0.2333 --- loss_d: 0.130278
0.3110 --- loss_d: 0.038120
0.3888 --- loss_d: 0.039363
0.4666 --- loss_d: 0.108117
0.5443 --- loss_d: 0.158194
0.6221 --- loss_d: 0.027431
0.6998 --- loss_d: 0.054316
0.7776 --- loss_d: 0.090018
0.8554 --- loss_d: 0.121459
0.9331 --- loss_d: 0.189711
Epoch finished! Loss: 0.15418869870336493
Starting epoch 6/10.
0.0000 --- loss_d: 0.051419
0.0778 --- loss_d: 0.013389
0.1555 --- loss_d: 0.011261
0.2333 --- loss_d: 0.028453
0.3110 --- loss_d: 0.267600
0.3888 --- loss_d: 0.105794
0.4666 --- loss_d: 0.146782
0.5443 --- loss_d: 0.014131
0.6221 --- loss_d: 0.050941
0.6998 --- loss_d: 0.075505
0.7776 --- loss_d: 0.364235
0.8554 --- loss_d: 0.403420
0.9331 --- loss_d: 0.015535
Epoch finished! Loss: 0.11478634914419672
Starting epoch 7/10.
0.0000 --- loss_d: 0.038743
0.0778 --- loss_d: 0.377073
0.1555 --- loss_d: 0.054847
0.2333 --- loss_d: 0.020968
0.3110 --- loss_d: 0.167052
0.3888 --- loss_d: 0.011779
0.4666 --- loss_d: 0.018224
0.5443 --- loss_d: 0.036479
0.6221 --- loss_d: 0.039109
0.6998 --- loss_d: 0.062759
0.7776 --- loss_d: 0.770425
0.8554 --- loss_d: 0.096204
0.9331 --- loss_d: 0.268318
Epoch finished! Loss: 0.10200132792488148
Starting epoch 8/10.
0.0000 --- loss_d: 0.020539
0.0778 --- loss_d: 0.022543
0.1555 --- loss_d: 0.009354
0.2333 --- loss_d: 0.178815
0.3110 --- loss_d: 0.001755
0.3888 --- loss_d: 0.283518
0.4666 --- loss_d: 0.022703
0.5443 --- loss_d: 0.002635
0.6221 --- loss_d: 0.003104
0.6998 --- loss_d: 0.013448
0.7776 --- loss_d: 0.065886
0.8554 --- loss_d: 0.002873
0.9331 --- loss_d: 0.014809
Epoch finished! Loss: 0.06619915322926317
Starting epoch 9/10.
0.0000 --- loss_d: 0.069636
0.0778 --- loss_d: 0.053862
0.1555 --- loss_d: 0.013238
0.2333 --- loss_d: 0.040706
0.3110 --- loss_d: 0.018455
0.3888 --- loss_d: 0.005338
0.4666 --- loss_d: 0.120805
0.5443 --- loss_d: 0.017764
0.6221 --- loss_d: 0.033815
0.6998 --- loss_d: 0.002594
0.7776 --- loss_d: 0.751836
0.8554 --- loss_d: 0.020887
0.9331 --- loss_d: 0.005291
Epoch finished! Loss: 0.06770120430519455
Starting epoch 10/10.
0.0000 --- loss_d: 0.001499
0.0778 --- loss_d: 0.005306
0.1555 --- loss_d: 0.002969
0.2333 --- loss_d: 0.031803
0.3110 --- loss_d: 0.018753
0.3888 --- loss_d: 0.004436
0.4666 --- loss_d: 0.003492
0.5443 --- loss_d: 0.153724
0.6221 --- loss_d: 0.008829
0.6998 --- loss_d: 0.004904
0.7776 --- loss_d: 0.032765
0.8554 --- loss_d: 0.012065
0.9331 --- loss_d: 0.003631
Epoch finished! Loss: 0.040799364742497346
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999928 0.99999905 0.99804664 0.99999881 0.99999988 0.99999928
 0.99999416 0.99999821 1.         0.99976844 0.99999702 1.
 1.         0.99999213]
pred: 0.9998423499720437, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp047-nsrr

=== Test on chp048-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.660037
0.0779 --- loss_d: 0.553906
0.1559 --- loss_d: 0.531375
0.2338 --- loss_d: 0.694289
0.3118 --- loss_d: 0.562373
0.3897 --- loss_d: 0.692336
0.4677 --- loss_d: 0.514388
0.5456 --- loss_d: 0.781141
0.6235 --- loss_d: 0.769343
0.7015 --- loss_d: 0.406922
0.7794 --- loss_d: 0.455445
0.8574 --- loss_d: 0.776536
0.9353 --- loss_d: 0.516398
Epoch finished! Loss: 0.6042598863132298
Starting epoch 2/10.
0.0000 --- loss_d: 0.452197
0.0779 --- loss_d: 0.480997
0.1559 --- loss_d: 0.640969
0.2338 --- loss_d: 0.394207
0.3118 --- loss_d: 0.996340
0.3897 --- loss_d: 0.548498
0.4677 --- loss_d: 0.385524
0.5456 --- loss_d: 0.695151
0.6235 --- loss_d: 0.563210
0.7015 --- loss_d: 0.443968
0.7794 --- loss_d: 0.377203
0.8574 --- loss_d: 0.353887
0.9353 --- loss_d: 0.152866
Epoch finished! Loss: 0.46575366804609075
Starting epoch 3/10.
0.0000 --- loss_d: 0.574111
0.0779 --- loss_d: 0.750909
0.1559 --- loss_d: 0.217979
0.2338 --- loss_d: 0.174778
0.3118 --- loss_d: 0.248704
0.3897 --- loss_d: 0.265326
0.4677 --- loss_d: 0.271239
0.5456 --- loss_d: 0.175303
0.6235 --- loss_d: 0.278156
0.7015 --- loss_d: 0.269891
0.7794 --- loss_d: 0.451681
0.8574 --- loss_d: 0.167609
0.9353 --- loss_d: 0.042235
Epoch finished! Loss: 0.31849699714803137
Starting epoch 4/10.
0.0000 --- loss_d: 0.099270
0.0779 --- loss_d: 0.117577
0.1559 --- loss_d: 0.069705
0.2338 --- loss_d: 0.206483
0.3118 --- loss_d: 0.036628
0.3897 --- loss_d: 0.528295
0.4677 --- loss_d: 0.139894
0.5456 --- loss_d: 0.017190
0.6235 --- loss_d: 0.326448
0.7015 --- loss_d: 0.247436
0.7794 --- loss_d: 0.097648
0.8574 --- loss_d: 0.373697
0.9353 --- loss_d: 0.010518
Epoch finished! Loss: 0.2167136405405472
Starting epoch 5/10.
0.0000 --- loss_d: 0.077148
0.0779 --- loss_d: 0.154179
0.1559 --- loss_d: 0.090563
0.2338 --- loss_d: 0.245731
0.3118 --- loss_d: 0.047987
0.3897 --- loss_d: 0.029821
0.4677 --- loss_d: 0.059124
0.5456 --- loss_d: 0.229625
0.6235 --- loss_d: 0.023255
0.7015 --- loss_d: 0.111171
0.7794 --- loss_d: 0.222460
0.8574 --- loss_d: 0.153381
0.9353 --- loss_d: 0.067240
Epoch finished! Loss: 0.17617455760773737
Starting epoch 6/10.
0.0000 --- loss_d: 0.200479
0.0779 --- loss_d: 0.248097
0.1559 --- loss_d: 0.157465
0.2338 --- loss_d: 0.385328
0.3118 --- loss_d: 0.091562
0.3897 --- loss_d: 0.477016
0.4677 --- loss_d: 0.052401
0.5456 --- loss_d: 0.147741
0.6235 --- loss_d: 0.034003
0.7015 --- loss_d: 0.021129
0.7794 --- loss_d: 0.251451
0.8574 --- loss_d: 0.260202
0.9353 --- loss_d: 0.068543
Epoch finished! Loss: 0.16602971373868058
Starting epoch 7/10.
0.0000 --- loss_d: 0.298426
0.0779 --- loss_d: 0.018252
0.1559 --- loss_d: 0.008518
0.2338 --- loss_d: 0.578330
0.3118 --- loss_d: 0.041490
0.3897 --- loss_d: 0.084394
0.4677 --- loss_d: 0.098220
0.5456 --- loss_d: 0.216180
0.6235 --- loss_d: 0.027797
0.7015 --- loss_d: 0.123654
0.7794 --- loss_d: 0.012900
0.8574 --- loss_d: 0.054353
0.9353 --- loss_d: 0.011707
Epoch finished! Loss: 0.12317457040262525
Starting epoch 8/10.
0.0000 --- loss_d: 0.018877
0.0779 --- loss_d: 0.097313
0.1559 --- loss_d: 0.012628
0.2338 --- loss_d: 0.015185
0.3118 --- loss_d: 0.063194
0.3897 --- loss_d: 0.061208
0.4677 --- loss_d: 0.112664
0.5456 --- loss_d: 0.014476
0.6235 --- loss_d: 0.018394
0.7015 --- loss_d: 0.344667
0.7794 --- loss_d: 0.029322
0.8574 --- loss_d: 0.229266
0.9353 --- loss_d: 0.014463
Epoch finished! Loss: 0.10504142801710259
Starting epoch 9/10.
0.0000 --- loss_d: 0.011035
0.0779 --- loss_d: 0.060116
0.1559 --- loss_d: 0.022173
0.2338 --- loss_d: 0.006799
0.3118 --- loss_d: 0.002702
0.3897 --- loss_d: 0.054421
0.4677 --- loss_d: 0.040050
0.5456 --- loss_d: 0.337331
0.6235 --- loss_d: 0.104474
0.7015 --- loss_d: 0.003561
0.7794 --- loss_d: 0.020696
0.8574 --- loss_d: 0.166663
0.9353 --- loss_d: 0.127509
Epoch finished! Loss: 0.07325077010773384
Starting epoch 10/10.
0.0000 --- loss_d: 0.013347
0.0779 --- loss_d: 0.028496
0.1559 --- loss_d: 0.006403
0.2338 --- loss_d: 0.099503
0.3118 --- loss_d: 0.018894
0.3897 --- loss_d: 0.004203
0.4677 --- loss_d: 0.013960
0.5456 --- loss_d: 0.097365
0.6235 --- loss_d: 0.036191
0.7015 --- loss_d: 0.072199
0.7794 --- loss_d: 0.059096
0.8574 --- loss_d: 0.153302
0.9353 --- loss_d: 0.005952
Epoch finished! Loss: 0.060742031964764465
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.058823529411764705
[1.67642522e-03 2.12343084e-03 2.04109540e-03 7.43095344e-03
 6.59792304e-01 2.58104410e-03 1.25225997e-02 3.05811339e-03
 3.24763561e-04 1.18541876e-02 4.30018418e-02 2.07098916e-01
 5.00175962e-03 6.21972233e-02 4.23363075e-02 7.95720965e-02
 1.86139699e-02]
pred: 0.06830747246653225, label: 1
Wrong!!! Real Diagnosis: NT1
Save 30mins of subject chp048-nsrr

=== Test on chp049-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.700051
0.0780 --- loss_d: 0.760390
0.1560 --- loss_d: 0.532025
0.2340 --- loss_d: 0.613334
0.3120 --- loss_d: 0.162185
0.3900 --- loss_d: 0.392948
0.4680 --- loss_d: 0.385825
0.5460 --- loss_d: 0.449508
0.6240 --- loss_d: 0.710256
0.7020 --- loss_d: 0.424005
0.7800 --- loss_d: 0.256664
0.8580 --- loss_d: 0.491688
0.9360 --- loss_d: 0.495838
Epoch finished! Loss: 0.595601019449532
Starting epoch 2/10.
0.0000 --- loss_d: 0.454710
0.0780 --- loss_d: 0.216239
0.1560 --- loss_d: 0.660976
0.2340 --- loss_d: 0.635041
0.3120 --- loss_d: 0.311256
0.3900 --- loss_d: 0.566974
0.4680 --- loss_d: 0.405220
0.5460 --- loss_d: 0.294417
0.6240 --- loss_d: 0.191905
0.7020 --- loss_d: 0.076351
0.7800 --- loss_d: 1.195535
0.8580 --- loss_d: 0.385073
0.9360 --- loss_d: 0.421264
Epoch finished! Loss: 0.36998114199377596
Starting epoch 3/10.
0.0000 --- loss_d: 0.231497
0.0780 --- loss_d: 0.072603
0.1560 --- loss_d: 0.118544
0.2340 --- loss_d: 0.590497
0.3120 --- loss_d: 0.143121
0.3900 --- loss_d: 0.042778
0.4680 --- loss_d: 0.191037
0.5460 --- loss_d: 0.387075
0.6240 --- loss_d: 0.349605
0.7020 --- loss_d: 0.145312
0.7800 --- loss_d: 0.496612
0.8580 --- loss_d: 0.399029
0.9360 --- loss_d: 0.250669
Epoch finished! Loss: 0.2637454578652978
Starting epoch 4/10.
0.0000 --- loss_d: 0.047089
0.0780 --- loss_d: 0.138616
0.1560 --- loss_d: 0.105775
0.2340 --- loss_d: 0.516669
0.3120 --- loss_d: 0.108098
0.3900 --- loss_d: 0.090881
0.4680 --- loss_d: 0.106530
0.5460 --- loss_d: 0.478229
0.6240 --- loss_d: 0.198488
0.7020 --- loss_d: 0.139845
0.7800 --- loss_d: 0.243983
0.8580 --- loss_d: 0.091782
0.9360 --- loss_d: 0.971645
Epoch finished! Loss: 0.24186432883288944
Starting epoch 5/10.
0.0000 --- loss_d: 0.116196
0.0780 --- loss_d: 0.345184
0.1560 --- loss_d: 0.302933
0.2340 --- loss_d: 0.047023
0.3120 --- loss_d: 0.044545
0.3900 --- loss_d: 0.028567
0.4680 --- loss_d: 0.318863
0.5460 --- loss_d: 0.023690
0.6240 --- loss_d: 0.266767
0.7020 --- loss_d: 0.307475
0.7800 --- loss_d: 0.084362
0.8580 --- loss_d: 0.032748
0.9360 --- loss_d: 0.051672
Epoch finished! Loss: 0.18493975266028428
Starting epoch 6/10.
0.0000 --- loss_d: 0.089425
0.0780 --- loss_d: 0.036054
0.1560 --- loss_d: 0.241245
0.2340 --- loss_d: 0.065129
0.3120 --- loss_d: 0.045435
0.3900 --- loss_d: 0.260409
0.4680 --- loss_d: 0.278454
0.5460 --- loss_d: 0.073705
0.6240 --- loss_d: 0.066286
0.7020 --- loss_d: 0.382872
0.7800 --- loss_d: 0.038783
0.8580 --- loss_d: 0.016991
0.9360 --- loss_d: 0.027289
Epoch finished! Loss: 0.18454415422456805
Starting epoch 7/10.
0.0000 --- loss_d: 0.215712
0.0780 --- loss_d: 0.106939
0.1560 --- loss_d: 0.174827
0.2340 --- loss_d: 0.250045
0.3120 --- loss_d: 0.539219
0.3900 --- loss_d: 0.119053
0.4680 --- loss_d: 0.008940
0.5460 --- loss_d: 0.042925
0.6240 --- loss_d: 0.023675
0.7020 --- loss_d: 0.775565
0.7800 --- loss_d: 0.068272
0.8580 --- loss_d: 0.035149
0.9360 --- loss_d: 0.020385
Epoch finished! Loss: 0.12531786623731023
Starting epoch 8/10.
0.0000 --- loss_d: 0.079470
0.0780 --- loss_d: 0.047593
0.1560 --- loss_d: 0.040065
0.2340 --- loss_d: 0.015629
0.3120 --- loss_d: 0.002449
0.3900 --- loss_d: 0.010034
0.4680 --- loss_d: 0.022287
0.5460 --- loss_d: 0.019015
0.6240 --- loss_d: 0.016429
0.7020 --- loss_d: 0.022071
0.7800 --- loss_d: 0.005907
0.8580 --- loss_d: 0.032733
0.9360 --- loss_d: 0.344900
Epoch finished! Loss: 0.10039942515777511
Starting epoch 9/10.
0.0000 --- loss_d: 0.079341
0.0780 --- loss_d: 0.078048
0.1560 --- loss_d: 0.125941
0.2340 --- loss_d: 0.036396
0.3120 --- loss_d: 0.077090
0.3900 --- loss_d: 0.081084
0.4680 --- loss_d: 0.483371
0.5460 --- loss_d: 0.069458
0.6240 --- loss_d: 0.022770
0.7020 --- loss_d: 0.026428
0.7800 --- loss_d: 0.032928
0.8580 --- loss_d: 0.014705
0.9360 --- loss_d: 0.120254
Epoch finished! Loss: 0.12764500705907267
Starting epoch 10/10.
0.0000 --- loss_d: 0.011181
0.0780 --- loss_d: 0.040657
0.1560 --- loss_d: 0.004646
0.2340 --- loss_d: 0.032869
0.3120 --- loss_d: 0.016482
0.3900 --- loss_d: 0.002114
0.4680 --- loss_d: 0.114621
0.5460 --- loss_d: 0.190845
0.6240 --- loss_d: 0.042366
0.7020 --- loss_d: 0.230849
0.7800 --- loss_d: 0.002841
0.8580 --- loss_d: 0.017413
0.9360 --- loss_d: 0.014829
Epoch finished! Loss: 0.06606049033871386
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99844801 0.99993455 0.97148651 0.99984753 0.99999881 0.99999523
 0.99962926 0.99623364 0.99999952 0.99980468 0.9999882  0.9999727
 0.99999928 0.99997115 0.99998164 0.99993515 0.99974054 0.99935919]
pred: 0.9980180892679427, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp049-nsrr

=== Test on chp051-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.672128
0.0780 --- loss_d: 0.803993
0.1560 --- loss_d: 0.631756
0.2340 --- loss_d: 1.005986
0.3120 --- loss_d: 0.425826
0.3900 --- loss_d: 0.697048
0.4680 --- loss_d: 0.538511
0.5460 --- loss_d: 0.666710
0.6240 --- loss_d: 0.418209
0.7020 --- loss_d: 0.617192
0.7800 --- loss_d: 0.386532
0.8580 --- loss_d: 0.708958
0.9360 --- loss_d: 0.462426
Epoch finished! Loss: 0.6225571364630014
Starting epoch 2/10.
0.0000 --- loss_d: 0.347497
0.0780 --- loss_d: 0.511701
0.1560 --- loss_d: 0.353174
0.2340 --- loss_d: 1.065977
0.3120 --- loss_d: 0.591705
0.3900 --- loss_d: 0.417107
0.4680 --- loss_d: 0.496914
0.5460 --- loss_d: 0.238775
0.6240 --- loss_d: 0.295735
0.7020 --- loss_d: 0.425698
0.7800 --- loss_d: 0.455374
0.8580 --- loss_d: 0.411103
0.9360 --- loss_d: 0.422915
Epoch finished! Loss: 0.431450956442859
Starting epoch 3/10.
0.0000 --- loss_d: 0.561159
0.0780 --- loss_d: 0.434261
0.1560 --- loss_d: 0.220412
0.2340 --- loss_d: 0.262961
0.3120 --- loss_d: 0.253440
0.3900 --- loss_d: 0.530345
0.4680 --- loss_d: 0.072655
0.5460 --- loss_d: 0.300155
0.6240 --- loss_d: 0.186029
0.7020 --- loss_d: 0.660931
0.7800 --- loss_d: 0.144142
0.8580 --- loss_d: 0.279677
0.9360 --- loss_d: 0.161416
Epoch finished! Loss: 0.3196514561714139
Starting epoch 4/10.
0.0000 --- loss_d: 0.164200
0.0780 --- loss_d: 0.124078
0.1560 --- loss_d: 0.129210
0.2340 --- loss_d: 0.225299
0.3120 --- loss_d: 0.105278
0.3900 --- loss_d: 0.115237
0.4680 --- loss_d: 0.197919
0.5460 --- loss_d: 0.299206
0.6240 --- loss_d: 0.464798
0.7020 --- loss_d: 0.161819
0.7800 --- loss_d: 0.174859
0.8580 --- loss_d: 0.577886
0.9360 --- loss_d: 0.342347
Epoch finished! Loss: 0.24326615367317572
Starting epoch 5/10.
0.0000 --- loss_d: 0.213758
0.0780 --- loss_d: 0.044122
0.1560 --- loss_d: 0.089303
0.2340 --- loss_d: 0.215270
0.3120 --- loss_d: 0.174102
0.3900 --- loss_d: 0.123849
0.4680 --- loss_d: 0.291589
0.5460 --- loss_d: 0.295250
0.6240 --- loss_d: 0.282932
0.7020 --- loss_d: 0.217944
0.7800 --- loss_d: 0.497151
0.8580 --- loss_d: 0.235742
0.9360 --- loss_d: 0.027622
Epoch finished! Loss: 0.20836060044530313
Starting epoch 6/10.
0.0000 --- loss_d: 0.115554
0.0780 --- loss_d: 0.054582
0.1560 --- loss_d: 0.041288
0.2340 --- loss_d: 0.143063
0.3120 --- loss_d: 0.023392
0.3900 --- loss_d: 0.102669
0.4680 --- loss_d: 0.051028
0.5460 --- loss_d: 0.029474
0.6240 --- loss_d: 0.264141
0.7020 --- loss_d: 0.103603
0.7800 --- loss_d: 0.118942
0.8580 --- loss_d: 0.275352
0.9360 --- loss_d: 0.088887
Epoch finished! Loss: 0.16153928821950103
Starting epoch 7/10.
0.0000 --- loss_d: 0.034698
0.0780 --- loss_d: 0.029596
0.1560 --- loss_d: 0.046964
0.2340 --- loss_d: 0.088172
0.3120 --- loss_d: 0.075852
0.3900 --- loss_d: 0.062295
0.4680 --- loss_d: 0.261388
0.5460 --- loss_d: 0.034401
0.6240 --- loss_d: 0.084531
0.7020 --- loss_d: 0.073332
0.7800 --- loss_d: 0.009274
0.8580 --- loss_d: 0.032361
0.9360 --- loss_d: 0.005802
Epoch finished! Loss: 0.10706366352314944
Starting epoch 8/10.
0.0000 --- loss_d: 0.033897
0.0780 --- loss_d: 1.304252
0.1560 --- loss_d: 0.027705
0.2340 --- loss_d: 0.028211
0.3120 --- loss_d: 0.016033
0.3900 --- loss_d: 0.129206
0.4680 --- loss_d: 0.006974
0.5460 --- loss_d: 0.044900
0.6240 --- loss_d: 0.015556
0.7020 --- loss_d: 0.065607
0.7800 --- loss_d: 0.056902
0.8580 --- loss_d: 0.007440
0.9360 --- loss_d: 0.037350
Epoch finished! Loss: 0.10395531115045742
Starting epoch 9/10.
0.0000 --- loss_d: 0.027781
0.0780 --- loss_d: 0.018053
0.1560 --- loss_d: 0.074540
0.2340 --- loss_d: 0.102229
0.3120 --- loss_d: 0.032212
0.3900 --- loss_d: 0.011053
0.4680 --- loss_d: 0.216165
0.5460 --- loss_d: 0.081770
0.6240 --- loss_d: 0.048056
0.7020 --- loss_d: 0.014648
0.7800 --- loss_d: 0.166206
0.8580 --- loss_d: 0.079235
0.9360 --- loss_d: 0.074583
Epoch finished! Loss: 0.07707378481245541
Starting epoch 10/10.
0.0000 --- loss_d: 0.103656
0.0780 --- loss_d: 0.078400
0.1560 --- loss_d: 0.020777
0.2340 --- loss_d: 0.178001
0.3120 --- loss_d: 0.143206
0.3900 --- loss_d: 0.032108
0.4680 --- loss_d: 0.068493
0.5460 --- loss_d: 0.058030
0.6240 --- loss_d: 0.061154
0.7020 --- loss_d: 0.009962
0.7800 --- loss_d: 0.130591
0.8580 --- loss_d: 0.003158
0.9360 --- loss_d: 0.004776
Epoch finished! Loss: 0.09071231418965908
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99997234 0.99978    0.999731   0.97222847 0.9999615  0.99999416
 0.99997795 0.99993002 0.99997091 0.99995661 0.9990055  0.99991572
 0.99994862 0.99960345 0.99815935 0.99937028 0.99992239 0.99992144]
pred: 0.9981860948933495, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp051-nsrr

=== Test on chp052-nsrr. train_data(1284), test_data(16) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.724986
0.0779 --- loss_d: 0.669139
0.1558 --- loss_d: 0.685497
0.2336 --- loss_d: 0.666337
0.3115 --- loss_d: 0.710463
0.3894 --- loss_d: 0.271001
0.4673 --- loss_d: 0.665899
0.5452 --- loss_d: 0.532437
0.6231 --- loss_d: 0.719825
0.7009 --- loss_d: 0.815205
0.7788 --- loss_d: 0.855361
0.8567 --- loss_d: 0.664508
0.9346 --- loss_d: 0.558630
Epoch finished! Loss: 0.5995810747845098
Starting epoch 2/10.
0.0000 --- loss_d: 0.491174
0.0779 --- loss_d: 0.470719
0.1558 --- loss_d: 0.700778
0.2336 --- loss_d: 0.725976
0.3115 --- loss_d: 0.450642
0.3894 --- loss_d: 0.384527
0.4673 --- loss_d: 0.665178
0.5452 --- loss_d: 0.609507
0.6231 --- loss_d: 0.377981
0.7009 --- loss_d: 0.213882
0.7788 --- loss_d: 0.384021
0.8567 --- loss_d: 0.392801
0.9346 --- loss_d: 0.177578
Epoch finished! Loss: 0.46472881513182074
Starting epoch 3/10.
0.0000 --- loss_d: 0.214955
0.0779 --- loss_d: 0.511144
0.1558 --- loss_d: 0.204657
0.2336 --- loss_d: 0.264755
0.3115 --- loss_d: 0.168784
0.3894 --- loss_d: 0.551539
0.4673 --- loss_d: 0.177341
0.5452 --- loss_d: 0.189512
0.6231 --- loss_d: 0.145183
0.7009 --- loss_d: 0.240779
0.7788 --- loss_d: 0.060022
0.8567 --- loss_d: 0.349501
0.9346 --- loss_d: 0.311791
Epoch finished! Loss: 0.3022828888206277
Starting epoch 4/10.
0.0000 --- loss_d: 0.133027
0.0779 --- loss_d: 0.188457
0.1558 --- loss_d: 0.120330
0.2336 --- loss_d: 0.189067
0.3115 --- loss_d: 0.823264
0.3894 --- loss_d: 0.891884
0.4673 --- loss_d: 0.519765
0.5452 --- loss_d: 0.074689
0.6231 --- loss_d: 0.353298
0.7009 --- loss_d: 0.083873
0.7788 --- loss_d: 0.103119
0.8567 --- loss_d: 0.180881
0.9346 --- loss_d: 0.167981
Epoch finished! Loss: 0.24042414872383233
Starting epoch 5/10.
0.0000 --- loss_d: 0.033850
0.0779 --- loss_d: 0.062259
0.1558 --- loss_d: 0.014885
0.2336 --- loss_d: 0.109722
0.3115 --- loss_d: 0.152528
0.3894 --- loss_d: 0.223105
0.4673 --- loss_d: 0.162989
0.5452 --- loss_d: 0.389543
0.6231 --- loss_d: 0.207688
0.7009 --- loss_d: 0.198270
0.7788 --- loss_d: 0.092116
0.8567 --- loss_d: 0.169011
0.9346 --- loss_d: 0.054646
Epoch finished! Loss: 0.15242612768270192
Starting epoch 6/10.
0.0000 --- loss_d: 0.020129
0.0779 --- loss_d: 0.139423
0.1558 --- loss_d: 0.125816
0.2336 --- loss_d: 0.163518
0.3115 --- loss_d: 0.063344
0.3894 --- loss_d: 0.051710
0.4673 --- loss_d: 0.126580
0.5452 --- loss_d: 0.475333
0.6231 --- loss_d: 0.048733
0.7009 --- loss_d: 0.376841
0.7788 --- loss_d: 0.029535
0.8567 --- loss_d: 0.118998
0.9346 --- loss_d: 0.260508
Epoch finished! Loss: 0.13428571071563056
Starting epoch 7/10.
0.0000 --- loss_d: 0.142674
0.0779 --- loss_d: 0.066338
0.1558 --- loss_d: 0.033142
0.2336 --- loss_d: 0.050429
0.3115 --- loss_d: 0.058975
0.3894 --- loss_d: 0.047358
0.4673 --- loss_d: 0.088985
0.5452 --- loss_d: 0.210993
0.6231 --- loss_d: 0.200330
0.7009 --- loss_d: 0.270793
0.7788 --- loss_d: 0.069655
0.8567 --- loss_d: 0.053684
0.9346 --- loss_d: 0.048560
Epoch finished! Loss: 0.13894150298074237
Starting epoch 8/10.
0.0000 --- loss_d: 0.049230
0.0779 --- loss_d: 0.017271
0.1558 --- loss_d: 0.011063
0.2336 --- loss_d: 0.046869
0.3115 --- loss_d: 0.009502
0.3894 --- loss_d: 0.018599
0.4673 --- loss_d: 0.033875
0.5452 --- loss_d: 0.014567
0.6231 --- loss_d: 0.009325
0.7009 --- loss_d: 0.101262
0.7788 --- loss_d: 0.098526
0.8567 --- loss_d: 0.038011
0.9346 --- loss_d: 0.103346
Epoch finished! Loss: 0.08337349801149685
Starting epoch 9/10.
0.0000 --- loss_d: 0.003494
0.0779 --- loss_d: 0.409323
0.1558 --- loss_d: 0.010463
0.2336 --- loss_d: 0.031005
0.3115 --- loss_d: 0.035814
0.3894 --- loss_d: 0.361675
0.4673 --- loss_d: 0.019584
0.5452 --- loss_d: 0.011022
0.6231 --- loss_d: 0.012205
0.7009 --- loss_d: 0.133534
0.7788 --- loss_d: 0.011582
0.8567 --- loss_d: 0.096170
0.9346 --- loss_d: 0.027040
Epoch finished! Loss: 0.06890559034445687
Starting epoch 10/10.
0.0000 --- loss_d: 0.003197
0.0779 --- loss_d: 0.069911
0.1558 --- loss_d: 0.053970
0.2336 --- loss_d: 0.271085
0.3115 --- loss_d: 0.006559
0.3894 --- loss_d: 0.011707
0.4673 --- loss_d: 0.024750
0.5452 --- loss_d: 0.038351
0.6231 --- loss_d: 0.017396
0.7009 --- loss_d: 0.061478
0.7788 --- loss_d: 0.004373
0.8567 --- loss_d: 0.011472
0.9346 --- loss_d: 0.034010
Epoch finished! Loss: 0.07225197991283494
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.9994325  0.95193756 0.99542266 0.88614845 0.97580862 0.99974436
 0.99995458 0.93519378 0.99493128 0.99494791 0.99993801 0.99979168
 0.97900987 0.99999988 0.97761089 0.95673323]
pred: 0.9779128283262253, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp052-nsrr

=== Test on chp053-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.707675
0.0780 --- loss_d: 1.095260
0.1560 --- loss_d: 0.636890
0.2340 --- loss_d: 0.346007
0.3120 --- loss_d: 0.524702
0.3900 --- loss_d: 0.624811
0.4680 --- loss_d: 0.563495
0.5460 --- loss_d: 0.677970
0.6240 --- loss_d: 0.549650
0.7020 --- loss_d: 0.477249
0.7800 --- loss_d: 0.387151
0.8580 --- loss_d: 0.407010
0.9360 --- loss_d: 0.797826
Epoch finished! Loss: 0.60047774144914
Starting epoch 2/10.
0.0000 --- loss_d: 0.911203
0.0780 --- loss_d: 0.603437
0.1560 --- loss_d: 0.278189
0.2340 --- loss_d: 0.616896
0.3120 --- loss_d: 0.382345
0.3900 --- loss_d: 0.292255
0.4680 --- loss_d: 0.700613
0.5460 --- loss_d: 0.248748
0.6240 --- loss_d: 0.313457
0.7020 --- loss_d: 0.443986
0.7800 --- loss_d: 0.307027
0.8580 --- loss_d: 0.354858
0.9360 --- loss_d: 0.505822
Epoch finished! Loss: 0.45801132125779986
Starting epoch 3/10.
0.0000 --- loss_d: 0.249122
0.0780 --- loss_d: 0.238523
0.1560 --- loss_d: 0.611743
0.2340 --- loss_d: 0.601339
0.3120 --- loss_d: 0.154177
0.3900 --- loss_d: 0.062291
0.4680 --- loss_d: 0.218009
0.5460 --- loss_d: 0.522085
0.6240 --- loss_d: 0.195973
0.7020 --- loss_d: 0.054385
0.7800 --- loss_d: 0.055026
0.8580 --- loss_d: 0.690734
0.9360 --- loss_d: 0.234700
Epoch finished! Loss: 0.2766245052043814
Starting epoch 4/10.
0.0000 --- loss_d: 0.113041
0.0780 --- loss_d: 0.360846
0.1560 --- loss_d: 0.493963
0.2340 --- loss_d: 0.174558
0.3120 --- loss_d: 0.268757
0.3900 --- loss_d: 0.097736
0.4680 --- loss_d: 0.349921
0.5460 --- loss_d: 0.068327
0.6240 --- loss_d: 0.356642
0.7020 --- loss_d: 0.122555
0.7800 --- loss_d: 0.596251
0.8580 --- loss_d: 0.904675
0.9360 --- loss_d: 0.231015
Epoch finished! Loss: 0.24626923675532453
Starting epoch 5/10.
0.0000 --- loss_d: 0.118990
0.0780 --- loss_d: 0.079172
0.1560 --- loss_d: 0.312379
0.2340 --- loss_d: 0.153607
0.3120 --- loss_d: 0.166431
0.3900 --- loss_d: 0.080670
0.4680 --- loss_d: 0.017040
0.5460 --- loss_d: 0.103316
0.6240 --- loss_d: 0.504678
0.7020 --- loss_d: 0.177587
0.7800 --- loss_d: 0.632759
0.8580 --- loss_d: 0.033736
0.9360 --- loss_d: 0.036209
Epoch finished! Loss: 0.20372082806716207
Starting epoch 6/10.
0.0000 --- loss_d: 0.092051
0.0780 --- loss_d: 0.122892
0.1560 --- loss_d: 0.108026
0.2340 --- loss_d: 0.006539
0.3120 --- loss_d: 0.007175
0.3900 --- loss_d: 0.279247
0.4680 --- loss_d: 0.069118
0.5460 --- loss_d: 0.041705
0.6240 --- loss_d: 0.059382
0.7020 --- loss_d: 0.017401
0.7800 --- loss_d: 0.107498
0.8580 --- loss_d: 0.129419
0.9360 --- loss_d: 0.203328
Epoch finished! Loss: 0.1482249078908353
Starting epoch 7/10.
0.0000 --- loss_d: 0.056912
0.0780 --- loss_d: 0.028284
0.1560 --- loss_d: 0.031775
0.2340 --- loss_d: 0.020421
0.3120 --- loss_d: 0.325967
0.3900 --- loss_d: 0.223471
0.4680 --- loss_d: 0.158821
0.5460 --- loss_d: 0.006871
0.6240 --- loss_d: 0.138621
0.7020 --- loss_d: 0.016364
0.7800 --- loss_d: 0.037850
0.8580 --- loss_d: 0.070653
0.9360 --- loss_d: 0.049822
Epoch finished! Loss: 0.11502070534515951
Starting epoch 8/10.
0.0000 --- loss_d: 0.032185
0.0780 --- loss_d: 0.685094
0.1560 --- loss_d: 0.060637
0.2340 --- loss_d: 0.040946
0.3120 --- loss_d: 0.019912
0.3900 --- loss_d: 0.157646
0.4680 --- loss_d: 0.008328
0.5460 --- loss_d: 0.230638
0.6240 --- loss_d: 0.027715
0.7020 --- loss_d: 0.065838
0.7800 --- loss_d: 0.020362
0.8580 --- loss_d: 0.392571
0.9360 --- loss_d: 0.093248
Epoch finished! Loss: 0.13696661864196358
Starting epoch 9/10.
0.0000 --- loss_d: 0.006202
0.0780 --- loss_d: 0.006537
0.1560 --- loss_d: 0.038413
0.2340 --- loss_d: 0.043936
0.3120 --- loss_d: 0.047744
0.3900 --- loss_d: 0.112982
0.4680 --- loss_d: 0.031460
0.5460 --- loss_d: 0.022594
0.6240 --- loss_d: 0.012660
0.7020 --- loss_d: 0.018082
0.7800 --- loss_d: 0.056229
0.8580 --- loss_d: 0.024797
0.9360 --- loss_d: 0.019533
Epoch finished! Loss: 0.06734003625206242
Starting epoch 10/10.
0.0000 --- loss_d: 0.001605
0.0780 --- loss_d: 0.017512
0.1560 --- loss_d: 0.159836
0.2340 --- loss_d: 0.108720
0.3120 --- loss_d: 0.036047
0.3900 --- loss_d: 0.002939
0.4680 --- loss_d: 0.008909
0.5460 --- loss_d: 0.013563
0.6240 --- loss_d: 0.010721
0.7020 --- loss_d: 0.226979
0.7800 --- loss_d: 0.001702
0.8580 --- loss_d: 0.057910
0.9360 --- loss_d: 0.007349
Epoch finished! Loss: 0.09569579053174948
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999607 0.99904817 0.99957854 0.99999905 0.99999988 0.99999011
 0.99999785 0.99997258 0.99989188 0.99999869 0.99999928 0.99999893
 0.99977022 0.99949992 0.99985874 0.99998832 0.99791211 0.99999177]
pred: 0.9997495611508688, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp053-nsrr

=== Test on chp054-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.706946
0.0780 --- loss_d: 0.769254
0.1560 --- loss_d: 0.491775
0.2340 --- loss_d: 0.538804
0.3120 --- loss_d: 0.402170
0.3900 --- loss_d: 0.328364
0.4680 --- loss_d: 0.707792
0.5460 --- loss_d: 0.599099
0.6240 --- loss_d: 0.931555
0.7020 --- loss_d: 0.548299
0.7800 --- loss_d: 0.383683
0.8580 --- loss_d: 0.525364
0.9360 --- loss_d: 0.437481
Epoch finished! Loss: 0.5921228800434619
Starting epoch 2/10.
0.0000 --- loss_d: 0.330731
0.0780 --- loss_d: 0.704560
0.1560 --- loss_d: 0.682894
0.2340 --- loss_d: 0.580262
0.3120 --- loss_d: 0.621864
0.3900 --- loss_d: 0.145643
0.4680 --- loss_d: 0.767744
0.5460 --- loss_d: 0.338079
0.6240 --- loss_d: 0.559011
0.7020 --- loss_d: 0.210028
0.7800 --- loss_d: 0.177216
0.8580 --- loss_d: 0.708974
0.9360 --- loss_d: 0.407741
Epoch finished! Loss: 0.40525593532947823
Starting epoch 3/10.
0.0000 --- loss_d: 0.363851
0.0780 --- loss_d: 0.063267
0.1560 --- loss_d: 0.145477
0.2340 --- loss_d: 0.111392
0.3120 --- loss_d: 0.165803
0.3900 --- loss_d: 0.185012
0.4680 --- loss_d: 0.175922
0.5460 --- loss_d: 0.128621
0.6240 --- loss_d: 0.169546
0.7020 --- loss_d: 0.053886
0.7800 --- loss_d: 0.158830
0.8580 --- loss_d: 0.174661
0.9360 --- loss_d: 0.138698
Epoch finished! Loss: 0.2767010740644764
Starting epoch 4/10.
0.0000 --- loss_d: 0.398736
0.0780 --- loss_d: 0.125456
0.1560 --- loss_d: 0.046256
0.2340 --- loss_d: 0.108440
0.3120 --- loss_d: 0.275373
0.3900 --- loss_d: 0.373293
0.4680 --- loss_d: 0.318183
0.5460 --- loss_d: 0.461303
0.6240 --- loss_d: 0.091516
0.7020 --- loss_d: 0.389268
0.7800 --- loss_d: 0.241164
0.8580 --- loss_d: 0.174724
0.9360 --- loss_d: 0.074543
Epoch finished! Loss: 0.22758362242893782
Starting epoch 5/10.
0.0000 --- loss_d: 0.284125
0.0780 --- loss_d: 0.594092
0.1560 --- loss_d: 0.243729
0.2340 --- loss_d: 0.066133
0.3120 --- loss_d: 0.266856
0.3900 --- loss_d: 0.018847
0.4680 --- loss_d: 0.101501
0.5460 --- loss_d: 0.064425
0.6240 --- loss_d: 0.305008
0.7020 --- loss_d: 0.142276
0.7800 --- loss_d: 0.337439
0.8580 --- loss_d: 0.490892
0.9360 --- loss_d: 0.077312
Epoch finished! Loss: 0.17588444919965696
Starting epoch 6/10.
0.0000 --- loss_d: 0.111289
0.0780 --- loss_d: 0.115461
0.1560 --- loss_d: 0.399438
0.2340 --- loss_d: 0.217896
0.3120 --- loss_d: 0.188935
0.3900 --- loss_d: 0.027445
0.4680 --- loss_d: 0.327578
0.5460 --- loss_d: 0.069154
0.6240 --- loss_d: 0.426251
0.7020 --- loss_d: 0.106982
0.7800 --- loss_d: 0.034449
0.8580 --- loss_d: 0.159864
0.9360 --- loss_d: 0.370121
Epoch finished! Loss: 0.1271198886406637
Starting epoch 7/10.
0.0000 --- loss_d: 0.021190
0.0780 --- loss_d: 0.136072
0.1560 --- loss_d: 0.785327
0.2340 --- loss_d: 0.038856
0.3120 --- loss_d: 2.503499
0.3900 --- loss_d: 0.280297
0.4680 --- loss_d: 0.114359
0.5460 --- loss_d: 0.156906
0.6240 --- loss_d: 0.056257
0.7020 --- loss_d: 0.092693
0.7800 --- loss_d: 0.161420
0.8580 --- loss_d: 0.011271
0.9360 --- loss_d: 0.311640
Epoch finished! Loss: 0.12779013542240136
Starting epoch 8/10.
0.0000 --- loss_d: 0.004344
0.0780 --- loss_d: 0.049205
0.1560 --- loss_d: 0.067041
0.2340 --- loss_d: 0.017370
0.3120 --- loss_d: 0.087130
0.3900 --- loss_d: 0.011704
0.4680 --- loss_d: 0.360756
0.5460 --- loss_d: 0.033253
0.6240 --- loss_d: 0.088304
0.7020 --- loss_d: 0.002566
0.7800 --- loss_d: 0.012785
0.8580 --- loss_d: 0.006188
0.9360 --- loss_d: 0.009989
Epoch finished! Loss: 0.09796455214473099
Starting epoch 9/10.
0.0000 --- loss_d: 0.011726
0.0780 --- loss_d: 0.001758
0.1560 --- loss_d: 0.004160
0.2340 --- loss_d: 0.026023
0.3120 --- loss_d: 0.058113
0.3900 --- loss_d: 0.002573
0.4680 --- loss_d: 0.022293
0.5460 --- loss_d: 0.097925
0.6240 --- loss_d: 0.029109
0.7020 --- loss_d: 0.018989
0.7800 --- loss_d: 0.001027
0.8580 --- loss_d: 0.009517
0.9360 --- loss_d: 0.109671
Epoch finished! Loss: 0.09433202620857628
Starting epoch 10/10.
0.0000 --- loss_d: 0.013914
0.0780 --- loss_d: 0.085572
0.1560 --- loss_d: 0.063173
0.2340 --- loss_d: 0.020566
0.3120 --- loss_d: 0.015528
0.3900 --- loss_d: 0.037155
0.4680 --- loss_d: 0.033256
0.5460 --- loss_d: 0.119165
0.6240 --- loss_d: 0.069360
0.7020 --- loss_d: 0.038576
0.7800 --- loss_d: 0.068611
0.8580 --- loss_d: 0.025590
0.9360 --- loss_d: 0.012817
Epoch finished! Loss: 0.09999514791616093
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.9992435  0.99748492 0.99980158 0.9807303  0.97561318 0.95266026
 0.99174339 0.95618498 0.99758768 0.99574924 0.99814737 0.9441542
 0.9966749  0.99940813 0.99964511 0.99997354 0.99993324 0.99993813]
pred: 0.9880374239550697, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp054-nsrr

=== Test on chp055-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.776838
0.0780 --- loss_d: 1.080541
0.1560 --- loss_d: 0.712763
0.2340 --- loss_d: 0.793604
0.3120 --- loss_d: 0.951295
0.3900 --- loss_d: 0.641976
0.4680 --- loss_d: 0.334486
0.5460 --- loss_d: 0.778302
0.6240 --- loss_d: 0.619204
0.7020 --- loss_d: 0.639501
0.7800 --- loss_d: 0.579991
0.8580 --- loss_d: 0.603865
0.9360 --- loss_d: 0.944340
Epoch finished! Loss: 0.6231041736900806
Starting epoch 2/10.
0.0000 --- loss_d: 0.389988
0.0780 --- loss_d: 0.473603
0.1560 --- loss_d: 0.647055
0.2340 --- loss_d: 0.536454
0.3120 --- loss_d: 0.320920
0.3900 --- loss_d: 0.568711
0.4680 --- loss_d: 0.757498
0.5460 --- loss_d: 0.534054
0.6240 --- loss_d: 0.325101
0.7020 --- loss_d: 0.380805
0.7800 --- loss_d: 0.100586
0.8580 --- loss_d: 0.426087
0.9360 --- loss_d: 0.327757
Epoch finished! Loss: 0.45459318545181304
Starting epoch 3/10.
0.0000 --- loss_d: 0.107026
0.0780 --- loss_d: 0.297103
0.1560 --- loss_d: 1.097602
0.2340 --- loss_d: 0.130916
0.3120 --- loss_d: 0.337999
0.3900 --- loss_d: 0.134327
0.4680 --- loss_d: 0.127098
0.5460 --- loss_d: 0.304058
0.6240 --- loss_d: 0.103390
0.7020 --- loss_d: 0.263119
0.7800 --- loss_d: 0.233676
0.8580 --- loss_d: 0.636807
0.9360 --- loss_d: 0.320328
Epoch finished! Loss: 0.2834582697832957
Starting epoch 4/10.
0.0000 --- loss_d: 0.354622
0.0780 --- loss_d: 0.178558
0.1560 --- loss_d: 0.211889
0.2340 --- loss_d: 0.272293
0.3120 --- loss_d: 0.485329
0.3900 --- loss_d: 0.437478
0.4680 --- loss_d: 0.147300
0.5460 --- loss_d: 0.065637
0.6240 --- loss_d: 0.159444
0.7020 --- loss_d: 0.353579
0.7800 --- loss_d: 0.847963
0.8580 --- loss_d: 0.216048
0.9360 --- loss_d: 0.452790
Epoch finished! Loss: 0.2601323785347631
Starting epoch 5/10.
0.0000 --- loss_d: 0.202848
0.0780 --- loss_d: 0.261507
0.1560 --- loss_d: 0.260458
0.2340 --- loss_d: 0.371577
0.3120 --- loss_d: 0.436557
0.3900 --- loss_d: 0.162393
0.4680 --- loss_d: 0.149962
0.5460 --- loss_d: 0.057941
0.6240 --- loss_d: 0.249781
0.7020 --- loss_d: 0.034178
0.7800 --- loss_d: 0.036393
0.8580 --- loss_d: 0.039226
0.9360 --- loss_d: 0.054925
Epoch finished! Loss: 0.1758780416166701
Starting epoch 6/10.
0.0000 --- loss_d: 0.041200
0.0780 --- loss_d: 0.085742
0.1560 --- loss_d: 0.138194
0.2340 --- loss_d: 0.020137
0.3120 --- loss_d: 0.038655
0.3900 --- loss_d: 0.400182
0.4680 --- loss_d: 0.930110
0.5460 --- loss_d: 0.016741
0.6240 --- loss_d: 0.006795
0.7020 --- loss_d: 0.009877
0.7800 --- loss_d: 0.355690
0.8580 --- loss_d: 0.364906
0.9360 --- loss_d: 0.199671
Epoch finished! Loss: 0.13577119309775298
Starting epoch 7/10.
0.0000 --- loss_d: 0.170674
0.0780 --- loss_d: 0.111323
0.1560 --- loss_d: 0.040461
0.2340 --- loss_d: 0.070775
0.3120 --- loss_d: 0.150433
0.3900 --- loss_d: 0.328271
0.4680 --- loss_d: 0.056696
0.5460 --- loss_d: 0.034230
0.6240 --- loss_d: 0.007512
0.7020 --- loss_d: 0.105264
0.7800 --- loss_d: 0.006027
0.8580 --- loss_d: 0.050000
0.9360 --- loss_d: 0.046148
Epoch finished! Loss: 0.11538280703643977
Starting epoch 8/10.
0.0000 --- loss_d: 0.011330
0.0780 --- loss_d: 0.076427
0.1560 --- loss_d: 0.086238
0.2340 --- loss_d: 0.304529
0.3120 --- loss_d: 0.024285
0.3900 --- loss_d: 0.473831
0.4680 --- loss_d: 0.298430
0.5460 --- loss_d: 0.040904
0.6240 --- loss_d: 0.002598
0.7020 --- loss_d: 0.007329
0.7800 --- loss_d: 0.073909
0.8580 --- loss_d: 0.167048
0.9360 --- loss_d: 0.020441
Epoch finished! Loss: 0.12186752748493745
Starting epoch 9/10.
0.0000 --- loss_d: 0.237746
0.0780 --- loss_d: 0.018765
0.1560 --- loss_d: 0.040340
0.2340 --- loss_d: 0.002280
0.3120 --- loss_d: 0.006637
0.3900 --- loss_d: 0.007675
0.4680 --- loss_d: 0.028475
0.5460 --- loss_d: 0.052797
0.6240 --- loss_d: 0.002575
0.7020 --- loss_d: 0.058127
0.7800 --- loss_d: 0.009972
0.8580 --- loss_d: 0.011922
0.9360 --- loss_d: 0.001234
Epoch finished! Loss: 0.05527420685984907
Starting epoch 10/10.
0.0000 --- loss_d: 0.122472
0.0780 --- loss_d: 0.035874
0.1560 --- loss_d: 0.018757
0.2340 --- loss_d: 0.008935
0.3120 --- loss_d: 0.010360
0.3900 --- loss_d: 0.006440
0.4680 --- loss_d: 0.077962
0.5460 --- loss_d: 0.077753
0.6240 --- loss_d: 0.007545
0.7020 --- loss_d: 0.036885
0.7800 --- loss_d: 0.072583
0.8580 --- loss_d: 0.086866
0.9360 --- loss_d: 0.025592
Epoch finished! Loss: 0.07236407048003457
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99854726 0.99956781 0.99966824 0.92714953 0.99966264 0.99999487
 0.99999464 0.99960631 0.89005876 0.99999774 0.9999491  0.99999833
 0.99950838 0.99972886 0.99997449 0.99999177 0.99998701 0.99959344]
pred: 0.9896099534299638, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp055-nsrr

=== Test on chp056-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.651337
0.0780 --- loss_d: 0.794958
0.1560 --- loss_d: 0.378883
0.2340 --- loss_d: 0.572466
0.3120 --- loss_d: 0.707760
0.3900 --- loss_d: 0.993862
0.4680 --- loss_d: 0.576607
0.5460 --- loss_d: 0.425836
0.6240 --- loss_d: 0.635279
0.7020 --- loss_d: 0.719938
0.7800 --- loss_d: 0.558613
0.8580 --- loss_d: 0.707538
0.9360 --- loss_d: 0.479294
Epoch finished! Loss: 0.6069964206544682
Starting epoch 2/10.
0.0000 --- loss_d: 0.264581
0.0780 --- loss_d: 0.310654
0.1560 --- loss_d: 1.016370
0.2340 --- loss_d: 0.436607
0.3120 --- loss_d: 0.256508
0.3900 --- loss_d: 0.415550
0.4680 --- loss_d: 0.201006
0.5460 --- loss_d: 0.438811
0.6240 --- loss_d: 0.394002
0.7020 --- loss_d: 0.228626
0.7800 --- loss_d: 0.459388
0.8580 --- loss_d: 0.250549
0.9360 --- loss_d: 0.948986
Epoch finished! Loss: 0.4167387278866954
Starting epoch 3/10.
0.0000 --- loss_d: 0.286439
0.0780 --- loss_d: 0.493875
0.1560 --- loss_d: 0.478777
0.2340 --- loss_d: 0.101236
0.3120 --- loss_d: 0.370115
0.3900 --- loss_d: 0.215315
0.4680 --- loss_d: 0.167584
0.5460 --- loss_d: 0.353126
0.6240 --- loss_d: 0.109964
0.7020 --- loss_d: 0.219647
0.7800 --- loss_d: 0.065005
0.8580 --- loss_d: 0.684087
0.9360 --- loss_d: 0.423587
Epoch finished! Loss: 0.31440696492791176
Starting epoch 4/10.
0.0000 --- loss_d: 0.471292
0.0780 --- loss_d: 0.193472
0.1560 --- loss_d: 0.092404
0.2340 --- loss_d: 0.152593
0.3120 --- loss_d: 0.026354
0.3900 --- loss_d: 0.186609
0.4680 --- loss_d: 0.923160
0.5460 --- loss_d: 0.089651
0.6240 --- loss_d: 0.791693
0.7020 --- loss_d: 0.141907
0.7800 --- loss_d: 0.131361
0.8580 --- loss_d: 0.156078
0.9360 --- loss_d: 0.051415
Epoch finished! Loss: 0.20930962338024983
Starting epoch 5/10.
0.0000 --- loss_d: 0.268826
0.0780 --- loss_d: 0.044465
0.1560 --- loss_d: 0.093687
0.2340 --- loss_d: 0.041663
0.3120 --- loss_d: 0.177518
0.3900 --- loss_d: 0.070927
0.4680 --- loss_d: 0.054486
0.5460 --- loss_d: 0.064089
0.6240 --- loss_d: 0.177976
0.7020 --- loss_d: 0.204125
0.7800 --- loss_d: 0.037088
0.8580 --- loss_d: 0.295234
0.9360 --- loss_d: 0.085124
Epoch finished! Loss: 0.15237195369263645
Starting epoch 6/10.
0.0000 --- loss_d: 0.031010
0.0780 --- loss_d: 0.039085
0.1560 --- loss_d: 0.127534
0.2340 --- loss_d: 0.101532
0.3120 --- loss_d: 0.022852
0.3900 --- loss_d: 0.113773
0.4680 --- loss_d: 0.003593
0.5460 --- loss_d: 0.061033
0.6240 --- loss_d: 0.017260
0.7020 --- loss_d: 0.196938
0.7800 --- loss_d: 0.035593
0.8580 --- loss_d: 0.005331
0.9360 --- loss_d: 0.048553
Epoch finished! Loss: 0.1052123266235867
Starting epoch 7/10.
0.0000 --- loss_d: 0.206678
0.0780 --- loss_d: 0.047743
0.1560 --- loss_d: 0.028813
0.2340 --- loss_d: 0.092499
0.3120 --- loss_d: 0.021209
0.3900 --- loss_d: 0.089847
0.4680 --- loss_d: 0.116348
0.5460 --- loss_d: 0.039429
0.6240 --- loss_d: 0.052990
0.7020 --- loss_d: 0.333827
0.7800 --- loss_d: 0.041172
0.8580 --- loss_d: 0.236370
0.9360 --- loss_d: 0.198359
Epoch finished! Loss: 0.10081996836561302
Starting epoch 8/10.
0.0000 --- loss_d: 0.018419
0.0780 --- loss_d: 1.581766
0.1560 --- loss_d: 0.126328
0.2340 --- loss_d: 0.217103
0.3120 --- loss_d: 0.092533
0.3900 --- loss_d: 0.114320
0.4680 --- loss_d: 0.036296
0.5460 --- loss_d: 0.088280
0.6240 --- loss_d: 0.069275
0.7020 --- loss_d: 0.022945
0.7800 --- loss_d: 0.080902
0.8580 --- loss_d: 0.016875
0.9360 --- loss_d: 0.067321
Epoch finished! Loss: 0.13915334248758882
Starting epoch 9/10.
0.0000 --- loss_d: 0.050794
0.0780 --- loss_d: 0.002714
0.1560 --- loss_d: 0.034915
0.2340 --- loss_d: 0.008583
0.3120 --- loss_d: 0.112759
0.3900 --- loss_d: 0.011131
0.4680 --- loss_d: 0.034097
0.5460 --- loss_d: 0.145416
0.6240 --- loss_d: 0.470019
0.7020 --- loss_d: 0.083459
0.7800 --- loss_d: 0.003624
0.8580 --- loss_d: 0.013865
0.9360 --- loss_d: 0.016661
Epoch finished! Loss: 0.05313223402208678
Starting epoch 10/10.
0.0000 --- loss_d: 0.004223
0.0780 --- loss_d: 0.097608
0.1560 --- loss_d: 0.001416
0.2340 --- loss_d: 0.018954
0.3120 --- loss_d: 0.005926
0.3900 --- loss_d: 0.006269
0.4680 --- loss_d: 0.003193
0.5460 --- loss_d: 0.019360
0.6240 --- loss_d: 0.010890
0.7020 --- loss_d: 0.002901
0.7800 --- loss_d: 0.012164
0.8580 --- loss_d: 0.005020
0.9360 --- loss_d: 0.076424
Epoch finished! Loss: 0.030728173850889107
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 0.9444444444444444
[0.99479634 0.9998067  0.99956816 0.99999058 0.99997091 0.99981302
 0.99922335 0.99999964 0.99999964 0.99998772 0.99999595 0.99997735
 0.99386215 0.08624953 0.99996758 0.99992812 0.99998212 0.99997568]
pred: 0.9485052525997162, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp056-nsrr

=== Test on chp057-nsrr. train_data(1281), test_data(19) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.745588
0.0781 --- loss_d: 0.570793
0.1561 --- loss_d: 0.511934
0.2342 --- loss_d: 0.721168
0.3123 --- loss_d: 0.504636
0.3903 --- loss_d: 0.793278
0.4684 --- loss_d: 0.811545
0.5464 --- loss_d: 0.513172
0.6245 --- loss_d: 0.482933
0.7026 --- loss_d: 0.423565
0.7806 --- loss_d: 0.542941
0.8587 --- loss_d: 0.538943
0.9368 --- loss_d: 0.231461
Epoch finished! Loss: 0.6237033162033185
Starting epoch 2/10.
0.0000 --- loss_d: 0.524889
0.0781 --- loss_d: 0.608304
0.1561 --- loss_d: 0.934435
0.2342 --- loss_d: 0.646762
0.3123 --- loss_d: 0.808465
0.3903 --- loss_d: 0.820917
0.4684 --- loss_d: 0.396848
0.5464 --- loss_d: 0.550689
0.6245 --- loss_d: 0.417774
0.7026 --- loss_d: 0.546774
0.7806 --- loss_d: 0.399325
0.8587 --- loss_d: 0.778940
0.9368 --- loss_d: 0.439800
Epoch finished! Loss: 0.5168881460558623
Starting epoch 3/10.
0.0000 --- loss_d: 0.146479
0.0781 --- loss_d: 0.304240
0.1561 --- loss_d: 0.656357
0.2342 --- loss_d: 0.335959
0.3123 --- loss_d: 0.193488
0.3903 --- loss_d: 0.154320
0.4684 --- loss_d: 0.086169
0.5464 --- loss_d: 0.229654
0.6245 --- loss_d: 0.763249
0.7026 --- loss_d: 0.148211
0.7806 --- loss_d: 0.490286
0.8587 --- loss_d: 0.469111
0.9368 --- loss_d: 0.344229
Epoch finished! Loss: 0.34217539051314816
Starting epoch 4/10.
0.0000 --- loss_d: 0.095790
0.0781 --- loss_d: 0.210762
0.1561 --- loss_d: 0.346472
0.2342 --- loss_d: 0.049974
0.3123 --- loss_d: 0.126919
0.3903 --- loss_d: 0.153920
0.4684 --- loss_d: 0.425935
0.5464 --- loss_d: 0.137590
0.6245 --- loss_d: 0.267434
0.7026 --- loss_d: 0.088991
0.7806 --- loss_d: 0.060782
0.8587 --- loss_d: 0.709804
0.9368 --- loss_d: 0.436133
Epoch finished! Loss: 0.2613571349065751
Starting epoch 5/10.
0.0000 --- loss_d: 0.227322
0.0781 --- loss_d: 0.371321
0.1561 --- loss_d: 0.069152
0.2342 --- loss_d: 0.351396
0.3123 --- loss_d: 0.241383
0.3903 --- loss_d: 0.281068
0.4684 --- loss_d: 0.147117
0.5464 --- loss_d: 0.277830
0.6245 --- loss_d: 0.046512
0.7026 --- loss_d: 0.059531
0.7806 --- loss_d: 0.082416
0.8587 --- loss_d: 0.193397
0.9368 --- loss_d: 0.045664
Epoch finished! Loss: 0.22957343816233333
Starting epoch 6/10.
0.0000 --- loss_d: 0.045816
0.0781 --- loss_d: 0.162937
0.1561 --- loss_d: 0.022070
0.2342 --- loss_d: 0.045700
0.3123 --- loss_d: 0.040768
0.3903 --- loss_d: 0.128854
0.4684 --- loss_d: 0.288002
0.5464 --- loss_d: 0.286248
0.6245 --- loss_d: 0.132626
0.7026 --- loss_d: 0.168235
0.7806 --- loss_d: 0.183972
0.8587 --- loss_d: 0.056264
0.9368 --- loss_d: 0.018547
Epoch finished! Loss: 0.13250831335608382
Starting epoch 7/10.
0.0000 --- loss_d: 0.022402
0.0781 --- loss_d: 0.035680
0.1561 --- loss_d: 0.074912
0.2342 --- loss_d: 0.057729
0.3123 --- loss_d: 0.236601
0.3903 --- loss_d: 0.035109
0.4684 --- loss_d: 0.052089
0.5464 --- loss_d: 0.007698
0.6245 --- loss_d: 0.080871
0.7026 --- loss_d: 0.013414
0.7806 --- loss_d: 0.045784
0.8587 --- loss_d: 0.212611
0.9368 --- loss_d: 0.084902
Epoch finished! Loss: 0.12892701331111311
Starting epoch 8/10.
0.0000 --- loss_d: 0.058121
0.0781 --- loss_d: 0.128474
0.1561 --- loss_d: 0.425721
0.2342 --- loss_d: 0.061978
0.3123 --- loss_d: 0.011267
0.3903 --- loss_d: 0.006577
0.4684 --- loss_d: 0.023151
0.5464 --- loss_d: 0.110035
0.6245 --- loss_d: 0.090615
0.7026 --- loss_d: 0.132459
0.7806 --- loss_d: 0.050601
0.8587 --- loss_d: 0.075845
0.9368 --- loss_d: 0.167001
Epoch finished! Loss: 0.10901979980917531
Starting epoch 9/10.
0.0000 --- loss_d: 0.062596
0.0781 --- loss_d: 0.015249
0.1561 --- loss_d: 0.172288
0.2342 --- loss_d: 0.282258
0.3123 --- loss_d: 0.034817
0.3903 --- loss_d: 0.065239
0.4684 --- loss_d: 0.088673
0.5464 --- loss_d: 0.056636
0.6245 --- loss_d: 0.015173
0.7026 --- loss_d: 0.026317
0.7806 --- loss_d: 0.004993
0.8587 --- loss_d: 0.006188
0.9368 --- loss_d: 0.054615
Epoch finished! Loss: 0.07174601452464913
Starting epoch 10/10.
0.0000 --- loss_d: 0.142368
0.0781 --- loss_d: 0.001241
0.1561 --- loss_d: 0.003820
0.2342 --- loss_d: 0.003213
0.3123 --- loss_d: 0.001948
0.3903 --- loss_d: 0.008828
0.4684 --- loss_d: 0.001661
0.5464 --- loss_d: 0.008560
0.6245 --- loss_d: 0.000307
0.7026 --- loss_d: 0.016116
0.7806 --- loss_d: 0.037600
0.8587 --- loss_d: 0.367488
0.9368 --- loss_d: 0.042444
Epoch finished! Loss: 0.06020085404998099
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[1.         0.99975103 0.99999881 0.99999988 0.99999762 1.
 1.         1.         0.99999928 0.99999988 0.99999928 0.99999964
 0.99984169 0.99998975 1.         1.         0.9999969  1.
 1.        ]
pred: 0.9999775666939584, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp057-nsrr

=== Test on chp058-nsrr. train_data(1283), test_data(17) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.679286
0.0779 --- loss_d: 0.889937
0.1559 --- loss_d: 0.604237
0.2338 --- loss_d: 0.404650
0.3118 --- loss_d: 0.636545
0.3897 --- loss_d: 0.470124
0.4677 --- loss_d: 0.562130
0.5456 --- loss_d: 0.639582
0.6235 --- loss_d: 0.504938
0.7015 --- loss_d: 0.811915
0.7794 --- loss_d: 0.489249
0.8574 --- loss_d: 0.674830
0.9353 --- loss_d: 0.421159
Epoch finished! Loss: 0.6026062187738717
Starting epoch 2/10.
0.0000 --- loss_d: 0.429478
0.0779 --- loss_d: 0.471575
0.1559 --- loss_d: 0.502539
0.2338 --- loss_d: 0.528658
0.3118 --- loss_d: 0.370628
0.3897 --- loss_d: 0.636648
0.4677 --- loss_d: 0.511035
0.5456 --- loss_d: 0.340887
0.6235 --- loss_d: 0.247634
0.7015 --- loss_d: 0.409133
0.7794 --- loss_d: 0.558168
0.8574 --- loss_d: 0.680137
0.9353 --- loss_d: 0.346659
Epoch finished! Loss: 0.4511293671675958
Starting epoch 3/10.
0.0000 --- loss_d: 0.352575
0.0779 --- loss_d: 0.308984
0.1559 --- loss_d: 0.464218
0.2338 --- loss_d: 0.191212
0.3118 --- loss_d: 0.225524
0.3897 --- loss_d: 0.363834
0.4677 --- loss_d: 0.180024
0.5456 --- loss_d: 0.206709
0.6235 --- loss_d: 0.248690
0.7015 --- loss_d: 0.779808
0.7794 --- loss_d: 0.284765
0.8574 --- loss_d: 0.313428
0.9353 --- loss_d: 0.353797
Epoch finished! Loss: 0.300686522241449
Starting epoch 4/10.
0.0000 --- loss_d: 0.117064
0.0779 --- loss_d: 0.293116
0.1559 --- loss_d: 0.136179
0.2338 --- loss_d: 0.176509
0.3118 --- loss_d: 0.150066
0.3897 --- loss_d: 0.209679
0.4677 --- loss_d: 0.238881
0.5456 --- loss_d: 0.130662
0.6235 --- loss_d: 0.115013
0.7015 --- loss_d: 0.803858
0.7794 --- loss_d: 0.724691
0.8574 --- loss_d: 0.104403
0.9353 --- loss_d: 0.188466
Epoch finished! Loss: 0.24022581843018997
Starting epoch 5/10.
0.0000 --- loss_d: 0.607133
0.0779 --- loss_d: 0.237794
0.1559 --- loss_d: 0.075495
0.2338 --- loss_d: 0.057622
0.3118 --- loss_d: 0.273296
0.3897 --- loss_d: 0.077535
0.4677 --- loss_d: 0.045556
0.5456 --- loss_d: 0.040533
0.6235 --- loss_d: 0.093402
0.7015 --- loss_d: 0.098822
0.7794 --- loss_d: 0.039492
0.8574 --- loss_d: 0.403694
0.9353 --- loss_d: 0.125777
Epoch finished! Loss: 0.20837171535822563
Starting epoch 6/10.
0.0000 --- loss_d: 0.426008
0.0779 --- loss_d: 0.071961
0.1559 --- loss_d: 0.044972
0.2338 --- loss_d: 0.164941
0.3118 --- loss_d: 0.642264
0.3897 --- loss_d: 0.224244
0.4677 --- loss_d: 0.037058
0.5456 --- loss_d: 0.122145
0.6235 --- loss_d: 0.330266
0.7015 --- loss_d: 0.077089
0.7794 --- loss_d: 0.240127
0.8574 --- loss_d: 0.199878
0.9353 --- loss_d: 0.091777
Epoch finished! Loss: 0.15382237740413984
Starting epoch 7/10.
0.0000 --- loss_d: 0.148696
0.0779 --- loss_d: 0.043580
0.1559 --- loss_d: 0.080061
0.2338 --- loss_d: 0.044756
0.3118 --- loss_d: 0.052051
0.3897 --- loss_d: 0.363644
0.4677 --- loss_d: 0.047163
0.5456 --- loss_d: 0.089329
0.6235 --- loss_d: 0.003645
0.7015 --- loss_d: 0.330454
0.7794 --- loss_d: 0.048213
0.8574 --- loss_d: 0.141117
0.9353 --- loss_d: 0.156184
Epoch finished! Loss: 0.13385704957545386
Starting epoch 8/10.
0.0000 --- loss_d: 0.086023
0.0779 --- loss_d: 0.021730
0.1559 --- loss_d: 0.008032
0.2338 --- loss_d: 0.066022
0.3118 --- loss_d: 0.061325
0.3897 --- loss_d: 0.015175
0.4677 --- loss_d: 0.011397
0.5456 --- loss_d: 0.125582
0.6235 --- loss_d: 0.008137
0.7015 --- loss_d: 0.328653
0.7794 --- loss_d: 0.224013
0.8574 --- loss_d: 0.040939
0.9353 --- loss_d: 0.021854
Epoch finished! Loss: 0.0777513142220414
Starting epoch 9/10.
0.0000 --- loss_d: 0.108431
0.0779 --- loss_d: 0.066383
0.1559 --- loss_d: 0.151279
0.2338 --- loss_d: 0.024178
0.3118 --- loss_d: 0.161737
0.3897 --- loss_d: 0.114590
0.4677 --- loss_d: 0.017593
0.5456 --- loss_d: 0.004411
0.6235 --- loss_d: 0.027417
0.7015 --- loss_d: 0.013075
0.7794 --- loss_d: 0.288357
0.8574 --- loss_d: 0.144347
0.9353 --- loss_d: 0.010349
Epoch finished! Loss: 0.10614205178171687
Starting epoch 10/10.
0.0000 --- loss_d: 0.039902
0.0779 --- loss_d: 0.020173
0.1559 --- loss_d: 0.007226
0.2338 --- loss_d: 0.134625
0.3118 --- loss_d: 0.008345
0.3897 --- loss_d: 0.000712
0.4677 --- loss_d: 0.065148
0.5456 --- loss_d: 0.040516
0.6235 --- loss_d: 0.050531
0.7015 --- loss_d: 0.006604
0.7794 --- loss_d: 0.002586
0.8574 --- loss_d: 0.003630
0.9353 --- loss_d: 0.044126
Epoch finished! Loss: 0.0990105035302804
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999356 0.99989831 0.99999571 0.99872655 0.99998462 0.99998558
 0.99999154 0.99987137 0.99999881 0.99998832 0.99999607 0.99999881
 0.99999988 0.99999714 0.99990535 0.9999814  0.99993908]
pred: 0.9998971819877625, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp058-nsrr

=== Test on chp059-nsrr. train_data(1282), test_data(18) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.805823
0.0780 --- loss_d: 0.778013
0.1560 --- loss_d: 0.543860
0.2340 --- loss_d: 0.825785
0.3120 --- loss_d: 0.424197
0.3900 --- loss_d: 0.675583
0.4680 --- loss_d: 0.590559
0.5460 --- loss_d: 0.564004
0.6240 --- loss_d: 0.449654
0.7020 --- loss_d: 0.796911
0.7800 --- loss_d: 0.453092
0.8580 --- loss_d: 0.391692
0.9360 --- loss_d: 0.592731
Epoch finished! Loss: 0.616239205468446
Starting epoch 2/10.
0.0000 --- loss_d: 0.408037
0.0780 --- loss_d: 0.417806
0.1560 --- loss_d: 0.795122
0.2340 --- loss_d: 0.410392
0.3120 --- loss_d: 0.444647
0.3900 --- loss_d: 0.591837
0.4680 --- loss_d: 0.400584
0.5460 --- loss_d: 0.351618
0.6240 --- loss_d: 0.468279
0.7020 --- loss_d: 0.580485
0.7800 --- loss_d: 0.156663
0.8580 --- loss_d: 0.319617
0.9360 --- loss_d: 0.457026
Epoch finished! Loss: 0.4184559464629274
Starting epoch 3/10.
0.0000 --- loss_d: 0.304430
0.0780 --- loss_d: 0.139133
0.1560 --- loss_d: 0.195610
0.2340 --- loss_d: 0.298456
0.3120 --- loss_d: 0.309564
0.3900 --- loss_d: 0.155185
0.4680 --- loss_d: 0.142362
0.5460 --- loss_d: 0.823789
0.6240 --- loss_d: 0.369714
0.7020 --- loss_d: 0.144883
0.7800 --- loss_d: 0.139928
0.8580 --- loss_d: 0.560436
0.9360 --- loss_d: 0.258995
Epoch finished! Loss: 0.2903582838480361
Starting epoch 4/10.
0.0000 --- loss_d: 0.099593
0.0780 --- loss_d: 0.220668
0.1560 --- loss_d: 0.174679
0.2340 --- loss_d: 0.132146
0.3120 --- loss_d: 0.378189
0.3900 --- loss_d: 0.513778
0.4680 --- loss_d: 0.183384
0.5460 --- loss_d: 0.304797
0.6240 --- loss_d: 0.150907
0.7020 --- loss_d: 0.027218
0.7800 --- loss_d: 0.054520
0.8580 --- loss_d: 0.265628
0.9360 --- loss_d: 0.326891
Epoch finished! Loss: 0.23217438939900603
Starting epoch 5/10.
0.0000 --- loss_d: 0.125161
0.0780 --- loss_d: 0.226603
0.1560 --- loss_d: 0.098885
0.2340 --- loss_d: 0.065566
0.3120 --- loss_d: 0.036926
0.3900 --- loss_d: 0.029244
0.4680 --- loss_d: 0.204299
0.5460 --- loss_d: 0.293343
0.6240 --- loss_d: 0.058673
0.7020 --- loss_d: 0.041407
0.7800 --- loss_d: 0.097028
0.8580 --- loss_d: 0.228892
0.9360 --- loss_d: 0.020365
Epoch finished! Loss: 0.17336357790918555
Starting epoch 6/10.
0.0000 --- loss_d: 0.099189
0.0780 --- loss_d: 0.052873
0.1560 --- loss_d: 0.186190
0.2340 --- loss_d: 0.032274
0.3120 --- loss_d: 0.062904
0.3900 --- loss_d: 0.101149
0.4680 --- loss_d: 0.185230
0.5460 --- loss_d: 0.247000
0.6240 --- loss_d: 0.253090
0.7020 --- loss_d: 0.063607
0.7800 --- loss_d: 0.017923
0.8580 --- loss_d: 0.014181
0.9360 --- loss_d: 0.031098
Epoch finished! Loss: 0.14451238948095124
Starting epoch 7/10.
0.0000 --- loss_d: 0.415766
0.0780 --- loss_d: 0.015953
0.1560 --- loss_d: 0.174831
0.2340 --- loss_d: 0.025293
0.3120 --- loss_d: 0.004981
0.3900 --- loss_d: 0.224172
0.4680 --- loss_d: 0.559434
0.5460 --- loss_d: 0.038876
0.6240 --- loss_d: 0.055629
0.7020 --- loss_d: 0.153988
0.7800 --- loss_d: 0.010330
0.8580 --- loss_d: 0.116830
0.9360 --- loss_d: 0.183952
Epoch finished! Loss: 0.11957529346182127
Starting epoch 8/10.
0.0000 --- loss_d: 0.046621
0.0780 --- loss_d: 0.070847
0.1560 --- loss_d: 0.008357
0.2340 --- loss_d: 0.004647
0.3120 --- loss_d: 0.005298
0.3900 --- loss_d: 0.039714
0.4680 --- loss_d: 0.020096
0.5460 --- loss_d: 0.150621
0.6240 --- loss_d: 0.018407
0.7020 --- loss_d: 0.003209
0.7800 --- loss_d: 0.153007
0.8580 --- loss_d: 0.084785
0.9360 --- loss_d: 0.003051
Epoch finished! Loss: 0.08743214512469422
Starting epoch 9/10.
0.0000 --- loss_d: 0.008873
0.0780 --- loss_d: 0.197377
0.1560 --- loss_d: 0.147366
0.2340 --- loss_d: 0.011768
0.3120 --- loss_d: 0.024889
0.3900 --- loss_d: 0.035488
0.4680 --- loss_d: 0.315518
0.5460 --- loss_d: 0.005448
0.6240 --- loss_d: 0.048054
0.7020 --- loss_d: 0.002840
0.7800 --- loss_d: 0.029121
0.8580 --- loss_d: 0.005321
0.9360 --- loss_d: 0.042319
Epoch finished! Loss: 0.09453854009007046
Starting epoch 10/10.
0.0000 --- loss_d: 0.003000
0.0780 --- loss_d: 0.198416
0.1560 --- loss_d: 0.007851
0.2340 --- loss_d: 0.010100
0.3120 --- loss_d: 0.478213
0.3900 --- loss_d: 0.012441
0.4680 --- loss_d: 0.202845
0.5460 --- loss_d: 0.027448
0.6240 --- loss_d: 0.046575
0.7020 --- loss_d: 0.005556
0.7800 --- loss_d: 0.003986
0.8580 --- loss_d: 0.010849
0.9360 --- loss_d: 0.024611
Epoch finished! Loss: 0.08069281401458284
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[0.99999881 0.99998224 0.99999642 0.99988723 1.         0.99999988
 0.99999988 0.99999905 0.99999821 0.99999928 1.         1.
 0.99997568 0.9999851  0.99999964 1.         0.99998462 0.99983311]
pred: 0.9999799529711405, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp059-nsrr

=== Test on chp060-nsrr. train_data(1279), test_data(21) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Starting epoch 1/10.
0.0000 --- loss_d: 0.657829
0.0782 --- loss_d: 0.394065
0.1564 --- loss_d: 0.722221
0.2346 --- loss_d: 0.580492
0.3127 --- loss_d: 0.604352
0.3909 --- loss_d: 0.515776
0.4691 --- loss_d: 0.678270
0.5473 --- loss_d: 0.518772
0.6255 --- loss_d: 0.532946
0.7037 --- loss_d: 0.717963
0.7819 --- loss_d: 0.622142
0.8600 --- loss_d: 0.392177
0.9382 --- loss_d: 0.812804
Epoch finished! Loss: 0.6118546966023333
Starting epoch 2/10.
0.0000 --- loss_d: 0.484236
0.0782 --- loss_d: 0.442172
0.1564 --- loss_d: 0.393473
0.2346 --- loss_d: 0.720063
0.3127 --- loss_d: 0.461081
0.3909 --- loss_d: 0.410481
0.4691 --- loss_d: 0.435616
0.5473 --- loss_d: 0.292106
0.6255 --- loss_d: 0.173772
0.7037 --- loss_d: 0.162668
0.7819 --- loss_d: 0.561111
0.8600 --- loss_d: 0.499037
0.9382 --- loss_d: 0.220134
Epoch finished! Loss: 0.43290172611165234
Starting epoch 3/10.
0.0000 --- loss_d: 0.405379
0.0782 --- loss_d: 0.206870
0.1564 --- loss_d: 0.236682
0.2346 --- loss_d: 0.287755
0.3127 --- loss_d: 0.304262
0.3909 --- loss_d: 0.445211
0.4691 --- loss_d: 0.129110
0.5473 --- loss_d: 0.814789
0.6255 --- loss_d: 0.247236
0.7037 --- loss_d: 0.340639
0.7819 --- loss_d: 0.280761
0.8600 --- loss_d: 0.448516
0.9382 --- loss_d: 0.457222
Epoch finished! Loss: 0.29562586651542994
Starting epoch 4/10.
0.0000 --- loss_d: 0.182821
0.0782 --- loss_d: 0.322509
0.1564 --- loss_d: 0.140846
0.2346 --- loss_d: 0.103233
0.3127 --- loss_d: 0.323537
0.3909 --- loss_d: 0.090979
0.4691 --- loss_d: 0.038208
0.5473 --- loss_d: 0.596624
0.6255 --- loss_d: 0.053088
0.7037 --- loss_d: 0.084268
0.7819 --- loss_d: 0.049832
0.8600 --- loss_d: 0.460256
0.9382 --- loss_d: 0.552507
Epoch finished! Loss: 0.20640185157086435
Starting epoch 5/10.
0.0000 --- loss_d: 0.274496
0.0782 --- loss_d: 0.021391
0.1564 --- loss_d: 0.029495
0.2346 --- loss_d: 0.074385
0.3127 --- loss_d: 0.110140
0.3909 --- loss_d: 0.072803
0.4691 --- loss_d: 0.289821
0.5473 --- loss_d: 0.056407
0.6255 --- loss_d: 0.608151
0.7037 --- loss_d: 0.039395
0.7819 --- loss_d: 0.023073
0.8600 --- loss_d: 0.373855
0.9382 --- loss_d: 0.214087
Epoch finished! Loss: 0.17304744681446102
Starting epoch 6/10.
0.0000 --- loss_d: 0.105268
0.0782 --- loss_d: 0.036613
0.1564 --- loss_d: 0.034148
0.2346 --- loss_d: 0.014705
0.3127 --- loss_d: 0.008929
0.3909 --- loss_d: 0.230227
0.4691 --- loss_d: 0.036444
0.5473 --- loss_d: 0.042219
0.6255 --- loss_d: 0.026101
0.7037 --- loss_d: 0.013823
0.7819 --- loss_d: 0.113739
0.8600 --- loss_d: 0.385940
0.9382 --- loss_d: 0.053194
Epoch finished! Loss: 0.1056348591379264
Starting epoch 7/10.
0.0000 --- loss_d: 0.011664
0.0782 --- loss_d: 0.121633
0.1564 --- loss_d: 0.178400
0.2346 --- loss_d: 0.057150
0.3127 --- loss_d: 0.214576
0.3909 --- loss_d: 0.237584
0.4691 --- loss_d: 0.148102
0.5473 --- loss_d: 0.093677
0.6255 --- loss_d: 0.050821
0.7037 --- loss_d: 0.031769
0.7819 --- loss_d: 0.010525
0.8600 --- loss_d: 0.612425
0.9382 --- loss_d: 0.141953
Epoch finished! Loss: 0.0851363576691979
Starting epoch 8/10.
0.0000 --- loss_d: 0.008818
0.0782 --- loss_d: 0.003425
0.1564 --- loss_d: 0.004710
0.2346 --- loss_d: 0.022566
0.3127 --- loss_d: 0.363562
0.3909 --- loss_d: 0.091075
0.4691 --- loss_d: 0.017740
0.5473 --- loss_d: 0.023925
0.6255 --- loss_d: 0.423400
0.7037 --- loss_d: 0.089936
0.7819 --- loss_d: 0.005299
0.8600 --- loss_d: 0.050468
0.9382 --- loss_d: 0.008989
Epoch finished! Loss: 0.07448762712652307
Starting epoch 9/10.
0.0000 --- loss_d: 0.000775
0.0782 --- loss_d: 0.004733
0.1564 --- loss_d: 0.011453
0.2346 --- loss_d: 0.008678
0.3127 --- loss_d: 0.259226
0.3909 --- loss_d: 0.006453
0.4691 --- loss_d: 0.026511
0.5473 --- loss_d: 0.087748
0.6255 --- loss_d: 0.014974
0.7037 --- loss_d: 0.204018
0.7819 --- loss_d: 0.015991
0.8600 --- loss_d: 0.156768
0.9382 --- loss_d: 0.008625
Epoch finished! Loss: 0.04854569541185903
Starting epoch 10/10.
0.0000 --- loss_d: 0.005289
0.0782 --- loss_d: 0.001012
0.1564 --- loss_d: 0.045937
0.2346 --- loss_d: 0.328735
0.3127 --- loss_d: 0.003040
0.3909 --- loss_d: 0.044137
0.4691 --- loss_d: 0.001723
0.5473 --- loss_d: 0.001025
0.6255 --- loss_d: 0.002637
0.7037 --- loss_d: 0.101842
0.7819 --- loss_d: 0.004290
0.8600 --- loss_d: 0.000340
0.9382 --- loss_d: 0.043131
Epoch finished! Loss: 0.02589924726142515
Model saved !

==== START TESTING ====
Diagnosis acc on 30mins: 1.0
[1.         1.         1.         1.         1.         1.
 0.99999976 1.         1.         1.         1.         1.
 1.         1.         1.         1.         1.         1.
 1.         0.99999976 1.        ]
pred: 0.9999999772934687, label: 1
Right! Diagnosis: NT1
Save 30mins of subject chp060-nsrr
Diagnosis acc on patients: 0.782051282051282

====== all ======
   acc %  sen %  spec %  ppr %  f1-score
0  78.21  30.43   98.18  87.50     45.16
1  78.21  98.18   30.43  77.14     86.40
Total accuracy: 78.21%
Average sen: 64.31%
Average spec: 64.31%
Macro f1-score: 65.78%
fpr: 0.0, tpr: 0.0, threshold: 1.9999999772934687, 
fpr: 0.0, tpr: 0.01818181818181818, threshold: 0.9999999772934687, 
fpr: 0.0, tpr: 0.6727272727272727, threshold: 0.9977793128866899, 
fpr: 0.08695652173913043, tpr: 0.6727272727272727, threshold: 0.9970827272960118, 
fpr: 0.08695652173913043, tpr: 0.7272727272727273, threshold: 0.9960284233093262, 
fpr: 0.13043478260869565, tpr: 0.7272727272727273, threshold: 0.9948103864987691, 
fpr: 0.13043478260869565, tpr: 0.8545454545454545, threshold: 0.9837442741674536, 
fpr: 0.17391304347826086, tpr: 0.8545454545454545, threshold: 0.9821043451627095, 
fpr: 0.17391304347826086, tpr: 0.9636363636363636, threshold: 0.9294826742261648, 
fpr: 0.391304347826087, tpr: 0.9636363636363636, threshold: 0.8635257073522856, 
fpr: 0.391304347826087, tpr: 0.9818181818181818, threshold: 0.8600275498979232, 
fpr: 0.9565217391304348, tpr: 0.9818181818181818, threshold: 0.10430897544678633, 
fpr: 0.9565217391304348, tpr: 1.0, threshold: 0.06830747246653225, 
fpr: 1.0, tpr: 1.0, threshold: 0.01068759590019069, 

=== best_threshold: 0.9294826742261648, best_fpr: 0.17391304347826086, best_tpr: 0.9636363636363636 ===
fpr: 0.0, tpr: 0.0, threshold: 2.0, 
fpr: 0.011869436201780416, tpr: 0.1952232606438214, threshold: 1.0, 
fpr: 0.017804154302670624, tpr: 0.2544132917964694, threshold: 0.9999998807907104, 
fpr: 0.02373887240356083, tpr: 0.2720664589823468, threshold: 0.9999997615814209, 
fpr: 0.026706231454005934, tpr: 0.2949117341640706, threshold: 0.9999996423721313, 
fpr: 0.032640949554896145, tpr: 0.3094496365524403, threshold: 0.9999995231628418, 
fpr: 0.032640949554896145, tpr: 0.31360332294911736, threshold: 0.9999994039535522, 
fpr: 0.03857566765578635, tpr: 0.3291796469366563, threshold: 0.9999992847442627, 
fpr: 0.04154302670623145, tpr: 0.3333333333333333, threshold: 0.9999991655349731, 
fpr: 0.04154302670623145, tpr: 0.3426791277258567, threshold: 0.9999990463256836, 
fpr: 0.04154302670623145, tpr: 0.34787123572170303, threshold: 0.999998927116394, 
fpr: 0.04451038575667656, tpr: 0.3572170301142264, threshold: 0.9999988079071045, 
fpr: 0.04451038575667656, tpr: 0.36863966770508827, threshold: 0.9999986886978149, 
fpr: 0.04747774480712166, tpr: 0.37383177570093457, threshold: 0.9999985694885254, 
fpr: 0.04747774480712166, tpr: 0.38317757009345793, threshold: 0.9999984502792358, 
fpr: 0.050445103857566766, tpr: 0.387331256490135, threshold: 0.9999983310699463, 
fpr: 0.050445103857566766, tpr: 0.3935617860851506, threshold: 0.9999982118606567, 
fpr: 0.050445103857566766, tpr: 0.39667705088265837, threshold: 0.9999980926513672, 
fpr: 0.050445103857566766, tpr: 0.40083073727933544, threshold: 0.9999979734420776, 
fpr: 0.050445103857566766, tpr: 0.40290758047767394, threshold: 0.9999978542327881, 
fpr: 0.05341246290801187, tpr: 0.40809968847352024, threshold: 0.9999977350234985, 
fpr: 0.05341246290801187, tpr: 0.4153686396677051, threshold: 0.999997615814209, 
fpr: 0.05341246290801187, tpr: 0.4195223260643821, threshold: 0.9999973773956299, 
fpr: 0.05341246290801187, tpr: 0.4236760124610592, threshold: 0.9999972581863403, 
fpr: 0.05341246290801187, tpr: 0.4257528556593977, threshold: 0.9999971389770508, 
fpr: 0.05341246290801187, tpr: 0.42679127725856697, threshold: 0.9999970197677612, 
fpr: 0.05341246290801187, tpr: 0.4392523364485981, threshold: 0.9999966621398926, 
fpr: 0.05341246290801187, tpr: 0.4402907580477674, threshold: 0.999996542930603, 
fpr: 0.05341246290801187, tpr: 0.4454828660436137, threshold: 0.9999964237213135, 
fpr: 0.05341246290801187, tpr: 0.4475597092419522, threshold: 0.9999961853027344, 
fpr: 0.05341246290801187, tpr: 0.45067497403946, threshold: 0.9999960660934448, 
fpr: 0.05341246290801187, tpr: 0.45275181723779856, threshold: 0.9999959468841553, 
fpr: 0.05637982195845697, tpr: 0.4537902388369678, threshold: 0.9999958276748657, 
fpr: 0.05637982195845697, tpr: 0.45898234683281414, threshold: 0.999995231628418, 
fpr: 0.05637982195845697, tpr: 0.4652128764278297, threshold: 0.9999948740005493, 
fpr: 0.05637982195845697, tpr: 0.4672897196261682, threshold: 0.9999946355819702, 
fpr: 0.05637982195845697, tpr: 0.470404984423676, threshold: 0.9999945163726807, 
fpr: 0.05637982195845697, tpr: 0.4714434060228453, threshold: 0.9999943971633911, 
fpr: 0.05637982195845697, tpr: 0.47767393561786087, threshold: 0.9999940395355225, 
fpr: 0.05637982195845697, tpr: 0.4797507788161994, threshold: 0.9999939203262329, 
fpr: 0.05637982195845697, tpr: 0.48078920041536866, threshold: 0.9999938011169434, 
fpr: 0.05637982195845697, tpr: 0.48286604361370716, threshold: 0.9999936819076538, 
fpr: 0.05637982195845697, tpr: 0.48390446521287644, threshold: 0.9999935626983643, 
fpr: 0.05637982195845697, tpr: 0.48598130841121495, threshold: 0.9999934434890747, 
fpr: 0.05637982195845697, tpr: 0.48701973001038423, threshold: 0.9999932050704956, 
fpr: 0.05637982195845697, tpr: 0.49117341640706125, threshold: 0.999992847442627, 
fpr: 0.05637982195845697, tpr: 0.49221183800623053, threshold: 0.9999927282333374, 
fpr: 0.05934718100890208, tpr: 0.49221183800623053, threshold: 0.9999926090240479, 
fpr: 0.05934718100890208, tpr: 0.4953271028037383, threshold: 0.9999921321868896, 
fpr: 0.05934718100890208, tpr: 0.4994807892004154, threshold: 0.999991774559021, 
fpr: 0.05934718100890208, tpr: 0.5005192107995846, threshold: 0.9999916553497314, 
fpr: 0.05934718100890208, tpr: 0.5067497403946002, threshold: 0.9999912977218628, 
fpr: 0.06231454005934718, tpr: 0.5067497403946002, threshold: 0.9999911785125732, 
fpr: 0.06231454005934718, tpr: 0.5088265835929388, threshold: 0.999990701675415, 
fpr: 0.06231454005934718, tpr: 0.509865005192108, threshold: 0.9999905824661255, 
fpr: 0.06528189910979229, tpr: 0.509865005192108, threshold: 0.9999903440475464, 
fpr: 0.06528189910979229, tpr: 0.5119418483904465, threshold: 0.9999899864196777, 
fpr: 0.06528189910979229, tpr: 0.5150571131879543, threshold: 0.9999898672103882, 
fpr: 0.06528189910979229, tpr: 0.5160955347871236, threshold: 0.9999897480010986, 
fpr: 0.06824925816023739, tpr: 0.5181723779854621, threshold: 0.9999896287918091, 
fpr: 0.06824925816023739, tpr: 0.5202492211838006, threshold: 0.9999892711639404, 
fpr: 0.06824925816023739, tpr: 0.5223260643821391, threshold: 0.9999890327453613, 
fpr: 0.0712166172106825, tpr: 0.5223260643821391, threshold: 0.9999887943267822, 
fpr: 0.0712166172106825, tpr: 0.5244029075804777, threshold: 0.999988317489624, 
fpr: 0.0712166172106825, tpr: 0.5254413291796469, threshold: 0.9999881982803345, 
fpr: 0.0712166172106825, tpr: 0.5275181723779855, threshold: 0.9999880790710449, 
fpr: 0.0712166172106825, tpr: 0.5285565939771547, threshold: 0.9999877214431763, 
fpr: 0.0712166172106825, tpr: 0.5316718587746625, threshold: 0.9999871253967285, 
fpr: 0.0712166172106825, tpr: 0.5358255451713395, threshold: 0.999987006187439, 
fpr: 0.0712166172106825, tpr: 0.5379023883696781, threshold: 0.9999868869781494, 
fpr: 0.0712166172106825, tpr: 0.5389408099688473, threshold: 0.9999867677688599, 
fpr: 0.0712166172106825, tpr: 0.5410176531671859, threshold: 0.9999866485595703, 
fpr: 0.0712166172106825, tpr: 0.5451713395638629, threshold: 0.999985933303833, 
fpr: 0.07418397626112759, tpr: 0.5472481827622014, threshold: 0.9999855756759644, 
fpr: 0.07418397626112759, tpr: 0.5482866043613707, threshold: 0.9999853372573853, 
fpr: 0.0771513353115727, tpr: 0.54932502596054, threshold: 0.9999850988388062, 
fpr: 0.0771513353115727, tpr: 0.5503634475597092, threshold: 0.9999849796295166, 
fpr: 0.0771513353115727, tpr: 0.5586708203530634, threshold: 0.9999840259552002, 
fpr: 0.0771513353115727, tpr: 0.5607476635514018, threshold: 0.9999837875366211, 
fpr: 0.0771513353115727, tpr: 0.564901349948079, threshold: 0.9999833106994629, 
fpr: 0.08011869436201781, tpr: 0.5659397715472482, threshold: 0.9999831914901733, 
fpr: 0.08011869436201781, tpr: 0.569055036344756, threshold: 0.999982476234436, 
fpr: 0.08011869436201781, tpr: 0.5711318795430945, threshold: 0.9999822378158569, 
fpr: 0.08011869436201781, tpr: 0.5752855659397715, threshold: 0.9999815225601196, 
fpr: 0.08011869436201781, tpr: 0.5794392523364486, threshold: 0.9999809265136719, 
fpr: 0.0830860534124629, tpr: 0.5804776739356179, threshold: 0.9999808073043823, 
fpr: 0.0830860534124629, tpr: 0.5815160955347871, threshold: 0.999980092048645, 
fpr: 0.08605341246290801, tpr: 0.5815160955347871, threshold: 0.9999797344207764, 
fpr: 0.08605341246290801, tpr: 0.5856697819314641, threshold: 0.9999788999557495, 
fpr: 0.08605341246290801, tpr: 0.5877466251298027, threshold: 0.99997878074646, 
fpr: 0.08605341246290801, tpr: 0.5960539979231568, threshold: 0.9999761581420898, 
fpr: 0.08605341246290801, tpr: 0.5991692627206646, threshold: 0.9999756813049316, 
fpr: 0.08605341246290801, tpr: 0.6012461059190031, threshold: 0.9999752044677734, 
fpr: 0.08605341246290801, tpr: 0.6043613707165109, threshold: 0.9999744892120361, 
fpr: 0.08902077151335312, tpr: 0.6043613707165109, threshold: 0.9999743700027466, 
fpr: 0.08902077151335312, tpr: 0.6074766355140186, threshold: 0.9999728202819824, 
fpr: 0.08902077151335312, tpr: 0.6095534787123572, threshold: 0.9999727010726929, 
fpr: 0.08902077151335312, tpr: 0.616822429906542, threshold: 0.9999711513519287, 
fpr: 0.08902077151335312, tpr: 0.6199376947040498, threshold: 0.9999709129333496, 
fpr: 0.08902077151335312, tpr: 0.6220145379023884, threshold: 0.9999701976776123, 
fpr: 0.09198813056379822, tpr: 0.6220145379023884, threshold: 0.9999690055847168, 
fpr: 0.09198813056379822, tpr: 0.6230529595015576, threshold: 0.9999688863754272, 
fpr: 0.09495548961424333, tpr: 0.6230529595015576, threshold: 0.9999685287475586, 
fpr: 0.09495548961424333, tpr: 0.6240913811007269, threshold: 0.9999681711196899, 
fpr: 0.09495548961424333, tpr: 0.6261682242990654, threshold: 0.9999675750732422, 
fpr: 0.10089020771513353, tpr: 0.6261682242990654, threshold: 0.9999666213989258, 
fpr: 0.10089020771513353, tpr: 0.6282450674974039, threshold: 0.9999662637710571, 
fpr: 0.10089020771513353, tpr: 0.6313603322949117, threshold: 0.9999642372131348, 
fpr: 0.10385756676557864, tpr: 0.6313603322949117, threshold: 0.9999639987945557, 
fpr: 0.10385756676557864, tpr: 0.6448598130841121, threshold: 0.9999566078186035, 
fpr: 0.10682492581602374, tpr: 0.6448598130841121, threshold: 0.9999549388885498, 
fpr: 0.10682492581602374, tpr: 0.6614745586708204, threshold: 0.9999436140060425, 
fpr: 0.10979228486646884, tpr: 0.6614745586708204, threshold: 0.9999433755874634, 
fpr: 0.10979228486646884, tpr: 0.6645898234683282, threshold: 0.9999407529830933, 
fpr: 0.11275964391691394, tpr: 0.6645898234683282, threshold: 0.9999393224716187, 
fpr: 0.11275964391691394, tpr: 0.6666666666666666, threshold: 0.99993896484375, 
fpr: 0.11275964391691394, tpr: 0.6687435098650052, threshold: 0.9999383687973022, 
fpr: 0.11275964391691394, tpr: 0.6708203530633438, threshold: 0.9999380111694336, 
fpr: 0.11275964391691394, tpr: 0.6728971962616822, threshold: 0.9999377727508545, 
fpr: 0.11275964391691394, tpr: 0.6739356178608515, threshold: 0.9999375343322754, 
fpr: 0.11572700296735905, tpr: 0.6739356178608515, threshold: 0.9999364614486694, 
fpr: 0.11572700296735905, tpr: 0.67601246105919, threshold: 0.9999345541000366, 
fpr: 0.11869436201780416, tpr: 0.67601246105919, threshold: 0.9999339580535889, 
fpr: 0.12166172106824925, tpr: 0.6770508826583593, threshold: 0.9999332427978516, 
fpr: 0.12462908011869436, tpr: 0.6770508826583593, threshold: 0.999930739402771, 
fpr: 0.12462908011869436, tpr: 0.6780893042575286, threshold: 0.9999300241470337, 
fpr: 0.12759643916913946, tpr: 0.6780893042575286, threshold: 0.9999295473098755, 
fpr: 0.12759643916913946, tpr: 0.6822429906542056, threshold: 0.9999258518218994, 
fpr: 0.13056379821958458, tpr: 0.6822429906542056, threshold: 0.999924898147583, 
fpr: 0.13056379821958458, tpr: 0.6936656282450675, threshold: 0.9999136924743652, 
fpr: 0.13649851632047477, tpr: 0.6936656282450675, threshold: 0.9999116659164429, 
fpr: 0.13649851632047477, tpr: 0.6967808930425753, threshold: 0.9998989105224609, 
fpr: 0.1394658753709199, tpr: 0.6967808930425753, threshold: 0.9998985528945923, 
fpr: 0.1394658753709199, tpr: 0.6998961578400831, threshold: 0.9998971223831177, 
fpr: 0.142433234421365, tpr: 0.6998961578400831, threshold: 0.9998970031738281, 
fpr: 0.142433234421365, tpr: 0.7061266874350987, threshold: 0.9998841285705566, 
fpr: 0.14836795252225518, tpr: 0.7061266874350987, threshold: 0.999880313873291, 
fpr: 0.14836795252225518, tpr: 0.7071651090342679, threshold: 0.9998794794082642, 
fpr: 0.1513353115727003, tpr: 0.7082035306334372, threshold: 0.9998781681060791, 
fpr: 0.1513353115727003, tpr: 0.7102803738317757, threshold: 0.9998780488967896, 
fpr: 0.1572700296735905, tpr: 0.7102803738317757, threshold: 0.9998736381530762, 
fpr: 0.1572700296735905, tpr: 0.715472481827622, threshold: 0.9998651742935181, 
fpr: 0.16023738872403562, tpr: 0.715472481827622, threshold: 0.999862551689148, 
fpr: 0.16023738872403562, tpr: 0.7165109034267912, threshold: 0.9998617172241211, 
fpr: 0.16023738872403562, tpr: 0.7185877466251298, threshold: 0.9998587369918823, 
fpr: 0.1632047477744807, tpr: 0.7185877466251298, threshold: 0.9998579025268555, 
fpr: 0.1632047477744807, tpr: 0.726895119418484, threshold: 0.9998455047607422, 
fpr: 0.1661721068249258, tpr: 0.726895119418484, threshold: 0.9998421669006348, 
fpr: 0.1661721068249258, tpr: 0.735202492211838, threshold: 0.9998292922973633, 
fpr: 0.16913946587537093, tpr: 0.735202492211838, threshold: 0.9998289346694946, 
fpr: 0.16913946587537093, tpr: 0.7445482866043613, threshold: 0.9998015761375427, 
fpr: 0.17210682492581603, tpr: 0.7445482866043613, threshold: 0.9998001456260681, 
fpr: 0.17210682492581603, tpr: 0.7466251298026999, threshold: 0.9997979998588562, 
fpr: 0.17507418397626112, tpr: 0.7466251298026999, threshold: 0.999796450138092, 
fpr: 0.17507418397626112, tpr: 0.7497403946002077, threshold: 0.9997907280921936, 
fpr: 0.17804154302670624, tpr: 0.7497403946002077, threshold: 0.9997841715812683, 
fpr: 0.17804154302670624, tpr: 0.7777777777777778, threshold: 0.9996956586837769, 
fpr: 0.18397626112759644, tpr: 0.7777777777777778, threshold: 0.9996793270111084, 
fpr: 0.18397626112759644, tpr: 0.778816199376947, threshold: 0.9996770620346069, 
fpr: 0.18694362017804153, tpr: 0.778816199376947, threshold: 0.9996689558029175, 
fpr: 0.18694362017804153, tpr: 0.7798546209761164, threshold: 0.9996682405471802, 
fpr: 0.18991097922848665, tpr: 0.7798546209761164, threshold: 0.9996680021286011, 
fpr: 0.18991097922848665, tpr: 0.7840083073727934, threshold: 0.999653697013855, 
fpr: 0.19287833827893175, tpr: 0.7840083073727934, threshold: 0.9996510744094849, 
fpr: 0.19287833827893175, tpr: 0.7850467289719626, threshold: 0.999650239944458, 
fpr: 0.19881305637982197, tpr: 0.7850467289719626, threshold: 0.9996455907821655, 
fpr: 0.19881305637982197, tpr: 0.7860851505711319, threshold: 0.9996451139450073, 
fpr: 0.20474777448071216, tpr: 0.7860851505711319, threshold: 0.9996392726898193, 
fpr: 0.20474777448071216, tpr: 0.7871235721703012, threshold: 0.999634861946106, 
fpr: 0.20771513353115728, tpr: 0.7871235721703012, threshold: 0.9996315240859985, 
fpr: 0.20771513353115728, tpr: 0.7892004153686397, threshold: 0.9996277093887329, 
fpr: 0.21068249258160238, tpr: 0.7892004153686397, threshold: 0.9996261596679688, 
fpr: 0.21068249258160238, tpr: 0.7954309449636553, threshold: 0.9996034502983093, 
fpr: 0.21364985163204747, tpr: 0.7954309449636553, threshold: 0.9996001124382019, 
fpr: 0.21364985163204747, tpr: 0.7975077881619937, threshold: 0.9995920062065125, 
fpr: 0.2195845697329377, tpr: 0.7975077881619937, threshold: 0.9995847344398499, 
fpr: 0.2195845697329377, tpr: 0.7995846313603323, threshold: 0.9995785355567932, 
fpr: 0.22255192878338279, tpr: 0.7995846313603323, threshold: 0.9995755553245544, 
fpr: 0.22255192878338279, tpr: 0.8037383177570093, threshold: 0.9995318651199341, 
fpr: 0.22551928783382788, tpr: 0.8037383177570093, threshold: 0.9995317459106445, 
fpr: 0.22551928783382788, tpr: 0.8058151609553479, threshold: 0.9995083808898926, 
fpr: 0.228486646884273, tpr: 0.8058151609553479, threshold: 0.9995015859603882, 
fpr: 0.228486646884273, tpr: 0.818276220145379, threshold: 0.999337375164032, 
fpr: 0.2314540059347181, tpr: 0.818276220145379, threshold: 0.9993351101875305, 
fpr: 0.2314540059347181, tpr: 0.8203530633437176, threshold: 0.9993048906326294, 
fpr: 0.2344213649851632, tpr: 0.8203530633437176, threshold: 0.9992792010307312, 
fpr: 0.2344213649851632, tpr: 0.8213914849428868, threshold: 0.9992730021476746, 
fpr: 0.23738872403560832, tpr: 0.8213914849428868, threshold: 0.9992644190788269, 
fpr: 0.23738872403560832, tpr: 0.8245067497403946, threshold: 0.9992177486419678, 
fpr: 0.24925816023738873, tpr: 0.8245067497403946, threshold: 0.9991852641105652, 
fpr: 0.24925816023738873, tpr: 0.8255451713395638, threshold: 0.9991711378097534, 
fpr: 0.2522255192878338, tpr: 0.8255451713395638, threshold: 0.9991514682769775, 
fpr: 0.2522255192878338, tpr: 0.8307372793354102, threshold: 0.9990886449813843, 
fpr: 0.2551928783382789, tpr: 0.8307372793354102, threshold: 0.9990756511688232, 
fpr: 0.2551928783382789, tpr: 0.8317757009345794, threshold: 0.9990707635879517, 
fpr: 0.258160237388724, tpr: 0.8317757009345794, threshold: 0.9990697503089905, 
fpr: 0.258160237388724, tpr: 0.8359293873312564, threshold: 0.9989966750144958, 
fpr: 0.26112759643916916, tpr: 0.8359293873312564, threshold: 0.9989809393882751, 
fpr: 0.26112759643916916, tpr: 0.838006230529595, threshold: 0.9989444613456726, 
fpr: 0.26409495548961426, tpr: 0.838006230529595, threshold: 0.9989368319511414, 
fpr: 0.26409495548961426, tpr: 0.8431983385254413, threshold: 0.9988732933998108, 
fpr: 0.26706231454005935, tpr: 0.8431983385254413, threshold: 0.9988583326339722, 
fpr: 0.26706231454005935, tpr: 0.8463136033229491, threshold: 0.9987855553627014, 
fpr: 0.27002967359050445, tpr: 0.8463136033229491, threshold: 0.9987744688987732, 
fpr: 0.27002967359050445, tpr: 0.8473520249221184, threshold: 0.9987401366233826, 
fpr: 0.27299703264094954, tpr: 0.8473520249221184, threshold: 0.9987369179725647, 
fpr: 0.27299703264094954, tpr: 0.8483904465212876, threshold: 0.9987265467643738, 
fpr: 0.2789317507418398, tpr: 0.8483904465212876, threshold: 0.9986975193023682, 
fpr: 0.2789317507418398, tpr: 0.8546209761163032, threshold: 0.998414158821106, 
fpr: 0.29080118694362017, tpr: 0.8546209761163032, threshold: 0.9983762502670288, 
fpr: 0.29080118694362017, tpr: 0.8598130841121495, threshold: 0.9982555508613586, 
fpr: 0.29673590504451036, tpr: 0.8598130841121495, threshold: 0.9982168078422546, 
fpr: 0.29673590504451036, tpr: 0.8618899273104881, threshold: 0.9981556534767151, 
fpr: 0.2997032640949555, tpr: 0.8618899273104881, threshold: 0.9981516003608704, 
fpr: 0.2997032640949555, tpr: 0.8639667705088265, threshold: 0.9981356859207153, 
fpr: 0.3026706231454006, tpr: 0.8639667705088265, threshold: 0.9981004595756531, 
fpr: 0.3026706231454006, tpr: 0.8660436137071651, threshold: 0.9979121088981628, 
fpr: 0.3056379821958457, tpr: 0.8660436137071651, threshold: 0.9979060888290405, 
fpr: 0.3056379821958457, tpr: 0.8670820353063343, threshold: 0.9978869557380676, 
fpr: 0.3086053412462908, tpr: 0.8670820353063343, threshold: 0.9978538155555725, 
fpr: 0.3086053412462908, tpr: 0.8681204569055037, threshold: 0.9978359341621399, 
fpr: 0.31750741839762614, tpr: 0.8681204569055037, threshold: 0.9977397918701172, 
fpr: 0.31750741839762614, tpr: 0.8764278296988577, threshold: 0.9973500967025757, 
fpr: 0.32047477744807124, tpr: 0.8764278296988577, threshold: 0.9972514510154724, 
fpr: 0.32047477744807124, tpr: 0.8785046728971962, threshold: 0.9972131848335266, 
fpr: 0.32344213649851633, tpr: 0.8785046728971962, threshold: 0.9971238970756531, 
fpr: 0.32344213649851633, tpr: 0.8878504672897196, threshold: 0.9965283274650574, 
fpr: 0.3323442136498516, tpr: 0.8878504672897196, threshold: 0.9963226318359375, 
fpr: 0.3323442136498516, tpr: 0.8909657320872274, threshold: 0.9961658716201782, 
fpr: 0.3353115727002967, tpr: 0.8909657320872274, threshold: 0.9959989786148071, 
fpr: 0.3353115727002967, tpr: 0.8920041536863966, threshold: 0.9957492351531982, 
fpr: 0.33827893175074186, tpr: 0.8920041536863966, threshold: 0.9957337975502014, 
fpr: 0.33827893175074186, tpr: 0.8940809968847352, threshold: 0.9954226613044739, 
fpr: 0.34124629080118696, tpr: 0.8940809968847352, threshold: 0.9954032897949219, 
fpr: 0.34124629080118696, tpr: 0.8951194184839044, threshold: 0.9953593611717224, 
fpr: 0.34718100890207715, tpr: 0.8951194184839044, threshold: 0.9951024055480957, 
fpr: 0.34718100890207715, tpr: 0.8961578400830738, threshold: 0.9950430393218994, 
fpr: 0.35014836795252224, tpr: 0.8961578400830738, threshold: 0.995018482208252, 
fpr: 0.35014836795252224, tpr: 0.8992731048805815, threshold: 0.9947963356971741, 
fpr: 0.35311572700296734, tpr: 0.8992731048805815, threshold: 0.9947912693023682, 
fpr: 0.35311572700296734, tpr: 0.9044652128764278, threshold: 0.9936455488204956, 
fpr: 0.3620178041543027, tpr: 0.9044652128764278, threshold: 0.9934722185134888, 
fpr: 0.3620178041543027, tpr: 0.9055036344755971, threshold: 0.9932335019111633, 
fpr: 0.3649851632047478, tpr: 0.9055036344755971, threshold: 0.9929617047309875, 
fpr: 0.3649851632047478, tpr: 0.9075804776739356, threshold: 0.9928871989250183, 
fpr: 0.37388724035608306, tpr: 0.9075804776739356, threshold: 0.9925079941749573, 
fpr: 0.37388724035608306, tpr: 0.9086188992731049, threshold: 0.9921322464942932, 
fpr: 0.3768545994065282, tpr: 0.9086188992731049, threshold: 0.9918246865272522, 
fpr: 0.3768545994065282, tpr: 0.9169262720664589, threshold: 0.9902567863464355, 
fpr: 0.3827893175074184, tpr: 0.9169262720664589, threshold: 0.9896773099899292, 
fpr: 0.3827893175074184, tpr: 0.9190031152647975, threshold: 0.9893375635147095, 
fpr: 0.3857566765578635, tpr: 0.9190031152647975, threshold: 0.9891564846038818, 
fpr: 0.3857566765578635, tpr: 0.9200415368639667, threshold: 0.9884220957756042, 
fpr: 0.3916913946587537, tpr: 0.9200415368639667, threshold: 0.9883410334587097, 
fpr: 0.3916913946587537, tpr: 0.9210799584631361, threshold: 0.988323450088501, 
fpr: 0.39762611275964393, tpr: 0.9210799584631361, threshold: 0.9865330457687378, 
fpr: 0.39762611275964393, tpr: 0.9221183800623053, threshold: 0.9862585067749023, 
fpr: 0.40059347181008903, tpr: 0.9221183800623053, threshold: 0.9859752058982849, 
fpr: 0.40059347181008903, tpr: 0.9262720664589823, threshold: 0.9837204217910767, 
fpr: 0.4035608308605341, tpr: 0.9262720664589823, threshold: 0.9828308820724487, 
fpr: 0.4035608308605341, tpr: 0.9283489096573209, threshold: 0.9811146855354309, 
fpr: 0.4065281899109792, tpr: 0.9283489096573209, threshold: 0.9808359146118164, 
fpr: 0.4065281899109792, tpr: 0.9293873312564901, threshold: 0.9807302951812744, 
fpr: 0.4124629080118694, tpr: 0.9293873312564901, threshold: 0.9804329872131348, 
fpr: 0.4124629080118694, tpr: 0.9304257528556594, threshold: 0.9800348281860352, 
fpr: 0.41839762611275966, tpr: 0.9304257528556594, threshold: 0.979292094707489, 
fpr: 0.41839762611275966, tpr: 0.9314641744548287, threshold: 0.9790098667144775, 
fpr: 0.42433234421364985, tpr: 0.9314641744548287, threshold: 0.9788773655891418, 
fpr: 0.42433234421364985, tpr: 0.9325025960539979, threshold: 0.978190541267395, 
fpr: 0.4332344213649852, tpr: 0.9325025960539979, threshold: 0.9779725074768066, 
fpr: 0.4332344213649852, tpr: 0.9345794392523364, threshold: 0.9770844578742981, 
fpr: 0.4391691394658754, tpr: 0.9345794392523364, threshold: 0.9765846133232117, 
fpr: 0.4391691394658754, tpr: 0.936656282450675, threshold: 0.9756131768226624, 
fpr: 0.44510385756676557, tpr: 0.936656282450675, threshold: 0.9750564098358154, 
fpr: 0.44510385756676557, tpr: 0.9376947040498442, threshold: 0.9745165109634399, 
fpr: 0.45103857566765576, tpr: 0.9376947040498442, threshold: 0.9726678133010864, 
fpr: 0.45103857566765576, tpr: 0.9387331256490135, threshold: 0.972228467464447, 
fpr: 0.4540059347181009, tpr: 0.9387331256490135, threshold: 0.9718071222305298, 
fpr: 0.4540059347181009, tpr: 0.9418483904465212, threshold: 0.9697040319442749, 
fpr: 0.4629080118694362, tpr: 0.9418483904465212, threshold: 0.9665181040763855, 
fpr: 0.4629080118694362, tpr: 0.9428868120456906, threshold: 0.9650407433509827, 
fpr: 0.4688427299703264, tpr: 0.9428868120456906, threshold: 0.963172435760498, 
fpr: 0.4688427299703264, tpr: 0.9439252336448598, threshold: 0.9630873203277588, 
fpr: 0.47477744807121663, tpr: 0.9439252336448598, threshold: 0.9619118571281433, 
fpr: 0.47477744807121663, tpr: 0.9460020768431984, threshold: 0.9600600004196167, 
fpr: 0.4807121661721068, tpr: 0.9460020768431984, threshold: 0.9574080109596252, 
fpr: 0.4807121661721068, tpr: 0.9480789200415368, threshold: 0.956184983253479, 
fpr: 0.4836795252225519, tpr: 0.9480789200415368, threshold: 0.956155002117157, 
fpr: 0.4836795252225519, tpr: 0.9491173416407062, threshold: 0.9526602625846863, 
fpr: 0.486646884272997, tpr: 0.9491173416407062, threshold: 0.9524107575416565, 
fpr: 0.486646884272997, tpr: 0.9501557632398754, threshold: 0.9519375562667847, 
fpr: 0.49554896142433236, tpr: 0.9501557632398754, threshold: 0.9484530091285706, 
fpr: 0.49554896142433236, tpr: 0.952232606438214, threshold: 0.9457460045814514, 
fpr: 0.5014836795252225, tpr: 0.952232606438214, threshold: 0.9443648457527161, 
fpr: 0.5014836795252225, tpr: 0.9532710280373832, threshold: 0.9441542029380798, 
fpr: 0.5044510385756676, tpr: 0.9532710280373832, threshold: 0.9408019781112671, 
fpr: 0.5044510385756676, tpr: 0.9574247144340602, threshold: 0.9351937770843506, 
fpr: 0.5103857566765578, tpr: 0.9574247144340602, threshold: 0.9338687658309937, 
fpr: 0.5103857566765578, tpr: 0.9584631360332295, threshold: 0.9271495342254639, 
fpr: 0.516320474777448, tpr: 0.9584631360332295, threshold: 0.9266884326934814, 
fpr: 0.516320474777448, tpr: 0.9595015576323987, threshold: 0.9262019395828247, 
fpr: 0.5192878338278932, tpr: 0.9595015576323987, threshold: 0.9233913421630859, 
fpr: 0.5192878338278932, tpr: 0.960539979231568, threshold: 0.9203159213066101, 
fpr: 0.5281899109792285, tpr: 0.960539979231568, threshold: 0.9103038311004639, 
fpr: 0.5281899109792285, tpr: 0.9626168224299065, threshold: 0.9058845043182373, 
fpr: 0.5311572700296736, tpr: 0.9626168224299065, threshold: 0.9026163816452026, 
fpr: 0.5311572700296736, tpr: 0.9657320872274143, threshold: 0.8900587558746338, 
fpr: 0.5341246290801187, tpr: 0.9657320872274143, threshold: 0.888376772403717, 
fpr: 0.5341246290801187, tpr: 0.9667705088265836, threshold: 0.8861484527587891, 
fpr: 0.5370919881305638, tpr: 0.9667705088265836, threshold: 0.8853371739387512, 
fpr: 0.5370919881305638, tpr: 0.9688473520249221, threshold: 0.8770531415939331, 
fpr: 0.543026706231454, tpr: 0.9688473520249221, threshold: 0.8551042079925537, 
fpr: 0.543026706231454, tpr: 0.9709241952232607, threshold: 0.846878170967102, 
fpr: 0.5548961424332344, tpr: 0.9709241952232607, threshold: 0.8150001168251038, 
fpr: 0.5548961424332344, tpr: 0.9719626168224299, threshold: 0.8117952942848206, 
fpr: 0.5727002967359051, tpr: 0.9719626168224299, threshold: 0.7583082914352417, 
fpr: 0.5727002967359051, tpr: 0.9730010384215991, threshold: 0.7536536455154419, 
fpr: 0.5875370919881305, tpr: 0.9730010384215991, threshold: 0.7078560590744019, 
fpr: 0.5875370919881305, tpr: 0.9740394600207685, threshold: 0.7072892189025879, 
fpr: 0.5934718100890207, tpr: 0.9740394600207685, threshold: 0.6874350309371948, 
fpr: 0.5934718100890207, tpr: 0.9750778816199377, threshold: 0.6827197074890137, 
fpr: 0.5964391691394659, tpr: 0.9750778816199377, threshold: 0.6779707670211792, 
fpr: 0.5964391691394659, tpr: 0.9781931464174455, threshold: 0.6597923040390015, 
fpr: 0.6142433234421365, tpr: 0.9781931464174455, threshold: 0.5885792970657349, 
fpr: 0.6142433234421365, tpr: 0.9792315680166147, threshold: 0.5873265862464905, 
fpr: 0.6706231454005934, tpr: 0.9792315680166147, threshold: 0.3967767059803009, 
fpr: 0.6706231454005934, tpr: 0.980269989615784, threshold: 0.3857554495334625, 
fpr: 0.712166172106825, tpr: 0.980269989615784, threshold: 0.25250881910324097, 
fpr: 0.712166172106825, tpr: 0.9823468328141225, threshold: 0.23161908984184265, 
fpr: 0.7210682492581603, tpr: 0.9823468328141225, threshold: 0.2187201976776123, 
fpr: 0.7210682492581603, tpr: 0.9833852544132918, threshold: 0.20709891617298126, 
fpr: 0.7685459940652819, tpr: 0.9833852544132918, threshold: 0.08868514746427536, 
fpr: 0.7685459940652819, tpr: 0.9844236760124611, threshold: 0.08624953031539917, 
fpr: 0.7744807121661721, tpr: 0.9844236760124611, threshold: 0.08131421357393265, 
fpr: 0.7744807121661721, tpr: 0.9854620976116303, threshold: 0.07957209646701813, 
fpr: 0.7893175074183977, tpr: 0.9854620976116303, threshold: 0.0639139786362648, 
fpr: 0.7893175074183977, tpr: 0.9865005192107996, threshold: 0.06219722330570221, 
fpr: 0.8189910979228486, tpr: 0.9865005192107996, threshold: 0.04567893221974373, 
fpr: 0.8189910979228486, tpr: 0.9885773624091381, threshold: 0.04233630746603012, 
fpr: 0.8516320474777448, tpr: 0.9885773624091381, threshold: 0.01861964352428913, 
fpr: 0.8516320474777448, tpr: 0.9896157840083074, threshold: 0.018613969907164574, 
fpr: 0.8664688427299704, tpr: 0.9896157840083074, threshold: 0.013157949782907963, 
fpr: 0.8664688427299704, tpr: 0.9906542056074766, threshold: 0.012522599659860134, 
fpr: 0.8694362017804155, tpr: 0.9906542056074766, threshold: 0.012005947530269623, 
fpr: 0.8694362017804155, tpr: 0.9916926272066459, threshold: 0.011854187585413456, 
fpr: 0.8991097922848664, tpr: 0.9916926272066459, threshold: 0.007754216436296701, 
fpr: 0.8991097922848664, tpr: 0.9927310488058152, threshold: 0.007430953439325094, 
fpr: 0.913946587537092, tpr: 0.9927310488058152, threshold: 0.005258063320070505, 
fpr: 0.913946587537092, tpr: 0.9937694704049844, threshold: 0.005001759622246027, 
fpr: 0.9198813056379822, tpr: 0.9937694704049844, threshold: 0.003338107606396079, 
fpr: 0.9198813056379822, tpr: 0.9948078920041536, threshold: 0.0030581133905798197, 
fpr: 0.9287833827893175, tpr: 0.9948078920041536, threshold: 0.002697821706533432, 
fpr: 0.9287833827893175, tpr: 0.995846313603323, threshold: 0.0025810441002249718, 
fpr: 0.9465875370919882, tpr: 0.995846313603323, threshold: 0.0021247921977192163, 
fpr: 0.9465875370919882, tpr: 0.9979231568016614, threshold: 0.0020410954020917416, 
fpr: 0.9554896142433235, tpr: 0.9979231568016614, threshold: 0.0017298193415626884, 
fpr: 0.9554896142433235, tpr: 0.9989615784008308, threshold: 0.001676425221376121, 
fpr: 0.9821958456973294, tpr: 0.9989615784008308, threshold: 0.0004239148402120918, 
fpr: 0.9821958456973294, tpr: 1.0, threshold: 0.00032476356136612594, 
fpr: 1.0, tpr: 1.0, threshold: 4.788794103660621e-05, 

=== best_threshold: 0.9996956586837769, best_fpr: 0.17804154302670624, best_tpr: 0.7777777777777778 ===
