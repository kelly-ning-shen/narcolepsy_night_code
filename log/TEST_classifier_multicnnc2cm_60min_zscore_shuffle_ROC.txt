cuda:0
Subjects num: 78

60min inputs: chc001-nsrr (6)
60min inputs: chc004-nsrr (8)
60min inputs: chc005-nsrr (7)
60min inputs: chc006-nsrr (6)
60min inputs: chc008-nsrr (8)
60min inputs: chc009-nsrr (7)
60min inputs: chc010-nsrr (7)
60min inputs: chc012-nsrr (7)
60min inputs: chc013-nsrr (7)
60min inputs: chc014-nsrr (7)
60min inputs: chc015-nsrr (7)
60min inputs: chc016-nsrr (7)
60min inputs: chc022-nsrr (6)
60min inputs: chc025-nsrr (6)
60min inputs: chc027-nsrr (7)
60min inputs: chc028-nsrr (7)
60min inputs: chc033-nsrr (7)
60min inputs: chc035-nsrr (7)
60min inputs: chc037-nsrr (7)
60min inputs: chc040-nsrr (9)
60min inputs: chc041-nsrr (7)
60min inputs: chc052-nsrr (7)
60min inputs: chc056-nsrr (7)
60min inputs: chp001-nsrr (9)
60min inputs: chp002-nsrr (9)
60min inputs: chp003-nsrr (8)
60min inputs: chp004-nsrr (8)
60min inputs: chp005-nsrr (10)
60min inputs: chp006-nsrr (9)
60min inputs: chp007-nsrr (9)
60min inputs: chp008-nsrr (7)
60min inputs: chp009-nsrr (8)
60min inputs: chp010-nsrr (8)
60min inputs: chp011-nsrr (8)
60min inputs: chp012-nsrr (9)
60min inputs: chp013-nsrr (8)
60min inputs: chp014-nsrr (8)
60min inputs: chp015-nsrr (9)
60min inputs: chp016-nsrr (10)
60min inputs: chp017-nsrr (8)
60min inputs: chp018-nsrr (9)
60min inputs: chp019-nsrr (7)
60min inputs: chp020-nsrr (9)
60min inputs: chp022-nsrr (10)
60min inputs: chp024-nsrr (9)
60min inputs: chp025-nsrr (3)
60min inputs: chp026-nsrr (7)
60min inputs: chp028-nsrr (8)
60min inputs: chp029-nsrr (8)
60min inputs: chp030-nsrr (10)
60min inputs: chp031-nsrr (9)
60min inputs: chp032-nsrr (8)
60min inputs: chp033-nsrr (8)
60min inputs: chp034-nsrr (8)
60min inputs: chp036-nsrr (10)
60min inputs: chp037-nsrr (8)
60min inputs: chp038-nsrr (8)
60min inputs: chp039-nsrr (9)
60min inputs: chp040-nsrr (8)
60min inputs: chp041-nsrr (9)
60min inputs: chp042-nsrr (9)
60min inputs: chp043-nsrr (10)
60min inputs: chp044-nsrr (8)
60min inputs: chp045-nsrr (10)
60min inputs: chp046-nsrr (9)
60min inputs: chp047-nsrr (7)
60min inputs: chp048-nsrr (8)
60min inputs: chp049-nsrr (9)
60min inputs: chp051-nsrr (9)
60min inputs: chp052-nsrr (8)
60min inputs: chp053-nsrr (9)
60min inputs: chp054-nsrr (9)
60min inputs: chp055-nsrr (9)
60min inputs: chp056-nsrr (9)
60min inputs: chp057-nsrr (9)
60min inputs: chp058-nsrr (8)
60min inputs: chp059-nsrr (9)
60min inputs: chp060-nsrr (10)

=== Test on chc001-nsrr. train_data(624), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.468949, loss_ss: 1.756130, loss_d: 0.712819
0.1603 --- loss: 2.202956, loss_ss: 1.598698, loss_d: 0.604258
0.3205 --- loss: 2.194467, loss_ss: 1.572855, loss_d: 0.621611
0.4808 --- loss: 2.344627, loss_ss: 1.531199, loss_d: 0.813427
0.6410 --- loss: 2.166744, loss_ss: 1.517063, loss_d: 0.649681
0.8013 --- loss: 1.863927, loss_ss: 1.490341, loss_d: 0.373586
0.9615 --- loss: 2.417259, loss_ss: 1.511029, loss_d: 0.906230
Epoch finished! Loss: 2.206138264748358
Starting epoch 2/10.
0.0000 --- loss: 2.061774, loss_ss: 1.510287, loss_d: 0.551487
0.1603 --- loss: 1.903152, loss_ss: 1.471862, loss_d: 0.431289
0.3205 --- loss: 2.233608, loss_ss: 1.406853, loss_d: 0.826755
0.4808 --- loss: 1.866914, loss_ss: 1.470352, loss_d: 0.396562
0.6410 --- loss: 1.861849, loss_ss: 1.501651, loss_d: 0.360197
0.8013 --- loss: 1.862029, loss_ss: 1.395555, loss_d: 0.466474
0.9615 --- loss: 1.779903, loss_ss: 1.443234, loss_d: 0.336669
Epoch finished! Loss: 1.9422851377917874
Starting epoch 3/10.
0.0000 --- loss: 1.599102, loss_ss: 1.359581, loss_d: 0.239521
0.1603 --- loss: 1.688189, loss_ss: 1.338719, loss_d: 0.349470
0.3205 --- loss: 1.608853, loss_ss: 1.255470, loss_d: 0.353383
0.4808 --- loss: 1.651180, loss_ss: 1.465006, loss_d: 0.186174
0.6410 --- loss: 1.675456, loss_ss: 1.457426, loss_d: 0.218031
0.8013 --- loss: 1.575429, loss_ss: 1.249202, loss_d: 0.326227
0.9615 --- loss: 1.957912, loss_ss: 1.312396, loss_d: 0.645515
Epoch finished! Loss: 1.730283877541942
Starting epoch 4/10.
0.0000 --- loss: 1.484115, loss_ss: 1.199092, loss_d: 0.285023
0.1603 --- loss: 1.802353, loss_ss: 1.330296, loss_d: 0.472057
0.3205 --- loss: 1.847392, loss_ss: 1.186404, loss_d: 0.660988
0.4808 --- loss: 1.411111, loss_ss: 1.275123, loss_d: 0.135988
0.6410 --- loss: 1.365881, loss_ss: 1.140254, loss_d: 0.225627
0.8013 --- loss: 1.324901, loss_ss: 1.136519, loss_d: 0.188382
0.9615 --- loss: 1.870644, loss_ss: 1.116780, loss_d: 0.753864
Epoch finished! Loss: 1.5028077575468248
Starting epoch 5/10.
0.0000 --- loss: 1.199256, loss_ss: 1.152773, loss_d: 0.046483
0.1603 --- loss: 1.286147, loss_ss: 1.226273, loss_d: 0.059874
0.3205 --- loss: 1.525574, loss_ss: 1.271515, loss_d: 0.254059
0.4808 --- loss: 1.159107, loss_ss: 1.106493, loss_d: 0.052615
0.6410 --- loss: 1.431322, loss_ss: 1.357073, loss_d: 0.074248
0.8013 --- loss: 1.262226, loss_ss: 1.218279, loss_d: 0.043947
0.9615 --- loss: 1.148654, loss_ss: 1.101784, loss_d: 0.046870
Epoch finished! Loss: 1.2784691837526136
Starting epoch 6/10.
0.0000 --- loss: 1.068176, loss_ss: 1.033723, loss_d: 0.034453
0.1603 --- loss: 1.204449, loss_ss: 1.161310, loss_d: 0.043140
0.3205 --- loss: 1.062153, loss_ss: 1.024682, loss_d: 0.037471
0.4808 --- loss: 1.093365, loss_ss: 1.020149, loss_d: 0.073216
0.6410 --- loss: 1.078413, loss_ss: 1.029253, loss_d: 0.049160
0.8013 --- loss: 1.067115, loss_ss: 0.981041, loss_d: 0.086073
0.9615 --- loss: 0.990893, loss_ss: 0.975524, loss_d: 0.015369
Epoch finished! Loss: 1.1361875610966836
Starting epoch 7/10.
0.0000 --- loss: 0.965437, loss_ss: 0.899989, loss_d: 0.065449
0.1603 --- loss: 1.085710, loss_ss: 1.075832, loss_d: 0.009879
0.3205 --- loss: 0.976785, loss_ss: 0.949854, loss_d: 0.026931
0.4808 --- loss: 1.226561, loss_ss: 1.212892, loss_d: 0.013669
0.6410 --- loss: 0.947219, loss_ss: 0.939235, loss_d: 0.007983
0.8013 --- loss: 0.890693, loss_ss: 0.882100, loss_d: 0.008593
0.9615 --- loss: 0.993889, loss_ss: 0.972709, loss_d: 0.021180
Epoch finished! Loss: 1.0277917644669932
Starting epoch 8/10.
0.0000 --- loss: 0.886427, loss_ss: 0.878426, loss_d: 0.008002
0.1603 --- loss: 0.983589, loss_ss: 0.982875, loss_d: 0.000714
0.3205 --- loss: 1.008468, loss_ss: 0.802498, loss_d: 0.205970
0.4808 --- loss: 0.970104, loss_ss: 0.948144, loss_d: 0.021960
0.6410 --- loss: 0.985286, loss_ss: 0.983408, loss_d: 0.001878
0.8013 --- loss: 1.016047, loss_ss: 1.013886, loss_d: 0.002161
0.9615 --- loss: 0.800753, loss_ss: 0.782815, loss_d: 0.017938
Epoch finished! Loss: 1.0085142533625326
Starting epoch 9/10.
0.0000 --- loss: 0.909625, loss_ss: 0.889085, loss_d: 0.020540
0.1603 --- loss: 0.831459, loss_ss: 0.820657, loss_d: 0.010801
0.3205 --- loss: 0.918246, loss_ss: 0.915725, loss_d: 0.002521
0.4808 --- loss: 0.998190, loss_ss: 0.975382, loss_d: 0.022808
0.6410 --- loss: 0.822302, loss_ss: 0.809247, loss_d: 0.013054
0.8013 --- loss: 0.985544, loss_ss: 0.976846, loss_d: 0.008698
0.9615 --- loss: 0.970584, loss_ss: 0.918160, loss_d: 0.052424
Epoch finished! Loss: 0.961427007952044
Starting epoch 10/10.
0.0000 --- loss: 0.762640, loss_ss: 0.759427, loss_d: 0.003212
0.1603 --- loss: 0.949186, loss_ss: 0.918688, loss_d: 0.030498
0.3205 --- loss: 1.123712, loss_ss: 1.116595, loss_d: 0.007117
0.4808 --- loss: 0.836580, loss_ss: 0.833002, loss_d: 0.003578
0.6410 --- loss: 0.736445, loss_ss: 0.731356, loss_d: 0.005089
0.8013 --- loss: 0.839430, loss_ss: 0.838475, loss_d: 0.000954
0.9615 --- loss: 0.854608, loss_ss: 0.851206, loss_d: 0.003403
Epoch finished! Loss: 0.932310143786092
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8305555555555556
             precision    recall  f1-score   support

        0.0       0.82      1.00      0.90        77
        1.0       0.00      0.00      0.00        48
        2.0       0.84      0.93      0.88       340
        3.0       1.00      0.67      0.80       143
        4.0       0.70      0.97      0.82       112

avg / total       0.79      0.83      0.80       720
 


====== chc001-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  97.64  100.00   97.36   81.91     90.06
1  93.33    0.00  100.00    0.00      0.00
2  88.47   92.94   84.47   84.27     88.39
3  93.47   67.13  100.00  100.00     80.33
4  93.19   97.32   92.43   70.32     81.65
Total accuracy: 83.06%
Average sen: 71.48%
Average spec: 94.85%
Macro f1-score: 68.09%
Diagnosis acc on 60mins: 0.0
[0.9992975  0.99164349 0.97049022 0.99844187 0.99990618 0.99931061]
pred: 0.9931816458702087, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc001-nsrr

=== Test on chc004-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.413870, loss_ss: 1.727954, loss_d: 0.685916
0.1608 --- loss: 2.157247, loss_ss: 1.629101, loss_d: 0.528146
0.3215 --- loss: 1.941540, loss_ss: 1.534273, loss_d: 0.407267
0.4823 --- loss: 2.337713, loss_ss: 1.499146, loss_d: 0.838566
0.6431 --- loss: 2.067751, loss_ss: 1.420472, loss_d: 0.647279
0.8039 --- loss: 1.610451, loss_ss: 1.410054, loss_d: 0.200397
0.9646 --- loss: 1.947727, loss_ss: 1.406081, loss_d: 0.541645
Epoch finished! Loss: 2.12525704983742
Starting epoch 2/10.
0.0000 --- loss: 1.937192, loss_ss: 1.441754, loss_d: 0.495438
0.1608 --- loss: 1.740397, loss_ss: 1.443293, loss_d: 0.297104
0.3215 --- loss: 1.792493, loss_ss: 1.405978, loss_d: 0.386516
0.4823 --- loss: 1.817894, loss_ss: 1.368312, loss_d: 0.449582
0.6431 --- loss: 1.821725, loss_ss: 1.351721, loss_d: 0.470004
0.8039 --- loss: 1.786369, loss_ss: 1.375833, loss_d: 0.410536
0.9646 --- loss: 1.766766, loss_ss: 1.272762, loss_d: 0.494004
Epoch finished! Loss: 1.8231977781941813
Starting epoch 3/10.
0.0000 --- loss: 1.642422, loss_ss: 1.432023, loss_d: 0.210399
0.1608 --- loss: 1.364743, loss_ss: 1.338805, loss_d: 0.025939
0.3215 --- loss: 1.493285, loss_ss: 1.280106, loss_d: 0.213180
0.4823 --- loss: 1.738859, loss_ss: 1.305678, loss_d: 0.433181
0.6431 --- loss: 2.082057, loss_ss: 1.244749, loss_d: 0.837308
0.8039 --- loss: 1.339397, loss_ss: 1.240729, loss_d: 0.098668
0.9646 --- loss: 1.598704, loss_ss: 1.328974, loss_d: 0.269730
Epoch finished! Loss: 1.6205921192323007
Starting epoch 4/10.
0.0000 --- loss: 1.275004, loss_ss: 1.144346, loss_d: 0.130658
0.1608 --- loss: 1.189697, loss_ss: 1.096486, loss_d: 0.093211
0.3215 --- loss: 1.625053, loss_ss: 1.352796, loss_d: 0.272257
0.4823 --- loss: 1.307627, loss_ss: 1.227263, loss_d: 0.080364
0.6431 --- loss: 1.541704, loss_ss: 1.229391, loss_d: 0.312312
0.8039 --- loss: 1.225140, loss_ss: 1.117543, loss_d: 0.107597
0.9646 --- loss: 1.397224, loss_ss: 1.251810, loss_d: 0.145415
Epoch finished! Loss: 1.4127968107500384
Starting epoch 5/10.
0.0000 --- loss: 1.466253, loss_ss: 1.369773, loss_d: 0.096480
0.1608 --- loss: 1.257449, loss_ss: 1.248341, loss_d: 0.009109
0.3215 --- loss: 1.269025, loss_ss: 1.194126, loss_d: 0.074899
0.4823 --- loss: 1.202275, loss_ss: 1.180818, loss_d: 0.021457
0.6431 --- loss: 1.106644, loss_ss: 1.080243, loss_d: 0.026402
0.8039 --- loss: 1.297738, loss_ss: 1.254258, loss_d: 0.043480
0.9646 --- loss: 1.133891, loss_ss: 1.094275, loss_d: 0.039617
Epoch finished! Loss: 1.3373915341592604
Starting epoch 6/10.
0.0000 --- loss: 1.113119, loss_ss: 1.093835, loss_d: 0.019285
0.1608 --- loss: 1.548638, loss_ss: 1.176970, loss_d: 0.371668
0.3215 --- loss: 1.247166, loss_ss: 1.225204, loss_d: 0.021962
0.4823 --- loss: 1.192965, loss_ss: 1.144772, loss_d: 0.048193
0.6431 --- loss: 1.263623, loss_ss: 1.258343, loss_d: 0.005280
0.8039 --- loss: 1.244155, loss_ss: 1.079939, loss_d: 0.164216
0.9646 --- loss: 1.163244, loss_ss: 1.145210, loss_d: 0.018034
Epoch finished! Loss: 1.2254733404805582
Starting epoch 7/10.
0.0000 --- loss: 1.187505, loss_ss: 1.141343, loss_d: 0.046162
0.1608 --- loss: 1.024232, loss_ss: 1.006986, loss_d: 0.017245
0.3215 --- loss: 0.991762, loss_ss: 0.989433, loss_d: 0.002329
0.4823 --- loss: 1.035951, loss_ss: 1.033538, loss_d: 0.002413
0.6431 --- loss: 1.086271, loss_ss: 1.082967, loss_d: 0.003304
0.8039 --- loss: 1.077356, loss_ss: 1.076042, loss_d: 0.001314
0.9646 --- loss: 1.113801, loss_ss: 1.099008, loss_d: 0.014794
Epoch finished! Loss: 1.149334676804081
Starting epoch 8/10.
0.0000 --- loss: 1.170131, loss_ss: 1.167706, loss_d: 0.002425
0.1608 --- loss: 1.256181, loss_ss: 1.099203, loss_d: 0.156978
0.3215 --- loss: 1.210376, loss_ss: 1.007874, loss_d: 0.202502
0.4823 --- loss: 1.380402, loss_ss: 1.330151, loss_d: 0.050251
0.6431 --- loss: 0.921989, loss_ss: 0.919242, loss_d: 0.002748
0.8039 --- loss: 1.112230, loss_ss: 1.012235, loss_d: 0.099995
0.9646 --- loss: 1.120684, loss_ss: 1.117829, loss_d: 0.002854
Epoch finished! Loss: 1.1376864525579637
Starting epoch 9/10.
0.0000 --- loss: 1.007111, loss_ss: 1.002044, loss_d: 0.005067
0.1608 --- loss: 1.098527, loss_ss: 1.050758, loss_d: 0.047769
0.3215 --- loss: 0.961872, loss_ss: 0.937078, loss_d: 0.024794
0.4823 --- loss: 1.086140, loss_ss: 0.995315, loss_d: 0.090826
0.6431 --- loss: 1.000572, loss_ss: 0.884196, loss_d: 0.116376
0.8039 --- loss: 1.046060, loss_ss: 1.043198, loss_d: 0.002862
0.9646 --- loss: 1.166169, loss_ss: 1.055452, loss_d: 0.110718
Epoch finished! Loss: 1.0740729291592874
Starting epoch 10/10.
0.0000 --- loss: 1.222033, loss_ss: 1.220132, loss_d: 0.001901
0.1608 --- loss: 1.059370, loss_ss: 0.931040, loss_d: 0.128330
0.3215 --- loss: 1.071137, loss_ss: 0.932511, loss_d: 0.138627
0.4823 --- loss: 0.901398, loss_ss: 0.862763, loss_d: 0.038635
0.6431 --- loss: 1.082435, loss_ss: 1.082256, loss_d: 0.000179
0.8039 --- loss: 0.955532, loss_ss: 0.839451, loss_d: 0.116081
0.9646 --- loss: 1.045220, loss_ss: 1.043704, loss_d: 0.001516
Epoch finished! Loss: 1.0240641755442466
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6947916666666667
             precision    recall  f1-score   support

        0.0       0.69      0.99      0.81        74
        1.0       0.13      0.24      0.17        41
        2.0       0.78      0.68      0.73       487
        3.0       0.95      0.60      0.73       243
        4.0       0.55      0.93      0.69       115

avg / total       0.76      0.69      0.71       960
 


====== chc004-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  96.46  98.65   96.28  68.87     81.11
1  89.58  24.39   92.49  12.66     16.67
2  73.96  68.17   79.92  77.75     72.65
3  89.06  59.67   99.02  95.39     73.42
4  89.90  93.04   89.47  54.59     68.81
Total accuracy: 69.48%
Average sen: 68.79%
Average spec: 91.43%
Macro f1-score: 62.53%
Diagnosis acc on 60mins: 0.125
[0.00148763 0.99993885 0.99811685 0.99934798 0.9465816  0.94565737
 0.98828679 0.99563003]
pred: 0.8593808880250435, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc004-nsrr

=== Test on chc005-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.379437, loss_ss: 1.650136, loss_d: 0.729301
0.1605 --- loss: 2.161480, loss_ss: 1.550904, loss_d: 0.610576
0.3210 --- loss: 2.277456, loss_ss: 1.508502, loss_d: 0.768954
0.4815 --- loss: 2.170976, loss_ss: 1.468064, loss_d: 0.702912
0.6421 --- loss: 1.858202, loss_ss: 1.443313, loss_d: 0.414890
0.8026 --- loss: 2.013696, loss_ss: 1.463847, loss_d: 0.549849
0.9631 --- loss: 1.886069, loss_ss: 1.402377, loss_d: 0.483692
Epoch finished! Loss: 2.12608999975266
Starting epoch 2/10.
0.0000 --- loss: 1.977232, loss_ss: 1.333750, loss_d: 0.643482
0.1605 --- loss: 2.069522, loss_ss: 1.493751, loss_d: 0.575771
0.3210 --- loss: 1.942901, loss_ss: 1.346210, loss_d: 0.596691
0.4815 --- loss: 1.790353, loss_ss: 1.408449, loss_d: 0.381904
0.6421 --- loss: 1.560999, loss_ss: 1.312763, loss_d: 0.248236
0.8026 --- loss: 1.907675, loss_ss: 1.397168, loss_d: 0.510507
0.9631 --- loss: 1.608838, loss_ss: 1.251054, loss_d: 0.357784
Epoch finished! Loss: 1.8548149601105721
Starting epoch 3/10.
0.0000 --- loss: 1.488812, loss_ss: 1.278278, loss_d: 0.210534
0.1605 --- loss: 1.702246, loss_ss: 1.235470, loss_d: 0.466776
0.3210 --- loss: 1.520510, loss_ss: 1.326610, loss_d: 0.193900
0.4815 --- loss: 1.495485, loss_ss: 1.265139, loss_d: 0.230346
0.6421 --- loss: 1.653559, loss_ss: 1.313457, loss_d: 0.340102
0.8026 --- loss: 1.468461, loss_ss: 1.192967, loss_d: 0.275494
0.9631 --- loss: 1.407831, loss_ss: 1.195895, loss_d: 0.211935
Epoch finished! Loss: 1.6205050253099011
Starting epoch 4/10.
0.0000 --- loss: 1.279710, loss_ss: 1.175928, loss_d: 0.103782
0.1605 --- loss: 1.479507, loss_ss: 1.220603, loss_d: 0.258904
0.3210 --- loss: 1.278643, loss_ss: 1.254724, loss_d: 0.023919
0.4815 --- loss: 1.473012, loss_ss: 1.436960, loss_d: 0.036052
0.6421 --- loss: 1.162086, loss_ss: 1.108330, loss_d: 0.053756
0.8026 --- loss: 1.196464, loss_ss: 1.139974, loss_d: 0.056490
0.9631 --- loss: 1.273771, loss_ss: 1.254636, loss_d: 0.019136
Epoch finished! Loss: 1.3754216317207582
Starting epoch 5/10.
0.0000 --- loss: 1.178628, loss_ss: 1.098382, loss_d: 0.080247
0.1605 --- loss: 1.217308, loss_ss: 1.180540, loss_d: 0.036767
0.3210 --- loss: 1.310123, loss_ss: 1.212135, loss_d: 0.097988
0.4815 --- loss: 1.087035, loss_ss: 1.074227, loss_d: 0.012808
0.6421 --- loss: 1.308243, loss_ss: 1.115890, loss_d: 0.192353
0.8026 --- loss: 1.255527, loss_ss: 1.134580, loss_d: 0.120946
0.9631 --- loss: 1.377479, loss_ss: 1.106729, loss_d: 0.270750
Epoch finished! Loss: 1.2513271127977679
Starting epoch 6/10.
0.0000 --- loss: 1.121301, loss_ss: 1.118561, loss_d: 0.002740
0.1605 --- loss: 1.000306, loss_ss: 0.983199, loss_d: 0.017107
0.3210 --- loss: 1.041214, loss_ss: 1.010356, loss_d: 0.030858
0.4815 --- loss: 1.063431, loss_ss: 1.059548, loss_d: 0.003883
0.6421 --- loss: 1.216549, loss_ss: 1.215868, loss_d: 0.000681
0.8026 --- loss: 1.099206, loss_ss: 1.097334, loss_d: 0.001872
0.9631 --- loss: 1.251970, loss_ss: 1.246731, loss_d: 0.005239
Epoch finished! Loss: 1.1218373044844596
Starting epoch 7/10.
0.0000 --- loss: 0.992835, loss_ss: 0.988438, loss_d: 0.004397
0.1605 --- loss: 0.993149, loss_ss: 0.992707, loss_d: 0.000442
0.3210 --- loss: 1.045573, loss_ss: 1.044519, loss_d: 0.001055
0.4815 --- loss: 1.036209, loss_ss: 1.035200, loss_d: 0.001009
0.6421 --- loss: 0.983390, loss_ss: 0.978970, loss_d: 0.004420
0.8026 --- loss: 1.139489, loss_ss: 1.097450, loss_d: 0.042040
0.9631 --- loss: 1.101799, loss_ss: 1.099053, loss_d: 0.002746
Epoch finished! Loss: 1.0639328514375994
Starting epoch 8/10.
0.0000 --- loss: 0.997863, loss_ss: 0.996123, loss_d: 0.001740
0.1605 --- loss: 1.208998, loss_ss: 1.207685, loss_d: 0.001314
0.3210 --- loss: 0.968991, loss_ss: 0.968798, loss_d: 0.000192
0.4815 --- loss: 1.011096, loss_ss: 1.007178, loss_d: 0.003919
0.6421 --- loss: 1.213291, loss_ss: 1.211575, loss_d: 0.001717
0.8026 --- loss: 0.956610, loss_ss: 0.955750, loss_d: 0.000860
0.9631 --- loss: 0.984738, loss_ss: 0.984472, loss_d: 0.000267
Epoch finished! Loss: 1.0333727732781441
Starting epoch 9/10.
0.0000 --- loss: 0.978620, loss_ss: 0.978412, loss_d: 0.000208
0.1605 --- loss: 0.947730, loss_ss: 0.946699, loss_d: 0.001031
0.3210 --- loss: 0.848041, loss_ss: 0.847072, loss_d: 0.000969
0.4815 --- loss: 1.227992, loss_ss: 1.227752, loss_d: 0.000240
0.6421 --- loss: 0.995817, loss_ss: 0.995165, loss_d: 0.000652
0.8026 --- loss: 0.944007, loss_ss: 0.941620, loss_d: 0.002387
0.9631 --- loss: 1.086460, loss_ss: 1.085776, loss_d: 0.000684
Epoch finished! Loss: 0.9891910668342344
Starting epoch 10/10.
0.0000 --- loss: 0.840997, loss_ss: 0.839589, loss_d: 0.001408
0.1605 --- loss: 0.934235, loss_ss: 0.933259, loss_d: 0.000976
0.3210 --- loss: 0.827228, loss_ss: 0.826839, loss_d: 0.000389
0.4815 --- loss: 0.922795, loss_ss: 0.922708, loss_d: 0.000088
0.6421 --- loss: 0.967267, loss_ss: 0.966586, loss_d: 0.000681
0.8026 --- loss: 0.981956, loss_ss: 0.981675, loss_d: 0.000281
0.9631 --- loss: 0.941892, loss_ss: 0.941818, loss_d: 0.000073
Epoch finished! Loss: 0.9581332543203908
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7178571428571429
             precision    recall  f1-score   support

        0.0       0.39      1.00      0.56        39
        1.0       0.00      0.00      0.00        26
        2.0       0.75      0.83      0.79       460
        3.0       0.99      0.47      0.63       236
        4.0       0.62      0.92      0.74        79

avg / total       0.76      0.72      0.70       840
 


====== chc005-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  92.62  100.00   92.26  38.61     55.71
1  96.90    0.00  100.00   0.00      0.00
2  75.24   82.83   66.05  74.71     78.56
3  84.88   46.61   99.83  99.10     63.40
4  93.93   92.41   94.09  61.86     74.11
Total accuracy: 71.79%
Average sen: 64.37%
Average spec: 90.45%
Macro f1-score: 54.36%
Diagnosis acc on 60mins: 0.8571428571428571
[0.46095377 0.00264707 0.01680879 0.48557314 0.38030848 0.80982202
 0.1288327 ]
pred: 0.3264208535464214, label: 0
Right! Diagnosis: Other
Save 60mins of subject chc005-nsrr

=== Test on chc006-nsrr. train_data(624), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.540082, loss_ss: 1.772334, loss_d: 0.767747
0.1603 --- loss: 2.330055, loss_ss: 1.728577, loss_d: 0.601478
0.3205 --- loss: 2.088998, loss_ss: 1.574911, loss_d: 0.514087
0.4808 --- loss: 2.029564, loss_ss: 1.630898, loss_d: 0.398666
0.6410 --- loss: 1.912225, loss_ss: 1.545822, loss_d: 0.366403
0.8013 --- loss: 1.997345, loss_ss: 1.483540, loss_d: 0.513805
0.9615 --- loss: 1.911154, loss_ss: 1.520797, loss_d: 0.390357
Epoch finished! Loss: 2.2279343528132283
Starting epoch 2/10.
0.0000 --- loss: 1.966321, loss_ss: 1.535614, loss_d: 0.430707
0.1603 --- loss: 1.802641, loss_ss: 1.493981, loss_d: 0.308659
0.3205 --- loss: 2.210128, loss_ss: 1.393576, loss_d: 0.816552
0.4808 --- loss: 1.912143, loss_ss: 1.558633, loss_d: 0.353510
0.6410 --- loss: 1.802576, loss_ss: 1.464874, loss_d: 0.337702
0.8013 --- loss: 1.724945, loss_ss: 1.438227, loss_d: 0.286718
0.9615 --- loss: 1.744839, loss_ss: 1.351774, loss_d: 0.393064
Epoch finished! Loss: 1.8941796806550795
Starting epoch 3/10.
0.0000 --- loss: 1.765239, loss_ss: 1.392208, loss_d: 0.373031
0.1603 --- loss: 1.553315, loss_ss: 1.417995, loss_d: 0.135320
0.3205 --- loss: 1.507868, loss_ss: 1.394582, loss_d: 0.113287
0.4808 --- loss: 1.713544, loss_ss: 1.342251, loss_d: 0.371293
0.6410 --- loss: 1.657293, loss_ss: 1.237162, loss_d: 0.420131
0.8013 --- loss: 1.729476, loss_ss: 1.298667, loss_d: 0.430809
0.9615 --- loss: 1.659943, loss_ss: 1.192345, loss_d: 0.467598
Epoch finished! Loss: 1.620106787450852
Starting epoch 4/10.
0.0000 --- loss: 1.483320, loss_ss: 1.265806, loss_d: 0.217513
0.1603 --- loss: 1.333464, loss_ss: 1.278916, loss_d: 0.054548
0.3205 --- loss: 1.262391, loss_ss: 1.219014, loss_d: 0.043377
0.4808 --- loss: 1.235587, loss_ss: 1.213034, loss_d: 0.022553
0.6410 --- loss: 1.331797, loss_ss: 1.250010, loss_d: 0.081787
0.8013 --- loss: 1.138965, loss_ss: 1.078784, loss_d: 0.060181
0.9615 --- loss: 1.397992, loss_ss: 1.112320, loss_d: 0.285672
Epoch finished! Loss: 1.3361690409721867
Starting epoch 5/10.
0.0000 --- loss: 1.114059, loss_ss: 1.061221, loss_d: 0.052838
0.1603 --- loss: 1.049860, loss_ss: 1.041333, loss_d: 0.008527
0.3205 --- loss: 1.104540, loss_ss: 1.102946, loss_d: 0.001594
0.4808 --- loss: 1.027891, loss_ss: 1.015621, loss_d: 0.012270
0.6410 --- loss: 1.227922, loss_ss: 1.222023, loss_d: 0.005899
0.8013 --- loss: 1.071896, loss_ss: 1.052336, loss_d: 0.019560
0.9615 --- loss: 1.375427, loss_ss: 1.103128, loss_d: 0.272299
Epoch finished! Loss: 1.1753396555300681
Starting epoch 6/10.
0.0000 --- loss: 0.982489, loss_ss: 0.970306, loss_d: 0.012184
0.1603 --- loss: 1.081287, loss_ss: 1.076333, loss_d: 0.004954
0.3205 --- loss: 1.225498, loss_ss: 1.194701, loss_d: 0.030797
0.4808 --- loss: 0.926364, loss_ss: 0.883118, loss_d: 0.043246
0.6410 --- loss: 1.055025, loss_ss: 1.054704, loss_d: 0.000321
0.8013 --- loss: 1.048740, loss_ss: 1.047560, loss_d: 0.001180
0.9615 --- loss: 1.022185, loss_ss: 1.009239, loss_d: 0.012945
Epoch finished! Loss: 1.0873364710038709
Starting epoch 7/10.
0.0000 --- loss: 1.006618, loss_ss: 0.991501, loss_d: 0.015116
0.1603 --- loss: 1.158433, loss_ss: 1.152761, loss_d: 0.005672
0.3205 --- loss: 1.005664, loss_ss: 1.002775, loss_d: 0.002889
0.4808 --- loss: 0.956221, loss_ss: 0.930742, loss_d: 0.025479
0.6410 --- loss: 0.972605, loss_ss: 0.971625, loss_d: 0.000981
0.8013 --- loss: 1.028732, loss_ss: 1.012595, loss_d: 0.016137
0.9615 --- loss: 1.019040, loss_ss: 1.018652, loss_d: 0.000387
Epoch finished! Loss: 1.0724335928117075
Starting epoch 8/10.
0.0000 --- loss: 1.079429, loss_ss: 1.059374, loss_d: 0.020056
0.1603 --- loss: 1.007110, loss_ss: 1.003242, loss_d: 0.003868
0.3205 --- loss: 1.001916, loss_ss: 0.995900, loss_d: 0.006016
0.4808 --- loss: 0.953669, loss_ss: 0.927260, loss_d: 0.026409
0.6410 --- loss: 0.950699, loss_ss: 0.948948, loss_d: 0.001751
0.8013 --- loss: 0.979790, loss_ss: 0.944844, loss_d: 0.034945
0.9615 --- loss: 1.093873, loss_ss: 0.992012, loss_d: 0.101861
Epoch finished! Loss: 1.0712260498154549
Starting epoch 9/10.
0.0000 --- loss: 1.529325, loss_ss: 0.991781, loss_d: 0.537544
0.1603 --- loss: 1.006426, loss_ss: 0.909611, loss_d: 0.096816
0.3205 --- loss: 0.945199, loss_ss: 0.760268, loss_d: 0.184931
0.4808 --- loss: 0.894064, loss_ss: 0.892272, loss_d: 0.001792
0.6410 --- loss: 1.038251, loss_ss: 0.979848, loss_d: 0.058403
0.8013 --- loss: 0.862350, loss_ss: 0.858911, loss_d: 0.003439
0.9615 --- loss: 1.053499, loss_ss: 1.048965, loss_d: 0.004533
Epoch finished! Loss: 1.0127182775928127
Starting epoch 10/10.
0.0000 --- loss: 0.988441, loss_ss: 0.977275, loss_d: 0.011166
0.1603 --- loss: 0.867247, loss_ss: 0.860839, loss_d: 0.006408
0.3205 --- loss: 0.900951, loss_ss: 0.896772, loss_d: 0.004179
0.4808 --- loss: 1.000904, loss_ss: 0.997597, loss_d: 0.003306
0.6410 --- loss: 0.844122, loss_ss: 0.841290, loss_d: 0.002832
0.8013 --- loss: 0.934229, loss_ss: 0.932965, loss_d: 0.001265
0.9615 --- loss: 0.915663, loss_ss: 0.638800, loss_d: 0.276863
Epoch finished! Loss: 0.9373291375175599
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6569444444444444
             precision    recall  f1-score   support

        0.0       0.97      0.64      0.77       103
        1.0       0.43      0.03      0.06        87
        2.0       0.60      0.98      0.75       300
        3.0       0.94      0.23      0.37       133
        4.0       0.63      0.80      0.71        97

avg / total       0.70      0.66      0.59       720
 


====== chc006-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  94.58  64.08   99.68  97.06     77.19
1  87.78   3.45   99.37  42.86      6.38
2  72.50  98.33   54.05  60.45     74.87
3  85.56  23.31   99.66  93.94     37.35
4  90.97  80.41   92.62  62.90     70.59
Total accuracy: 65.69%
Average sen: 53.92%
Average spec: 89.07%
Macro f1-score: 53.28%
Diagnosis acc on 60mins: 0.0
[0.89678526 0.99996889 0.99089921 0.99198264 0.9999963  0.99691486]
pred: 0.9794245262940725, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc006-nsrr

=== Test on chc008-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.378066, loss_ss: 1.641950, loss_d: 0.736116
0.1608 --- loss: 2.003223, loss_ss: 1.501063, loss_d: 0.502160
0.3215 --- loss: 2.153830, loss_ss: 1.433054, loss_d: 0.720776
0.4823 --- loss: 2.015671, loss_ss: 1.421346, loss_d: 0.594325
0.6431 --- loss: 1.914661, loss_ss: 1.324613, loss_d: 0.590048
0.8039 --- loss: 1.716212, loss_ss: 1.334942, loss_d: 0.381270
0.9646 --- loss: 2.005549, loss_ss: 1.308334, loss_d: 0.697216
Epoch finished! Loss: 2.0353065806050457
Starting epoch 2/10.
0.0000 --- loss: 2.121574, loss_ss: 1.258037, loss_d: 0.863537
0.1608 --- loss: 1.700371, loss_ss: 1.287767, loss_d: 0.412604
0.3215 --- loss: 1.867351, loss_ss: 1.227090, loss_d: 0.640261
0.4823 --- loss: 2.013686, loss_ss: 1.311992, loss_d: 0.701695
0.6431 --- loss: 1.843160, loss_ss: 1.502254, loss_d: 0.340906
0.8039 --- loss: 1.537679, loss_ss: 1.185334, loss_d: 0.352345
0.9646 --- loss: 1.571286, loss_ss: 1.326566, loss_d: 0.244720
Epoch finished! Loss: 1.7815418493363164
Starting epoch 3/10.
0.0000 --- loss: 1.629421, loss_ss: 1.218612, loss_d: 0.410809
0.1608 --- loss: 1.743494, loss_ss: 1.300018, loss_d: 0.443475
0.3215 --- loss: 1.401735, loss_ss: 1.061312, loss_d: 0.340423
0.4823 --- loss: 1.432124, loss_ss: 1.173383, loss_d: 0.258741
0.6431 --- loss: 1.235730, loss_ss: 1.099559, loss_d: 0.136171
0.8039 --- loss: 1.359958, loss_ss: 1.085057, loss_d: 0.274900
0.9646 --- loss: 1.402021, loss_ss: 1.022669, loss_d: 0.379351
Epoch finished! Loss: 1.549457307784788
Starting epoch 4/10.
0.0000 --- loss: 1.284898, loss_ss: 1.137605, loss_d: 0.147293
0.1608 --- loss: 1.204996, loss_ss: 1.063702, loss_d: 0.141294
0.3215 --- loss: 1.192338, loss_ss: 1.104962, loss_d: 0.087376
0.4823 --- loss: 1.339707, loss_ss: 1.265628, loss_d: 0.074080
0.6431 --- loss: 1.217990, loss_ss: 1.045423, loss_d: 0.172567
0.8039 --- loss: 1.166300, loss_ss: 1.076903, loss_d: 0.089397
0.9646 --- loss: 1.120788, loss_ss: 1.070151, loss_d: 0.050637
Epoch finished! Loss: 1.2894988521452873
Starting epoch 5/10.
0.0000 --- loss: 1.282208, loss_ss: 1.276662, loss_d: 0.005546
0.1608 --- loss: 1.062032, loss_ss: 1.041168, loss_d: 0.020864
0.3215 --- loss: 1.054158, loss_ss: 1.025247, loss_d: 0.028911
0.4823 --- loss: 1.107188, loss_ss: 1.089011, loss_d: 0.018177
0.6431 --- loss: 1.127055, loss_ss: 1.113522, loss_d: 0.013533
0.8039 --- loss: 1.072785, loss_ss: 1.056208, loss_d: 0.016577
0.9646 --- loss: 1.041414, loss_ss: 1.038889, loss_d: 0.002525
Epoch finished! Loss: 1.1596364417383749
Starting epoch 6/10.
0.0000 --- loss: 1.100424, loss_ss: 1.096959, loss_d: 0.003465
0.1608 --- loss: 0.994555, loss_ss: 0.967277, loss_d: 0.027278
0.3215 --- loss: 1.018954, loss_ss: 1.016480, loss_d: 0.002473
0.4823 --- loss: 0.991066, loss_ss: 0.969653, loss_d: 0.021413
0.6431 --- loss: 1.055115, loss_ss: 1.042184, loss_d: 0.012931
0.8039 --- loss: 1.322904, loss_ss: 1.252855, loss_d: 0.070049
0.9646 --- loss: 1.074965, loss_ss: 1.070468, loss_d: 0.004497
Epoch finished! Loss: 1.0961832654091619
Starting epoch 7/10.
0.0000 --- loss: 0.926890, loss_ss: 0.909995, loss_d: 0.016896
0.1608 --- loss: 1.104164, loss_ss: 1.051924, loss_d: 0.052240
0.3215 --- loss: 0.991775, loss_ss: 0.984957, loss_d: 0.006818
0.4823 --- loss: 1.025944, loss_ss: 0.986137, loss_d: 0.039807
0.6431 --- loss: 1.002508, loss_ss: 0.998458, loss_d: 0.004050
0.8039 --- loss: 1.355134, loss_ss: 1.032516, loss_d: 0.322618
0.9646 --- loss: 1.035853, loss_ss: 1.032653, loss_d: 0.003199
Epoch finished! Loss: 1.0949340328093498
Starting epoch 8/10.
0.0000 --- loss: 0.938855, loss_ss: 0.936367, loss_d: 0.002488
0.1608 --- loss: 1.189422, loss_ss: 0.994495, loss_d: 0.194927
0.3215 --- loss: 0.984965, loss_ss: 0.911243, loss_d: 0.073722
0.4823 --- loss: 1.151480, loss_ss: 0.852873, loss_d: 0.298607
0.6431 --- loss: 1.056655, loss_ss: 1.027881, loss_d: 0.028774
0.8039 --- loss: 1.246586, loss_ss: 0.928799, loss_d: 0.317787
0.9646 --- loss: 1.084928, loss_ss: 1.066589, loss_d: 0.018338
Epoch finished! Loss: 1.141342411118169
Starting epoch 9/10.
0.0000 --- loss: 0.955790, loss_ss: 0.944371, loss_d: 0.011419
0.1608 --- loss: 1.178137, loss_ss: 1.135966, loss_d: 0.042171
0.3215 --- loss: 1.273445, loss_ss: 0.872633, loss_d: 0.400812
0.4823 --- loss: 1.089802, loss_ss: 0.914413, loss_d: 0.175389
0.6431 --- loss: 0.968262, loss_ss: 0.929269, loss_d: 0.038993
0.8039 --- loss: 1.041116, loss_ss: 1.024673, loss_d: 0.016443
0.9646 --- loss: 0.938276, loss_ss: 0.902742, loss_d: 0.035535
Epoch finished! Loss: 1.0680615527014579
Starting epoch 10/10.
0.0000 --- loss: 0.889585, loss_ss: 0.876521, loss_d: 0.013064
0.1608 --- loss: 0.932396, loss_ss: 0.924396, loss_d: 0.008000
0.3215 --- loss: 0.942968, loss_ss: 0.907297, loss_d: 0.035671
0.4823 --- loss: 0.977805, loss_ss: 0.975724, loss_d: 0.002080
0.6431 --- loss: 0.985778, loss_ss: 0.984471, loss_d: 0.001307
0.8039 --- loss: 1.023178, loss_ss: 1.014531, loss_d: 0.008647
0.9646 --- loss: 1.029242, loss_ss: 1.024946, loss_d: 0.004296
Epoch finished! Loss: 0.9369742216602448
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.690625
             precision    recall  f1-score   support

        0.0       0.73      0.98      0.83       144
        1.0       0.67      0.32      0.43        82
        2.0       0.69      0.74      0.72       379
        3.0       1.00      0.44      0.62       227
        4.0       0.52      0.88      0.66       128

avg / total       0.74      0.69      0.68       960
 


====== chc008-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  94.17  97.92   93.50   72.68     83.43
1  92.81  31.71   98.52   66.67     42.98
2  76.67  74.41   78.14   68.95     71.57
3  86.88  44.49  100.00  100.00     61.59
4  87.60  88.28   87.50   52.07     65.51
Total accuracy: 69.06%
Average sen: 67.36%
Average spec: 91.53%
Macro f1-score: 65.01%
Diagnosis acc on 60mins: 0.0
[1.         0.93096054 0.9961189  0.98952138 0.9999994  0.99944085
 0.99159616 0.99996889]
pred: 0.9884507656097412, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc008-nsrr

=== Test on chc009-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.380518, loss_ss: 1.692810, loss_d: 0.687708
0.1605 --- loss: 2.313878, loss_ss: 1.548433, loss_d: 0.765444
0.3210 --- loss: 2.052431, loss_ss: 1.520378, loss_d: 0.532052
0.4815 --- loss: 1.868321, loss_ss: 1.518866, loss_d: 0.349455
0.6421 --- loss: 1.911314, loss_ss: 1.364187, loss_d: 0.547127
0.8026 --- loss: 2.033525, loss_ss: 1.422376, loss_d: 0.611149
0.9631 --- loss: 1.809634, loss_ss: 1.333266, loss_d: 0.476368
Epoch finished! Loss: 2.1600352102710354
Starting epoch 2/10.
0.0000 --- loss: 1.915758, loss_ss: 1.348623, loss_d: 0.567135
0.1605 --- loss: 1.777447, loss_ss: 1.294305, loss_d: 0.483142
0.3210 --- loss: 1.595606, loss_ss: 1.326760, loss_d: 0.268846
0.4815 --- loss: 1.918221, loss_ss: 1.388140, loss_d: 0.530082
0.6421 --- loss: 1.838943, loss_ss: 1.226512, loss_d: 0.612432
0.8026 --- loss: 1.819932, loss_ss: 1.370970, loss_d: 0.448962
0.9631 --- loss: 2.491659, loss_ss: 1.313596, loss_d: 1.178063
Epoch finished! Loss: 1.8488193058198499
Starting epoch 3/10.
0.0000 --- loss: 1.496861, loss_ss: 1.084568, loss_d: 0.412293
0.1605 --- loss: 1.471421, loss_ss: 1.127449, loss_d: 0.343972
0.3210 --- loss: 1.695145, loss_ss: 1.167226, loss_d: 0.527918
0.4815 --- loss: 1.714136, loss_ss: 1.341914, loss_d: 0.372222
0.6421 --- loss: 1.707591, loss_ss: 1.206982, loss_d: 0.500609
0.8026 --- loss: 1.583346, loss_ss: 1.206099, loss_d: 0.377246
0.9631 --- loss: 1.762956, loss_ss: 1.181860, loss_d: 0.581096
Epoch finished! Loss: 1.6354620072149462
Starting epoch 4/10.
0.0000 --- loss: 1.258159, loss_ss: 1.143955, loss_d: 0.114204
0.1605 --- loss: 1.322210, loss_ss: 1.114938, loss_d: 0.207272
0.3210 --- loss: 1.549555, loss_ss: 1.241151, loss_d: 0.308404
0.4815 --- loss: 1.348331, loss_ss: 1.199192, loss_d: 0.149139
0.6421 --- loss: 1.319625, loss_ss: 1.221666, loss_d: 0.097959
0.8026 --- loss: 1.183038, loss_ss: 1.018944, loss_d: 0.164094
0.9631 --- loss: 1.308341, loss_ss: 1.001264, loss_d: 0.307077
Epoch finished! Loss: 1.4140453492441485
Starting epoch 5/10.
0.0000 --- loss: 1.235754, loss_ss: 1.002162, loss_d: 0.233592
0.1605 --- loss: 1.090412, loss_ss: 1.061945, loss_d: 0.028466
0.3210 --- loss: 1.489775, loss_ss: 0.982114, loss_d: 0.507661
0.4815 --- loss: 1.029831, loss_ss: 0.953048, loss_d: 0.076783
0.6421 --- loss: 1.075690, loss_ss: 1.041074, loss_d: 0.034616
0.8026 --- loss: 1.282583, loss_ss: 1.053751, loss_d: 0.228832
0.9631 --- loss: 1.332445, loss_ss: 1.039574, loss_d: 0.292871
Epoch finished! Loss: 1.2773965443334272
Starting epoch 6/10.
0.0000 --- loss: 1.226066, loss_ss: 1.189433, loss_d: 0.036633
0.1605 --- loss: 1.350648, loss_ss: 0.968505, loss_d: 0.382143
0.3210 --- loss: 1.124171, loss_ss: 1.079078, loss_d: 0.045093
0.4815 --- loss: 1.508229, loss_ss: 1.104362, loss_d: 0.403867
0.6421 --- loss: 1.540473, loss_ss: 1.099929, loss_d: 0.440544
0.8026 --- loss: 1.056851, loss_ss: 0.949100, loss_d: 0.107751
0.9631 --- loss: 1.022427, loss_ss: 0.991368, loss_d: 0.031059
Epoch finished! Loss: 1.2008345386674326
Starting epoch 7/10.
0.0000 --- loss: 1.278628, loss_ss: 1.148533, loss_d: 0.130095
0.1605 --- loss: 1.012002, loss_ss: 0.976596, loss_d: 0.035407
0.3210 --- loss: 1.083996, loss_ss: 0.984398, loss_d: 0.099598
0.4815 --- loss: 0.976823, loss_ss: 0.920133, loss_d: 0.056690
0.6421 --- loss: 1.115978, loss_ss: 0.951851, loss_d: 0.164127
0.8026 --- loss: 1.191455, loss_ss: 1.067170, loss_d: 0.124285
0.9631 --- loss: 1.091222, loss_ss: 1.077163, loss_d: 0.014059
Epoch finished! Loss: 1.0839217093683058
Starting epoch 8/10.
0.0000 --- loss: 0.921876, loss_ss: 0.886265, loss_d: 0.035611
0.1605 --- loss: 0.875940, loss_ss: 0.867366, loss_d: 0.008574
0.3210 --- loss: 0.977598, loss_ss: 0.966780, loss_d: 0.010818
0.4815 --- loss: 0.896080, loss_ss: 0.866828, loss_d: 0.029252
0.6421 --- loss: 0.836427, loss_ss: 0.830288, loss_d: 0.006139
0.8026 --- loss: 0.968819, loss_ss: 0.961741, loss_d: 0.007079
0.9631 --- loss: 0.917671, loss_ss: 0.905501, loss_d: 0.012170
Epoch finished! Loss: 0.9764449548336768
Starting epoch 9/10.
0.0000 --- loss: 0.913463, loss_ss: 0.911280, loss_d: 0.002183
0.1605 --- loss: 0.989970, loss_ss: 0.981215, loss_d: 0.008755
0.3210 --- loss: 0.946566, loss_ss: 0.861971, loss_d: 0.084595
0.4815 --- loss: 0.974922, loss_ss: 0.961535, loss_d: 0.013387
0.6421 --- loss: 1.025645, loss_ss: 1.024274, loss_d: 0.001371
0.8026 --- loss: 0.912420, loss_ss: 0.910994, loss_d: 0.001426
0.9631 --- loss: 0.751179, loss_ss: 0.745785, loss_d: 0.005394
Epoch finished! Loss: 0.9545746436042171
Starting epoch 10/10.
0.0000 --- loss: 0.845940, loss_ss: 0.843839, loss_d: 0.002101
0.1605 --- loss: 0.831180, loss_ss: 0.721465, loss_d: 0.109715
0.3210 --- loss: 0.917454, loss_ss: 0.912477, loss_d: 0.004977
0.4815 --- loss: 0.830929, loss_ss: 0.827290, loss_d: 0.003639
0.6421 --- loss: 0.853482, loss_ss: 0.835998, loss_d: 0.017485
0.8026 --- loss: 0.824966, loss_ss: 0.821949, loss_d: 0.003017
0.9631 --- loss: 0.908107, loss_ss: 0.877434, loss_d: 0.030673
Epoch finished! Loss: 0.9165177941322327
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8559523809523809
             precision    recall  f1-score   support

        0.0       0.72      1.00      0.84        57
        1.0       0.39      0.26      0.31        42
        2.0       0.95      0.83      0.88       432
        3.0       0.93      0.94      0.94       196
        4.0       0.69      0.96      0.80       113

avg / total       0.87      0.86      0.85       840
 


====== chc009-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  97.38  100.00   97.19  72.15     83.82
1  94.29   26.19   97.87  39.29     31.43
2  88.81   82.87   95.10  94.71     88.40
3  97.02   93.88   97.98  93.40     93.64
4  93.69   96.46   93.26  68.99     80.44
Total accuracy: 85.60%
Average sen: 79.88%
Average spec: 96.28%
Macro f1-score: 75.55%
Diagnosis acc on 60mins: 0.8571428571428571
[0.01046484 0.00226818 0.01448941 0.4940998  0.12201007 0.58929622
 0.17439546]
pred: 0.2010034248898072, label: 0
Right! Diagnosis: Other
Save 60mins of subject chc009-nsrr

=== Test on chc010-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.395642, loss_ss: 1.690600, loss_d: 0.705041
0.1605 --- loss: 2.117839, loss_ss: 1.613644, loss_d: 0.504195
0.3210 --- loss: 1.864042, loss_ss: 1.506661, loss_d: 0.357381
0.4815 --- loss: 2.031520, loss_ss: 1.583787, loss_d: 0.447733
0.6421 --- loss: 2.098684, loss_ss: 1.503975, loss_d: 0.594710
0.8026 --- loss: 2.035287, loss_ss: 1.486548, loss_d: 0.548739
0.9631 --- loss: 1.903477, loss_ss: 1.454644, loss_d: 0.448834
Epoch finished! Loss: 2.158429278481391
Starting epoch 2/10.
0.0000 --- loss: 2.298606, loss_ss: 1.404688, loss_d: 0.893918
0.1605 --- loss: 1.982354, loss_ss: 1.373300, loss_d: 0.609054
0.3210 --- loss: 1.977875, loss_ss: 1.349781, loss_d: 0.628093
0.4815 --- loss: 1.740895, loss_ss: 1.400438, loss_d: 0.340457
0.6421 --- loss: 1.687736, loss_ss: 1.346478, loss_d: 0.341258
0.8026 --- loss: 1.573135, loss_ss: 1.290225, loss_d: 0.282910
0.9631 --- loss: 1.821453, loss_ss: 1.341253, loss_d: 0.480201
Epoch finished! Loss: 1.8312980724919228
Starting epoch 3/10.
0.0000 --- loss: 1.552292, loss_ss: 1.291019, loss_d: 0.261274
0.1605 --- loss: 1.530762, loss_ss: 1.315093, loss_d: 0.215669
0.3210 --- loss: 1.522571, loss_ss: 1.252785, loss_d: 0.269786
0.4815 --- loss: 1.406519, loss_ss: 1.250599, loss_d: 0.155920
0.6421 --- loss: 1.420344, loss_ss: 1.161678, loss_d: 0.258666
0.8026 --- loss: 1.583412, loss_ss: 1.221820, loss_d: 0.361593
0.9631 --- loss: 1.486783, loss_ss: 1.256757, loss_d: 0.230025
Epoch finished! Loss: 1.5851628568864637
Starting epoch 4/10.
0.0000 --- loss: 1.519771, loss_ss: 1.268281, loss_d: 0.251489
0.1605 --- loss: 1.310066, loss_ss: 1.188714, loss_d: 0.121352
0.3210 --- loss: 1.213919, loss_ss: 1.170936, loss_d: 0.042983
0.4815 --- loss: 1.145620, loss_ss: 1.090076, loss_d: 0.055543
0.6421 --- loss: 1.200163, loss_ss: 1.174053, loss_d: 0.026109
0.8026 --- loss: 1.116031, loss_ss: 1.103324, loss_d: 0.012707
0.9631 --- loss: 1.522397, loss_ss: 1.143059, loss_d: 0.379337
Epoch finished! Loss: 1.3285064101219177
Starting epoch 5/10.
0.0000 --- loss: 1.157719, loss_ss: 1.092115, loss_d: 0.065604
0.1605 --- loss: 1.220316, loss_ss: 1.211646, loss_d: 0.008670
0.3210 --- loss: 1.228881, loss_ss: 0.991245, loss_d: 0.237637
0.4815 --- loss: 1.084230, loss_ss: 1.072568, loss_d: 0.011661
0.6421 --- loss: 1.078855, loss_ss: 1.052359, loss_d: 0.026496
0.8026 --- loss: 1.184844, loss_ss: 1.005022, loss_d: 0.179822
0.9631 --- loss: 1.149017, loss_ss: 1.129902, loss_d: 0.019115
Epoch finished! Loss: 1.1810099213354048
Starting epoch 6/10.
0.0000 --- loss: 0.956047, loss_ss: 0.907714, loss_d: 0.048333
0.1605 --- loss: 1.000232, loss_ss: 0.969691, loss_d: 0.030541
0.3210 --- loss: 0.987066, loss_ss: 0.971705, loss_d: 0.015361
0.4815 --- loss: 1.085191, loss_ss: 0.998324, loss_d: 0.086867
0.6421 --- loss: 1.035414, loss_ss: 1.035062, loss_d: 0.000352
0.8026 --- loss: 0.959319, loss_ss: 0.949454, loss_d: 0.009865
0.9631 --- loss: 1.184079, loss_ss: 1.103557, loss_d: 0.080522
Epoch finished! Loss: 1.0928800807845207
Starting epoch 7/10.
0.0000 --- loss: 1.048894, loss_ss: 1.021498, loss_d: 0.027396
0.1605 --- loss: 1.160384, loss_ss: 1.157359, loss_d: 0.003025
0.3210 --- loss: 0.969104, loss_ss: 0.947595, loss_d: 0.021509
0.4815 --- loss: 1.223244, loss_ss: 1.076002, loss_d: 0.147242
0.6421 --- loss: 1.014349, loss_ss: 1.013350, loss_d: 0.000999
0.8026 --- loss: 0.937078, loss_ss: 0.935961, loss_d: 0.001116
0.9631 --- loss: 1.083892, loss_ss: 1.080134, loss_d: 0.003758
Epoch finished! Loss: 1.0281388471203465
Starting epoch 8/10.
0.0000 --- loss: 0.932452, loss_ss: 0.927204, loss_d: 0.005248
0.1605 --- loss: 0.991118, loss_ss: 0.989830, loss_d: 0.001288
0.3210 --- loss: 0.929696, loss_ss: 0.927419, loss_d: 0.002277
0.4815 --- loss: 0.891253, loss_ss: 0.888784, loss_d: 0.002469
0.6421 --- loss: 0.848361, loss_ss: 0.838523, loss_d: 0.009839
0.8026 --- loss: 0.892872, loss_ss: 0.890461, loss_d: 0.002412
0.9631 --- loss: 0.974597, loss_ss: 0.970332, loss_d: 0.004265
Epoch finished! Loss: 0.9553910003554437
Starting epoch 9/10.
0.0000 --- loss: 0.965711, loss_ss: 0.964400, loss_d: 0.001310
0.1605 --- loss: 1.042670, loss_ss: 1.000780, loss_d: 0.041890
0.3210 --- loss: 0.849800, loss_ss: 0.849387, loss_d: 0.000413
0.4815 --- loss: 0.906119, loss_ss: 0.904437, loss_d: 0.001682
0.6421 --- loss: 0.774670, loss_ss: 0.773245, loss_d: 0.001425
0.8026 --- loss: 1.175849, loss_ss: 1.175645, loss_d: 0.000204
0.9631 --- loss: 0.815840, loss_ss: 0.815085, loss_d: 0.000756
Epoch finished! Loss: 0.9293927809884471
Starting epoch 10/10.
0.0000 --- loss: 1.022266, loss_ss: 1.021947, loss_d: 0.000320
0.1605 --- loss: 0.852212, loss_ss: 0.847320, loss_d: 0.004892
0.3210 --- loss: 0.853436, loss_ss: 0.853231, loss_d: 0.000205
0.4815 --- loss: 0.943015, loss_ss: 0.942936, loss_d: 0.000079
0.6421 --- loss: 0.763539, loss_ss: 0.763243, loss_d: 0.000296
0.8026 --- loss: 1.036497, loss_ss: 1.035944, loss_d: 0.000553
0.9631 --- loss: 0.975928, loss_ss: 0.975550, loss_d: 0.000378
Epoch finished! Loss: 0.8922955095767975
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6773809523809524
             precision    recall  f1-score   support

        0.0       0.76      1.00      0.87       123
        1.0       0.00      0.00      0.00        43
        2.0       0.68      0.91      0.78       400
        3.0       1.00      0.01      0.02       193
        4.0       0.56      0.99      0.71        81

avg / total       0.72      0.68      0.57       840
 


====== chc010-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  95.48  100.00   94.70   76.40     86.62
1  94.88    0.00  100.00    0.00      0.00
2  75.60   91.00   61.59   68.29     78.03
3  77.26    1.04  100.00  100.00      2.05
4  92.26   98.77   91.57   55.56     71.11
Total accuracy: 67.74%
Average sen: 58.16%
Average spec: 89.57%
Macro f1-score: 47.56%
Diagnosis acc on 60mins: 0.2857142857142857
[0.96099389 0.98690563 0.82677245 0.07772325 0.06997368 0.99689639
 0.86452001]
pred: 0.6833979008453233, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc010-nsrr

=== Test on chc012-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.430664, loss_ss: 1.725334, loss_d: 0.705330
0.1605 --- loss: 2.191089, loss_ss: 1.546786, loss_d: 0.644304
0.3210 --- loss: 2.090289, loss_ss: 1.547032, loss_d: 0.543257
0.4815 --- loss: 2.033464, loss_ss: 1.389792, loss_d: 0.643672
0.6421 --- loss: 1.865998, loss_ss: 1.346985, loss_d: 0.519014
0.8026 --- loss: 1.786535, loss_ss: 1.306451, loss_d: 0.480084
0.9631 --- loss: 1.951814, loss_ss: 1.382470, loss_d: 0.569344
Epoch finished! Loss: 2.05563562339352
Starting epoch 2/10.
0.0000 --- loss: 1.735960, loss_ss: 1.351942, loss_d: 0.384019
0.1605 --- loss: 1.602621, loss_ss: 1.273869, loss_d: 0.328753
0.3210 --- loss: 1.787894, loss_ss: 1.292078, loss_d: 0.495816
0.4815 --- loss: 1.655817, loss_ss: 1.250716, loss_d: 0.405101
0.6421 --- loss: 1.540155, loss_ss: 1.172270, loss_d: 0.367885
0.8026 --- loss: 1.729953, loss_ss: 1.163216, loss_d: 0.566738
0.9631 --- loss: 1.354592, loss_ss: 1.138321, loss_d: 0.216272
Epoch finished! Loss: 1.7085226408896907
Starting epoch 3/10.
0.0000 --- loss: 1.500017, loss_ss: 1.268566, loss_d: 0.231451
0.1605 --- loss: 1.285165, loss_ss: 1.132625, loss_d: 0.152540
0.3210 --- loss: 1.316599, loss_ss: 1.159860, loss_d: 0.156739
0.4815 --- loss: 1.362131, loss_ss: 1.119871, loss_d: 0.242261
0.6421 --- loss: 1.606345, loss_ss: 1.187876, loss_d: 0.418469
0.8026 --- loss: 1.282089, loss_ss: 1.103254, loss_d: 0.178835
0.9631 --- loss: 1.233715, loss_ss: 1.072449, loss_d: 0.161266
Epoch finished! Loss: 1.408685443862792
Starting epoch 4/10.
0.0000 --- loss: 1.169236, loss_ss: 1.094684, loss_d: 0.074552
0.1605 --- loss: 1.643211, loss_ss: 1.288215, loss_d: 0.354996
0.3210 --- loss: 1.255803, loss_ss: 1.215332, loss_d: 0.040470
0.4815 --- loss: 1.561702, loss_ss: 1.304217, loss_d: 0.257486
0.6421 --- loss: 1.058197, loss_ss: 1.047614, loss_d: 0.010583
0.8026 --- loss: 1.123691, loss_ss: 1.023522, loss_d: 0.100168
0.9631 --- loss: 1.413838, loss_ss: 1.159997, loss_d: 0.253840
Epoch finished! Loss: 1.2788894291846984
Starting epoch 5/10.
0.0000 --- loss: 1.046106, loss_ss: 1.016765, loss_d: 0.029341
0.1605 --- loss: 1.296353, loss_ss: 1.117960, loss_d: 0.178393
0.3210 --- loss: 1.061978, loss_ss: 0.998646, loss_d: 0.063331
0.4815 --- loss: 1.516302, loss_ss: 1.221790, loss_d: 0.294512
0.6421 --- loss: 1.087814, loss_ss: 0.920393, loss_d: 0.167422
0.8026 --- loss: 1.033132, loss_ss: 1.024723, loss_d: 0.008409
0.9631 --- loss: 0.939703, loss_ss: 0.852996, loss_d: 0.086707
Epoch finished! Loss: 1.162482564487765
Starting epoch 6/10.
0.0000 --- loss: 1.072765, loss_ss: 1.057148, loss_d: 0.015617
0.1605 --- loss: 0.845033, loss_ss: 0.836236, loss_d: 0.008797
0.3210 --- loss: 0.992201, loss_ss: 0.974781, loss_d: 0.017420
0.4815 --- loss: 1.125758, loss_ss: 1.015843, loss_d: 0.109915
0.6421 --- loss: 0.874744, loss_ss: 0.847938, loss_d: 0.026806
0.8026 --- loss: 0.850604, loss_ss: 0.844734, loss_d: 0.005871
0.9631 --- loss: 0.961610, loss_ss: 0.923079, loss_d: 0.038531
Epoch finished! Loss: 1.0480067028153328
Starting epoch 7/10.
0.0000 --- loss: 1.026940, loss_ss: 1.000977, loss_d: 0.025963
0.1605 --- loss: 0.858909, loss_ss: 0.828469, loss_d: 0.030440
0.3210 --- loss: 1.129369, loss_ss: 1.043944, loss_d: 0.085425
0.4815 --- loss: 0.901615, loss_ss: 0.895283, loss_d: 0.006332
0.6421 --- loss: 1.034999, loss_ss: 1.029340, loss_d: 0.005658
0.8026 --- loss: 0.985615, loss_ss: 0.956224, loss_d: 0.029391
0.9631 --- loss: 0.911651, loss_ss: 0.865738, loss_d: 0.045913
Epoch finished! Loss: 0.988129936879681
Starting epoch 8/10.
0.0000 --- loss: 0.802377, loss_ss: 0.797614, loss_d: 0.004764
0.1605 --- loss: 0.843070, loss_ss: 0.832900, loss_d: 0.010170
0.3210 --- loss: 0.975025, loss_ss: 0.948361, loss_d: 0.026664
0.4815 --- loss: 1.091120, loss_ss: 1.080716, loss_d: 0.010404
0.6421 --- loss: 0.929116, loss_ss: 0.857458, loss_d: 0.071658
0.8026 --- loss: 0.844366, loss_ss: 0.810505, loss_d: 0.033861
0.9631 --- loss: 0.871237, loss_ss: 0.829772, loss_d: 0.041465
Epoch finished! Loss: 0.9919433814864005
Starting epoch 9/10.
0.0000 --- loss: 1.052831, loss_ss: 0.809432, loss_d: 0.243399
0.1605 --- loss: 0.967240, loss_ss: 0.936013, loss_d: 0.031227
0.3210 --- loss: 0.858445, loss_ss: 0.855325, loss_d: 0.003121
0.4815 --- loss: 1.129218, loss_ss: 1.071721, loss_d: 0.057497
0.6421 --- loss: 1.131741, loss_ss: 1.130662, loss_d: 0.001079
0.8026 --- loss: 0.902893, loss_ss: 0.880530, loss_d: 0.022363
0.9631 --- loss: 0.792196, loss_ss: 0.763182, loss_d: 0.029014
Epoch finished! Loss: 0.929432632461671
Starting epoch 10/10.
0.0000 --- loss: 0.888268, loss_ss: 0.887286, loss_d: 0.000981
0.1605 --- loss: 0.938802, loss_ss: 0.935819, loss_d: 0.002983
0.3210 --- loss: 0.745083, loss_ss: 0.743526, loss_d: 0.001557
0.4815 --- loss: 0.866687, loss_ss: 0.862748, loss_d: 0.003939
0.6421 --- loss: 0.968414, loss_ss: 0.962887, loss_d: 0.005528
0.8026 --- loss: 0.813866, loss_ss: 0.812387, loss_d: 0.001479
0.9631 --- loss: 1.088958, loss_ss: 1.083610, loss_d: 0.005348
Epoch finished! Loss: 0.8827126276108527
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.736904761904762
             precision    recall  f1-score   support

        0.0       0.88      0.48      0.62        63
        1.0       0.17      0.05      0.07        22
        2.0       0.77      0.91      0.83       481
        3.0       1.00      0.40      0.57       204
        4.0       0.46      0.99      0.63        70

avg / total       0.79      0.74      0.72       840
 


====== chc012-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  95.60  47.62   99.49   88.24     61.86
1  96.90   4.55   99.39   16.67      7.14
2  79.29  91.06   63.51   76.98     83.43
3  85.36  39.71  100.00  100.00     56.84
4  90.24  98.57   89.48   46.00     62.73
Total accuracy: 73.69%
Average sen: 56.30%
Average spec: 90.37%
Macro f1-score: 54.40%
Diagnosis acc on 60mins: 0.42857142857142855
[0.99928588 0.34803477 0.99000996 0.22755328 0.00462271 0.9590714
 0.88388747]
pred: 0.6303522098543388, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc012-nsrr

=== Test on chc013-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.308754, loss_ss: 1.651996, loss_d: 0.656758
0.1605 --- loss: 2.001911, loss_ss: 1.480234, loss_d: 0.521676
0.3210 --- loss: 2.168541, loss_ss: 1.428775, loss_d: 0.739766
0.4815 --- loss: 2.016026, loss_ss: 1.491076, loss_d: 0.524950
0.6421 --- loss: 1.964286, loss_ss: 1.417893, loss_d: 0.546393
0.8026 --- loss: 2.109601, loss_ss: 1.355447, loss_d: 0.754154
0.9631 --- loss: 1.590762, loss_ss: 1.303893, loss_d: 0.286869
Epoch finished! Loss: 2.0743236080292733
Starting epoch 2/10.
0.0000 --- loss: 1.784610, loss_ss: 1.282376, loss_d: 0.502234
0.1605 --- loss: 1.475361, loss_ss: 1.253111, loss_d: 0.222249
0.3210 --- loss: 1.701286, loss_ss: 1.274976, loss_d: 0.426311
0.4815 --- loss: 1.730675, loss_ss: 1.151560, loss_d: 0.579115
0.6421 --- loss: 1.442422, loss_ss: 1.280257, loss_d: 0.162166
0.8026 --- loss: 1.835594, loss_ss: 1.212397, loss_d: 0.623198
0.9631 --- loss: 1.579577, loss_ss: 1.221747, loss_d: 0.357830
Epoch finished! Loss: 1.7622396638316493
Starting epoch 3/10.
0.0000 --- loss: 1.363886, loss_ss: 1.251889, loss_d: 0.111996
0.1605 --- loss: 1.736904, loss_ss: 1.299685, loss_d: 0.437219
0.3210 --- loss: 1.606561, loss_ss: 1.062615, loss_d: 0.543946
0.4815 --- loss: 1.309967, loss_ss: 1.160372, loss_d: 0.149594
0.6421 --- loss: 1.134340, loss_ss: 1.102070, loss_d: 0.032271
0.8026 --- loss: 1.180628, loss_ss: 1.114987, loss_d: 0.065641
0.9631 --- loss: 1.905196, loss_ss: 1.137473, loss_d: 0.767724
Epoch finished! Loss: 1.5049747209395132
Starting epoch 4/10.
0.0000 --- loss: 1.149110, loss_ss: 1.068786, loss_d: 0.080324
0.1605 --- loss: 1.193337, loss_ss: 1.093483, loss_d: 0.099854
0.3210 --- loss: 1.258501, loss_ss: 1.241724, loss_d: 0.016777
0.4815 --- loss: 1.102078, loss_ss: 1.039636, loss_d: 0.062441
0.6421 --- loss: 1.033035, loss_ss: 0.982550, loss_d: 0.050485
0.8026 --- loss: 1.073212, loss_ss: 1.044011, loss_d: 0.029201
0.9631 --- loss: 2.016634, loss_ss: 1.111551, loss_d: 0.905083
Epoch finished! Loss: 1.3170571788664787
Starting epoch 5/10.
0.0000 --- loss: 1.088929, loss_ss: 1.055015, loss_d: 0.033914
0.1605 --- loss: 0.971344, loss_ss: 0.900579, loss_d: 0.070765
0.3210 --- loss: 1.327744, loss_ss: 1.309258, loss_d: 0.018485
0.4815 --- loss: 1.112808, loss_ss: 1.057270, loss_d: 0.055538
0.6421 --- loss: 0.903517, loss_ss: 0.890678, loss_d: 0.012839
0.8026 --- loss: 0.976529, loss_ss: 0.945997, loss_d: 0.030532
0.9631 --- loss: 1.059707, loss_ss: 1.042484, loss_d: 0.017223
Epoch finished! Loss: 1.1334904893752067
Starting epoch 6/10.
0.0000 --- loss: 1.040157, loss_ss: 1.038142, loss_d: 0.002015
0.1605 --- loss: 0.990805, loss_ss: 0.971747, loss_d: 0.019058
0.3210 --- loss: 1.003418, loss_ss: 1.001437, loss_d: 0.001982
0.4815 --- loss: 1.323221, loss_ss: 1.072033, loss_d: 0.251188
0.6421 --- loss: 1.028213, loss_ss: 1.026753, loss_d: 0.001460
0.8026 --- loss: 0.977546, loss_ss: 0.961530, loss_d: 0.016017
0.9631 --- loss: 0.952340, loss_ss: 0.942820, loss_d: 0.009521
Epoch finished! Loss: 1.0346003107486232
Starting epoch 7/10.
0.0000 --- loss: 0.946508, loss_ss: 0.908573, loss_d: 0.037935
0.1605 --- loss: 0.891390, loss_ss: 0.887356, loss_d: 0.004035
0.3210 --- loss: 0.991585, loss_ss: 0.973012, loss_d: 0.018573
0.4815 --- loss: 0.927064, loss_ss: 0.925632, loss_d: 0.001432
0.6421 --- loss: 0.858625, loss_ss: 0.858445, loss_d: 0.000179
0.8026 --- loss: 0.911118, loss_ss: 0.908111, loss_d: 0.003007
0.9631 --- loss: 0.940566, loss_ss: 0.830840, loss_d: 0.109726
Epoch finished! Loss: 0.9912757027533746
Starting epoch 8/10.
0.0000 --- loss: 1.018005, loss_ss: 1.014579, loss_d: 0.003426
0.1605 --- loss: 0.919485, loss_ss: 0.919267, loss_d: 0.000218
0.3210 --- loss: 0.775420, loss_ss: 0.769969, loss_d: 0.005451
0.4815 --- loss: 0.866376, loss_ss: 0.856563, loss_d: 0.009813
0.6421 --- loss: 1.022498, loss_ss: 1.003766, loss_d: 0.018732
0.8026 --- loss: 1.412746, loss_ss: 0.931070, loss_d: 0.481676
0.9631 --- loss: 1.082760, loss_ss: 1.043380, loss_d: 0.039380
Epoch finished! Loss: 0.9915939627155181
Starting epoch 9/10.
0.0000 --- loss: 0.945421, loss_ss: 0.941038, loss_d: 0.004382
0.1605 --- loss: 1.013404, loss_ss: 1.010906, loss_d: 0.002499
0.3210 --- loss: 0.896834, loss_ss: 0.893299, loss_d: 0.003535
0.4815 --- loss: 0.878119, loss_ss: 0.877732, loss_d: 0.000387
0.6421 --- loss: 0.905633, loss_ss: 0.896025, loss_d: 0.009608
0.8026 --- loss: 0.880683, loss_ss: 0.869905, loss_d: 0.010778
0.9631 --- loss: 1.002469, loss_ss: 1.002278, loss_d: 0.000191
Epoch finished! Loss: 0.9322666160521969
Starting epoch 10/10.
0.0000 --- loss: 0.809491, loss_ss: 0.805508, loss_d: 0.003983
0.1605 --- loss: 1.070848, loss_ss: 1.052171, loss_d: 0.018677
0.3210 --- loss: 0.935607, loss_ss: 0.920541, loss_d: 0.015067
0.4815 --- loss: 0.929845, loss_ss: 0.927273, loss_d: 0.002572
0.6421 --- loss: 0.879121, loss_ss: 0.873571, loss_d: 0.005549
0.8026 --- loss: 0.905158, loss_ss: 0.896948, loss_d: 0.008210
0.9631 --- loss: 0.801252, loss_ss: 0.800836, loss_d: 0.000416
Epoch finished! Loss: 0.9185753157061916
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5928571428571429
             precision    recall  f1-score   support

        0.0       0.78      0.38      0.51        56
        1.0       0.00      0.00      0.00        33
        2.0       0.64      0.62      0.63       368
        3.0       1.00      0.42      0.59       228
        4.0       0.42      0.99      0.59       155

avg / total       0.68      0.59      0.58       840
 


====== chc013-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  95.12  37.50   99.23   77.78     50.60
1  96.07   0.00  100.00    0.00      0.00
2  68.33  61.68   73.52   64.49     63.06
3  84.29  42.11  100.00  100.00     59.26
4  74.76  99.35   69.20   42.19     59.23
Total accuracy: 59.29%
Average sen: 48.13%
Average spec: 88.39%
Macro f1-score: 46.43%
Diagnosis acc on 60mins: 0.14285714285714285
[5.60153916e-04 9.99205887e-01 9.99794304e-01 9.99744952e-01
 9.63562012e-01 9.81687844e-01 9.99868751e-01]
pred: 0.8492034147743003, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc013-nsrr

=== Test on chc014-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.453465, loss_ss: 1.760187, loss_d: 0.693278
0.1605 --- loss: 2.131034, loss_ss: 1.681788, loss_d: 0.449246
0.3210 --- loss: 2.437836, loss_ss: 1.589954, loss_d: 0.847882
0.4815 --- loss: 2.115507, loss_ss: 1.505187, loss_d: 0.610320
0.6421 --- loss: 2.055843, loss_ss: 1.517538, loss_d: 0.538305
0.8026 --- loss: 2.019436, loss_ss: 1.589325, loss_d: 0.430111
0.9631 --- loss: 2.166932, loss_ss: 1.421181, loss_d: 0.745750
Epoch finished! Loss: 2.2002427827927376
Starting epoch 2/10.
0.0000 --- loss: 2.083085, loss_ss: 1.516048, loss_d: 0.567037
0.1605 --- loss: 1.873668, loss_ss: 1.426835, loss_d: 0.446833
0.3210 --- loss: 1.816182, loss_ss: 1.426293, loss_d: 0.389889
0.4815 --- loss: 2.005325, loss_ss: 1.478614, loss_d: 0.526712
0.6421 --- loss: 1.966601, loss_ss: 1.329134, loss_d: 0.637467
0.8026 --- loss: 1.987958, loss_ss: 1.485912, loss_d: 0.502046
0.9631 --- loss: 2.049007, loss_ss: 1.306204, loss_d: 0.742802
Epoch finished! Loss: 1.929665196326471
Starting epoch 3/10.
0.0000 --- loss: 1.816481, loss_ss: 1.323103, loss_d: 0.493379
0.1605 --- loss: 1.588440, loss_ss: 1.384465, loss_d: 0.203975
0.3210 --- loss: 2.002181, loss_ss: 1.427079, loss_d: 0.575102
0.4815 --- loss: 1.349812, loss_ss: 1.246140, loss_d: 0.103672
0.6421 --- loss: 1.427772, loss_ss: 1.298418, loss_d: 0.129354
0.8026 --- loss: 1.715666, loss_ss: 1.217582, loss_d: 0.498084
0.9631 --- loss: 1.555860, loss_ss: 1.255046, loss_d: 0.300813
Epoch finished! Loss: 1.62294654884646
Starting epoch 4/10.
0.0000 --- loss: 1.432770, loss_ss: 1.306969, loss_d: 0.125801
0.1605 --- loss: 1.445273, loss_ss: 1.236161, loss_d: 0.209112
0.3210 --- loss: 1.323191, loss_ss: 1.187207, loss_d: 0.135984
0.4815 --- loss: 1.358120, loss_ss: 1.208847, loss_d: 0.149273
0.6421 --- loss: 1.524165, loss_ss: 1.230632, loss_d: 0.293533
0.8026 --- loss: 1.490544, loss_ss: 1.214460, loss_d: 0.276084
0.9631 --- loss: 1.187065, loss_ss: 1.145923, loss_d: 0.041141
Epoch finished! Loss: 1.4354346413766184
Starting epoch 5/10.
0.0000 --- loss: 1.236958, loss_ss: 1.198229, loss_d: 0.038729
0.1605 --- loss: 1.486818, loss_ss: 1.408584, loss_d: 0.078234
0.3210 --- loss: 1.213241, loss_ss: 1.198143, loss_d: 0.015098
0.4815 --- loss: 1.103440, loss_ss: 1.076307, loss_d: 0.027133
0.6421 --- loss: 1.164205, loss_ss: 1.096749, loss_d: 0.067456
0.8026 --- loss: 1.107889, loss_ss: 1.096038, loss_d: 0.011850
0.9631 --- loss: 1.023302, loss_ss: 1.018377, loss_d: 0.004925
Epoch finished! Loss: 1.2091522755161408
Starting epoch 6/10.
0.0000 --- loss: 1.137526, loss_ss: 1.121993, loss_d: 0.015532
0.1605 --- loss: 1.003633, loss_ss: 1.001764, loss_d: 0.001870
0.3210 --- loss: 1.150944, loss_ss: 1.138871, loss_d: 0.012073
0.4815 --- loss: 1.214549, loss_ss: 1.214208, loss_d: 0.000340
0.6421 --- loss: 1.121584, loss_ss: 1.103130, loss_d: 0.018454
0.8026 --- loss: 1.315920, loss_ss: 1.041252, loss_d: 0.274668
0.9631 --- loss: 0.997926, loss_ss: 0.992946, loss_d: 0.004980
Epoch finished! Loss: 1.1484890810904964
Starting epoch 7/10.
0.0000 --- loss: 1.086698, loss_ss: 1.082858, loss_d: 0.003840
0.1605 --- loss: 1.067080, loss_ss: 1.061253, loss_d: 0.005828
0.3210 --- loss: 1.098874, loss_ss: 1.084309, loss_d: 0.014566
0.4815 --- loss: 0.920346, loss_ss: 0.919508, loss_d: 0.000839
0.6421 --- loss: 1.069955, loss_ss: 1.004972, loss_d: 0.064983
0.8026 --- loss: 1.088186, loss_ss: 1.050927, loss_d: 0.037258
0.9631 --- loss: 0.983882, loss_ss: 0.979591, loss_d: 0.004290
Epoch finished! Loss: 1.0845311360974466
Starting epoch 8/10.
0.0000 --- loss: 0.880702, loss_ss: 0.879645, loss_d: 0.001057
0.1605 --- loss: 0.898135, loss_ss: 0.882077, loss_d: 0.016057
0.3210 --- loss: 1.231977, loss_ss: 1.228754, loss_d: 0.003222
0.4815 --- loss: 1.003006, loss_ss: 0.915517, loss_d: 0.087489
0.6421 --- loss: 0.846446, loss_ss: 0.811701, loss_d: 0.034744
0.8026 --- loss: 0.915784, loss_ss: 0.876324, loss_d: 0.039460
0.9631 --- loss: 0.872245, loss_ss: 0.871009, loss_d: 0.001236
Epoch finished! Loss: 1.0009718498876017
Starting epoch 9/10.
0.0000 --- loss: 0.910552, loss_ss: 0.879147, loss_d: 0.031405
0.1605 --- loss: 0.864342, loss_ss: 0.859627, loss_d: 0.004715
0.3210 --- loss: 0.906630, loss_ss: 0.904491, loss_d: 0.002139
0.4815 --- loss: 0.903369, loss_ss: 0.882346, loss_d: 0.021023
0.6421 --- loss: 0.858008, loss_ss: 0.852188, loss_d: 0.005821
0.8026 --- loss: 0.871297, loss_ss: 0.862653, loss_d: 0.008644
0.9631 --- loss: 0.793985, loss_ss: 0.793108, loss_d: 0.000877
Epoch finished! Loss: 0.9440432661964048
Starting epoch 10/10.
0.0000 --- loss: 0.896343, loss_ss: 0.892123, loss_d: 0.004220
0.1605 --- loss: 0.981644, loss_ss: 0.953570, loss_d: 0.028074
0.3210 --- loss: 0.918298, loss_ss: 0.871384, loss_d: 0.046914
0.4815 --- loss: 0.848755, loss_ss: 0.847418, loss_d: 0.001337
0.6421 --- loss: 0.945429, loss_ss: 0.944596, loss_d: 0.000833
0.8026 --- loss: 0.810700, loss_ss: 0.774828, loss_d: 0.035872
0.9631 --- loss: 0.828535, loss_ss: 0.828041, loss_d: 0.000495
Epoch finished! Loss: 0.9202025878813959
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.775
             precision    recall  f1-score   support

        0.0       0.94      1.00      0.97       240
        1.0       0.00      0.00      0.00         6
        2.0       0.81      0.67      0.73       376
        3.0       0.99      0.59      0.74       143
        4.0       0.40      1.00      0.57        75

avg / total       0.84      0.78      0.78       840
 


====== chc014-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  98.33  100.00   97.67  94.49     97.17
1  99.05    0.00   99.76   0.00      0.00
2  78.21   66.76   87.50  81.23     73.28
3  92.98   59.44   99.86  98.84     74.24
4  86.43  100.00   85.10  39.68     56.82
Total accuracy: 77.50%
Average sen: 65.24%
Average spec: 93.98%
Macro f1-score: 60.30%
Diagnosis acc on 60mins: 0.42857142857142855
[0.98265529 0.26960927 0.56225556 0.64403111 0.39528728 0.29874402
 0.85290337]
pred: 0.5722122703279767, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc014-nsrr

=== Test on chc015-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.400290, loss_ss: 1.675512, loss_d: 0.724778
0.1605 --- loss: 2.339247, loss_ss: 1.614864, loss_d: 0.724383
0.3210 --- loss: 2.265324, loss_ss: 1.496824, loss_d: 0.768500
0.4815 --- loss: 2.183852, loss_ss: 1.403855, loss_d: 0.779997
0.6421 --- loss: 2.239586, loss_ss: 1.586870, loss_d: 0.652716
0.8026 --- loss: 1.878835, loss_ss: 1.217850, loss_d: 0.660985
0.9631 --- loss: 1.620245, loss_ss: 1.226498, loss_d: 0.393747
Epoch finished! Loss: 2.072047527759306
Starting epoch 2/10.
0.0000 --- loss: 1.862623, loss_ss: 1.346523, loss_d: 0.516099
0.1605 --- loss: 1.865991, loss_ss: 1.190060, loss_d: 0.675931
0.3210 --- loss: 1.710785, loss_ss: 1.306684, loss_d: 0.404100
0.4815 --- loss: 1.755147, loss_ss: 1.254150, loss_d: 0.500997
0.6421 --- loss: 1.618038, loss_ss: 1.266528, loss_d: 0.351510
0.8026 --- loss: 1.805782, loss_ss: 1.269228, loss_d: 0.536554
0.9631 --- loss: 1.374048, loss_ss: 1.183895, loss_d: 0.190153
Epoch finished! Loss: 1.7851016790636125
Starting epoch 3/10.
0.0000 --- loss: 1.908889, loss_ss: 1.116572, loss_d: 0.792317
0.1605 --- loss: 1.452005, loss_ss: 1.102494, loss_d: 0.349511
0.3210 --- loss: 1.426857, loss_ss: 1.177405, loss_d: 0.249452
0.4815 --- loss: 1.293833, loss_ss: 1.057440, loss_d: 0.236393
0.6421 --- loss: 1.346794, loss_ss: 1.126087, loss_d: 0.220707
0.8026 --- loss: 1.517270, loss_ss: 1.180573, loss_d: 0.336697
0.9631 --- loss: 1.662496, loss_ss: 1.172464, loss_d: 0.490032
Epoch finished! Loss: 1.496424799965274
Starting epoch 4/10.
0.0000 --- loss: 1.992837, loss_ss: 1.157602, loss_d: 0.835235
0.1605 --- loss: 1.183178, loss_ss: 1.094914, loss_d: 0.088264
0.3210 --- loss: 1.120353, loss_ss: 1.086177, loss_d: 0.034176
0.4815 --- loss: 1.197199, loss_ss: 1.134972, loss_d: 0.062226
0.6421 --- loss: 1.319941, loss_ss: 0.981008, loss_d: 0.338933
0.8026 --- loss: 1.303268, loss_ss: 1.228225, loss_d: 0.075043
0.9631 --- loss: 1.279833, loss_ss: 1.054110, loss_d: 0.225723
Epoch finished! Loss: 1.3278282227054719
Starting epoch 5/10.
0.0000 --- loss: 1.032366, loss_ss: 1.024336, loss_d: 0.008030
0.1605 --- loss: 1.246209, loss_ss: 1.173227, loss_d: 0.072982
0.3210 --- loss: 1.188737, loss_ss: 1.177304, loss_d: 0.011434
0.4815 --- loss: 1.152542, loss_ss: 1.003112, loss_d: 0.149431
0.6421 --- loss: 1.105490, loss_ss: 0.940214, loss_d: 0.165275
0.8026 --- loss: 1.021140, loss_ss: 1.012774, loss_d: 0.008365
0.9631 --- loss: 1.181738, loss_ss: 1.170162, loss_d: 0.011576
Epoch finished! Loss: 1.168679222945244
Starting epoch 6/10.
0.0000 --- loss: 1.269349, loss_ss: 1.256135, loss_d: 0.013214
0.1605 --- loss: 1.145569, loss_ss: 1.142092, loss_d: 0.003476
0.3210 --- loss: 1.225953, loss_ss: 1.221092, loss_d: 0.004860
0.4815 --- loss: 0.985774, loss_ss: 0.957761, loss_d: 0.028013
0.6421 --- loss: 0.882976, loss_ss: 0.873411, loss_d: 0.009565
0.8026 --- loss: 1.059729, loss_ss: 1.050700, loss_d: 0.009029
0.9631 --- loss: 1.086764, loss_ss: 1.083144, loss_d: 0.003620
Epoch finished! Loss: 1.0658785816161864
Starting epoch 7/10.
0.0000 --- loss: 1.174145, loss_ss: 1.156171, loss_d: 0.017974
0.1605 --- loss: 0.959484, loss_ss: 0.950255, loss_d: 0.009229
0.3210 --- loss: 0.997571, loss_ss: 0.994767, loss_d: 0.002804
0.4815 --- loss: 0.966291, loss_ss: 0.947333, loss_d: 0.018958
0.6421 --- loss: 1.060772, loss_ss: 1.015315, loss_d: 0.045457
0.8026 --- loss: 1.039146, loss_ss: 1.037602, loss_d: 0.001544
0.9631 --- loss: 1.151112, loss_ss: 1.128927, loss_d: 0.022184
Epoch finished! Loss: 1.0440425122937849
Starting epoch 8/10.
0.0000 --- loss: 0.951991, loss_ss: 0.936267, loss_d: 0.015724
0.1605 --- loss: 1.102731, loss_ss: 1.071957, loss_d: 0.030774
0.3210 --- loss: 1.007563, loss_ss: 1.007174, loss_d: 0.000389
0.4815 --- loss: 0.843262, loss_ss: 0.839931, loss_d: 0.003331
0.6421 --- loss: 0.873564, loss_ss: 0.870870, loss_d: 0.002694
0.8026 --- loss: 0.878195, loss_ss: 0.874142, loss_d: 0.004053
0.9631 --- loss: 0.957344, loss_ss: 0.957041, loss_d: 0.000303
Epoch finished! Loss: 0.9959313927158233
Starting epoch 9/10.
0.0000 --- loss: 0.894513, loss_ss: 0.892781, loss_d: 0.001732
0.1605 --- loss: 0.864254, loss_ss: 0.861287, loss_d: 0.002967
0.3210 --- loss: 1.020449, loss_ss: 1.019003, loss_d: 0.001446
0.4815 --- loss: 1.040653, loss_ss: 1.036103, loss_d: 0.004550
0.6421 --- loss: 0.915718, loss_ss: 0.912261, loss_d: 0.003457
0.8026 --- loss: 1.357472, loss_ss: 0.868945, loss_d: 0.488527
0.9631 --- loss: 0.916863, loss_ss: 0.914629, loss_d: 0.002234
Epoch finished! Loss: 0.9943637905582305
Starting epoch 10/10.
0.0000 --- loss: 0.884476, loss_ss: 0.881731, loss_d: 0.002745
0.1605 --- loss: 0.801020, loss_ss: 0.783187, loss_d: 0.017833
0.3210 --- loss: 0.862825, loss_ss: 0.861352, loss_d: 0.001473
0.4815 --- loss: 0.966615, loss_ss: 0.964942, loss_d: 0.001672
0.6421 --- loss: 0.816009, loss_ss: 0.806600, loss_d: 0.009408
0.8026 --- loss: 1.272175, loss_ss: 1.265063, loss_d: 0.007112
0.9631 --- loss: 1.307549, loss_ss: 0.828898, loss_d: 0.478652
Epoch finished! Loss: 0.9894496952333758
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7583333333333333
             precision    recall  f1-score   support

        0.0       0.64      0.60      0.62        35
        1.0       0.00      0.00      0.00        70
        2.0       0.70      0.99      0.82       438
        3.0       1.00      0.58      0.74       166
        4.0       0.92      0.65      0.76       131

avg / total       0.73      0.76      0.72       840
 


====== chc015-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  96.90  60.00   98.51   63.64     61.76
1  91.55   0.00   99.87    0.00      0.00
2  77.74  99.09   54.48   70.34     82.27
3  91.79  58.43  100.00  100.00     73.76
4  93.69  64.89   99.01   92.39     76.23
Total accuracy: 75.83%
Average sen: 56.48%
Average spec: 90.37%
Macro f1-score: 58.81%
Diagnosis acc on 60mins: 0.14285714285714285
[0.38579625 0.99975401 0.99994385 0.99979037 0.9992047  0.97871333
 0.98729426]
pred: 0.9072138241359166, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc015-nsrr

=== Test on chc016-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.472888, loss_ss: 1.787538, loss_d: 0.685350
0.1605 --- loss: 2.387091, loss_ss: 1.608884, loss_d: 0.778208
0.3210 --- loss: 2.157439, loss_ss: 1.554817, loss_d: 0.602621
0.4815 --- loss: 2.141145, loss_ss: 1.476095, loss_d: 0.665050
0.6421 --- loss: 2.298768, loss_ss: 1.541701, loss_d: 0.757067
0.8026 --- loss: 1.936742, loss_ss: 1.425501, loss_d: 0.511242
0.9631 --- loss: 2.053806, loss_ss: 1.436022, loss_d: 0.617784
Epoch finished! Loss: 2.160486227081668
Starting epoch 2/10.
0.0000 --- loss: 1.989816, loss_ss: 1.457114, loss_d: 0.532702
0.1605 --- loss: 1.937141, loss_ss: 1.402831, loss_d: 0.534310
0.3210 --- loss: 1.904657, loss_ss: 1.377024, loss_d: 0.527634
0.4815 --- loss: 1.950061, loss_ss: 1.355266, loss_d: 0.594795
0.6421 --- loss: 1.973220, loss_ss: 1.329530, loss_d: 0.643690
0.8026 --- loss: 1.912839, loss_ss: 1.441399, loss_d: 0.471440
0.9631 --- loss: 1.611401, loss_ss: 1.311002, loss_d: 0.300399
Epoch finished! Loss: 1.8634725059232404
Starting epoch 3/10.
0.0000 --- loss: 1.656398, loss_ss: 1.379965, loss_d: 0.276433
0.1605 --- loss: 1.508739, loss_ss: 1.265054, loss_d: 0.243685
0.3210 --- loss: 1.425238, loss_ss: 1.350153, loss_d: 0.075085
0.4815 --- loss: 1.647774, loss_ss: 1.278293, loss_d: 0.369480
0.6421 --- loss: 1.575618, loss_ss: 1.285714, loss_d: 0.289904
0.8026 --- loss: 1.884045, loss_ss: 1.307318, loss_d: 0.576727
0.9631 --- loss: 1.771098, loss_ss: 1.276742, loss_d: 0.494356
Epoch finished! Loss: 1.613569059679585
Starting epoch 4/10.
0.0000 --- loss: 1.292020, loss_ss: 1.141085, loss_d: 0.150936
0.1605 --- loss: 1.379899, loss_ss: 1.302922, loss_d: 0.076977
0.3210 --- loss: 1.326944, loss_ss: 1.194518, loss_d: 0.132426
0.4815 --- loss: 1.288433, loss_ss: 1.211467, loss_d: 0.076966
0.6421 --- loss: 1.168550, loss_ss: 1.097134, loss_d: 0.071417
0.8026 --- loss: 1.334423, loss_ss: 1.319154, loss_d: 0.015269
0.9631 --- loss: 1.236800, loss_ss: 1.208437, loss_d: 0.028363
Epoch finished! Loss: 1.398878328261837
Starting epoch 5/10.
0.0000 --- loss: 1.246286, loss_ss: 1.138569, loss_d: 0.107718
0.1605 --- loss: 1.177672, loss_ss: 1.142050, loss_d: 0.035622
0.3210 --- loss: 1.127452, loss_ss: 1.092480, loss_d: 0.034973
0.4815 --- loss: 1.164322, loss_ss: 1.017503, loss_d: 0.146819
0.6421 --- loss: 1.176825, loss_ss: 1.171611, loss_d: 0.005214
0.8026 --- loss: 1.210890, loss_ss: 1.203890, loss_d: 0.007001
0.9631 --- loss: 1.174513, loss_ss: 1.169337, loss_d: 0.005177
Epoch finished! Loss: 1.199815942395118
Starting epoch 6/10.
0.0000 --- loss: 1.155188, loss_ss: 1.043459, loss_d: 0.111729
0.1605 --- loss: 1.125977, loss_ss: 1.122557, loss_d: 0.003420
0.3210 --- loss: 1.083871, loss_ss: 1.065052, loss_d: 0.018819
0.4815 --- loss: 1.282403, loss_ss: 1.244664, loss_d: 0.037739
0.6421 --- loss: 1.178415, loss_ss: 1.059239, loss_d: 0.119176
0.8026 --- loss: 1.250512, loss_ss: 1.247280, loss_d: 0.003232
0.9631 --- loss: 1.057712, loss_ss: 1.053429, loss_d: 0.004283
Epoch finished! Loss: 1.1453953779512835
Starting epoch 7/10.
0.0000 --- loss: 0.992591, loss_ss: 0.965682, loss_d: 0.026909
0.1605 --- loss: 1.038724, loss_ss: 0.989332, loss_d: 0.049391
0.3210 --- loss: 1.139435, loss_ss: 1.080693, loss_d: 0.058742
0.4815 --- loss: 0.936275, loss_ss: 0.934090, loss_d: 0.002185
0.6421 --- loss: 1.046097, loss_ss: 0.999627, loss_d: 0.046470
0.8026 --- loss: 1.120632, loss_ss: 1.106060, loss_d: 0.014572
0.9631 --- loss: 1.208183, loss_ss: 1.206577, loss_d: 0.001606
Epoch finished! Loss: 1.0769079375651576
Starting epoch 8/10.
0.0000 --- loss: 1.059650, loss_ss: 1.056273, loss_d: 0.003377
0.1605 --- loss: 0.965940, loss_ss: 0.915688, loss_d: 0.050251
0.3210 --- loss: 0.915600, loss_ss: 0.915177, loss_d: 0.000423
0.4815 --- loss: 1.002807, loss_ss: 1.001467, loss_d: 0.001340
0.6421 --- loss: 0.974834, loss_ss: 0.968536, loss_d: 0.006298
0.8026 --- loss: 1.023175, loss_ss: 0.920218, loss_d: 0.102957
0.9631 --- loss: 0.895137, loss_ss: 0.868469, loss_d: 0.026669
Epoch finished! Loss: 0.9849930472912327
Starting epoch 9/10.
0.0000 --- loss: 0.820568, loss_ss: 0.820086, loss_d: 0.000482
0.1605 --- loss: 1.024297, loss_ss: 0.959419, loss_d: 0.064878
0.3210 --- loss: 0.974560, loss_ss: 0.921200, loss_d: 0.053360
0.4815 --- loss: 0.838138, loss_ss: 0.837768, loss_d: 0.000370
0.6421 --- loss: 0.966662, loss_ss: 0.954185, loss_d: 0.012477
0.8026 --- loss: 0.811118, loss_ss: 0.810734, loss_d: 0.000384
0.9631 --- loss: 0.973152, loss_ss: 0.960924, loss_d: 0.012228
Epoch finished! Loss: 0.9846270834245989
Starting epoch 10/10.
0.0000 --- loss: 1.149211, loss_ss: 0.863740, loss_d: 0.285471
0.1605 --- loss: 0.871092, loss_ss: 0.870749, loss_d: 0.000344
0.3210 --- loss: 0.845556, loss_ss: 0.844887, loss_d: 0.000669
0.4815 --- loss: 0.920715, loss_ss: 0.919982, loss_d: 0.000733
0.6421 --- loss: 1.152444, loss_ss: 1.150653, loss_d: 0.001791
0.8026 --- loss: 0.917249, loss_ss: 0.915895, loss_d: 0.001354
0.9631 --- loss: 0.884489, loss_ss: 0.808209, loss_d: 0.076280
Epoch finished! Loss: 0.9741037276483351
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8404761904761905
             precision    recall  f1-score   support

        0.0       0.83      1.00      0.90       225
        1.0       0.00      0.00      0.00        52
        2.0       0.85      0.92      0.89       363
        3.0       1.00      0.57      0.73       108
        4.0       0.75      0.92      0.83        92

avg / total       0.80      0.84      0.81       840
 


====== chc016-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  94.29  99.56   92.36   82.66     90.32
1  93.81   0.00  100.00    0.00      0.00
2  89.76  92.29   87.84   85.24     88.62
3  94.52  57.41  100.00  100.00     72.94
4  95.71  92.39   96.12   74.56     82.52
Total accuracy: 84.05%
Average sen: 68.33%
Average spec: 95.26%
Macro f1-score: 66.88%
Diagnosis acc on 60mins: 0.2857142857142857
[0.9999783  0.02866047 0.78459233 0.75708413 0.71337914 0.00216755
 0.90910083]
pred: 0.5992803948465735, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc016-nsrr

=== Test on chc022-nsrr. train_data(624), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.450914, loss_ss: 1.716362, loss_d: 0.734552
0.1603 --- loss: 2.231566, loss_ss: 1.589900, loss_d: 0.641666
0.3205 --- loss: 2.360038, loss_ss: 1.542467, loss_d: 0.817571
0.4808 --- loss: 1.951346, loss_ss: 1.392986, loss_d: 0.558359
0.6410 --- loss: 1.918117, loss_ss: 1.434592, loss_d: 0.483525
0.8013 --- loss: 1.906652, loss_ss: 1.441468, loss_d: 0.465185
0.9615 --- loss: 1.956373, loss_ss: 1.433723, loss_d: 0.522650
Epoch finished! Loss: 2.131453815967806
Starting epoch 2/10.
0.0000 --- loss: 1.909166, loss_ss: 1.383786, loss_d: 0.525380
0.1603 --- loss: 2.020696, loss_ss: 1.382542, loss_d: 0.638155
0.3205 --- loss: 1.603420, loss_ss: 1.333246, loss_d: 0.270175
0.4808 --- loss: 2.234654, loss_ss: 1.282796, loss_d: 0.951858
0.6410 --- loss: 1.717359, loss_ss: 1.295846, loss_d: 0.421513
0.8013 --- loss: 1.788624, loss_ss: 1.331035, loss_d: 0.457590
0.9615 --- loss: 1.579037, loss_ss: 1.185409, loss_d: 0.393627
Epoch finished! Loss: 1.7961735379311345
Starting epoch 3/10.
0.0000 --- loss: 1.623250, loss_ss: 1.255696, loss_d: 0.367555
0.1603 --- loss: 1.374219, loss_ss: 1.142169, loss_d: 0.232049
0.3205 --- loss: 1.358277, loss_ss: 1.171317, loss_d: 0.186961
0.4808 --- loss: 1.728078, loss_ss: 1.121243, loss_d: 0.606834
0.6410 --- loss: 1.809123, loss_ss: 1.161762, loss_d: 0.647361
0.8013 --- loss: 1.301980, loss_ss: 1.081615, loss_d: 0.220366
0.9615 --- loss: 1.311239, loss_ss: 1.082841, loss_d: 0.228397
Epoch finished! Loss: 1.5315015046827254
Starting epoch 4/10.
0.0000 --- loss: 1.214800, loss_ss: 1.143476, loss_d: 0.071324
0.1603 --- loss: 1.174307, loss_ss: 1.069339, loss_d: 0.104968
0.3205 --- loss: 1.290142, loss_ss: 1.234240, loss_d: 0.055902
0.4808 --- loss: 1.249425, loss_ss: 1.162168, loss_d: 0.087258
0.6410 --- loss: 1.178270, loss_ss: 1.128937, loss_d: 0.049333
0.8013 --- loss: 1.463311, loss_ss: 1.139138, loss_d: 0.324173
0.9615 --- loss: 1.510702, loss_ss: 1.114864, loss_d: 0.395839
Epoch finished! Loss: 1.3445837017028563
Starting epoch 5/10.
0.0000 --- loss: 1.051707, loss_ss: 0.987387, loss_d: 0.064321
0.1603 --- loss: 1.169465, loss_ss: 1.134776, loss_d: 0.034689
0.3205 --- loss: 1.129798, loss_ss: 1.101975, loss_d: 0.027823
0.4808 --- loss: 1.270192, loss_ss: 1.176410, loss_d: 0.093782
0.6410 --- loss: 1.046914, loss_ss: 1.018810, loss_d: 0.028104
0.8013 --- loss: 0.970833, loss_ss: 0.959751, loss_d: 0.011081
0.9615 --- loss: 1.099216, loss_ss: 1.018135, loss_d: 0.081081
Epoch finished! Loss: 1.1964557074731397
Starting epoch 6/10.
0.0000 --- loss: 1.122819, loss_ss: 1.117842, loss_d: 0.004977
0.1603 --- loss: 1.141349, loss_ss: 1.015098, loss_d: 0.126251
0.3205 --- loss: 1.108593, loss_ss: 1.072278, loss_d: 0.036315
0.4808 --- loss: 1.066471, loss_ss: 1.063979, loss_d: 0.002492
0.6410 --- loss: 1.057519, loss_ss: 1.047719, loss_d: 0.009800
0.8013 --- loss: 1.011853, loss_ss: 1.006383, loss_d: 0.005470
0.9615 --- loss: 1.049608, loss_ss: 1.046282, loss_d: 0.003327
Epoch finished! Loss: 1.0795695695184893
Starting epoch 7/10.
0.0000 --- loss: 1.053135, loss_ss: 1.051113, loss_d: 0.002022
0.1603 --- loss: 0.892153, loss_ss: 0.890363, loss_d: 0.001790
0.3205 --- loss: 1.051868, loss_ss: 1.032169, loss_d: 0.019698
0.4808 --- loss: 0.868766, loss_ss: 0.856033, loss_d: 0.012733
0.6410 --- loss: 1.112534, loss_ss: 1.107492, loss_d: 0.005043
0.8013 --- loss: 1.083701, loss_ss: 1.076912, loss_d: 0.006789
0.9615 --- loss: 1.154010, loss_ss: 1.148772, loss_d: 0.005238
Epoch finished! Loss: 1.0032883382612658
Starting epoch 8/10.
0.0000 --- loss: 1.007999, loss_ss: 1.006058, loss_d: 0.001941
0.1603 --- loss: 1.076854, loss_ss: 1.056202, loss_d: 0.020653
0.3205 --- loss: 0.984843, loss_ss: 0.983303, loss_d: 0.001539
0.4808 --- loss: 0.810778, loss_ss: 0.804662, loss_d: 0.006116
0.6410 --- loss: 1.000636, loss_ss: 0.997676, loss_d: 0.002960
0.8013 --- loss: 0.977280, loss_ss: 0.976607, loss_d: 0.000672
0.9615 --- loss: 0.916347, loss_ss: 0.914987, loss_d: 0.001360
Epoch finished! Loss: 0.9888014668418516
Starting epoch 9/10.
0.0000 --- loss: 1.130518, loss_ss: 1.128711, loss_d: 0.001808
0.1603 --- loss: 0.955592, loss_ss: 0.949193, loss_d: 0.006400
0.3205 --- loss: 1.000737, loss_ss: 0.999317, loss_d: 0.001420
0.4808 --- loss: 0.791211, loss_ss: 0.788870, loss_d: 0.002341
0.6410 --- loss: 1.003143, loss_ss: 0.991029, loss_d: 0.012114
0.8013 --- loss: 0.969680, loss_ss: 0.963445, loss_d: 0.006234
0.9615 --- loss: 0.838677, loss_ss: 0.838357, loss_d: 0.000319
Epoch finished! Loss: 0.9576229260813806
Starting epoch 10/10.
0.0000 --- loss: 1.121105, loss_ss: 1.120537, loss_d: 0.000568
0.1603 --- loss: 0.872648, loss_ss: 0.871862, loss_d: 0.000786
0.3205 --- loss: 0.903990, loss_ss: 0.902818, loss_d: 0.001172
0.4808 --- loss: 1.067749, loss_ss: 1.067493, loss_d: 0.000255
0.6410 --- loss: 0.744621, loss_ss: 0.744030, loss_d: 0.000590
0.8013 --- loss: 0.844819, loss_ss: 0.841568, loss_d: 0.003252
0.9615 --- loss: 0.832779, loss_ss: 0.816320, loss_d: 0.016459
Epoch finished! Loss: 0.9339634208909927
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7680555555555556
             precision    recall  f1-score   support

        0.0       0.96      0.55      0.70        91
        1.0       0.00      0.00      0.00         5
        2.0       0.75      0.94      0.83       328
        3.0       0.93      0.71      0.81       187
        4.0       0.55      0.58      0.57       109

avg / total       0.79      0.77      0.76       720
 


====== chc022-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  94.03  54.95   99.68  96.15     69.93
1  99.31   0.00  100.00   0.00      0.00
2  82.64  93.60   73.47  74.70     83.09
3  91.11  71.12   98.12  93.01     80.61
4  86.53  57.80   91.65  55.26     56.50
Total accuracy: 76.81%
Average sen: 55.49%
Average spec: 92.59%
Macro f1-score: 58.02%
Diagnosis acc on 60mins: 0.6666666666666666
[9.97607708e-01 8.52807643e-05 8.86320099e-02 1.20153747e-01
 6.89450085e-01 1.56245783e-01]
pred: 0.34202910238309414, label: 0
Right! Diagnosis: Other
Save 60mins of subject chc022-nsrr

=== Test on chc025-nsrr. train_data(624), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.461031, loss_ss: 1.677447, loss_d: 0.783585
0.1603 --- loss: 2.179410, loss_ss: 1.575905, loss_d: 0.603506
0.3205 --- loss: 2.226229, loss_ss: 1.568768, loss_d: 0.657461
0.4808 --- loss: 2.197717, loss_ss: 1.516266, loss_d: 0.681451
0.6410 --- loss: 1.836380, loss_ss: 1.439469, loss_d: 0.396911
0.8013 --- loss: 1.895925, loss_ss: 1.352877, loss_d: 0.543048
0.9615 --- loss: 2.079858, loss_ss: 1.472526, loss_d: 0.607332
Epoch finished! Loss: 2.1208000644560783
Starting epoch 2/10.
0.0000 --- loss: 1.810639, loss_ss: 1.339592, loss_d: 0.471047
0.1603 --- loss: 2.056166, loss_ss: 1.322387, loss_d: 0.733779
0.3205 --- loss: 1.864513, loss_ss: 1.305490, loss_d: 0.559023
0.4808 --- loss: 1.717914, loss_ss: 1.336480, loss_d: 0.381434
0.6410 --- loss: 1.508913, loss_ss: 1.305725, loss_d: 0.203188
0.8013 --- loss: 1.780057, loss_ss: 1.267917, loss_d: 0.512139
0.9615 --- loss: 1.577441, loss_ss: 1.259668, loss_d: 0.317773
Epoch finished! Loss: 1.8035411373261483
Starting epoch 3/10.
0.0000 --- loss: 1.464972, loss_ss: 1.274673, loss_d: 0.190299
0.1603 --- loss: 1.679549, loss_ss: 1.341620, loss_d: 0.337929
0.3205 --- loss: 1.915918, loss_ss: 1.276538, loss_d: 0.639380
0.4808 --- loss: 1.404828, loss_ss: 1.304074, loss_d: 0.100754
0.6410 --- loss: 1.479484, loss_ss: 1.165015, loss_d: 0.314469
0.8013 --- loss: 1.461352, loss_ss: 1.179225, loss_d: 0.282127
0.9615 --- loss: 1.396028, loss_ss: 1.182604, loss_d: 0.213425
Epoch finished! Loss: 1.5134195877659706
Starting epoch 4/10.
0.0000 --- loss: 1.370530, loss_ss: 1.210133, loss_d: 0.160397
0.1603 --- loss: 1.362608, loss_ss: 1.157937, loss_d: 0.204670
0.3205 --- loss: 1.514279, loss_ss: 1.158803, loss_d: 0.355477
0.4808 --- loss: 1.372407, loss_ss: 1.162492, loss_d: 0.209915
0.6410 --- loss: 1.154039, loss_ss: 1.095702, loss_d: 0.058337
0.8013 --- loss: 1.118984, loss_ss: 1.102464, loss_d: 0.016520
0.9615 --- loss: 1.121442, loss_ss: 1.077181, loss_d: 0.044261
Epoch finished! Loss: 1.3169506230661947
Starting epoch 5/10.
0.0000 --- loss: 1.217556, loss_ss: 1.152640, loss_d: 0.064916
0.1603 --- loss: 1.124193, loss_ss: 1.089227, loss_d: 0.034966
0.3205 --- loss: 1.106592, loss_ss: 1.062466, loss_d: 0.044126
0.4808 --- loss: 1.008847, loss_ss: 0.999654, loss_d: 0.009193
0.6410 --- loss: 1.078212, loss_ss: 1.064052, loss_d: 0.014160
0.8013 --- loss: 1.117514, loss_ss: 1.077711, loss_d: 0.039802
0.9615 --- loss: 0.964062, loss_ss: 0.941298, loss_d: 0.022765
Epoch finished! Loss: 1.1497939988490073
Starting epoch 6/10.
0.0000 --- loss: 1.128949, loss_ss: 1.036921, loss_d: 0.092028
0.1603 --- loss: 1.114601, loss_ss: 1.110294, loss_d: 0.004307
0.3205 --- loss: 1.128807, loss_ss: 1.017308, loss_d: 0.111499
0.4808 --- loss: 1.090331, loss_ss: 1.075915, loss_d: 0.014416
0.6410 --- loss: 0.930021, loss_ss: 0.924014, loss_d: 0.006007
0.8013 --- loss: 0.933854, loss_ss: 0.927280, loss_d: 0.006574
0.9615 --- loss: 1.107937, loss_ss: 1.008314, loss_d: 0.099624
Epoch finished! Loss: 1.1226352135981283
Starting epoch 7/10.
0.0000 --- loss: 1.036162, loss_ss: 1.018640, loss_d: 0.017522
0.1603 --- loss: 0.937313, loss_ss: 0.920338, loss_d: 0.016975
0.3205 --- loss: 1.041627, loss_ss: 1.040698, loss_d: 0.000930
0.4808 --- loss: 1.122691, loss_ss: 1.114379, loss_d: 0.008312
0.6410 --- loss: 1.127980, loss_ss: 1.075030, loss_d: 0.052950
0.8013 --- loss: 1.093749, loss_ss: 1.081455, loss_d: 0.012294
0.9615 --- loss: 1.084317, loss_ss: 1.041194, loss_d: 0.043123
Epoch finished! Loss: 1.0710909107039053
Starting epoch 8/10.
0.0000 --- loss: 0.953080, loss_ss: 0.833339, loss_d: 0.119741
0.1603 --- loss: 1.065861, loss_ss: 1.046004, loss_d: 0.019857
0.3205 --- loss: 0.949798, loss_ss: 0.920258, loss_d: 0.029540
0.4808 --- loss: 1.083622, loss_ss: 1.078580, loss_d: 0.005042
0.6410 --- loss: 1.000473, loss_ss: 0.956562, loss_d: 0.043911
0.8013 --- loss: 0.905840, loss_ss: 0.903888, loss_d: 0.001952
0.9615 --- loss: 0.858306, loss_ss: 0.855724, loss_d: 0.002582
Epoch finished! Loss: 0.9694280259070858
Starting epoch 9/10.
0.0000 --- loss: 1.053064, loss_ss: 1.051729, loss_d: 0.001335
0.1603 --- loss: 1.126560, loss_ss: 1.071217, loss_d: 0.055343
0.3205 --- loss: 0.912918, loss_ss: 0.905224, loss_d: 0.007693
0.4808 --- loss: 0.979922, loss_ss: 0.977663, loss_d: 0.002259
0.6410 --- loss: 0.858331, loss_ss: 0.848792, loss_d: 0.009539
0.8013 --- loss: 0.904886, loss_ss: 0.826468, loss_d: 0.078418
0.9615 --- loss: 1.818675, loss_ss: 0.949896, loss_d: 0.868779
Epoch finished! Loss: 0.9652450815323861
Starting epoch 10/10.
0.0000 --- loss: 1.264271, loss_ss: 0.982911, loss_d: 0.281360
0.1603 --- loss: 0.929796, loss_ss: 0.927759, loss_d: 0.002037
0.3205 --- loss: 1.117210, loss_ss: 1.103116, loss_d: 0.014094
0.4808 --- loss: 0.888504, loss_ss: 0.887875, loss_d: 0.000629
0.6410 --- loss: 0.966334, loss_ss: 0.964656, loss_d: 0.001678
0.8013 --- loss: 0.896338, loss_ss: 0.890220, loss_d: 0.006118
0.9615 --- loss: 0.925438, loss_ss: 0.924876, loss_d: 0.000562
Epoch finished! Loss: 0.9281984442664731
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5805555555555556
             precision    recall  f1-score   support

        0.0       0.13      0.86      0.22        21
        1.0       0.00      0.00      0.00        39
        2.0       0.66      0.85      0.74       382
        3.0       0.97      0.25      0.40       114
        4.0       0.84      0.29      0.43       164

avg / total       0.70      0.58      0.56       720
 


====== chc025-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  82.22  85.71   82.12  12.59     21.95
1  94.17   0.00   99.56   0.00      0.00
2  69.03  84.55   51.48  66.32     74.34
3  88.06  25.44   99.83  96.67     40.28
4  82.64  29.27   98.38  84.21     43.44
Total accuracy: 58.06%
Average sen: 45.00%
Average spec: 86.27%
Macro f1-score: 36.00%
Diagnosis acc on 60mins: 0.16666666666666666
[0.99266279 0.99989915 0.02861102 0.56640607 0.98152852 0.97806329]
pred: 0.7578618054588636, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc025-nsrr

=== Test on chc027-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.579915, loss_ss: 1.867652, loss_d: 0.712263
0.1605 --- loss: 2.782586, loss_ss: 1.722799, loss_d: 1.059787
0.3210 --- loss: 2.638158, loss_ss: 1.701260, loss_d: 0.936898
0.4815 --- loss: 2.638884, loss_ss: 1.534472, loss_d: 1.104412
0.6421 --- loss: 2.267936, loss_ss: 1.604323, loss_d: 0.663612
0.8026 --- loss: 2.220153, loss_ss: 1.524904, loss_d: 0.695250
0.9631 --- loss: 1.940895, loss_ss: 1.492017, loss_d: 0.448879
Epoch finished! Loss: 2.215727542677233
Starting epoch 2/10.
0.0000 --- loss: 1.991030, loss_ss: 1.471451, loss_d: 0.519578
0.1605 --- loss: 1.990517, loss_ss: 1.595360, loss_d: 0.395158
0.3210 --- loss: 1.800825, loss_ss: 1.417299, loss_d: 0.383525
0.4815 --- loss: 2.072269, loss_ss: 1.485530, loss_d: 0.586739
0.6421 --- loss: 1.866973, loss_ss: 1.515550, loss_d: 0.351423
0.8026 --- loss: 1.682433, loss_ss: 1.338935, loss_d: 0.343498
0.9631 --- loss: 1.892424, loss_ss: 1.414100, loss_d: 0.478325
Epoch finished! Loss: 1.9261394027740724
Starting epoch 3/10.
0.0000 --- loss: 1.575555, loss_ss: 1.339805, loss_d: 0.235750
0.1605 --- loss: 1.658868, loss_ss: 1.361168, loss_d: 0.297700
0.3210 --- loss: 1.459667, loss_ss: 1.355237, loss_d: 0.104431
0.4815 --- loss: 1.604933, loss_ss: 1.302896, loss_d: 0.302036
0.6421 --- loss: 1.613938, loss_ss: 1.327366, loss_d: 0.286572
0.8026 --- loss: 1.398641, loss_ss: 1.281818, loss_d: 0.116823
0.9631 --- loss: 1.424159, loss_ss: 1.212274, loss_d: 0.211885
Epoch finished! Loss: 1.6334306059345123
Starting epoch 4/10.
0.0000 --- loss: 1.347694, loss_ss: 1.287649, loss_d: 0.060044
0.1605 --- loss: 1.428080, loss_ss: 1.194256, loss_d: 0.233823
0.3210 --- loss: 1.235696, loss_ss: 1.182678, loss_d: 0.053019
0.4815 --- loss: 1.448271, loss_ss: 1.354886, loss_d: 0.093385
0.6421 --- loss: 1.156743, loss_ss: 1.107604, loss_d: 0.049139
0.8026 --- loss: 1.356543, loss_ss: 1.129597, loss_d: 0.226946
0.9631 --- loss: 1.188308, loss_ss: 1.130899, loss_d: 0.057409
Epoch finished! Loss: 1.340233293271834
Starting epoch 5/10.
0.0000 --- loss: 1.530926, loss_ss: 1.216629, loss_d: 0.314297
0.1605 --- loss: 1.424867, loss_ss: 1.189571, loss_d: 0.235296
0.3210 --- loss: 1.023981, loss_ss: 1.022453, loss_d: 0.001528
0.4815 --- loss: 1.180009, loss_ss: 1.141450, loss_d: 0.038560
0.6421 --- loss: 1.205457, loss_ss: 1.174664, loss_d: 0.030793
0.8026 --- loss: 1.252381, loss_ss: 1.088227, loss_d: 0.164154
0.9631 --- loss: 1.019956, loss_ss: 1.014980, loss_d: 0.004976
Epoch finished! Loss: 1.2355533934408618
Starting epoch 6/10.
0.0000 --- loss: 1.082970, loss_ss: 1.080524, loss_d: 0.002446
0.1605 --- loss: 1.117804, loss_ss: 1.066509, loss_d: 0.051296
0.3210 --- loss: 1.087914, loss_ss: 1.046999, loss_d: 0.040915
0.4815 --- loss: 1.078074, loss_ss: 1.019758, loss_d: 0.058316
0.6421 --- loss: 1.920310, loss_ss: 1.159750, loss_d: 0.760560
0.8026 --- loss: 1.408926, loss_ss: 1.072518, loss_d: 0.336408
0.9631 --- loss: 1.156433, loss_ss: 0.964108, loss_d: 0.192324
Epoch finished! Loss: 1.2359289930712791
Starting epoch 7/10.
0.0000 --- loss: 1.024145, loss_ss: 0.932680, loss_d: 0.091465
0.1605 --- loss: 1.530537, loss_ss: 1.253141, loss_d: 0.277396
0.3210 --- loss: 1.093423, loss_ss: 1.081124, loss_d: 0.012299
0.4815 --- loss: 1.176659, loss_ss: 1.170357, loss_d: 0.006301
0.6421 --- loss: 1.166398, loss_ss: 1.065027, loss_d: 0.101372
0.8026 --- loss: 1.149632, loss_ss: 1.127077, loss_d: 0.022555
0.9631 --- loss: 0.997214, loss_ss: 0.979070, loss_d: 0.018144
Epoch finished! Loss: 1.140611840832618
Starting epoch 8/10.
0.0000 --- loss: 1.046836, loss_ss: 0.957605, loss_d: 0.089231
0.1605 --- loss: 1.172724, loss_ss: 1.170597, loss_d: 0.002127
0.3210 --- loss: 1.093147, loss_ss: 1.089406, loss_d: 0.003742
0.4815 --- loss: 0.940374, loss_ss: 0.933860, loss_d: 0.006513
0.6421 --- loss: 0.970066, loss_ss: 0.964802, loss_d: 0.005264
0.8026 --- loss: 0.869856, loss_ss: 0.863768, loss_d: 0.006088
0.9631 --- loss: 1.142822, loss_ss: 1.141149, loss_d: 0.001673
Epoch finished! Loss: 1.0581408892908404
Starting epoch 9/10.
0.0000 --- loss: 0.946858, loss_ss: 0.944291, loss_d: 0.002567
0.1605 --- loss: 1.031645, loss_ss: 1.015816, loss_d: 0.015829
0.3210 --- loss: 1.083178, loss_ss: 1.078797, loss_d: 0.004381
0.4815 --- loss: 0.884224, loss_ss: 0.881106, loss_d: 0.003118
0.6421 --- loss: 0.893958, loss_ss: 0.892004, loss_d: 0.001954
0.8026 --- loss: 1.016944, loss_ss: 1.016561, loss_d: 0.000383
0.9631 --- loss: 0.999101, loss_ss: 0.998093, loss_d: 0.001008
Epoch finished! Loss: 1.024141138599765
Starting epoch 10/10.
0.0000 --- loss: 0.990782, loss_ss: 0.987675, loss_d: 0.003107
0.1605 --- loss: 1.056410, loss_ss: 1.055651, loss_d: 0.000760
0.3210 --- loss: 0.935025, loss_ss: 0.930489, loss_d: 0.004537
0.4815 --- loss: 0.989283, loss_ss: 0.954581, loss_d: 0.034702
0.6421 --- loss: 1.119500, loss_ss: 1.021267, loss_d: 0.098233
0.8026 --- loss: 1.335933, loss_ss: 0.903191, loss_d: 0.432742
0.9631 --- loss: 1.005966, loss_ss: 1.005576, loss_d: 0.000390
Epoch finished! Loss: 1.030174276521129
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7035714285714286
             precision    recall  f1-score   support

        0.0       0.95      0.60      0.73       275
        1.0       0.25      0.53      0.34        64
        2.0       0.65      0.87      0.74       252
        3.0       1.00      0.60      0.75       174
        4.0       0.75      0.93      0.83        75

avg / total       0.80      0.70      0.72       840
 


====== chc027-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  85.83  60.00   98.41   94.83     73.50
1  84.52  53.12   87.11   25.37     34.34
2  82.02  86.51   80.10   65.07     74.28
3  91.67  59.77  100.00  100.00     74.82
4  96.67  93.33   96.99   75.27     83.33
Total accuracy: 70.36%
Average sen: 70.55%
Average spec: 92.52%
Macro f1-score: 68.05%
Diagnosis acc on 60mins: 0.0
[0.98526222 0.99877709 0.79228115 0.97253609 0.95938563 0.98999548
 0.9562639 ]
pred: 0.9506430796214512, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc027-nsrr

=== Test on chc028-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.396708, loss_ss: 1.673479, loss_d: 0.723229
0.1605 --- loss: 2.094248, loss_ss: 1.615297, loss_d: 0.478950
0.3210 --- loss: 2.279978, loss_ss: 1.617317, loss_d: 0.662661
0.4815 --- loss: 2.177638, loss_ss: 1.413715, loss_d: 0.763923
0.6421 --- loss: 1.950590, loss_ss: 1.467826, loss_d: 0.482764
0.8026 --- loss: 1.891668, loss_ss: 1.380939, loss_d: 0.510729
0.9631 --- loss: 1.858758, loss_ss: 1.374766, loss_d: 0.483992
Epoch finished! Loss: 2.1631779574578807
Starting epoch 2/10.
0.0000 --- loss: 1.649074, loss_ss: 1.365813, loss_d: 0.283261
0.1605 --- loss: 1.654545, loss_ss: 1.285977, loss_d: 0.368568
0.3210 --- loss: 1.642957, loss_ss: 1.315277, loss_d: 0.327680
0.4815 --- loss: 2.182444, loss_ss: 1.433663, loss_d: 0.748781
0.6421 --- loss: 1.687153, loss_ss: 1.290455, loss_d: 0.396698
0.8026 --- loss: 1.892067, loss_ss: 1.299243, loss_d: 0.592824
0.9631 --- loss: 2.016526, loss_ss: 1.319669, loss_d: 0.696857
Epoch finished! Loss: 1.8286450639847787
Starting epoch 3/10.
0.0000 --- loss: 1.780740, loss_ss: 1.356843, loss_d: 0.423898
0.1605 --- loss: 1.530505, loss_ss: 1.298232, loss_d: 0.232273
0.3210 --- loss: 1.293345, loss_ss: 1.176881, loss_d: 0.116464
0.4815 --- loss: 1.503561, loss_ss: 1.265543, loss_d: 0.238018
0.6421 --- loss: 1.799519, loss_ss: 1.362868, loss_d: 0.436651
0.8026 --- loss: 1.270159, loss_ss: 1.224083, loss_d: 0.046076
0.9631 --- loss: 1.896285, loss_ss: 1.257905, loss_d: 0.638380
Epoch finished! Loss: 1.5735963602219858
Starting epoch 4/10.
0.0000 --- loss: 1.271932, loss_ss: 1.141758, loss_d: 0.130174
0.1605 --- loss: 1.138376, loss_ss: 1.097388, loss_d: 0.040988
0.3210 --- loss: 1.552182, loss_ss: 1.214180, loss_d: 0.338002
0.4815 --- loss: 1.031188, loss_ss: 0.993517, loss_d: 0.037671
0.6421 --- loss: 1.233473, loss_ss: 1.134251, loss_d: 0.099223
0.8026 --- loss: 1.620634, loss_ss: 1.126089, loss_d: 0.494545
0.9631 --- loss: 1.211986, loss_ss: 1.161287, loss_d: 0.050699
Epoch finished! Loss: 1.321968202629397
Starting epoch 5/10.
0.0000 --- loss: 1.735050, loss_ss: 0.965976, loss_d: 0.769074
0.1605 --- loss: 1.301638, loss_ss: 1.276917, loss_d: 0.024721
0.3210 --- loss: 1.096229, loss_ss: 1.031474, loss_d: 0.064755
0.4815 --- loss: 1.247807, loss_ss: 1.191610, loss_d: 0.056197
0.6421 --- loss: 1.090014, loss_ss: 0.903472, loss_d: 0.186542
0.8026 --- loss: 1.274758, loss_ss: 0.972380, loss_d: 0.302378
0.9631 --- loss: 1.152570, loss_ss: 1.084301, loss_d: 0.068270
Epoch finished! Loss: 1.2367954340673262
Starting epoch 6/10.
0.0000 --- loss: 1.101778, loss_ss: 1.077535, loss_d: 0.024243
0.1605 --- loss: 1.131762, loss_ss: 1.113916, loss_d: 0.017846
0.3210 --- loss: 1.065743, loss_ss: 1.055268, loss_d: 0.010475
0.4815 --- loss: 0.947799, loss_ss: 0.946395, loss_d: 0.001404
0.6421 --- loss: 1.101260, loss_ss: 1.096228, loss_d: 0.005032
0.8026 --- loss: 1.024715, loss_ss: 1.009559, loss_d: 0.015156
0.9631 --- loss: 1.037152, loss_ss: 0.985055, loss_d: 0.052097
Epoch finished! Loss: 1.081491804892017
Starting epoch 7/10.
0.0000 --- loss: 1.601817, loss_ss: 1.596869, loss_d: 0.004948
0.1605 --- loss: 1.104286, loss_ss: 1.086514, loss_d: 0.017772
0.3210 --- loss: 0.923538, loss_ss: 0.911954, loss_d: 0.011584
0.4815 --- loss: 1.032690, loss_ss: 1.007438, loss_d: 0.025252
0.6421 --- loss: 0.923224, loss_ss: 0.922523, loss_d: 0.000701
0.8026 --- loss: 1.001898, loss_ss: 0.952223, loss_d: 0.049675
0.9631 --- loss: 0.879318, loss_ss: 0.848177, loss_d: 0.031141
Epoch finished! Loss: 1.063285171024261
Starting epoch 8/10.
0.0000 --- loss: 0.909165, loss_ss: 0.909035, loss_d: 0.000130
0.1605 --- loss: 0.919028, loss_ss: 0.915711, loss_d: 0.003317
0.3210 --- loss: 0.939249, loss_ss: 0.933108, loss_d: 0.006141
0.4815 --- loss: 0.859378, loss_ss: 0.858599, loss_d: 0.000778
0.6421 --- loss: 1.188502, loss_ss: 1.168951, loss_d: 0.019551
0.8026 --- loss: 0.969762, loss_ss: 0.967420, loss_d: 0.002342
0.9631 --- loss: 1.120274, loss_ss: 1.115316, loss_d: 0.004958
Epoch finished! Loss: 1.0305378725451808
Starting epoch 9/10.
0.0000 --- loss: 0.979689, loss_ss: 0.973807, loss_d: 0.005882
0.1605 --- loss: 0.993880, loss_ss: 0.984130, loss_d: 0.009750
0.3210 --- loss: 0.901053, loss_ss: 0.898778, loss_d: 0.002275
0.4815 --- loss: 1.079268, loss_ss: 1.078027, loss_d: 0.001241
0.6421 --- loss: 1.031920, loss_ss: 1.025404, loss_d: 0.006515
0.8026 --- loss: 1.151237, loss_ss: 1.150581, loss_d: 0.000656
0.9631 --- loss: 0.905673, loss_ss: 0.902967, loss_d: 0.002706
Epoch finished! Loss: 0.9884378688950692
Starting epoch 10/10.
0.0000 --- loss: 0.864120, loss_ss: 0.861837, loss_d: 0.002283
0.1605 --- loss: 1.057594, loss_ss: 1.052623, loss_d: 0.004970
0.3210 --- loss: 0.894417, loss_ss: 0.893468, loss_d: 0.000949
0.4815 --- loss: 0.731941, loss_ss: 0.730021, loss_d: 0.001920
0.6421 --- loss: 1.124084, loss_ss: 1.118317, loss_d: 0.005767
0.8026 --- loss: 1.052649, loss_ss: 1.052466, loss_d: 0.000182
0.9631 --- loss: 1.153655, loss_ss: 1.153434, loss_d: 0.000221
Epoch finished! Loss: 0.945850380005375
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7226190476190476
             precision    recall  f1-score   support

        0.0       0.84      0.86      0.85        98
        1.0       0.00      0.00      0.00        50
        2.0       0.87      0.72      0.78       454
        3.0       0.98      0.76      0.86       164
        4.0       0.31      0.99      0.47        74

avg / total       0.78      0.72      0.73       840
 


====== chc028-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  96.43  85.71   97.84  84.00     84.85
1  94.05   0.00  100.00   0.00      0.00
2  78.69  71.59   87.05  86.67     78.41
3  95.00  76.22   99.56  97.66     85.62
4  80.36  98.65   78.59  30.80     46.95
Total accuracy: 72.26%
Average sen: 66.43%
Average spec: 92.61%
Macro f1-score: 59.16%
Diagnosis acc on 60mins: 0.0
[0.99994624 0.99926704 0.99999952 0.97551787 0.99989915 0.99979967
 0.99999571]
pred: 0.9963464566639492, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc028-nsrr

=== Test on chc033-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.477686, loss_ss: 1.738874, loss_d: 0.738813
0.1605 --- loss: 2.545793, loss_ss: 1.527702, loss_d: 1.018091
0.3210 --- loss: 2.225199, loss_ss: 1.509012, loss_d: 0.716187
0.4815 --- loss: 2.448118, loss_ss: 1.468257, loss_d: 0.979861
0.6421 --- loss: 2.161983, loss_ss: 1.502705, loss_d: 0.659278
0.8026 --- loss: 1.906546, loss_ss: 1.467368, loss_d: 0.439178
0.9631 --- loss: 1.915768, loss_ss: 1.418924, loss_d: 0.496844
Epoch finished! Loss: 2.121521509462787
Starting epoch 2/10.
0.0000 --- loss: 2.102878, loss_ss: 1.411205, loss_d: 0.691673
0.1605 --- loss: 2.131496, loss_ss: 1.450291, loss_d: 0.681205
0.3210 --- loss: 2.032059, loss_ss: 1.442401, loss_d: 0.589658
0.4815 --- loss: 1.565333, loss_ss: 1.383109, loss_d: 0.182224
0.6421 --- loss: 1.921759, loss_ss: 1.334112, loss_d: 0.587646
0.8026 --- loss: 1.528916, loss_ss: 1.366941, loss_d: 0.161975
0.9631 --- loss: 1.602947, loss_ss: 1.370991, loss_d: 0.231956
Epoch finished! Loss: 1.9048706120060337
Starting epoch 3/10.
0.0000 --- loss: 1.750192, loss_ss: 1.310537, loss_d: 0.439655
0.1605 --- loss: 1.659637, loss_ss: 1.325238, loss_d: 0.334399
0.3210 --- loss: 1.711858, loss_ss: 1.311704, loss_d: 0.400154
0.4815 --- loss: 1.603157, loss_ss: 1.200617, loss_d: 0.402540
0.6421 --- loss: 1.598410, loss_ss: 1.271370, loss_d: 0.327040
0.8026 --- loss: 1.391462, loss_ss: 1.242196, loss_d: 0.149266
0.9631 --- loss: 1.339733, loss_ss: 1.191368, loss_d: 0.148365
Epoch finished! Loss: 1.615858143375766
Starting epoch 4/10.
0.0000 --- loss: 1.449590, loss_ss: 1.229912, loss_d: 0.219678
0.1605 --- loss: 2.010654, loss_ss: 1.253277, loss_d: 0.757377
0.3210 --- loss: 1.395655, loss_ss: 1.249636, loss_d: 0.146018
0.4815 --- loss: 1.204995, loss_ss: 1.102335, loss_d: 0.102659
0.6421 --- loss: 1.491474, loss_ss: 1.246233, loss_d: 0.245241
0.8026 --- loss: 1.504403, loss_ss: 1.220312, loss_d: 0.284091
0.9631 --- loss: 1.203834, loss_ss: 1.155027, loss_d: 0.048807
Epoch finished! Loss: 1.4261608392961564
Starting epoch 5/10.
0.0000 --- loss: 1.329846, loss_ss: 1.133883, loss_d: 0.195963
0.1605 --- loss: 1.130419, loss_ss: 1.085974, loss_d: 0.044444
0.3210 --- loss: 1.278289, loss_ss: 1.211702, loss_d: 0.066587
0.4815 --- loss: 1.182295, loss_ss: 1.173458, loss_d: 0.008836
0.6421 --- loss: 1.071761, loss_ss: 1.053480, loss_d: 0.018281
0.8026 --- loss: 1.156908, loss_ss: 1.131954, loss_d: 0.024954
0.9631 --- loss: 1.021091, loss_ss: 1.006115, loss_d: 0.014977
Epoch finished! Loss: 1.2961399247569423
Starting epoch 6/10.
0.0000 --- loss: 1.146732, loss_ss: 1.102719, loss_d: 0.044013
0.1605 --- loss: 1.240120, loss_ss: 1.154112, loss_d: 0.086008
0.3210 --- loss: 1.257714, loss_ss: 1.249645, loss_d: 0.008070
0.4815 --- loss: 1.136232, loss_ss: 1.109108, loss_d: 0.027123
0.6421 --- loss: 1.100156, loss_ss: 1.077132, loss_d: 0.023023
0.8026 --- loss: 1.235387, loss_ss: 0.930915, loss_d: 0.304472
0.9631 --- loss: 1.181385, loss_ss: 1.124764, loss_d: 0.056622
Epoch finished! Loss: 1.302193925265343
Starting epoch 7/10.
0.0000 --- loss: 1.047231, loss_ss: 1.034954, loss_d: 0.012277
0.1605 --- loss: 1.151846, loss_ss: 1.107604, loss_d: 0.044241
0.3210 --- loss: 1.025683, loss_ss: 0.958423, loss_d: 0.067260
0.4815 --- loss: 0.989633, loss_ss: 0.944660, loss_d: 0.044974
0.6421 --- loss: 1.270805, loss_ss: 1.075111, loss_d: 0.195694
0.8026 --- loss: 1.003218, loss_ss: 0.993554, loss_d: 0.009664
0.9631 --- loss: 1.010638, loss_ss: 1.007790, loss_d: 0.002849
Epoch finished! Loss: 1.1544959708567588
Starting epoch 8/10.
0.0000 --- loss: 1.085400, loss_ss: 0.980482, loss_d: 0.104918
0.1605 --- loss: 1.133672, loss_ss: 1.089227, loss_d: 0.044445
0.3210 --- loss: 0.992630, loss_ss: 0.971817, loss_d: 0.020812
0.4815 --- loss: 0.970385, loss_ss: 0.946878, loss_d: 0.023507
0.6421 --- loss: 1.008285, loss_ss: 0.994327, loss_d: 0.013959
0.8026 --- loss: 1.017041, loss_ss: 1.010933, loss_d: 0.006108
0.9631 --- loss: 1.294009, loss_ss: 1.009063, loss_d: 0.284946
Epoch finished! Loss: 1.1283571623986768
Starting epoch 9/10.
0.0000 --- loss: 1.025089, loss_ss: 1.020916, loss_d: 0.004173
0.1605 --- loss: 1.108937, loss_ss: 1.043521, loss_d: 0.065416
0.3210 --- loss: 1.021846, loss_ss: 0.909998, loss_d: 0.111848
0.4815 --- loss: 1.002529, loss_ss: 0.981343, loss_d: 0.021186
0.6421 --- loss: 1.109102, loss_ss: 1.089946, loss_d: 0.019156
0.8026 --- loss: 0.910994, loss_ss: 0.906680, loss_d: 0.004314
0.9631 --- loss: 1.096788, loss_ss: 1.038705, loss_d: 0.058084
Epoch finished! Loss: 1.0376875823543918
Starting epoch 10/10.
0.0000 --- loss: 0.935103, loss_ss: 0.927371, loss_d: 0.007731
0.1605 --- loss: 0.961319, loss_ss: 0.950747, loss_d: 0.010572
0.3210 --- loss: 0.974563, loss_ss: 0.969049, loss_d: 0.005514
0.4815 --- loss: 0.885951, loss_ss: 0.864564, loss_d: 0.021387
0.6421 --- loss: 1.005648, loss_ss: 1.001660, loss_d: 0.003987
0.8026 --- loss: 1.028510, loss_ss: 1.026105, loss_d: 0.002405
0.9631 --- loss: 0.993721, loss_ss: 0.983387, loss_d: 0.010334
Epoch finished! Loss: 1.0357429615912899
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6488095238095238
             precision    recall  f1-score   support

        0.0       1.00      0.29      0.45        59
        1.0       1.00      0.02      0.03        60
        2.0       0.74      0.74      0.74       376
        3.0       0.98      0.35      0.52       151
        4.0       0.50      1.00      0.66       194

avg / total       0.76      0.65      0.61       840
 


====== chc033-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  95.00   28.81  100.00  100.00     44.74
1  92.98    1.67  100.00  100.00      3.28
2  76.90   74.47   78.88   74.07     74.27
3  88.21   35.10   99.85   98.15     51.71
4  76.67  100.00   69.66   49.74     66.44
Total accuracy: 64.88%
Average sen: 48.01%
Average spec: 89.68%
Macro f1-score: 48.09%
Diagnosis acc on 60mins: 0.42857142857142855
[0.99786335 0.1235465  0.27134109 0.98445064 0.75430638 0.47483674
 0.87476909]
pred: 0.6401591120021684, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc033-nsrr

=== Test on chc035-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.400363, loss_ss: 1.670654, loss_d: 0.729709
0.1605 --- loss: 2.134245, loss_ss: 1.512336, loss_d: 0.621910
0.3210 --- loss: 2.376262, loss_ss: 1.459379, loss_d: 0.916883
0.4815 --- loss: 2.041493, loss_ss: 1.461742, loss_d: 0.579752
0.6421 --- loss: 1.870527, loss_ss: 1.362611, loss_d: 0.507916
0.8026 --- loss: 2.226027, loss_ss: 1.298529, loss_d: 0.927499
0.9631 --- loss: 1.985801, loss_ss: 1.268503, loss_d: 0.717298
Epoch finished! Loss: 2.093699849420978
Starting epoch 2/10.
0.0000 --- loss: 1.871966, loss_ss: 1.341473, loss_d: 0.530493
0.1605 --- loss: 1.685883, loss_ss: 1.315411, loss_d: 0.370472
0.3210 --- loss: 1.739642, loss_ss: 1.345857, loss_d: 0.393785
0.4815 --- loss: 1.836047, loss_ss: 1.224801, loss_d: 0.611246
0.6421 --- loss: 1.825466, loss_ss: 1.289344, loss_d: 0.536122
0.8026 --- loss: 1.590615, loss_ss: 1.241234, loss_d: 0.349382
0.9631 --- loss: 2.028105, loss_ss: 1.248754, loss_d: 0.779351
Epoch finished! Loss: 1.8015869778971518
Starting epoch 3/10.
0.0000 --- loss: 1.573164, loss_ss: 1.194922, loss_d: 0.378242
0.1605 --- loss: 1.644085, loss_ss: 1.220399, loss_d: 0.423686
0.3210 --- loss: 1.412185, loss_ss: 1.228982, loss_d: 0.183203
0.4815 --- loss: 1.406465, loss_ss: 1.257099, loss_d: 0.149366
0.6421 --- loss: 1.605282, loss_ss: 1.278579, loss_d: 0.326703
0.8026 --- loss: 1.958324, loss_ss: 1.313626, loss_d: 0.644698
0.9631 --- loss: 1.547943, loss_ss: 1.160272, loss_d: 0.387670
Epoch finished! Loss: 1.5774091559071695
Starting epoch 4/10.
0.0000 --- loss: 1.391803, loss_ss: 1.210446, loss_d: 0.181356
0.1605 --- loss: 1.451866, loss_ss: 1.141250, loss_d: 0.310617
0.3210 --- loss: 1.280773, loss_ss: 1.134112, loss_d: 0.146661
0.4815 --- loss: 1.456210, loss_ss: 1.168570, loss_d: 0.287640
0.6421 --- loss: 1.220058, loss_ss: 1.156135, loss_d: 0.063923
0.8026 --- loss: 1.488817, loss_ss: 1.338164, loss_d: 0.150654
0.9631 --- loss: 1.574748, loss_ss: 1.079611, loss_d: 0.495137
Epoch finished! Loss: 1.427080960043015
Starting epoch 5/10.
0.0000 --- loss: 1.177451, loss_ss: 1.129138, loss_d: 0.048313
0.1605 --- loss: 1.265490, loss_ss: 1.151964, loss_d: 0.113526
0.3210 --- loss: 1.177787, loss_ss: 1.084207, loss_d: 0.093580
0.4815 --- loss: 1.141816, loss_ss: 1.112531, loss_d: 0.029285
0.6421 --- loss: 1.063931, loss_ss: 1.045632, loss_d: 0.018299
0.8026 --- loss: 1.158427, loss_ss: 1.152105, loss_d: 0.006323
0.9631 --- loss: 1.127825, loss_ss: 1.122278, loss_d: 0.005547
Epoch finished! Loss: 1.2270254627350838
Starting epoch 6/10.
0.0000 --- loss: 1.057748, loss_ss: 1.047530, loss_d: 0.010218
0.1605 --- loss: 1.060439, loss_ss: 1.058707, loss_d: 0.001732
0.3210 --- loss: 1.161778, loss_ss: 1.060964, loss_d: 0.100814
0.4815 --- loss: 1.321109, loss_ss: 1.047909, loss_d: 0.273199
0.6421 --- loss: 1.295981, loss_ss: 1.270735, loss_d: 0.025246
0.8026 --- loss: 1.011252, loss_ss: 1.004741, loss_d: 0.006511
0.9631 --- loss: 1.033176, loss_ss: 1.022214, loss_d: 0.010962
Epoch finished! Loss: 1.1461429057582733
Starting epoch 7/10.
0.0000 --- loss: 1.164693, loss_ss: 1.143701, loss_d: 0.020992
0.1605 --- loss: 1.174487, loss_ss: 1.166477, loss_d: 0.008010
0.3210 --- loss: 1.051677, loss_ss: 1.050193, loss_d: 0.001483
0.4815 --- loss: 1.080409, loss_ss: 1.078239, loss_d: 0.002170
0.6421 --- loss: 1.159972, loss_ss: 1.159462, loss_d: 0.000510
0.8026 --- loss: 1.089199, loss_ss: 1.084305, loss_d: 0.004894
0.9631 --- loss: 0.931122, loss_ss: 0.899091, loss_d: 0.032031
Epoch finished! Loss: 1.0856195861293423
Starting epoch 8/10.
0.0000 --- loss: 1.029760, loss_ss: 1.028362, loss_d: 0.001397
0.1605 --- loss: 1.127594, loss_ss: 1.126604, loss_d: 0.000990
0.3210 --- loss: 1.055224, loss_ss: 0.966576, loss_d: 0.088649
0.4815 --- loss: 0.988929, loss_ss: 0.985559, loss_d: 0.003370
0.6421 --- loss: 1.046917, loss_ss: 1.046493, loss_d: 0.000425
0.8026 --- loss: 1.236076, loss_ss: 1.235239, loss_d: 0.000837
0.9631 --- loss: 0.974330, loss_ss: 0.923604, loss_d: 0.050726
Epoch finished! Loss: 1.0522854222405342
Starting epoch 9/10.
0.0000 --- loss: 0.936459, loss_ss: 0.934869, loss_d: 0.001590
0.1605 --- loss: 1.046290, loss_ss: 1.042080, loss_d: 0.004210
0.3210 --- loss: 1.027943, loss_ss: 1.027160, loss_d: 0.000782
0.4815 --- loss: 0.901502, loss_ss: 0.900938, loss_d: 0.000564
0.6421 --- loss: 1.099867, loss_ss: 1.099075, loss_d: 0.000793
0.8026 --- loss: 0.919881, loss_ss: 0.899887, loss_d: 0.019994
0.9631 --- loss: 1.082853, loss_ss: 1.080436, loss_d: 0.002417
Epoch finished! Loss: 1.0207382825113112
Starting epoch 10/10.
0.0000 --- loss: 0.859599, loss_ss: 0.858927, loss_d: 0.000671
0.1605 --- loss: 1.084449, loss_ss: 1.078140, loss_d: 0.006308
0.3210 --- loss: 1.075596, loss_ss: 1.071677, loss_d: 0.003919
0.4815 --- loss: 0.904075, loss_ss: 0.903894, loss_d: 0.000181
0.6421 --- loss: 1.106890, loss_ss: 1.106665, loss_d: 0.000226
0.8026 --- loss: 0.995008, loss_ss: 0.989101, loss_d: 0.005907
0.9631 --- loss: 0.902830, loss_ss: 0.894772, loss_d: 0.008058
Epoch finished! Loss: 1.0109004368705135
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6738095238095239
             precision    recall  f1-score   support

        0.0       0.59      0.71      0.65        28
        1.0       0.00      0.00      0.00        56
        2.0       0.67      0.88      0.76       374
        3.0       1.00      0.34      0.50       238
        4.0       0.59      0.94      0.73       144

avg / total       0.70      0.67      0.63       840
 


====== chc035-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  97.38  71.43   98.28   58.82     64.52
1  93.33   0.00  100.00    0.00      0.00
2  75.12  88.24   64.59   66.67     75.95
3  81.19  33.61  100.00  100.00     50.31
4  87.74  94.44   86.35   58.87     72.53
Total accuracy: 67.38%
Average sen: 57.54%
Average spec: 89.84%
Macro f1-score: 52.66%
Diagnosis acc on 60mins: 0.14285714285714285
[0.99502951 0.63603669 0.01399119 0.99990308 0.9998759  0.9999975
 0.99686372]
pred: 0.805956800468266, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc035-nsrr

=== Test on chc037-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.377930, loss_ss: 1.653059, loss_d: 0.724871
0.1605 --- loss: 1.976504, loss_ss: 1.453794, loss_d: 0.522711
0.3210 --- loss: 2.249723, loss_ss: 1.548528, loss_d: 0.701195
0.4815 --- loss: 2.006590, loss_ss: 1.415555, loss_d: 0.591036
0.6421 --- loss: 1.898768, loss_ss: 1.612071, loss_d: 0.286696
0.8026 --- loss: 1.984000, loss_ss: 1.633849, loss_d: 0.350151
0.9631 --- loss: 2.116053, loss_ss: 1.469151, loss_d: 0.646902
Epoch finished! Loss: 2.121709858217547
Starting epoch 2/10.
0.0000 --- loss: 1.999363, loss_ss: 1.456376, loss_d: 0.542987
0.1605 --- loss: 1.700060, loss_ss: 1.369110, loss_d: 0.330949
0.3210 --- loss: 1.810526, loss_ss: 1.425407, loss_d: 0.385119
0.4815 --- loss: 1.873261, loss_ss: 1.470754, loss_d: 0.402507
0.6421 --- loss: 1.839510, loss_ss: 1.458376, loss_d: 0.381134
0.8026 --- loss: 1.633223, loss_ss: 1.289468, loss_d: 0.343755
0.9631 --- loss: 1.570309, loss_ss: 1.363047, loss_d: 0.207262
Epoch finished! Loss: 1.879511385194717
Starting epoch 3/10.
0.0000 --- loss: 1.639154, loss_ss: 1.340986, loss_d: 0.298168
0.1605 --- loss: 1.721771, loss_ss: 1.292626, loss_d: 0.429146
0.3210 --- loss: 1.764690, loss_ss: 1.154287, loss_d: 0.610404
0.4815 --- loss: 2.348389, loss_ss: 1.283842, loss_d: 1.064547
0.6421 --- loss: 1.327370, loss_ss: 1.180712, loss_d: 0.146658
0.8026 --- loss: 1.431464, loss_ss: 1.163550, loss_d: 0.267914
0.9631 --- loss: 1.885488, loss_ss: 1.488443, loss_d: 0.397044
Epoch finished! Loss: 1.6899829795283656
Starting epoch 4/10.
0.0000 --- loss: 1.317347, loss_ss: 1.208330, loss_d: 0.109017
0.1605 --- loss: 1.306921, loss_ss: 1.189693, loss_d: 0.117228
0.3210 --- loss: 1.387443, loss_ss: 1.336723, loss_d: 0.050720
0.4815 --- loss: 1.363661, loss_ss: 1.238350, loss_d: 0.125311
0.6421 --- loss: 1.617760, loss_ss: 1.472238, loss_d: 0.145521
0.8026 --- loss: 1.355442, loss_ss: 1.187219, loss_d: 0.168223
0.9631 --- loss: 1.265013, loss_ss: 1.099271, loss_d: 0.165742
Epoch finished! Loss: 1.40243814645275
Starting epoch 5/10.
0.0000 --- loss: 1.502041, loss_ss: 1.207201, loss_d: 0.294840
0.1605 --- loss: 1.263215, loss_ss: 1.215542, loss_d: 0.047673
0.3210 --- loss: 1.348903, loss_ss: 1.290822, loss_d: 0.058081
0.4815 --- loss: 1.226795, loss_ss: 1.146460, loss_d: 0.080335
0.6421 --- loss: 1.108527, loss_ss: 1.086749, loss_d: 0.021778
0.8026 --- loss: 1.239033, loss_ss: 1.189789, loss_d: 0.049244
0.9631 --- loss: 1.152530, loss_ss: 1.112303, loss_d: 0.040226
Epoch finished! Loss: 1.2333195209503174
Starting epoch 6/10.
0.0000 --- loss: 1.249387, loss_ss: 1.241863, loss_d: 0.007524
0.1605 --- loss: 1.147661, loss_ss: 1.137273, loss_d: 0.010388
0.3210 --- loss: 1.033033, loss_ss: 0.945687, loss_d: 0.087346
0.4815 --- loss: 1.200763, loss_ss: 1.069178, loss_d: 0.131585
0.6421 --- loss: 1.224803, loss_ss: 1.131246, loss_d: 0.093557
0.8026 --- loss: 1.068578, loss_ss: 1.019382, loss_d: 0.049196
0.9631 --- loss: 1.094670, loss_ss: 1.084039, loss_d: 0.010631
Epoch finished! Loss: 1.147640037921167
Starting epoch 7/10.
0.0000 --- loss: 1.142546, loss_ss: 1.134742, loss_d: 0.007804
0.1605 --- loss: 0.936010, loss_ss: 0.923927, loss_d: 0.012082
0.3210 --- loss: 1.164892, loss_ss: 1.159349, loss_d: 0.005543
0.4815 --- loss: 1.025965, loss_ss: 1.011266, loss_d: 0.014699
0.6421 --- loss: 1.127483, loss_ss: 1.090902, loss_d: 0.036581
0.8026 --- loss: 1.139729, loss_ss: 1.047458, loss_d: 0.092271
0.9631 --- loss: 0.817867, loss_ss: 0.815349, loss_d: 0.002518
Epoch finished! Loss: 1.0476057721722511
Starting epoch 8/10.
0.0000 --- loss: 0.995741, loss_ss: 0.983105, loss_d: 0.012636
0.1605 --- loss: 0.842747, loss_ss: 0.837461, loss_d: 0.005286
0.3210 --- loss: 1.001801, loss_ss: 1.001287, loss_d: 0.000514
0.4815 --- loss: 0.855998, loss_ss: 0.854375, loss_d: 0.001623
0.6421 --- loss: 1.030212, loss_ss: 1.019371, loss_d: 0.010841
0.8026 --- loss: 1.022521, loss_ss: 1.009605, loss_d: 0.012916
0.9631 --- loss: 0.922111, loss_ss: 0.908767, loss_d: 0.013344
Epoch finished! Loss: 0.9980097826450102
Starting epoch 9/10.
0.0000 --- loss: 0.875642, loss_ss: 0.872838, loss_d: 0.002804
0.1605 --- loss: 0.929544, loss_ss: 0.887298, loss_d: 0.042246
0.3210 --- loss: 0.895823, loss_ss: 0.863579, loss_d: 0.032244
0.4815 --- loss: 0.924591, loss_ss: 0.923494, loss_d: 0.001097
0.6421 --- loss: 0.927936, loss_ss: 0.924702, loss_d: 0.003235
0.8026 --- loss: 1.062533, loss_ss: 1.049645, loss_d: 0.012887
0.9631 --- loss: 0.892816, loss_ss: 0.885617, loss_d: 0.007199
Epoch finished! Loss: 0.9751012632923741
Starting epoch 10/10.
0.0000 --- loss: 0.991213, loss_ss: 0.988938, loss_d: 0.002275
0.1605 --- loss: 0.750325, loss_ss: 0.749789, loss_d: 0.000536
0.3210 --- loss: 0.798002, loss_ss: 0.784063, loss_d: 0.013939
0.4815 --- loss: 0.834821, loss_ss: 0.822727, loss_d: 0.012095
0.6421 --- loss: 0.903709, loss_ss: 0.896477, loss_d: 0.007232
0.8026 --- loss: 1.045183, loss_ss: 0.855584, loss_d: 0.189599
0.9631 --- loss: 0.862664, loss_ss: 0.847579, loss_d: 0.015085
Epoch finished! Loss: 0.9318213981966819
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8666666666666667
             precision    recall  f1-score   support

        0.0       0.85      1.00      0.92       154
        1.0       0.00      0.00      0.00        34
        2.0       0.89      0.83      0.86       277
        3.0       0.99      0.84      0.91       168
        4.0       0.80      0.99      0.88       207

avg / total       0.84      0.87      0.85       840
 


====== chc037-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  96.79  100.00   96.06  85.08     91.94
1  95.71    0.00   99.75   0.00      0.00
2  90.83   82.67   94.85  88.76     85.61
3  96.55   83.93   99.70  98.60     90.68
4  93.45   98.55   91.79  79.69     88.12
Total accuracy: 86.67%
Average sen: 73.03%
Average spec: 96.43%
Macro f1-score: 71.27%
Diagnosis acc on 60mins: 0.8571428571428571
[4.03331704e-02 6.22457683e-01 1.31863810e-04 3.27402740e-05
 3.09166964e-03 2.44930074e-01 5.51108224e-03]
pred: 0.13092689758819429, label: 0
Right! Diagnosis: Other
Save 60mins of subject chc037-nsrr

=== Test on chc040-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.268817, loss_ss: 1.617437, loss_d: 0.651381
0.1610 --- loss: 2.125461, loss_ss: 1.451433, loss_d: 0.674029
0.3221 --- loss: 1.848341, loss_ss: 1.411827, loss_d: 0.436514
0.4831 --- loss: 1.873379, loss_ss: 1.412783, loss_d: 0.460596
0.6441 --- loss: 1.863286, loss_ss: 1.347534, loss_d: 0.515752
0.8052 --- loss: 1.912284, loss_ss: 1.320962, loss_d: 0.591322
0.9662 --- loss: 1.804032, loss_ss: 1.243845, loss_d: 0.560187
Epoch finished! Loss: 1.9949263295819681
Starting epoch 2/10.
0.0000 --- loss: 1.925472, loss_ss: 1.413804, loss_d: 0.511668
0.1610 --- loss: 1.655064, loss_ss: 1.242152, loss_d: 0.412912
0.3221 --- loss: 1.776267, loss_ss: 1.186092, loss_d: 0.590175
0.4831 --- loss: 1.978059, loss_ss: 1.150903, loss_d: 0.827156
0.6441 --- loss: 1.957259, loss_ss: 1.186824, loss_d: 0.770435
0.8052 --- loss: 1.674741, loss_ss: 1.381661, loss_d: 0.293081
0.9662 --- loss: 1.524592, loss_ss: 1.106103, loss_d: 0.418489
Epoch finished! Loss: 1.7449680066877795
Starting epoch 3/10.
0.0000 --- loss: 1.475825, loss_ss: 1.151955, loss_d: 0.323869
0.1610 --- loss: 1.499655, loss_ss: 1.293198, loss_d: 0.206457
0.3221 --- loss: 1.542731, loss_ss: 1.242686, loss_d: 0.300045
0.4831 --- loss: 1.571084, loss_ss: 1.217881, loss_d: 0.353203
0.6441 --- loss: 1.214770, loss_ss: 1.117271, loss_d: 0.097499
0.8052 --- loss: 1.184386, loss_ss: 1.075880, loss_d: 0.108505
0.9662 --- loss: 1.414347, loss_ss: 1.215934, loss_d: 0.198414
Epoch finished! Loss: 1.5168676760888868
Starting epoch 4/10.
0.0000 --- loss: 1.332812, loss_ss: 1.149909, loss_d: 0.182903
0.1610 --- loss: 1.312206, loss_ss: 1.177592, loss_d: 0.134615
0.3221 --- loss: 1.444808, loss_ss: 1.040258, loss_d: 0.404550
0.4831 --- loss: 1.168943, loss_ss: 1.104678, loss_d: 0.064265
0.6441 --- loss: 1.305447, loss_ss: 1.027996, loss_d: 0.277451
0.8052 --- loss: 1.108096, loss_ss: 1.084929, loss_d: 0.023167
0.9662 --- loss: 1.239189, loss_ss: 1.149733, loss_d: 0.089456
Epoch finished! Loss: 1.3214304024173367
Starting epoch 5/10.
0.0000 --- loss: 1.268803, loss_ss: 1.148219, loss_d: 0.120584
0.1610 --- loss: 1.260755, loss_ss: 1.150172, loss_d: 0.110584
0.3221 --- loss: 1.075218, loss_ss: 0.941234, loss_d: 0.133984
0.4831 --- loss: 1.739039, loss_ss: 1.397412, loss_d: 0.341626
0.6441 --- loss: 1.313929, loss_ss: 0.968687, loss_d: 0.345243
0.8052 --- loss: 1.095981, loss_ss: 1.034381, loss_d: 0.061600
0.9662 --- loss: 1.066694, loss_ss: 1.055280, loss_d: 0.011414
Epoch finished! Loss: 1.2606226042393716
Starting epoch 6/10.
0.0000 --- loss: 1.180819, loss_ss: 1.169935, loss_d: 0.010884
0.1610 --- loss: 1.056428, loss_ss: 0.964600, loss_d: 0.091827
0.3221 --- loss: 1.077656, loss_ss: 1.034348, loss_d: 0.043308
0.4831 --- loss: 0.957419, loss_ss: 0.863951, loss_d: 0.093468
0.6441 --- loss: 0.908073, loss_ss: 0.894894, loss_d: 0.013179
0.8052 --- loss: 1.055602, loss_ss: 0.951480, loss_d: 0.104121
0.9662 --- loss: 1.207091, loss_ss: 1.202485, loss_d: 0.004607
Epoch finished! Loss: 1.090647985858302
Starting epoch 7/10.
0.0000 --- loss: 1.244916, loss_ss: 0.973511, loss_d: 0.271405
0.1610 --- loss: 0.929675, loss_ss: 0.909505, loss_d: 0.020170
0.3221 --- loss: 0.994116, loss_ss: 0.990522, loss_d: 0.003594
0.4831 --- loss: 1.017526, loss_ss: 1.003730, loss_d: 0.013796
0.6441 --- loss: 1.102193, loss_ss: 1.094862, loss_d: 0.007331
0.8052 --- loss: 1.128441, loss_ss: 1.094111, loss_d: 0.034330
0.9662 --- loss: 0.935655, loss_ss: 0.930103, loss_d: 0.005551
Epoch finished! Loss: 1.0826915637139352
Starting epoch 8/10.
0.0000 --- loss: 0.906128, loss_ss: 0.824883, loss_d: 0.081245
0.1610 --- loss: 0.898287, loss_ss: 0.894681, loss_d: 0.003606
0.3221 --- loss: 0.899371, loss_ss: 0.896962, loss_d: 0.002409
0.4831 --- loss: 0.912610, loss_ss: 0.908430, loss_d: 0.004180
0.6441 --- loss: 0.847157, loss_ss: 0.835670, loss_d: 0.011488
0.8052 --- loss: 1.148140, loss_ss: 1.137586, loss_d: 0.010554
0.9662 --- loss: 0.891841, loss_ss: 0.884556, loss_d: 0.007286
Epoch finished! Loss: 0.9772514402866364
Starting epoch 9/10.
0.0000 --- loss: 0.916046, loss_ss: 0.909974, loss_d: 0.006072
0.1610 --- loss: 0.945135, loss_ss: 0.901107, loss_d: 0.044028
0.3221 --- loss: 0.980805, loss_ss: 0.979310, loss_d: 0.001495
0.4831 --- loss: 0.925475, loss_ss: 0.923244, loss_d: 0.002231
0.6441 --- loss: 0.860033, loss_ss: 0.856228, loss_d: 0.003806
0.8052 --- loss: 0.902848, loss_ss: 0.868460, loss_d: 0.034388
0.9662 --- loss: 0.830043, loss_ss: 0.828950, loss_d: 0.001093
Epoch finished! Loss: 0.9379452053577669
Starting epoch 10/10.
0.0000 --- loss: 0.888432, loss_ss: 0.881665, loss_d: 0.006766
0.1610 --- loss: 0.854084, loss_ss: 0.851332, loss_d: 0.002752
0.3221 --- loss: 0.893320, loss_ss: 0.835115, loss_d: 0.058205
0.4831 --- loss: 0.867641, loss_ss: 0.867019, loss_d: 0.000622
0.6441 --- loss: 0.858959, loss_ss: 0.856914, loss_d: 0.002045
0.8052 --- loss: 0.869827, loss_ss: 0.868888, loss_d: 0.000939
0.9662 --- loss: 1.001212, loss_ss: 0.997500, loss_d: 0.003712
Epoch finished! Loss: 0.9128516018390656
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6648148148148149
             precision    recall  f1-score   support

        0.0       0.79      0.89      0.84       185
        1.0       0.00      0.00      0.00        50
        2.0       0.68      0.84      0.75       483
        3.0       1.00      0.12      0.22       216
        4.0       0.49      0.82      0.61       146

avg / total       0.70      0.66      0.61      1080
 


====== chc040-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  94.17  89.19   95.20   79.33     83.97
1  95.37   0.00  100.00    0.00      0.00
2  75.00  84.27   67.50   67.72     75.09
3  82.50  12.50  100.00  100.00     22.22
4  85.93  81.51   86.62   48.77     61.03
Total accuracy: 66.48%
Average sen: 53.49%
Average spec: 89.86%
Macro f1-score: 48.46%
Diagnosis acc on 60mins: 0.2222222222222222
[0.99998188 0.95514339 0.84994227 0.99401218 0.64079517 0.04328293
 0.5125888  0.14271344 0.70101857]
pred: 0.6488309589525064, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc040-nsrr

=== Test on chc041-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.492839, loss_ss: 1.713087, loss_d: 0.779752
0.1605 --- loss: 1.974103, loss_ss: 1.514665, loss_d: 0.459438
0.3210 --- loss: 1.927781, loss_ss: 1.472235, loss_d: 0.455546
0.4815 --- loss: 1.878719, loss_ss: 1.471375, loss_d: 0.407344
0.6421 --- loss: 1.856345, loss_ss: 1.382758, loss_d: 0.473587
0.8026 --- loss: 1.918479, loss_ss: 1.405298, loss_d: 0.513181
0.9631 --- loss: 2.011488, loss_ss: 1.388348, loss_d: 0.623140
Epoch finished! Loss: 2.098880450571737
Starting epoch 2/10.
0.0000 --- loss: 2.041512, loss_ss: 1.370096, loss_d: 0.671415
0.1605 --- loss: 1.809886, loss_ss: 1.309972, loss_d: 0.499915
0.3210 --- loss: 1.853917, loss_ss: 1.196025, loss_d: 0.657892
0.4815 --- loss: 1.924048, loss_ss: 1.281389, loss_d: 0.642659
0.6421 --- loss: 1.792913, loss_ss: 1.297704, loss_d: 0.495209
0.8026 --- loss: 1.357268, loss_ss: 1.102046, loss_d: 0.255222
0.9631 --- loss: 1.609411, loss_ss: 1.262213, loss_d: 0.347199
Epoch finished! Loss: 1.7631382461517089
Starting epoch 3/10.
0.0000 --- loss: 1.493244, loss_ss: 1.259801, loss_d: 0.233443
0.1605 --- loss: 1.360256, loss_ss: 1.214140, loss_d: 0.146116
0.3210 --- loss: 1.253197, loss_ss: 1.128920, loss_d: 0.124277
0.4815 --- loss: 1.382808, loss_ss: 1.168324, loss_d: 0.214484
0.6421 --- loss: 1.375980, loss_ss: 1.177675, loss_d: 0.198305
0.8026 --- loss: 1.337358, loss_ss: 1.134467, loss_d: 0.202891
0.9631 --- loss: 1.477010, loss_ss: 1.325596, loss_d: 0.151414
Epoch finished! Loss: 1.4679114318663073
Starting epoch 4/10.
0.0000 --- loss: 1.443416, loss_ss: 1.201405, loss_d: 0.242010
0.1605 --- loss: 1.342286, loss_ss: 1.281847, loss_d: 0.060440
0.3210 --- loss: 1.082522, loss_ss: 0.971007, loss_d: 0.111515
0.4815 --- loss: 1.208942, loss_ss: 1.153619, loss_d: 0.055323
0.6421 --- loss: 1.033598, loss_ss: 1.009572, loss_d: 0.024026
0.8026 --- loss: 1.449100, loss_ss: 1.101908, loss_d: 0.347192
0.9631 --- loss: 1.225719, loss_ss: 1.095193, loss_d: 0.130526
Epoch finished! Loss: 1.3226026354297515
Starting epoch 5/10.
0.0000 --- loss: 1.137144, loss_ss: 1.079922, loss_d: 0.057222
0.1605 --- loss: 1.127055, loss_ss: 1.098029, loss_d: 0.029026
0.3210 --- loss: 1.010429, loss_ss: 0.957333, loss_d: 0.053096
0.4815 --- loss: 1.016590, loss_ss: 0.991735, loss_d: 0.024855
0.6421 --- loss: 1.071160, loss_ss: 1.060960, loss_d: 0.010200
0.8026 --- loss: 0.981521, loss_ss: 0.924901, loss_d: 0.056619
0.9631 --- loss: 1.054546, loss_ss: 1.005696, loss_d: 0.048849
Epoch finished! Loss: 1.1207010553729149
Starting epoch 6/10.
0.0000 --- loss: 1.112381, loss_ss: 0.895213, loss_d: 0.217168
0.1605 --- loss: 0.938021, loss_ss: 0.927536, loss_d: 0.010485
0.3210 --- loss: 1.257449, loss_ss: 1.016114, loss_d: 0.241335
0.4815 --- loss: 0.847994, loss_ss: 0.840346, loss_d: 0.007648
0.6421 --- loss: 1.253692, loss_ss: 1.158869, loss_d: 0.094823
0.8026 --- loss: 0.984094, loss_ss: 0.973561, loss_d: 0.010533
0.9631 --- loss: 1.037321, loss_ss: 1.035749, loss_d: 0.001572
Epoch finished! Loss: 1.0822241402441455
Starting epoch 7/10.
0.0000 --- loss: 0.961229, loss_ss: 0.960503, loss_d: 0.000726
0.1605 --- loss: 1.092300, loss_ss: 0.980515, loss_d: 0.111784
0.3210 --- loss: 1.063434, loss_ss: 1.061513, loss_d: 0.001920
0.4815 --- loss: 1.005056, loss_ss: 0.998394, loss_d: 0.006662
0.6421 --- loss: 1.154051, loss_ss: 1.152866, loss_d: 0.001185
0.8026 --- loss: 0.971683, loss_ss: 0.949079, loss_d: 0.022604
0.9631 --- loss: 1.025074, loss_ss: 0.972820, loss_d: 0.052254
Epoch finished! Loss: 1.0355447963360818
Starting epoch 8/10.
0.0000 --- loss: 1.009296, loss_ss: 1.005028, loss_d: 0.004268
0.1605 --- loss: 1.004768, loss_ss: 0.997043, loss_d: 0.007726
0.3210 --- loss: 1.072215, loss_ss: 1.070074, loss_d: 0.002141
0.4815 --- loss: 0.754977, loss_ss: 0.753056, loss_d: 0.001921
0.6421 --- loss: 0.938490, loss_ss: 0.934543, loss_d: 0.003947
0.8026 --- loss: 0.942251, loss_ss: 0.942102, loss_d: 0.000150
0.9631 --- loss: 0.941876, loss_ss: 0.941694, loss_d: 0.000182
Epoch finished! Loss: 0.972421912416335
Starting epoch 9/10.
0.0000 --- loss: 1.311400, loss_ss: 1.308788, loss_d: 0.002612
0.1605 --- loss: 1.202112, loss_ss: 1.201106, loss_d: 0.001006
0.3210 --- loss: 0.981469, loss_ss: 0.981103, loss_d: 0.000365
0.4815 --- loss: 0.998799, loss_ss: 0.998707, loss_d: 0.000092
0.6421 --- loss: 0.869089, loss_ss: 0.867204, loss_d: 0.001886
0.8026 --- loss: 1.195448, loss_ss: 1.182746, loss_d: 0.012702
0.9631 --- loss: 0.799370, loss_ss: 0.728552, loss_d: 0.070817
Epoch finished! Loss: 0.9603903889656067
Starting epoch 10/10.
0.0000 --- loss: 1.055030, loss_ss: 1.012400, loss_d: 0.042630
0.1605 --- loss: 1.063180, loss_ss: 0.928738, loss_d: 0.134442
0.3210 --- loss: 1.050532, loss_ss: 0.999723, loss_d: 0.050809
0.4815 --- loss: 0.811598, loss_ss: 0.810773, loss_d: 0.000825
0.6421 --- loss: 1.183217, loss_ss: 0.794455, loss_d: 0.388762
0.8026 --- loss: 0.938784, loss_ss: 0.888637, loss_d: 0.050147
0.9631 --- loss: 1.239815, loss_ss: 0.876989, loss_d: 0.362826
Epoch finished! Loss: 0.9747932957064721
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7440476190476191
             precision    recall  f1-score   support

        0.0       0.47      0.16      0.24        56
        1.0       0.20      0.13      0.16        38
        2.0       0.81      0.86      0.83       416
        3.0       0.98      0.67      0.80       188
        4.0       0.56      0.90      0.69       142

avg / total       0.76      0.74      0.73       840
 


====== chc041-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  93.21  16.07   98.72  47.37     24.00
1  93.69  13.16   97.51  20.00     15.87
2  83.10  85.82   80.42  81.14     83.41
3  92.38  67.02   99.69  98.44     79.75
4  86.43  90.14   85.67  56.14     69.19
Total accuracy: 74.40%
Average sen: 54.44%
Average spec: 92.40%
Macro f1-score: 54.44%
Diagnosis acc on 60mins: 0.14285714285714285
[0.99999988 0.44308385 0.99994481 0.99440503 0.99999726 0.99985564
 0.70840949]
pred: 0.8779565649373191, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc041-nsrr

=== Test on chc052-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.506063, loss_ss: 1.812167, loss_d: 0.693896
0.1605 --- loss: 2.208273, loss_ss: 1.637197, loss_d: 0.571076
0.3210 --- loss: 2.008050, loss_ss: 1.555717, loss_d: 0.452334
0.4815 --- loss: 2.004813, loss_ss: 1.387405, loss_d: 0.617408
0.6421 --- loss: 1.995292, loss_ss: 1.446295, loss_d: 0.548996
0.8026 --- loss: 1.879253, loss_ss: 1.500732, loss_d: 0.378521
0.9631 --- loss: 2.057952, loss_ss: 1.511231, loss_d: 0.546721
Epoch finished! Loss: 2.132332134631372
Starting epoch 2/10.
0.0000 --- loss: 1.841280, loss_ss: 1.435906, loss_d: 0.405374
0.1605 --- loss: 2.115098, loss_ss: 1.377243, loss_d: 0.737855
0.3210 --- loss: 1.736255, loss_ss: 1.245405, loss_d: 0.490849
0.4815 --- loss: 1.906351, loss_ss: 1.377399, loss_d: 0.528952
0.6421 --- loss: 1.902307, loss_ss: 1.345846, loss_d: 0.556461
0.8026 --- loss: 1.622376, loss_ss: 1.339199, loss_d: 0.283177
0.9631 --- loss: 1.828194, loss_ss: 1.377573, loss_d: 0.450621
Epoch finished! Loss: 1.8730613704650634
Starting epoch 3/10.
0.0000 --- loss: 1.525395, loss_ss: 1.159647, loss_d: 0.365748
0.1605 --- loss: 1.605193, loss_ss: 1.213058, loss_d: 0.392135
0.3210 --- loss: 1.342500, loss_ss: 1.215139, loss_d: 0.127361
0.4815 --- loss: 1.353130, loss_ss: 1.217840, loss_d: 0.135290
0.6421 --- loss: 1.579417, loss_ss: 1.277398, loss_d: 0.302019
0.8026 --- loss: 1.389905, loss_ss: 1.215328, loss_d: 0.174577
0.9631 --- loss: 1.365493, loss_ss: 1.185511, loss_d: 0.179982
Epoch finished! Loss: 1.6117151610312923
Starting epoch 4/10.
0.0000 --- loss: 1.305021, loss_ss: 1.139995, loss_d: 0.165026
0.1605 --- loss: 1.562270, loss_ss: 1.286682, loss_d: 0.275588
0.3210 --- loss: 1.564652, loss_ss: 1.145477, loss_d: 0.419176
0.4815 --- loss: 1.381729, loss_ss: 1.249385, loss_d: 0.132344
0.6421 --- loss: 1.284539, loss_ss: 1.085473, loss_d: 0.199066
0.8026 --- loss: 1.252110, loss_ss: 1.165778, loss_d: 0.086332
0.9631 --- loss: 1.954932, loss_ss: 1.294179, loss_d: 0.660753
Epoch finished! Loss: 1.4036024059018781
Starting epoch 5/10.
0.0000 --- loss: 1.204763, loss_ss: 1.106416, loss_d: 0.098346
0.1605 --- loss: 1.424426, loss_ss: 1.348275, loss_d: 0.076151
0.3210 --- loss: 1.113150, loss_ss: 1.076859, loss_d: 0.036291
0.4815 --- loss: 1.086241, loss_ss: 1.066192, loss_d: 0.020049
0.6421 --- loss: 1.207895, loss_ss: 1.095561, loss_d: 0.112334
0.8026 --- loss: 1.125844, loss_ss: 1.096256, loss_d: 0.029589
0.9631 --- loss: 1.109023, loss_ss: 1.072604, loss_d: 0.036418
Epoch finished! Loss: 1.2017490979163878
Starting epoch 6/10.
0.0000 --- loss: 0.927839, loss_ss: 0.917119, loss_d: 0.010721
0.1605 --- loss: 1.055060, loss_ss: 1.046681, loss_d: 0.008380
0.3210 --- loss: 1.019214, loss_ss: 0.997096, loss_d: 0.022118
0.4815 --- loss: 1.118535, loss_ss: 0.989230, loss_d: 0.129305
0.6421 --- loss: 0.907768, loss_ss: 0.902517, loss_d: 0.005250
0.8026 --- loss: 1.051769, loss_ss: 0.911779, loss_d: 0.139990
0.9631 --- loss: 1.130023, loss_ss: 1.110281, loss_d: 0.019742
Epoch finished! Loss: 1.0860990968442732
Starting epoch 7/10.
0.0000 --- loss: 0.895101, loss_ss: 0.889067, loss_d: 0.006033
0.1605 --- loss: 1.103499, loss_ss: 1.090155, loss_d: 0.013344
0.3210 --- loss: 0.994440, loss_ss: 0.993950, loss_d: 0.000490
0.4815 --- loss: 0.819738, loss_ss: 0.812436, loss_d: 0.007301
0.6421 --- loss: 1.190795, loss_ss: 1.190225, loss_d: 0.000570
0.8026 --- loss: 0.951436, loss_ss: 0.948960, loss_d: 0.002476
0.9631 --- loss: 0.867436, loss_ss: 0.850457, loss_d: 0.016979
Epoch finished! Loss: 1.0080668916625362
Starting epoch 8/10.
0.0000 --- loss: 1.099194, loss_ss: 1.099012, loss_d: 0.000182
0.1605 --- loss: 0.881086, loss_ss: 0.876909, loss_d: 0.004177
0.3210 --- loss: 1.087596, loss_ss: 1.087296, loss_d: 0.000300
0.4815 --- loss: 0.933783, loss_ss: 0.930563, loss_d: 0.003220
0.6421 --- loss: 1.026292, loss_ss: 1.026013, loss_d: 0.000279
0.8026 --- loss: 0.930010, loss_ss: 0.922523, loss_d: 0.007487
0.9631 --- loss: 1.069702, loss_ss: 1.065521, loss_d: 0.004181
Epoch finished! Loss: 0.9567420040407488
Starting epoch 9/10.
0.0000 --- loss: 0.887682, loss_ss: 0.887229, loss_d: 0.000453
0.1605 --- loss: 0.850723, loss_ss: 0.847335, loss_d: 0.003388
0.3210 --- loss: 0.890561, loss_ss: 0.889062, loss_d: 0.001499
0.4815 --- loss: 0.930148, loss_ss: 0.848026, loss_d: 0.082123
0.6421 --- loss: 0.856947, loss_ss: 0.853263, loss_d: 0.003683
0.8026 --- loss: 0.902954, loss_ss: 0.902746, loss_d: 0.000208
0.9631 --- loss: 0.995037, loss_ss: 0.994657, loss_d: 0.000379
Epoch finished! Loss: 0.930987355209166
Starting epoch 10/10.
0.0000 --- loss: 0.964095, loss_ss: 0.963438, loss_d: 0.000657
0.1605 --- loss: 0.942776, loss_ss: 0.942375, loss_d: 0.000401
0.3210 --- loss: 0.889744, loss_ss: 0.889563, loss_d: 0.000181
0.4815 --- loss: 0.849734, loss_ss: 0.835467, loss_d: 0.014267
0.6421 --- loss: 0.908704, loss_ss: 0.880329, loss_d: 0.028375
0.8026 --- loss: 0.918380, loss_ss: 0.913932, loss_d: 0.004448
0.9631 --- loss: 0.940373, loss_ss: 0.938187, loss_d: 0.002186
Epoch finished! Loss: 0.9479608660744082
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8452380952380952
             precision    recall  f1-score   support

        0.0       0.85      1.00      0.92       142
        1.0       0.00      0.00      0.00        23
        2.0       0.83      0.92      0.87       429
        3.0       0.97      0.71      0.82       144
        4.0       0.76      0.72      0.74       102

avg / total       0.83      0.85      0.83       840
 


====== chc052-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  96.90  100.00   96.28  84.52     91.61
1  97.26    0.00  100.00   0.00      0.00
2  86.43   91.61   81.02  83.44     87.33
3  94.64   70.83   99.57  97.14     81.93
4  93.81   71.57   96.88  76.04     73.74
Total accuracy: 84.52%
Average sen: 66.80%
Average spec: 94.75%
Macro f1-score: 66.92%
Diagnosis acc on 60mins: 0.42857142857142855
[0.98186308 0.550035   0.00224121 0.24054316 0.66316086 0.00287391
 0.79713714]
pred: 0.4625506221449801, label: 0
Right! Diagnosis: Other
Save 60mins of subject chc052-nsrr

=== Test on chc056-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.413230, loss_ss: 1.742174, loss_d: 0.671056
0.1605 --- loss: 2.799677, loss_ss: 1.572683, loss_d: 1.226994
0.3210 --- loss: 2.595328, loss_ss: 1.576940, loss_d: 1.018388
0.4815 --- loss: 2.465537, loss_ss: 1.612241, loss_d: 0.853296
0.6421 --- loss: 1.976695, loss_ss: 1.483982, loss_d: 0.492713
0.8026 --- loss: 1.976882, loss_ss: 1.414783, loss_d: 0.562100
0.9631 --- loss: 2.099383, loss_ss: 1.348028, loss_d: 0.751355
Epoch finished! Loss: 2.177630232226464
Starting epoch 2/10.
0.0000 --- loss: 1.709063, loss_ss: 1.387420, loss_d: 0.321643
0.1605 --- loss: 1.792388, loss_ss: 1.377295, loss_d: 0.415094
0.3210 --- loss: 2.004941, loss_ss: 1.399177, loss_d: 0.605764
0.4815 --- loss: 1.747000, loss_ss: 1.287714, loss_d: 0.459286
0.6421 --- loss: 1.803554, loss_ss: 1.312280, loss_d: 0.491274
0.8026 --- loss: 1.719482, loss_ss: 1.273525, loss_d: 0.445957
0.9631 --- loss: 1.464055, loss_ss: 1.192100, loss_d: 0.271955
Epoch finished! Loss: 1.7997225119221596
Starting epoch 3/10.
0.0000 --- loss: 1.359205, loss_ss: 1.308638, loss_d: 0.050567
0.1605 --- loss: 1.507186, loss_ss: 1.226577, loss_d: 0.280609
0.3210 --- loss: 1.254593, loss_ss: 1.149615, loss_d: 0.104978
0.4815 --- loss: 1.759827, loss_ss: 1.124029, loss_d: 0.635798
0.6421 --- loss: 1.793657, loss_ss: 1.126284, loss_d: 0.667373
0.8026 --- loss: 1.503887, loss_ss: 1.084953, loss_d: 0.418934
0.9631 --- loss: 1.467080, loss_ss: 1.061043, loss_d: 0.406037
Epoch finished! Loss: 1.5402229466745931
Starting epoch 4/10.
0.0000 --- loss: 1.280012, loss_ss: 1.125920, loss_d: 0.154092
0.1605 --- loss: 1.363073, loss_ss: 1.226117, loss_d: 0.136956
0.3210 --- loss: 1.024859, loss_ss: 1.009165, loss_d: 0.015694
0.4815 --- loss: 1.297576, loss_ss: 1.274204, loss_d: 0.023372
0.6421 --- loss: 1.450168, loss_ss: 1.050347, loss_d: 0.399822
0.8026 --- loss: 1.303976, loss_ss: 1.165281, loss_d: 0.138695
0.9631 --- loss: 1.123341, loss_ss: 1.047714, loss_d: 0.075627
Epoch finished! Loss: 1.3024421411175882
Starting epoch 5/10.
0.0000 --- loss: 0.935409, loss_ss: 0.914388, loss_d: 0.021021
0.1605 --- loss: 1.114320, loss_ss: 1.100849, loss_d: 0.013471
0.3210 --- loss: 1.115611, loss_ss: 1.002100, loss_d: 0.113511
0.4815 --- loss: 1.146491, loss_ss: 1.106453, loss_d: 0.040038
0.6421 --- loss: 1.067645, loss_ss: 1.011135, loss_d: 0.056510
0.8026 --- loss: 1.334610, loss_ss: 1.162756, loss_d: 0.171854
0.9631 --- loss: 1.093516, loss_ss: 0.898888, loss_d: 0.194628
Epoch finished! Loss: 1.1633425941390376
Starting epoch 6/10.
0.0000 --- loss: 1.261326, loss_ss: 1.127686, loss_d: 0.133640
0.1605 --- loss: 1.003531, loss_ss: 0.997085, loss_d: 0.006447
0.3210 --- loss: 1.023832, loss_ss: 0.896852, loss_d: 0.126980
0.4815 --- loss: 0.988819, loss_ss: 0.986677, loss_d: 0.002142
0.6421 --- loss: 1.215182, loss_ss: 0.885124, loss_d: 0.330058
0.8026 --- loss: 0.853355, loss_ss: 0.803441, loss_d: 0.049914
0.9631 --- loss: 1.030350, loss_ss: 0.913945, loss_d: 0.116405
Epoch finished! Loss: 1.1340837353660214
Starting epoch 7/10.
0.0000 --- loss: 0.893878, loss_ss: 0.891093, loss_d: 0.002785
0.1605 --- loss: 0.922538, loss_ss: 0.916427, loss_d: 0.006111
0.3210 --- loss: 1.170531, loss_ss: 1.050734, loss_d: 0.119797
0.4815 --- loss: 1.069183, loss_ss: 1.050286, loss_d: 0.018897
0.6421 --- loss: 1.051040, loss_ss: 1.040140, loss_d: 0.010899
0.8026 --- loss: 1.136019, loss_ss: 1.063205, loss_d: 0.072814
0.9631 --- loss: 0.885870, loss_ss: 0.822255, loss_d: 0.063615
Epoch finished! Loss: 1.0533762554968558
Starting epoch 8/10.
0.0000 --- loss: 1.137335, loss_ss: 1.131270, loss_d: 0.006065
0.1605 --- loss: 1.003547, loss_ss: 1.001505, loss_d: 0.002042
0.3210 --- loss: 0.927825, loss_ss: 0.926692, loss_d: 0.001132
0.4815 --- loss: 1.094591, loss_ss: 0.983350, loss_d: 0.111241
0.6421 --- loss: 0.873028, loss_ss: 0.856576, loss_d: 0.016452
0.8026 --- loss: 0.918179, loss_ss: 0.904087, loss_d: 0.014092
0.9631 --- loss: 1.123045, loss_ss: 1.120478, loss_d: 0.002567
Epoch finished! Loss: 1.0848250773645216
Starting epoch 9/10.
0.0000 --- loss: 0.956454, loss_ss: 0.955735, loss_d: 0.000718
0.1605 --- loss: 1.509394, loss_ss: 1.134488, loss_d: 0.374906
0.3210 --- loss: 1.217048, loss_ss: 1.202285, loss_d: 0.014762
0.4815 --- loss: 0.928630, loss_ss: 0.913398, loss_d: 0.015232
0.6421 --- loss: 0.856351, loss_ss: 0.847658, loss_d: 0.008693
0.8026 --- loss: 0.851726, loss_ss: 0.848702, loss_d: 0.003024
0.9631 --- loss: 1.108199, loss_ss: 1.102656, loss_d: 0.005543
Epoch finished! Loss: 1.036719637532388
Starting epoch 10/10.
0.0000 --- loss: 0.915976, loss_ss: 0.883611, loss_d: 0.032365
0.1605 --- loss: 0.823683, loss_ss: 0.821469, loss_d: 0.002214
0.3210 --- loss: 0.881730, loss_ss: 0.880313, loss_d: 0.001417
0.4815 --- loss: 0.884942, loss_ss: 0.879475, loss_d: 0.005467
0.6421 --- loss: 0.988853, loss_ss: 0.983376, loss_d: 0.005477
0.8026 --- loss: 1.012534, loss_ss: 0.911502, loss_d: 0.101032
0.9631 --- loss: 0.925625, loss_ss: 0.851717, loss_d: 0.073908
Epoch finished! Loss: 0.9605668523619252
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.575
             precision    recall  f1-score   support

        0.0       0.60      0.03      0.07       172
        1.0       1.00      0.01      0.02        82
        2.0       0.72      0.85      0.78       368
        3.0       1.00      0.70      0.82       128
        4.0       0.24      0.82      0.37        90

avg / total       0.71      0.57      0.52       840
 


====== chc056-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  79.76   3.49   99.40   60.00      6.59
1  90.36   1.22  100.00  100.00      2.41
2  79.05  85.05   74.36   72.12     78.05
3  95.36  69.53  100.00  100.00     82.03
4  70.48  82.22   69.07   24.18     37.37
Total accuracy: 57.50%
Average sen: 48.30%
Average spec: 88.57%
Macro f1-score: 41.29%
Diagnosis acc on 60mins: 0.14285714285714285
[0.58203316 0.98584312 0.59294283 0.98599523 0.99622607 0.17118622
 0.99986315]
pred: 0.7591556842838015, label: 0
Wrong!!! Real Diagnosis: Other
Save 60mins of subject chc056-nsrr

=== Test on chp001-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.467978, loss_ss: 1.776777, loss_d: 0.691201
0.1610 --- loss: 2.244164, loss_ss: 1.525691, loss_d: 0.718472
0.3221 --- loss: 2.282058, loss_ss: 1.489796, loss_d: 0.792262
0.4831 --- loss: 1.908002, loss_ss: 1.442135, loss_d: 0.465867
0.6441 --- loss: 2.117223, loss_ss: 1.509496, loss_d: 0.607726
0.8052 --- loss: 1.884967, loss_ss: 1.373527, loss_d: 0.511440
0.9662 --- loss: 2.166822, loss_ss: 1.344415, loss_d: 0.822407
Epoch finished! Loss: 2.1500565948024875
Starting epoch 2/10.
0.0000 --- loss: 1.832605, loss_ss: 1.301216, loss_d: 0.531390
0.1610 --- loss: 1.959432, loss_ss: 1.472368, loss_d: 0.487064
0.3221 --- loss: 1.832021, loss_ss: 1.449071, loss_d: 0.382950
0.4831 --- loss: 1.964821, loss_ss: 1.341111, loss_d: 0.623710
0.6441 --- loss: 1.739942, loss_ss: 1.367001, loss_d: 0.372941
0.8052 --- loss: 1.662853, loss_ss: 1.386440, loss_d: 0.276413
0.9662 --- loss: 2.465748, loss_ss: 1.245911, loss_d: 1.219837
Epoch finished! Loss: 1.8889911886184447
Starting epoch 3/10.
0.0000 --- loss: 1.656334, loss_ss: 1.327684, loss_d: 0.328650
0.1610 --- loss: 1.712802, loss_ss: 1.295813, loss_d: 0.416988
0.3221 --- loss: 1.568367, loss_ss: 1.262954, loss_d: 0.305413
0.4831 --- loss: 1.547941, loss_ss: 1.251077, loss_d: 0.296864
0.6441 --- loss: 1.423080, loss_ss: 1.299741, loss_d: 0.123340
0.8052 --- loss: 1.443112, loss_ss: 1.206170, loss_d: 0.236942
0.9662 --- loss: 1.542777, loss_ss: 1.244577, loss_d: 0.298200
Epoch finished! Loss: 1.568875474314536
Starting epoch 4/10.
0.0000 --- loss: 1.441097, loss_ss: 1.359389, loss_d: 0.081708
0.1610 --- loss: 1.483651, loss_ss: 1.217790, loss_d: 0.265860
0.3221 --- loss: 1.339690, loss_ss: 1.220387, loss_d: 0.119304
0.4831 --- loss: 1.346366, loss_ss: 1.271445, loss_d: 0.074920
0.6441 --- loss: 1.472177, loss_ss: 1.161695, loss_d: 0.310482
0.8052 --- loss: 1.167478, loss_ss: 1.093869, loss_d: 0.073609
0.9662 --- loss: 1.137967, loss_ss: 1.091735, loss_d: 0.046231
Epoch finished! Loss: 1.4388352747886413
Starting epoch 5/10.
0.0000 --- loss: 1.233417, loss_ss: 1.214221, loss_d: 0.019197
0.1610 --- loss: 1.184726, loss_ss: 1.171381, loss_d: 0.013346
0.3221 --- loss: 1.305851, loss_ss: 1.293851, loss_d: 0.011999
0.4831 --- loss: 1.027024, loss_ss: 1.011318, loss_d: 0.015706
0.6441 --- loss: 1.105841, loss_ss: 1.043639, loss_d: 0.062202
0.8052 --- loss: 1.281925, loss_ss: 1.180725, loss_d: 0.101200
0.9662 --- loss: 1.092515, loss_ss: 1.041678, loss_d: 0.050837
Epoch finished! Loss: 1.2141899620333025
Starting epoch 6/10.
0.0000 --- loss: 1.220287, loss_ss: 1.186568, loss_d: 0.033719
0.1610 --- loss: 1.201885, loss_ss: 1.021348, loss_d: 0.180537
0.3221 --- loss: 1.288124, loss_ss: 0.987996, loss_d: 0.300128
0.4831 --- loss: 1.135372, loss_ss: 1.068087, loss_d: 0.067286
0.6441 --- loss: 1.091985, loss_ss: 1.035047, loss_d: 0.056938
0.8052 --- loss: 1.085819, loss_ss: 1.047071, loss_d: 0.038749
0.9662 --- loss: 1.101985, loss_ss: 0.962979, loss_d: 0.139006
Epoch finished! Loss: 1.21894625694521
Starting epoch 7/10.
0.0000 --- loss: 1.021088, loss_ss: 0.959859, loss_d: 0.061229
0.1610 --- loss: 0.936968, loss_ss: 0.921563, loss_d: 0.015405
0.3221 --- loss: 1.092645, loss_ss: 1.065987, loss_d: 0.026658
0.4831 --- loss: 1.100439, loss_ss: 1.060950, loss_d: 0.039489
0.6441 --- loss: 0.981073, loss_ss: 0.973926, loss_d: 0.007147
0.8052 --- loss: 1.108983, loss_ss: 1.082045, loss_d: 0.026937
0.9662 --- loss: 1.051531, loss_ss: 1.039342, loss_d: 0.012189
Epoch finished! Loss: 1.0596251007049315
Starting epoch 8/10.
0.0000 --- loss: 0.887906, loss_ss: 0.885491, loss_d: 0.002415
0.1610 --- loss: 1.005090, loss_ss: 1.003528, loss_d: 0.001563
0.3221 --- loss: 1.034516, loss_ss: 1.030119, loss_d: 0.004397
0.4831 --- loss: 1.120570, loss_ss: 1.099320, loss_d: 0.021249
0.6441 --- loss: 0.854776, loss_ss: 0.854419, loss_d: 0.000358
0.8052 --- loss: 0.933477, loss_ss: 0.928641, loss_d: 0.004836
0.9662 --- loss: 1.034547, loss_ss: 1.033687, loss_d: 0.000860
Epoch finished! Loss: 1.0177733023320474
Starting epoch 9/10.
0.0000 --- loss: 0.988843, loss_ss: 0.988516, loss_d: 0.000327
0.1610 --- loss: 0.833673, loss_ss: 0.825833, loss_d: 0.007841
0.3221 --- loss: 0.874595, loss_ss: 0.872831, loss_d: 0.001765
0.4831 --- loss: 0.980848, loss_ss: 0.980204, loss_d: 0.000644
0.6441 --- loss: 0.984268, loss_ss: 0.984204, loss_d: 0.000064
0.8052 --- loss: 0.835215, loss_ss: 0.833444, loss_d: 0.001770
0.9662 --- loss: 1.040790, loss_ss: 1.038929, loss_d: 0.001861
Epoch finished! Loss: 0.9518781064018127
Starting epoch 10/10.
0.0000 --- loss: 0.910298, loss_ss: 0.909285, loss_d: 0.001013
0.1610 --- loss: 0.807109, loss_ss: 0.805890, loss_d: 0.001219
0.3221 --- loss: 0.904459, loss_ss: 0.902155, loss_d: 0.002304
0.4831 --- loss: 0.759615, loss_ss: 0.758548, loss_d: 0.001067
0.6441 --- loss: 1.017357, loss_ss: 1.010548, loss_d: 0.006809
0.8052 --- loss: 0.912463, loss_ss: 0.909880, loss_d: 0.002583
0.9662 --- loss: 0.931072, loss_ss: 0.929466, loss_d: 0.001606
Epoch finished! Loss: 0.93430321831857
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4935185185185185
             precision    recall  f1-score   support

        0.0       0.07      0.96      0.14        25
        1.0       0.06      0.05      0.05        77
        2.0       0.74      0.91      0.82       553
        3.0       0.00      0.00      0.00        69
        4.0       0.00      0.00      0.00       356

avg / total       0.39      0.49      0.43      1080
 


====== chp001-nsrr ======

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.

The ppr of  4  has ZeroDivisionError.

The f1-score of  4  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  71.76  96.00   71.18   7.32     13.60
1  86.94   5.19   93.22   5.56      5.37
2  79.35  91.32   66.79  74.26     81.91
3  93.61   0.00  100.00   0.00      0.00
4  67.04   0.00  100.00   0.00      0.00
Total accuracy: 49.35%
Average sen: 38.50%
Average spec: 86.24%
Macro f1-score: 20.18%
Diagnosis acc on 60mins: 0.6666666666666666
[0.02132245 0.93602413 0.91446751 0.99966896 0.53241169 0.60172987
 0.27343112 0.99556524 0.0200633 ]
pred: 0.5882982524732748, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp001-nsrr

=== Test on chp002-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.376400, loss_ss: 1.652873, loss_d: 0.723527
0.1610 --- loss: 2.230410, loss_ss: 1.587482, loss_d: 0.642928
0.3221 --- loss: 2.063471, loss_ss: 1.579845, loss_d: 0.483626
0.4831 --- loss: 1.843460, loss_ss: 1.494644, loss_d: 0.348816
0.6441 --- loss: 1.963246, loss_ss: 1.420142, loss_d: 0.543104
0.8052 --- loss: 1.910477, loss_ss: 1.460806, loss_d: 0.449671
0.9662 --- loss: 2.011669, loss_ss: 1.418442, loss_d: 0.593227
Epoch finished! Loss: 2.203318807386583
Starting epoch 2/10.
0.0000 --- loss: 1.864207, loss_ss: 1.335932, loss_d: 0.528275
0.1610 --- loss: 2.053130, loss_ss: 1.483754, loss_d: 0.569376
0.3221 --- loss: 1.694211, loss_ss: 1.326845, loss_d: 0.367366
0.4831 --- loss: 1.990049, loss_ss: 1.364352, loss_d: 0.625696
0.6441 --- loss: 1.962677, loss_ss: 1.434655, loss_d: 0.528022
0.8052 --- loss: 1.652616, loss_ss: 1.299113, loss_d: 0.353503
0.9662 --- loss: 1.635099, loss_ss: 1.264262, loss_d: 0.370838
Epoch finished! Loss: 1.923071797816984
Starting epoch 3/10.
0.0000 --- loss: 2.041472, loss_ss: 1.437701, loss_d: 0.603771
0.1610 --- loss: 1.693314, loss_ss: 1.321716, loss_d: 0.371598
0.3221 --- loss: 1.501031, loss_ss: 1.236634, loss_d: 0.264396
0.4831 --- loss: 1.648046, loss_ss: 1.371892, loss_d: 0.276155
0.6441 --- loss: 1.731517, loss_ss: 1.238304, loss_d: 0.493213
0.8052 --- loss: 1.698024, loss_ss: 1.269776, loss_d: 0.428248
0.9662 --- loss: 1.475116, loss_ss: 1.180334, loss_d: 0.294782
Epoch finished! Loss: 1.6921369625676064
Starting epoch 4/10.
0.0000 --- loss: 1.617358, loss_ss: 1.299855, loss_d: 0.317504
0.1610 --- loss: 1.225889, loss_ss: 1.175070, loss_d: 0.050819
0.3221 --- loss: 1.197272, loss_ss: 1.184300, loss_d: 0.012972
0.4831 --- loss: 1.518816, loss_ss: 1.266859, loss_d: 0.251957
0.6441 --- loss: 1.345453, loss_ss: 1.253049, loss_d: 0.092404
0.8052 --- loss: 1.284870, loss_ss: 1.203319, loss_d: 0.081551
0.9662 --- loss: 1.365264, loss_ss: 1.077783, loss_d: 0.287482
Epoch finished! Loss: 1.4384710384953407
Starting epoch 5/10.
0.0000 --- loss: 1.258615, loss_ss: 1.216143, loss_d: 0.042472
0.1610 --- loss: 1.572725, loss_ss: 1.281999, loss_d: 0.290727
0.3221 --- loss: 1.393428, loss_ss: 1.296103, loss_d: 0.097325
0.4831 --- loss: 1.462998, loss_ss: 1.237225, loss_d: 0.225774
0.6441 --- loss: 1.146963, loss_ss: 1.063924, loss_d: 0.083039
0.8052 --- loss: 1.347338, loss_ss: 1.120524, loss_d: 0.226814
0.9662 --- loss: 1.144939, loss_ss: 1.000616, loss_d: 0.144323
Epoch finished! Loss: 1.240276220344728
Starting epoch 6/10.
0.0000 --- loss: 1.159210, loss_ss: 1.145959, loss_d: 0.013251
0.1610 --- loss: 1.033622, loss_ss: 1.024092, loss_d: 0.009529
0.3221 --- loss: 1.208353, loss_ss: 1.121202, loss_d: 0.087151
0.4831 --- loss: 1.026474, loss_ss: 0.983108, loss_d: 0.043367
0.6441 --- loss: 1.313825, loss_ss: 1.310177, loss_d: 0.003647
0.8052 --- loss: 0.993839, loss_ss: 0.942611, loss_d: 0.051228
0.9662 --- loss: 1.247087, loss_ss: 0.997204, loss_d: 0.249883
Epoch finished! Loss: 1.1646411293937313
Starting epoch 7/10.
0.0000 --- loss: 0.956660, loss_ss: 0.950928, loss_d: 0.005732
0.1610 --- loss: 1.012306, loss_ss: 1.001963, loss_d: 0.010343
0.3221 --- loss: 1.156974, loss_ss: 1.146188, loss_d: 0.010786
0.4831 --- loss: 1.074830, loss_ss: 1.057685, loss_d: 0.017145
0.6441 --- loss: 1.410186, loss_ss: 1.042980, loss_d: 0.367205
0.8052 --- loss: 1.194122, loss_ss: 0.904221, loss_d: 0.289901
0.9662 --- loss: 0.884033, loss_ss: 0.880752, loss_d: 0.003282
Epoch finished! Loss: 1.0520762089760072
Starting epoch 8/10.
0.0000 --- loss: 1.004402, loss_ss: 1.002496, loss_d: 0.001906
0.1610 --- loss: 0.874197, loss_ss: 0.846348, loss_d: 0.027849
0.3221 --- loss: 0.993679, loss_ss: 0.989331, loss_d: 0.004348
0.4831 --- loss: 0.926744, loss_ss: 0.925925, loss_d: 0.000819
0.6441 --- loss: 1.069116, loss_ss: 0.950426, loss_d: 0.118689
0.8052 --- loss: 0.875997, loss_ss: 0.866024, loss_d: 0.009973
0.9662 --- loss: 0.781714, loss_ss: 0.757586, loss_d: 0.024128
Epoch finished! Loss: 0.9778145801636481
Starting epoch 9/10.
0.0000 --- loss: 0.953571, loss_ss: 0.943569, loss_d: 0.010003
0.1610 --- loss: 0.965487, loss_ss: 0.958614, loss_d: 0.006873
0.3221 --- loss: 1.084585, loss_ss: 1.083762, loss_d: 0.000823
0.4831 --- loss: 1.053705, loss_ss: 1.052086, loss_d: 0.001620
0.6441 --- loss: 0.876511, loss_ss: 0.871751, loss_d: 0.004760
0.8052 --- loss: 0.804025, loss_ss: 0.803355, loss_d: 0.000670
0.9662 --- loss: 0.765295, loss_ss: 0.760842, loss_d: 0.004453
Epoch finished! Loss: 0.950214950307723
Starting epoch 10/10.
0.0000 --- loss: 1.062751, loss_ss: 1.058069, loss_d: 0.004682
0.1610 --- loss: 0.767338, loss_ss: 0.764865, loss_d: 0.002473
0.3221 --- loss: 0.924780, loss_ss: 0.900906, loss_d: 0.023874
0.4831 --- loss: 0.825760, loss_ss: 0.823796, loss_d: 0.001964
0.6441 --- loss: 0.821235, loss_ss: 0.818203, loss_d: 0.003032
0.8052 --- loss: 1.035135, loss_ss: 1.034131, loss_d: 0.001004
0.9662 --- loss: 0.814019, loss_ss: 0.812962, loss_d: 0.001057
Epoch finished! Loss: 0.8992453275188323
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5222222222222223
             precision    recall  f1-score   support

        0.0       0.98      0.18      0.30       260
        1.0       0.00      0.00      0.00       248
        2.0       0.89      0.94      0.91       375
        3.0       1.00      0.80      0.89       169
        4.0       0.06      1.00      0.11        28

avg / total       0.70      0.52      0.53      1080
 


====== chp002-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  80.09   17.69   99.88   97.87     29.97
1  76.67    0.00   99.52    0.00      0.00
2  93.89   94.40   93.62   88.72     91.47
3  96.94   80.47  100.00  100.00     89.18
4  56.85  100.00   55.70    5.67     10.73
Total accuracy: 52.22%
Average sen: 58.51%
Average spec: 89.74%
Macro f1-score: 44.27%
Diagnosis acc on 60mins: 0.8888888888888888
[0.99894649 0.9998771  0.97668171 0.41879877 0.92953908 0.99990892
 0.55179387 0.99978012 0.99961084]
pred: 0.8749929898315005, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp002-nsrr

=== Test on chp003-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.295261, loss_ss: 1.592756, loss_d: 0.702505
0.1608 --- loss: 2.320727, loss_ss: 1.491661, loss_d: 0.829066
0.3215 --- loss: 2.195147, loss_ss: 1.424545, loss_d: 0.770602
0.4823 --- loss: 1.915042, loss_ss: 1.452247, loss_d: 0.462795
0.6431 --- loss: 1.724312, loss_ss: 1.345387, loss_d: 0.378925
0.8039 --- loss: 2.048397, loss_ss: 1.434010, loss_d: 0.614386
0.9646 --- loss: 2.190658, loss_ss: 1.318535, loss_d: 0.872122
Epoch finished! Loss: 2.070671702584913
Starting epoch 2/10.
0.0000 --- loss: 1.967559, loss_ss: 1.403897, loss_d: 0.563662
0.1608 --- loss: 1.668139, loss_ss: 1.351689, loss_d: 0.316450
0.3215 --- loss: 2.079134, loss_ss: 1.301120, loss_d: 0.778014
0.4823 --- loss: 1.812536, loss_ss: 1.312255, loss_d: 0.500281
0.6431 --- loss: 1.669815, loss_ss: 1.233420, loss_d: 0.436395
0.8039 --- loss: 1.736617, loss_ss: 1.150074, loss_d: 0.586543
0.9646 --- loss: 1.588620, loss_ss: 1.263893, loss_d: 0.324726
Epoch finished! Loss: 1.8264526051859702
Starting epoch 3/10.
0.0000 --- loss: 1.631248, loss_ss: 1.215091, loss_d: 0.416157
0.1608 --- loss: 1.806756, loss_ss: 1.201330, loss_d: 0.605425
0.3215 --- loss: 1.200695, loss_ss: 1.043662, loss_d: 0.157032
0.4823 --- loss: 1.425572, loss_ss: 1.152686, loss_d: 0.272886
0.6431 --- loss: 1.323696, loss_ss: 1.185869, loss_d: 0.137827
0.8039 --- loss: 1.293670, loss_ss: 1.111475, loss_d: 0.182196
0.9646 --- loss: 1.248160, loss_ss: 1.156016, loss_d: 0.092144
Epoch finished! Loss: 1.5612458106010192
Starting epoch 4/10.
0.0000 --- loss: 1.416400, loss_ss: 1.176868, loss_d: 0.239532
0.1608 --- loss: 1.260739, loss_ss: 1.121399, loss_d: 0.139340
0.3215 --- loss: 1.489233, loss_ss: 1.058424, loss_d: 0.430809
0.4823 --- loss: 1.148142, loss_ss: 1.050574, loss_d: 0.097568
0.6431 --- loss: 2.210816, loss_ss: 1.278363, loss_d: 0.932453
0.8039 --- loss: 1.077281, loss_ss: 0.963889, loss_d: 0.113393
0.9646 --- loss: 1.078573, loss_ss: 1.031605, loss_d: 0.046968
Epoch finished! Loss: 1.3905406998049827
Starting epoch 5/10.
0.0000 --- loss: 1.148780, loss_ss: 1.093912, loss_d: 0.054868
0.1608 --- loss: 1.133476, loss_ss: 1.107009, loss_d: 0.026468
0.3215 --- loss: 1.126521, loss_ss: 0.999536, loss_d: 0.126985
0.4823 --- loss: 1.148431, loss_ss: 1.075029, loss_d: 0.073402
0.6431 --- loss: 0.999557, loss_ss: 0.982435, loss_d: 0.017122
0.8039 --- loss: 1.170575, loss_ss: 1.160529, loss_d: 0.010046
0.9646 --- loss: 1.037962, loss_ss: 1.028694, loss_d: 0.009268
Epoch finished! Loss: 1.1857097591123273
Starting epoch 6/10.
0.0000 --- loss: 1.040263, loss_ss: 0.992256, loss_d: 0.048007
0.1608 --- loss: 0.964913, loss_ss: 0.959027, loss_d: 0.005886
0.3215 --- loss: 1.172135, loss_ss: 1.144607, loss_d: 0.027528
0.4823 --- loss: 1.111378, loss_ss: 1.108831, loss_d: 0.002546
0.6431 --- loss: 0.917053, loss_ss: 0.869989, loss_d: 0.047064
0.8039 --- loss: 0.946488, loss_ss: 0.923210, loss_d: 0.023278
0.9646 --- loss: 1.009398, loss_ss: 1.007401, loss_d: 0.001997
Epoch finished! Loss: 1.0483886368813053
Starting epoch 7/10.
0.0000 --- loss: 1.022379, loss_ss: 1.018441, loss_d: 0.003938
0.1608 --- loss: 0.914706, loss_ss: 0.881048, loss_d: 0.033658
0.3215 --- loss: 0.969415, loss_ss: 0.861455, loss_d: 0.107959
0.4823 --- loss: 0.932734, loss_ss: 0.913869, loss_d: 0.018865
0.6431 --- loss: 1.040211, loss_ss: 0.978601, loss_d: 0.061610
0.8039 --- loss: 0.911398, loss_ss: 0.906905, loss_d: 0.004494
0.9646 --- loss: 0.996146, loss_ss: 0.819303, loss_d: 0.176843
Epoch finished! Loss: 1.0165056672788435
Starting epoch 8/10.
0.0000 --- loss: 1.034226, loss_ss: 0.957739, loss_d: 0.076487
0.1608 --- loss: 0.922559, loss_ss: 0.919279, loss_d: 0.003280
0.3215 --- loss: 0.925231, loss_ss: 0.919161, loss_d: 0.006070
0.4823 --- loss: 0.927652, loss_ss: 0.914629, loss_d: 0.013023
0.6431 --- loss: 0.857827, loss_ss: 0.847344, loss_d: 0.010483
0.8039 --- loss: 1.264513, loss_ss: 1.195433, loss_d: 0.069080
0.9646 --- loss: 1.004274, loss_ss: 1.002424, loss_d: 0.001849
Epoch finished! Loss: 0.9907278610814002
Starting epoch 9/10.
0.0000 --- loss: 0.894811, loss_ss: 0.894328, loss_d: 0.000483
0.1608 --- loss: 0.959736, loss_ss: 0.958385, loss_d: 0.001351
0.3215 --- loss: 0.895322, loss_ss: 0.894851, loss_d: 0.000471
0.4823 --- loss: 0.850590, loss_ss: 0.843750, loss_d: 0.006840
0.6431 --- loss: 0.969746, loss_ss: 0.968087, loss_d: 0.001659
0.8039 --- loss: 0.971721, loss_ss: 0.964344, loss_d: 0.007378
0.9646 --- loss: 0.885628, loss_ss: 0.884796, loss_d: 0.000832
Epoch finished! Loss: 0.9156798047404135
Starting epoch 10/10.
0.0000 --- loss: 0.821832, loss_ss: 0.819733, loss_d: 0.002098
0.1608 --- loss: 0.843902, loss_ss: 0.829899, loss_d: 0.014003
0.3215 --- loss: 0.964671, loss_ss: 0.957176, loss_d: 0.007495
0.4823 --- loss: 0.768148, loss_ss: 0.765281, loss_d: 0.002868
0.6431 --- loss: 0.750333, loss_ss: 0.748584, loss_d: 0.001749
0.8039 --- loss: 0.820472, loss_ss: 0.817138, loss_d: 0.003334
0.9646 --- loss: 0.886541, loss_ss: 0.883525, loss_d: 0.003016
Epoch finished! Loss: 0.8766323751018893
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.684375
             precision    recall  f1-score   support

        0.0       0.33      0.43      0.37        67
        1.0       0.00      0.00      0.00        31
        2.0       0.86      0.71      0.78       468
        3.0       0.98      0.74      0.84       196
        4.0       0.45      0.76      0.56       198

avg / total       0.73      0.68      0.69       960
 


====== chp003-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  89.79  43.28   93.28  32.58     37.18
1  96.77   0.00  100.00   0.00      0.00
2  80.10  71.15   88.62  85.60     77.71
3  94.38  73.98   99.61  97.97     84.30
4  75.83  75.76   75.85  44.91     56.39
Total accuracy: 68.44%
Average sen: 52.83%
Average spec: 91.47%
Macro f1-score: 51.12%
Diagnosis acc on 60mins: 0.875
[0.991557   0.9952063  0.9663381  0.40412748 0.99787307 0.98446679
 0.79826337 0.99960655]
pred: 0.8921798318624496, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp003-nsrr

=== Test on chp004-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.269387, loss_ss: 1.610197, loss_d: 0.659190
0.1608 --- loss: 2.359610, loss_ss: 1.496117, loss_d: 0.863493
0.3215 --- loss: 2.344138, loss_ss: 1.588344, loss_d: 0.755794
0.4823 --- loss: 2.083529, loss_ss: 1.527012, loss_d: 0.556516
0.6431 --- loss: 1.944124, loss_ss: 1.548429, loss_d: 0.395694
0.8039 --- loss: 2.516834, loss_ss: 1.410827, loss_d: 1.106007
0.9646 --- loss: 2.083756, loss_ss: 1.500922, loss_d: 0.582834
Epoch finished! Loss: 2.203586264964073
Starting epoch 2/10.
0.0000 --- loss: 2.063661, loss_ss: 1.484966, loss_d: 0.578695
0.1608 --- loss: 1.724456, loss_ss: 1.416131, loss_d: 0.308324
0.3215 --- loss: 1.744158, loss_ss: 1.377290, loss_d: 0.366868
0.4823 --- loss: 1.728111, loss_ss: 1.380539, loss_d: 0.347571
0.6431 --- loss: 2.110507, loss_ss: 1.444249, loss_d: 0.666257
0.8039 --- loss: 1.996366, loss_ss: 1.362006, loss_d: 0.634359
0.9646 --- loss: 1.684523, loss_ss: 1.333363, loss_d: 0.351160
Epoch finished! Loss: 1.936081918977922
Starting epoch 3/10.
0.0000 --- loss: 1.608934, loss_ss: 1.300403, loss_d: 0.308530
0.1608 --- loss: 1.479570, loss_ss: 1.301754, loss_d: 0.177815
0.3215 --- loss: 1.291552, loss_ss: 1.192610, loss_d: 0.098942
0.4823 --- loss: 1.448700, loss_ss: 1.285608, loss_d: 0.163092
0.6431 --- loss: 1.371158, loss_ss: 1.246114, loss_d: 0.125044
0.8039 --- loss: 1.586648, loss_ss: 1.253570, loss_d: 0.333078
0.9646 --- loss: 1.545483, loss_ss: 1.165105, loss_d: 0.380378
Epoch finished! Loss: 1.6008493996435595
Starting epoch 4/10.
0.0000 --- loss: 1.526856, loss_ss: 1.319961, loss_d: 0.206895
0.1608 --- loss: 1.283557, loss_ss: 1.260184, loss_d: 0.023373
0.3215 --- loss: 1.447473, loss_ss: 1.097708, loss_d: 0.349764
0.4823 --- loss: 1.527848, loss_ss: 1.234258, loss_d: 0.293590
0.6431 --- loss: 1.313900, loss_ss: 1.077528, loss_d: 0.236371
0.8039 --- loss: 1.184742, loss_ss: 1.140189, loss_d: 0.044553
0.9646 --- loss: 1.119666, loss_ss: 1.088295, loss_d: 0.031372
Epoch finished! Loss: 1.342698787489245
Starting epoch 5/10.
0.0000 --- loss: 1.018176, loss_ss: 1.010299, loss_d: 0.007877
0.1608 --- loss: 1.140754, loss_ss: 1.127059, loss_d: 0.013695
0.3215 --- loss: 1.219390, loss_ss: 1.076696, loss_d: 0.142694
0.4823 --- loss: 1.110747, loss_ss: 1.012966, loss_d: 0.097781
0.6431 --- loss: 1.019754, loss_ss: 1.005674, loss_d: 0.014080
0.8039 --- loss: 1.319000, loss_ss: 1.231690, loss_d: 0.087310
0.9646 --- loss: 1.272357, loss_ss: 1.058042, loss_d: 0.214315
Epoch finished! Loss: 1.167261189991428
Starting epoch 6/10.
0.0000 --- loss: 1.103086, loss_ss: 1.099198, loss_d: 0.003887
0.1608 --- loss: 0.985378, loss_ss: 0.983454, loss_d: 0.001924
0.3215 --- loss: 1.040777, loss_ss: 1.040233, loss_d: 0.000544
0.4823 --- loss: 1.030966, loss_ss: 1.028152, loss_d: 0.002815
0.6431 --- loss: 0.947989, loss_ss: 0.944774, loss_d: 0.003215
0.8039 --- loss: 1.289401, loss_ss: 1.277133, loss_d: 0.012268
0.9646 --- loss: 1.056488, loss_ss: 1.052408, loss_d: 0.004080
Epoch finished! Loss: 1.0501112139994098
Starting epoch 7/10.
0.0000 --- loss: 0.993734, loss_ss: 0.993423, loss_d: 0.000311
0.1608 --- loss: 1.028325, loss_ss: 1.027972, loss_d: 0.000353
0.3215 --- loss: 1.029965, loss_ss: 1.021497, loss_d: 0.008468
0.4823 --- loss: 1.229952, loss_ss: 1.042470, loss_d: 0.187482
0.6431 --- loss: 0.882385, loss_ss: 0.873828, loss_d: 0.008557
0.8039 --- loss: 0.955481, loss_ss: 0.952294, loss_d: 0.003187
0.9646 --- loss: 1.050073, loss_ss: 1.044551, loss_d: 0.005523
Epoch finished! Loss: 1.0390911727182326
Starting epoch 8/10.
0.0000 --- loss: 1.017942, loss_ss: 1.010692, loss_d: 0.007250
0.1608 --- loss: 0.875648, loss_ss: 0.863421, loss_d: 0.012228
0.3215 --- loss: 1.087364, loss_ss: 0.948818, loss_d: 0.138545
0.4823 --- loss: 1.321494, loss_ss: 1.003374, loss_d: 0.318120
0.6431 --- loss: 0.940142, loss_ss: 0.879940, loss_d: 0.060202
0.8039 --- loss: 1.140362, loss_ss: 1.071536, loss_d: 0.068826
0.9646 --- loss: 1.094837, loss_ss: 0.915823, loss_d: 0.179014
Epoch finished! Loss: 1.0809059527612501
Starting epoch 9/10.
0.0000 --- loss: 0.848449, loss_ss: 0.843659, loss_d: 0.004790
0.1608 --- loss: 0.913427, loss_ss: 0.905735, loss_d: 0.007692
0.3215 --- loss: 0.885679, loss_ss: 0.861406, loss_d: 0.024273
0.4823 --- loss: 0.842008, loss_ss: 0.821731, loss_d: 0.020277
0.6431 --- loss: 0.984453, loss_ss: 0.970339, loss_d: 0.014113
0.8039 --- loss: 0.886371, loss_ss: 0.854043, loss_d: 0.032328
0.9646 --- loss: 0.828408, loss_ss: 0.772590, loss_d: 0.055819
Epoch finished! Loss: 1.02710215122469
Starting epoch 10/10.
0.0000 --- loss: 1.024103, loss_ss: 0.990120, loss_d: 0.033983
0.1608 --- loss: 0.978808, loss_ss: 0.847672, loss_d: 0.131136
0.3215 --- loss: 1.048559, loss_ss: 1.011974, loss_d: 0.036584
0.4823 --- loss: 0.878606, loss_ss: 0.868426, loss_d: 0.010180
0.6431 --- loss: 0.731684, loss_ss: 0.725640, loss_d: 0.006043
0.8039 --- loss: 1.034999, loss_ss: 0.921206, loss_d: 0.113793
0.9646 --- loss: 0.775880, loss_ss: 0.774830, loss_d: 0.001050
Epoch finished! Loss: 0.9288597039638027
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.64375
             precision    recall  f1-score   support

        0.0       0.61      0.68      0.64       135
        1.0       0.35      0.05      0.09       141
        2.0       0.59      0.92      0.72       354
        3.0       1.00      0.57      0.73       197
        4.0       0.65      0.60      0.62       133

avg / total       0.65      0.64      0.60       960
 


====== chp004-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  89.38  68.15   92.85   60.93     64.34
1  84.69   4.96   98.41   35.00      8.70
2  73.44  92.09   62.54   58.95     71.89
3  91.25  57.36  100.00  100.00     72.90
4  90.00  60.15   94.80   65.04     62.50
Total accuracy: 64.38%
Average sen: 56.54%
Average spec: 89.72%
Macro f1-score: 56.06%
Diagnosis acc on 60mins: 1.0
[0.98529643 0.99995148 0.98572171 0.99840349 0.74432421 0.99935967
 0.99777007 0.97990108]
pred: 0.9613410159945488, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp004-nsrr

=== Test on chp005-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.357805, loss_ss: 1.693031, loss_d: 0.664774
0.1613 --- loss: 2.295219, loss_ss: 1.556963, loss_d: 0.738256
0.3226 --- loss: 2.145270, loss_ss: 1.547487, loss_d: 0.597783
0.4839 --- loss: 2.177592, loss_ss: 1.548555, loss_d: 0.629037
0.6452 --- loss: 1.979263, loss_ss: 1.424818, loss_d: 0.554445
0.8065 --- loss: 1.947474, loss_ss: 1.473346, loss_d: 0.474128
0.9677 --- loss: 2.149580, loss_ss: 1.387068, loss_d: 0.762511
Epoch finished! Loss: 2.156268000602722
Starting epoch 2/10.
0.0000 --- loss: 2.023892, loss_ss: 1.386215, loss_d: 0.637677
0.1613 --- loss: 2.004804, loss_ss: 1.361492, loss_d: 0.643313
0.3226 --- loss: 1.680733, loss_ss: 1.364332, loss_d: 0.316401
0.4839 --- loss: 1.637336, loss_ss: 1.345728, loss_d: 0.291608
0.6452 --- loss: 1.839870, loss_ss: 1.343877, loss_d: 0.495993
0.8065 --- loss: 1.704174, loss_ss: 1.316900, loss_d: 0.387275
0.9677 --- loss: 2.222061, loss_ss: 1.306268, loss_d: 0.915793
Epoch finished! Loss: 1.8458090766531523
Starting epoch 3/10.
0.0000 --- loss: 1.565507, loss_ss: 1.342947, loss_d: 0.222561
0.1613 --- loss: 1.576155, loss_ss: 1.307369, loss_d: 0.268786
0.3226 --- loss: 1.857962, loss_ss: 1.221332, loss_d: 0.636630
0.4839 --- loss: 1.423742, loss_ss: 1.289419, loss_d: 0.134323
0.6452 --- loss: 1.846155, loss_ss: 1.249455, loss_d: 0.596699
0.8065 --- loss: 1.403002, loss_ss: 1.204050, loss_d: 0.198952
0.9677 --- loss: 1.576516, loss_ss: 1.293732, loss_d: 0.282783
Epoch finished! Loss: 1.5920984588685583
Starting epoch 4/10.
0.0000 --- loss: 1.389269, loss_ss: 1.249850, loss_d: 0.139419
0.1613 --- loss: 1.193633, loss_ss: 1.150533, loss_d: 0.043100
0.3226 --- loss: 1.160596, loss_ss: 1.115055, loss_d: 0.045541
0.4839 --- loss: 1.252182, loss_ss: 1.193576, loss_d: 0.058606
0.6452 --- loss: 1.266102, loss_ss: 1.150773, loss_d: 0.115329
0.8065 --- loss: 1.144617, loss_ss: 1.129429, loss_d: 0.015188
0.9677 --- loss: 1.185890, loss_ss: 1.167617, loss_d: 0.018273
Epoch finished! Loss: 1.3143407692674731
Starting epoch 5/10.
0.0000 --- loss: 1.070681, loss_ss: 1.065541, loss_d: 0.005140
0.1613 --- loss: 1.132327, loss_ss: 1.122313, loss_d: 0.010013
0.3226 --- loss: 1.084921, loss_ss: 1.069445, loss_d: 0.015476
0.4839 --- loss: 1.275437, loss_ss: 1.110675, loss_d: 0.164762
0.6452 --- loss: 1.091368, loss_ss: 1.087038, loss_d: 0.004330
0.8065 --- loss: 1.215231, loss_ss: 1.162971, loss_d: 0.052260
0.9677 --- loss: 1.293183, loss_ss: 1.265677, loss_d: 0.027507
Epoch finished! Loss: 1.193998604524331
Starting epoch 6/10.
0.0000 --- loss: 1.065202, loss_ss: 1.056246, loss_d: 0.008956
0.1613 --- loss: 1.101268, loss_ss: 1.097364, loss_d: 0.003904
0.3226 --- loss: 0.989245, loss_ss: 0.984834, loss_d: 0.004411
0.4839 --- loss: 1.281295, loss_ss: 1.032347, loss_d: 0.248948
0.6452 --- loss: 1.139589, loss_ss: 1.134241, loss_d: 0.005348
0.8065 --- loss: 1.112949, loss_ss: 1.111273, loss_d: 0.001676
0.9677 --- loss: 0.969644, loss_ss: 0.950476, loss_d: 0.019168
Epoch finished! Loss: 1.118959252951575
Starting epoch 7/10.
0.0000 --- loss: 1.386542, loss_ss: 1.052087, loss_d: 0.334454
0.1613 --- loss: 1.021374, loss_ss: 1.000664, loss_d: 0.020711
0.3226 --- loss: 1.074357, loss_ss: 1.065392, loss_d: 0.008965
0.4839 --- loss: 1.085062, loss_ss: 1.051008, loss_d: 0.034054
0.6452 --- loss: 0.953390, loss_ss: 0.950037, loss_d: 0.003352
0.8065 --- loss: 1.029480, loss_ss: 1.017311, loss_d: 0.012169
0.9677 --- loss: 1.361518, loss_ss: 1.037269, loss_d: 0.324248
Epoch finished! Loss: 1.1382135787948233
Starting epoch 8/10.
0.0000 --- loss: 0.931544, loss_ss: 0.929509, loss_d: 0.002035
0.1613 --- loss: 0.911767, loss_ss: 0.887841, loss_d: 0.023926
0.3226 --- loss: 0.943660, loss_ss: 0.937542, loss_d: 0.006118
0.4839 --- loss: 1.082674, loss_ss: 1.081054, loss_d: 0.001620
0.6452 --- loss: 1.024391, loss_ss: 0.932861, loss_d: 0.091530
0.8065 --- loss: 1.082124, loss_ss: 1.059596, loss_d: 0.022528
0.9677 --- loss: 0.989575, loss_ss: 0.987936, loss_d: 0.001640
Epoch finished! Loss: 1.0629378850342797
Starting epoch 9/10.
0.0000 --- loss: 0.944489, loss_ss: 0.936423, loss_d: 0.008066
0.1613 --- loss: 0.898950, loss_ss: 0.881281, loss_d: 0.017668
0.3226 --- loss: 0.894591, loss_ss: 0.893787, loss_d: 0.000805
0.4839 --- loss: 1.027214, loss_ss: 1.025511, loss_d: 0.001703
0.6452 --- loss: 0.920397, loss_ss: 0.919824, loss_d: 0.000572
0.8065 --- loss: 1.057189, loss_ss: 1.031456, loss_d: 0.025734
0.9677 --- loss: 1.047225, loss_ss: 1.038118, loss_d: 0.009107
Epoch finished! Loss: 0.9976912854147739
Starting epoch 10/10.
0.0000 --- loss: 0.907964, loss_ss: 0.900249, loss_d: 0.007715
0.1613 --- loss: 0.782874, loss_ss: 0.782639, loss_d: 0.000235
0.3226 --- loss: 0.855451, loss_ss: 0.850032, loss_d: 0.005419
0.4839 --- loss: 0.879764, loss_ss: 0.879609, loss_d: 0.000155
0.6452 --- loss: 0.922067, loss_ss: 0.921750, loss_d: 0.000318
0.8065 --- loss: 1.070570, loss_ss: 1.062628, loss_d: 0.007942
0.9677 --- loss: 1.196840, loss_ss: 1.190464, loss_d: 0.006375
Epoch finished! Loss: 0.979735517110981
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5383333333333333
             precision    recall  f1-score   support

        0.0       0.29      0.59      0.39        54
        1.0       0.35      0.85      0.49       218
        2.0       0.75      0.66      0.70       562
        3.0       1.00      0.12      0.21       136
        4.0       0.95      0.18      0.30       230

avg / total       0.72      0.54      0.52      1200
 


====== chp005-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  91.50  59.26   93.02   28.57     38.55
1  68.25  84.86   64.56   34.71     49.27
2  73.83  66.19   80.56   75.00     70.32
3  90.00  11.76  100.00  100.00     21.05
4  84.08  17.83   99.79   95.35     30.04
Total accuracy: 53.83%
Average sen: 47.98%
Average spec: 87.59%
Macro f1-score: 41.85%
Diagnosis acc on 60mins: 0.9
[0.99996996 0.83703172 0.2416794  0.99998224 0.99936491 0.99992454
 1.         0.99937099 0.96757853 0.99820554]
pred: 0.9043107837438583, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp005-nsrr

=== Test on chp006-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.482482, loss_ss: 1.813707, loss_d: 0.668775
0.1610 --- loss: 2.354775, loss_ss: 1.599970, loss_d: 0.754805
0.3221 --- loss: 1.857828, loss_ss: 1.558234, loss_d: 0.299594
0.4831 --- loss: 1.956943, loss_ss: 1.538751, loss_d: 0.418192
0.6441 --- loss: 2.263608, loss_ss: 1.520136, loss_d: 0.743472
0.8052 --- loss: 2.123246, loss_ss: 1.436291, loss_d: 0.686954
0.9662 --- loss: 1.957783, loss_ss: 1.418037, loss_d: 0.539747
Epoch finished! Loss: 2.1828591016031083
Starting epoch 2/10.
0.0000 --- loss: 1.813617, loss_ss: 1.368678, loss_d: 0.444939
0.1610 --- loss: 2.022091, loss_ss: 1.498921, loss_d: 0.523170
0.3221 --- loss: 1.918847, loss_ss: 1.328005, loss_d: 0.590842
0.4831 --- loss: 1.761427, loss_ss: 1.330910, loss_d: 0.430517
0.6441 --- loss: 1.870023, loss_ss: 1.404412, loss_d: 0.465611
0.8052 --- loss: 1.552965, loss_ss: 1.336724, loss_d: 0.216241
0.9662 --- loss: 1.748993, loss_ss: 1.282493, loss_d: 0.466500
Epoch finished! Loss: 1.8647662208926292
Starting epoch 3/10.
0.0000 --- loss: 1.723158, loss_ss: 1.376398, loss_d: 0.346760
0.1610 --- loss: 1.394454, loss_ss: 1.227061, loss_d: 0.167393
0.3221 --- loss: 1.359892, loss_ss: 1.198486, loss_d: 0.161406
0.4831 --- loss: 1.659055, loss_ss: 1.279996, loss_d: 0.379059
0.6441 --- loss: 1.475075, loss_ss: 1.288144, loss_d: 0.186932
0.8052 --- loss: 1.520243, loss_ss: 1.266820, loss_d: 0.253422
0.9662 --- loss: 1.343611, loss_ss: 1.118904, loss_d: 0.224707
Epoch finished! Loss: 1.6077903624503844
Starting epoch 4/10.
0.0000 --- loss: 1.347785, loss_ss: 1.151837, loss_d: 0.195949
0.1610 --- loss: 1.342977, loss_ss: 1.189765, loss_d: 0.153212
0.3221 --- loss: 1.384178, loss_ss: 1.143441, loss_d: 0.240736
0.4831 --- loss: 1.231607, loss_ss: 1.116483, loss_d: 0.115124
0.6441 --- loss: 1.305132, loss_ss: 1.288671, loss_d: 0.016461
0.8052 --- loss: 1.121054, loss_ss: 1.059788, loss_d: 0.061266
0.9662 --- loss: 1.227844, loss_ss: 1.199392, loss_d: 0.028453
Epoch finished! Loss: 1.3741089163287994
Starting epoch 5/10.
0.0000 --- loss: 1.252349, loss_ss: 1.223286, loss_d: 0.029063
0.1610 --- loss: 1.195234, loss_ss: 1.190715, loss_d: 0.004520
0.3221 --- loss: 1.054563, loss_ss: 0.981541, loss_d: 0.073022
0.4831 --- loss: 1.049261, loss_ss: 1.012061, loss_d: 0.037201
0.6441 --- loss: 1.179617, loss_ss: 1.159003, loss_d: 0.020613
0.8052 --- loss: 1.148240, loss_ss: 1.109818, loss_d: 0.038421
0.9662 --- loss: 1.072184, loss_ss: 1.021459, loss_d: 0.050725
Epoch finished! Loss: 1.1485053339312155
Starting epoch 6/10.
0.0000 --- loss: 1.120915, loss_ss: 1.088427, loss_d: 0.032488
0.1610 --- loss: 1.038610, loss_ss: 0.904434, loss_d: 0.134176
0.3221 --- loss: 1.174801, loss_ss: 1.159029, loss_d: 0.015771
0.4831 --- loss: 1.087883, loss_ss: 1.042385, loss_d: 0.045497
0.6441 --- loss: 0.939166, loss_ss: 0.937883, loss_d: 0.001283
0.8052 --- loss: 0.996711, loss_ss: 0.990752, loss_d: 0.005960
0.9662 --- loss: 0.992237, loss_ss: 0.987461, loss_d: 0.004776
Epoch finished! Loss: 1.0948202581174913
Starting epoch 7/10.
0.0000 --- loss: 1.395253, loss_ss: 1.129478, loss_d: 0.265775
0.1610 --- loss: 1.002180, loss_ss: 0.998959, loss_d: 0.003220
0.3221 --- loss: 0.952605, loss_ss: 0.948184, loss_d: 0.004421
0.4831 --- loss: 1.138813, loss_ss: 0.973775, loss_d: 0.165038
0.6441 --- loss: 0.985803, loss_ss: 0.983924, loss_d: 0.001880
0.8052 --- loss: 0.972423, loss_ss: 0.965095, loss_d: 0.007328
0.9662 --- loss: 1.003976, loss_ss: 1.002293, loss_d: 0.001683
Epoch finished! Loss: 1.062246270718113
Starting epoch 8/10.
0.0000 --- loss: 0.902534, loss_ss: 0.898894, loss_d: 0.003640
0.1610 --- loss: 1.079798, loss_ss: 1.077023, loss_d: 0.002775
0.3221 --- loss: 1.349010, loss_ss: 1.245171, loss_d: 0.103839
0.4831 --- loss: 0.813408, loss_ss: 0.812243, loss_d: 0.001165
0.6441 --- loss: 0.894083, loss_ss: 0.883637, loss_d: 0.010446
0.8052 --- loss: 1.193777, loss_ss: 1.157734, loss_d: 0.036043
0.9662 --- loss: 0.963258, loss_ss: 0.953363, loss_d: 0.009895
Epoch finished! Loss: 1.0216288441611874
Starting epoch 9/10.
0.0000 --- loss: 1.031063, loss_ss: 1.023093, loss_d: 0.007970
0.1610 --- loss: 0.967876, loss_ss: 0.934488, loss_d: 0.033387
0.3221 --- loss: 0.905244, loss_ss: 0.899453, loss_d: 0.005791
0.4831 --- loss: 1.005621, loss_ss: 1.003069, loss_d: 0.002552
0.6441 --- loss: 0.797005, loss_ss: 0.795645, loss_d: 0.001361
0.8052 --- loss: 0.815527, loss_ss: 0.814965, loss_d: 0.000562
0.9662 --- loss: 1.011364, loss_ss: 1.010804, loss_d: 0.000560
Epoch finished! Loss: 0.9545879210195234
Starting epoch 10/10.
0.0000 --- loss: 0.768377, loss_ss: 0.767366, loss_d: 0.001011
0.1610 --- loss: 0.846509, loss_ss: 0.844617, loss_d: 0.001892
0.3221 --- loss: 0.892221, loss_ss: 0.888696, loss_d: 0.003525
0.4831 --- loss: 1.132745, loss_ss: 0.833025, loss_d: 0.299720
0.6441 --- loss: 0.920609, loss_ss: 0.881207, loss_d: 0.039401
0.8052 --- loss: 0.834726, loss_ss: 0.833791, loss_d: 0.000935
0.9662 --- loss: 0.891080, loss_ss: 0.852453, loss_d: 0.038627
Epoch finished! Loss: 0.9271415712371949
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.512962962962963
             precision    recall  f1-score   support

        0.0       0.55      0.53      0.54       120
        1.0       0.29      0.02      0.03       322
        2.0       0.70      0.67      0.68       274
        3.0       1.00      0.74      0.85       224
        4.0       0.26      0.98      0.42       140

avg / total       0.57      0.51      0.47      1080
 


====== chp006-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  89.91  52.50   94.58   54.78     53.62
1  69.35   1.86   98.02   28.57      3.50
2  84.35  66.79   90.32   70.11     68.41
3  94.54  73.66  100.00  100.00     84.83
4  64.44  97.86   59.47   26.45     41.64
Total accuracy: 51.30%
Average sen: 58.53%
Average spec: 88.48%
Macro f1-score: 50.40%
Diagnosis acc on 60mins: 1.0
[0.99634981 0.99994338 0.99998009 0.90692556 0.99764699 0.99999833
 0.99999309 0.99999869 0.99250823]
pred: 0.9881493515438504, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp006-nsrr

=== Test on chp007-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.427923, loss_ss: 1.746724, loss_d: 0.681199
0.1610 --- loss: 2.339607, loss_ss: 1.487586, loss_d: 0.852022
0.3221 --- loss: 2.199222, loss_ss: 1.517523, loss_d: 0.681699
0.4831 --- loss: 1.985802, loss_ss: 1.462885, loss_d: 0.522917
0.6441 --- loss: 2.075402, loss_ss: 1.466674, loss_d: 0.608728
0.8052 --- loss: 2.256116, loss_ss: 1.440463, loss_d: 0.815653
0.9662 --- loss: 2.010747, loss_ss: 1.571199, loss_d: 0.439548
Epoch finished! Loss: 2.16489714384079
Starting epoch 2/10.
0.0000 --- loss: 1.938648, loss_ss: 1.426109, loss_d: 0.512539
0.1610 --- loss: 1.714068, loss_ss: 1.415148, loss_d: 0.298921
0.3221 --- loss: 1.868886, loss_ss: 1.378612, loss_d: 0.490274
0.4831 --- loss: 2.014308, loss_ss: 1.446299, loss_d: 0.568009
0.6441 --- loss: 2.145078, loss_ss: 1.401177, loss_d: 0.743902
0.8052 --- loss: 1.972750, loss_ss: 1.356809, loss_d: 0.615941
0.9662 --- loss: 1.580024, loss_ss: 1.355850, loss_d: 0.224174
Epoch finished! Loss: 1.9844153792627397
Starting epoch 3/10.
0.0000 --- loss: 2.400377, loss_ss: 1.479731, loss_d: 0.920646
0.1610 --- loss: 1.847354, loss_ss: 1.438062, loss_d: 0.409292
0.3221 --- loss: 1.728639, loss_ss: 1.415360, loss_d: 0.313278
0.4831 --- loss: 1.634017, loss_ss: 1.270509, loss_d: 0.363508
0.6441 --- loss: 2.038173, loss_ss: 1.329643, loss_d: 0.708531
0.8052 --- loss: 1.787557, loss_ss: 1.312289, loss_d: 0.475268
0.9662 --- loss: 1.692427, loss_ss: 1.348034, loss_d: 0.344393
Epoch finished! Loss: 1.7732513143170265
Starting epoch 4/10.
0.0000 --- loss: 1.384649, loss_ss: 1.265687, loss_d: 0.118963
0.1610 --- loss: 1.463601, loss_ss: 1.303207, loss_d: 0.160394
0.3221 --- loss: 1.310214, loss_ss: 1.248445, loss_d: 0.061769
0.4831 --- loss: 1.582997, loss_ss: 1.410908, loss_d: 0.172089
0.6441 --- loss: 1.446432, loss_ss: 1.279025, loss_d: 0.167406
0.8052 --- loss: 1.408316, loss_ss: 1.248527, loss_d: 0.159788
0.9662 --- loss: 1.398938, loss_ss: 1.336956, loss_d: 0.061982
Epoch finished! Loss: 1.5061099010129129
Starting epoch 5/10.
0.0000 --- loss: 1.484431, loss_ss: 1.231217, loss_d: 0.253215
0.1610 --- loss: 1.250075, loss_ss: 1.189898, loss_d: 0.060176
0.3221 --- loss: 1.494934, loss_ss: 1.246139, loss_d: 0.248795
0.4831 --- loss: 1.296677, loss_ss: 1.182527, loss_d: 0.114150
0.6441 --- loss: 1.488401, loss_ss: 1.179613, loss_d: 0.308788
0.8052 --- loss: 1.244729, loss_ss: 1.229641, loss_d: 0.015088
0.9662 --- loss: 1.256762, loss_ss: 1.146878, loss_d: 0.109885
Epoch finished! Loss: 1.3479016154043135
Starting epoch 6/10.
0.0000 --- loss: 1.480298, loss_ss: 1.290137, loss_d: 0.190161
0.1610 --- loss: 1.136500, loss_ss: 1.118265, loss_d: 0.018235
0.3221 --- loss: 1.291589, loss_ss: 1.274129, loss_d: 0.017461
0.4831 --- loss: 1.280678, loss_ss: 1.272881, loss_d: 0.007797
0.6441 --- loss: 1.213669, loss_ss: 1.185032, loss_d: 0.028637
0.8052 --- loss: 1.067752, loss_ss: 0.985973, loss_d: 0.081779
0.9662 --- loss: 1.186024, loss_ss: 1.164197, loss_d: 0.021827
Epoch finished! Loss: 1.296496497046563
Starting epoch 7/10.
0.0000 --- loss: 1.081188, loss_ss: 1.058407, loss_d: 0.022781
0.1610 --- loss: 1.033204, loss_ss: 1.031109, loss_d: 0.002094
0.3221 --- loss: 0.997406, loss_ss: 0.989936, loss_d: 0.007470
0.4831 --- loss: 1.104106, loss_ss: 1.098757, loss_d: 0.005349
0.6441 --- loss: 1.062885, loss_ss: 1.037338, loss_d: 0.025546
0.8052 --- loss: 1.111735, loss_ss: 1.070922, loss_d: 0.040813
0.9662 --- loss: 1.032330, loss_ss: 1.029109, loss_d: 0.003220
Epoch finished! Loss: 1.1687630886031735
Starting epoch 8/10.
0.0000 --- loss: 1.112915, loss_ss: 1.112134, loss_d: 0.000781
0.1610 --- loss: 1.146708, loss_ss: 1.106977, loss_d: 0.039731
0.3221 --- loss: 1.358143, loss_ss: 1.127504, loss_d: 0.230639
0.4831 --- loss: 1.092609, loss_ss: 1.089456, loss_d: 0.003153
0.6441 --- loss: 0.980196, loss_ss: 0.973776, loss_d: 0.006421
0.8052 --- loss: 1.123873, loss_ss: 1.123143, loss_d: 0.000731
0.9662 --- loss: 1.087442, loss_ss: 1.083925, loss_d: 0.003517
Epoch finished! Loss: 1.1377088129520416
Starting epoch 9/10.
0.0000 --- loss: 1.181723, loss_ss: 1.180221, loss_d: 0.001501
0.1610 --- loss: 1.308326, loss_ss: 1.297521, loss_d: 0.010804
0.3221 --- loss: 1.162132, loss_ss: 1.145961, loss_d: 0.016171
0.4831 --- loss: 1.173128, loss_ss: 1.172388, loss_d: 0.000740
0.6441 --- loss: 0.875596, loss_ss: 0.870471, loss_d: 0.005125
0.8052 --- loss: 0.922323, loss_ss: 0.921820, loss_d: 0.000503
0.9662 --- loss: 1.037232, loss_ss: 1.036273, loss_d: 0.000958
Epoch finished! Loss: 1.1042830963288583
Starting epoch 10/10.
0.0000 --- loss: 1.102292, loss_ss: 1.100726, loss_d: 0.001566
0.1610 --- loss: 1.021212, loss_ss: 1.019816, loss_d: 0.001396
0.3221 --- loss: 0.982590, loss_ss: 0.967584, loss_d: 0.015006
0.4831 --- loss: 0.960256, loss_ss: 0.959865, loss_d: 0.000391
0.6441 --- loss: 1.011648, loss_ss: 0.991154, loss_d: 0.020494
0.8052 --- loss: 1.024230, loss_ss: 1.024206, loss_d: 0.000024
0.9662 --- loss: 0.947657, loss_ss: 0.937609, loss_d: 0.010048
Epoch finished! Loss: 1.0449114403417032
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5972222222222222
             precision    recall  f1-score   support

        0.0       0.72      0.70      0.71       166
        1.0       0.10      0.55      0.17        58
        2.0       0.80      0.52      0.63       369
        3.0       1.00      0.70      0.83       135
        4.0       0.80      0.60      0.68       352

avg / total       0.77      0.60      0.66      1080
 


====== chp007-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  91.20  69.88   95.08   72.05     70.95
1  70.83  55.17   71.72    9.97     16.89
2  79.07  52.03   93.11   79.67     62.95
3  96.30  70.37  100.00  100.00     82.61
4  82.04  59.66   92.86   80.15     68.40
Total accuracy: 59.72%
Average sen: 61.42%
Average spec: 90.55%
Macro f1-score: 60.36%
Diagnosis acc on 60mins: 1.0
[0.9999969  0.99999976 0.99999809 0.99992037 0.99988008 0.99950445
 0.99991286 0.9992637  0.9513917 ]
pred: 0.9944297671318054, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp007-nsrr

=== Test on chp008-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.626704, loss_ss: 1.908602, loss_d: 0.718102
0.1605 --- loss: 2.331693, loss_ss: 1.768331, loss_d: 0.563362
0.3210 --- loss: 2.143165, loss_ss: 1.525530, loss_d: 0.617634
0.4815 --- loss: 2.125529, loss_ss: 1.675200, loss_d: 0.450328
0.6421 --- loss: 2.122729, loss_ss: 1.610374, loss_d: 0.512355
0.8026 --- loss: 2.074305, loss_ss: 1.487499, loss_d: 0.586806
0.9631 --- loss: 1.855895, loss_ss: 1.508201, loss_d: 0.347694
Epoch finished! Loss: 2.290054888494553
Starting epoch 2/10.
0.0000 --- loss: 1.997583, loss_ss: 1.624337, loss_d: 0.373246
0.1605 --- loss: 2.065038, loss_ss: 1.573663, loss_d: 0.491376
0.3210 --- loss: 1.985168, loss_ss: 1.495764, loss_d: 0.489404
0.4815 --- loss: 1.824295, loss_ss: 1.510113, loss_d: 0.314181
0.6421 --- loss: 1.772181, loss_ss: 1.366354, loss_d: 0.405827
0.8026 --- loss: 1.693437, loss_ss: 1.447648, loss_d: 0.245789
0.9631 --- loss: 1.831479, loss_ss: 1.345518, loss_d: 0.485961
Epoch finished! Loss: 1.9728913634054122
Starting epoch 3/10.
0.0000 --- loss: 1.872383, loss_ss: 1.374417, loss_d: 0.497966
0.1605 --- loss: 1.832797, loss_ss: 1.431855, loss_d: 0.400942
0.3210 --- loss: 1.619675, loss_ss: 1.255408, loss_d: 0.364266
0.4815 --- loss: 1.736372, loss_ss: 1.367146, loss_d: 0.369226
0.6421 --- loss: 1.576802, loss_ss: 1.377008, loss_d: 0.199794
0.8026 --- loss: 1.365370, loss_ss: 1.292330, loss_d: 0.073040
0.9631 --- loss: 1.413874, loss_ss: 1.235339, loss_d: 0.178535
Epoch finished! Loss: 1.6984035757280165
Starting epoch 4/10.
0.0000 --- loss: 1.349971, loss_ss: 1.306151, loss_d: 0.043820
0.1605 --- loss: 1.604375, loss_ss: 1.259834, loss_d: 0.344542
0.3210 --- loss: 1.468223, loss_ss: 1.191768, loss_d: 0.276455
0.4815 --- loss: 1.230311, loss_ss: 1.102969, loss_d: 0.127342
0.6421 --- loss: 1.453834, loss_ss: 1.246451, loss_d: 0.207383
0.8026 --- loss: 1.298150, loss_ss: 1.058373, loss_d: 0.239777
0.9631 --- loss: 1.289166, loss_ss: 1.122207, loss_d: 0.166959
Epoch finished! Loss: 1.4503079364376683
Starting epoch 5/10.
0.0000 --- loss: 1.144245, loss_ss: 1.116707, loss_d: 0.027538
0.1605 --- loss: 1.238709, loss_ss: 1.142280, loss_d: 0.096429
0.3210 --- loss: 1.263285, loss_ss: 1.048813, loss_d: 0.214473
0.4815 --- loss: 1.209934, loss_ss: 1.156960, loss_d: 0.052973
0.6421 --- loss: 1.211205, loss_ss: 1.053838, loss_d: 0.157367
0.8026 --- loss: 1.023096, loss_ss: 1.013778, loss_d: 0.009318
0.9631 --- loss: 1.168871, loss_ss: 1.144350, loss_d: 0.024521
Epoch finished! Loss: 1.216050757515815
Starting epoch 6/10.
0.0000 --- loss: 1.039752, loss_ss: 0.966529, loss_d: 0.073224
0.1605 --- loss: 1.062936, loss_ss: 1.016921, loss_d: 0.046015
0.3210 --- loss: 1.106978, loss_ss: 1.061988, loss_d: 0.044989
0.4815 --- loss: 1.177068, loss_ss: 1.073040, loss_d: 0.104028
0.6421 --- loss: 1.142660, loss_ss: 1.078795, loss_d: 0.063866
0.8026 --- loss: 1.030387, loss_ss: 1.007640, loss_d: 0.022747
0.9631 --- loss: 0.975633, loss_ss: 0.973620, loss_d: 0.002013
Epoch finished! Loss: 1.0992104420738835
Starting epoch 7/10.
0.0000 --- loss: 1.065473, loss_ss: 1.063796, loss_d: 0.001677
0.1605 --- loss: 1.081556, loss_ss: 1.034614, loss_d: 0.046942
0.3210 --- loss: 0.919648, loss_ss: 0.916095, loss_d: 0.003553
0.4815 --- loss: 0.932538, loss_ss: 0.930638, loss_d: 0.001900
0.6421 --- loss: 1.000897, loss_ss: 0.970438, loss_d: 0.030459
0.8026 --- loss: 0.989130, loss_ss: 0.942031, loss_d: 0.047099
0.9631 --- loss: 0.878726, loss_ss: 0.877936, loss_d: 0.000790
Epoch finished! Loss: 1.0186487263248813
Starting epoch 8/10.
0.0000 --- loss: 1.127219, loss_ss: 1.126323, loss_d: 0.000896
0.1605 --- loss: 1.230814, loss_ss: 1.166678, loss_d: 0.064136
0.3210 --- loss: 0.975761, loss_ss: 0.917039, loss_d: 0.058722
0.4815 --- loss: 0.955404, loss_ss: 0.953359, loss_d: 0.002044
0.6421 --- loss: 0.847052, loss_ss: 0.846722, loss_d: 0.000330
0.8026 --- loss: 1.160436, loss_ss: 0.959561, loss_d: 0.200875
0.9631 --- loss: 1.724143, loss_ss: 0.929108, loss_d: 0.795035
Epoch finished! Loss: 1.0255744313040087
Starting epoch 9/10.
0.0000 --- loss: 1.257440, loss_ss: 1.097265, loss_d: 0.160175
0.1605 --- loss: 0.913131, loss_ss: 0.911153, loss_d: 0.001978
0.3210 --- loss: 1.154570, loss_ss: 1.119316, loss_d: 0.035254
0.4815 --- loss: 0.945762, loss_ss: 0.939046, loss_d: 0.006716
0.6421 --- loss: 1.388301, loss_ss: 0.967411, loss_d: 0.420890
0.8026 --- loss: 1.228642, loss_ss: 1.186088, loss_d: 0.042554
0.9631 --- loss: 0.865675, loss_ss: 0.861510, loss_d: 0.004164
Epoch finished! Loss: 1.0160908429853377
Starting epoch 10/10.
0.0000 --- loss: 0.893169, loss_ss: 0.854583, loss_d: 0.038586
0.1605 --- loss: 1.326148, loss_ss: 1.252673, loss_d: 0.073475
0.3210 --- loss: 1.135311, loss_ss: 0.826452, loss_d: 0.308859
0.4815 --- loss: 0.877735, loss_ss: 0.817913, loss_d: 0.059822
0.6421 --- loss: 1.059034, loss_ss: 0.808815, loss_d: 0.250219
0.8026 --- loss: 0.983627, loss_ss: 0.933065, loss_d: 0.050562
0.9631 --- loss: 0.869437, loss_ss: 0.861912, loss_d: 0.007525
Epoch finished! Loss: 0.9813850887360112
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6857142857142857
             precision    recall  f1-score   support

        0.0       0.36      0.89      0.51        56
        1.0       0.00      0.00      0.00        35
        2.0       0.78      0.59      0.67       365
        3.0       0.96      0.76      0.85       263
        4.0       0.52      0.93      0.66       121

avg / total       0.74      0.69      0.69       840
 


====== chp008-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  88.57  89.29   88.52  35.71     51.02
1  95.83   0.00  100.00   0.00      0.00
2  75.00  58.90   87.37  78.18     67.19
3  91.31  75.67   98.44  95.67     84.50
4  86.43  92.56   85.40  51.61     66.27
Total accuracy: 68.57%
Average sen: 63.28%
Average spec: 91.95%
Macro f1-score: 53.80%
Diagnosis acc on 60mins: 1.0
[0.99984026 0.99995327 0.99999976 0.99999964 0.99863106 0.99999988
 0.99999678]
pred: 0.9997743793896267, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp008-nsrr

=== Test on chp009-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.468956, loss_ss: 1.753197, loss_d: 0.715759
0.1608 --- loss: 1.984737, loss_ss: 1.475652, loss_d: 0.509085
0.3215 --- loss: 1.846672, loss_ss: 1.465938, loss_d: 0.380733
0.4823 --- loss: 1.981671, loss_ss: 1.394761, loss_d: 0.586910
0.6431 --- loss: 2.390955, loss_ss: 1.414963, loss_d: 0.975992
0.8039 --- loss: 1.702886, loss_ss: 1.344601, loss_d: 0.358285
0.9646 --- loss: 2.150105, loss_ss: 1.372863, loss_d: 0.777242
Epoch finished! Loss: 2.120240646023904
Starting epoch 2/10.
0.0000 --- loss: 1.652492, loss_ss: 1.337352, loss_d: 0.315139
0.1608 --- loss: 1.880177, loss_ss: 1.369537, loss_d: 0.510640
0.3215 --- loss: 1.851615, loss_ss: 1.313329, loss_d: 0.538285
0.4823 --- loss: 1.914631, loss_ss: 1.262682, loss_d: 0.651949
0.6431 --- loss: 2.017167, loss_ss: 1.266964, loss_d: 0.750203
0.8039 --- loss: 1.645211, loss_ss: 1.264954, loss_d: 0.380257
0.9646 --- loss: 1.682668, loss_ss: 1.271537, loss_d: 0.411131
Epoch finished! Loss: 1.8187567034075338
Starting epoch 3/10.
0.0000 --- loss: 1.708945, loss_ss: 1.375443, loss_d: 0.333502
0.1608 --- loss: 1.663298, loss_ss: 1.264401, loss_d: 0.398897
0.3215 --- loss: 1.398878, loss_ss: 1.150120, loss_d: 0.248758
0.4823 --- loss: 1.278081, loss_ss: 1.138300, loss_d: 0.139782
0.6431 --- loss: 1.469008, loss_ss: 1.267035, loss_d: 0.201973
0.8039 --- loss: 1.387914, loss_ss: 1.121138, loss_d: 0.266776
0.9646 --- loss: 1.483605, loss_ss: 1.178133, loss_d: 0.305472
Epoch finished! Loss: 1.5503501257588785
Starting epoch 4/10.
0.0000 --- loss: 1.262343, loss_ss: 1.159905, loss_d: 0.102438
0.1608 --- loss: 1.306498, loss_ss: 1.169357, loss_d: 0.137141
0.3215 --- loss: 1.335023, loss_ss: 1.182906, loss_d: 0.152117
0.4823 --- loss: 1.240469, loss_ss: 1.145554, loss_d: 0.094915
0.6431 --- loss: 1.242380, loss_ss: 1.083320, loss_d: 0.159060
0.8039 --- loss: 1.266002, loss_ss: 1.152356, loss_d: 0.113646
0.9646 --- loss: 1.182683, loss_ss: 1.134299, loss_d: 0.048384
Epoch finished! Loss: 1.3087203214245458
Starting epoch 5/10.
0.0000 --- loss: 1.109190, loss_ss: 1.100040, loss_d: 0.009150
0.1608 --- loss: 1.172546, loss_ss: 1.099857, loss_d: 0.072689
0.3215 --- loss: 1.235485, loss_ss: 1.152114, loss_d: 0.083372
0.4823 --- loss: 1.388164, loss_ss: 0.954674, loss_d: 0.433490
0.6431 --- loss: 1.170856, loss_ss: 1.090832, loss_d: 0.080024
0.8039 --- loss: 1.138035, loss_ss: 0.947386, loss_d: 0.190648
0.9646 --- loss: 1.395671, loss_ss: 1.013488, loss_d: 0.382182
Epoch finished! Loss: 1.2012741709909132
Starting epoch 6/10.
0.0000 --- loss: 1.132882, loss_ss: 1.116271, loss_d: 0.016612
0.1608 --- loss: 1.142205, loss_ss: 1.129573, loss_d: 0.012632
0.3215 --- loss: 1.308869, loss_ss: 0.896906, loss_d: 0.411963
0.4823 --- loss: 0.931625, loss_ss: 0.926650, loss_d: 0.004975
0.6431 --- loss: 0.933637, loss_ss: 0.895151, loss_d: 0.038486
0.8039 --- loss: 0.847646, loss_ss: 0.815589, loss_d: 0.032057
0.9646 --- loss: 1.215103, loss_ss: 1.202964, loss_d: 0.012139
Epoch finished! Loss: 1.1085496333337599
Starting epoch 7/10.
0.0000 --- loss: 1.065220, loss_ss: 1.061809, loss_d: 0.003410
0.1608 --- loss: 1.188729, loss_ss: 1.105030, loss_d: 0.083699
0.3215 --- loss: 1.210160, loss_ss: 1.140279, loss_d: 0.069882
0.4823 --- loss: 1.368388, loss_ss: 0.965588, loss_d: 0.402800
0.6431 --- loss: 1.047367, loss_ss: 1.035968, loss_d: 0.011399
0.8039 --- loss: 0.900758, loss_ss: 0.896152, loss_d: 0.004606
0.9646 --- loss: 1.091991, loss_ss: 0.958889, loss_d: 0.133102
Epoch finished! Loss: 1.0476842820644379
Starting epoch 8/10.
0.0000 --- loss: 0.840130, loss_ss: 0.836838, loss_d: 0.003292
0.1608 --- loss: 1.051836, loss_ss: 1.049636, loss_d: 0.002201
0.3215 --- loss: 0.911961, loss_ss: 0.907032, loss_d: 0.004928
0.4823 --- loss: 0.878060, loss_ss: 0.877398, loss_d: 0.000662
0.6431 --- loss: 0.904766, loss_ss: 0.899542, loss_d: 0.005224
0.8039 --- loss: 0.854091, loss_ss: 0.841522, loss_d: 0.012569
0.9646 --- loss: 0.950565, loss_ss: 0.940020, loss_d: 0.010546
Epoch finished! Loss: 0.951823067280554
Starting epoch 9/10.
0.0000 --- loss: 0.803944, loss_ss: 0.796721, loss_d: 0.007223
0.1608 --- loss: 0.878483, loss_ss: 0.876914, loss_d: 0.001569
0.3215 --- loss: 1.091337, loss_ss: 1.086672, loss_d: 0.004665
0.4823 --- loss: 1.013890, loss_ss: 1.006977, loss_d: 0.006913
0.6431 --- loss: 0.838010, loss_ss: 0.837261, loss_d: 0.000749
0.8039 --- loss: 0.824228, loss_ss: 0.822045, loss_d: 0.002183
0.9646 --- loss: 0.994335, loss_ss: 0.991438, loss_d: 0.002897
Epoch finished! Loss: 0.9125160171139625
Starting epoch 10/10.
0.0000 --- loss: 0.710444, loss_ss: 0.709447, loss_d: 0.000997
0.1608 --- loss: 0.842975, loss_ss: 0.831447, loss_d: 0.011528
0.3215 --- loss: 1.203992, loss_ss: 1.203152, loss_d: 0.000840
0.4823 --- loss: 1.010931, loss_ss: 1.008613, loss_d: 0.002318
0.6431 --- loss: 0.898624, loss_ss: 0.898054, loss_d: 0.000570
0.8039 --- loss: 0.843212, loss_ss: 0.842498, loss_d: 0.000714
0.9646 --- loss: 1.029384, loss_ss: 1.026300, loss_d: 0.003084
Epoch finished! Loss: 0.9228730567039982
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6770833333333334
             precision    recall  f1-score   support

        0.0       0.85      0.60      0.71        96
        1.0       0.24      0.51      0.33       105
        2.0       0.87      0.46      0.61       340
        3.0       1.00      0.90      0.95       192
        4.0       0.67      0.92      0.77       227

avg / total       0.78      0.68      0.69       960
 


====== chp009-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  95.00  60.42   98.84   85.29     70.73
1  76.77  51.43   79.88   23.89     32.63
2  78.54  46.47   96.13   86.81     60.54
3  97.92  89.58  100.00  100.00     94.51
4  87.19  91.63   85.81   66.67     77.18
Total accuracy: 67.71%
Average sen: 67.91%
Average spec: 92.13%
Macro f1-score: 67.12%
Diagnosis acc on 60mins: 1.0
[0.99999928 0.99999726 0.99998891 0.99999821 0.99999976 0.99999809
 0.99999988 0.99929965]
pred: 0.9999101310968399, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp009-nsrr

=== Test on chp010-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.495113, loss_ss: 1.772262, loss_d: 0.722852
0.1608 --- loss: 2.382437, loss_ss: 1.563933, loss_d: 0.818503
0.3215 --- loss: 2.359516, loss_ss: 1.487904, loss_d: 0.871612
0.4823 --- loss: 1.985044, loss_ss: 1.477164, loss_d: 0.507881
0.6431 --- loss: 2.341939, loss_ss: 1.379738, loss_d: 0.962202
0.8039 --- loss: 1.975642, loss_ss: 1.409148, loss_d: 0.566493
0.9646 --- loss: 2.109823, loss_ss: 1.421750, loss_d: 0.688072
Epoch finished! Loss: 2.1173926611100473
Starting epoch 2/10.
0.0000 --- loss: 1.786561, loss_ss: 1.297304, loss_d: 0.489257
0.1608 --- loss: 1.759821, loss_ss: 1.270261, loss_d: 0.489560
0.3215 --- loss: 1.610402, loss_ss: 1.400487, loss_d: 0.209915
0.4823 --- loss: 1.688965, loss_ss: 1.272572, loss_d: 0.416393
0.6431 --- loss: 1.560080, loss_ss: 1.215675, loss_d: 0.344406
0.8039 --- loss: 1.761971, loss_ss: 1.180869, loss_d: 0.581102
0.9646 --- loss: 1.774115, loss_ss: 1.239565, loss_d: 0.534550
Epoch finished! Loss: 1.8236043510898468
Starting epoch 3/10.
0.0000 --- loss: 1.608160, loss_ss: 1.243082, loss_d: 0.365078
0.1608 --- loss: 1.738212, loss_ss: 1.317440, loss_d: 0.420772
0.3215 --- loss: 1.817065, loss_ss: 1.189309, loss_d: 0.627756
0.4823 --- loss: 1.790991, loss_ss: 1.153596, loss_d: 0.637395
0.6431 --- loss: 1.483846, loss_ss: 1.250799, loss_d: 0.233047
0.8039 --- loss: 1.387720, loss_ss: 1.257664, loss_d: 0.130056
0.9646 --- loss: 1.547880, loss_ss: 1.116034, loss_d: 0.431846
Epoch finished! Loss: 1.6106739678690511
Starting epoch 4/10.
0.0000 --- loss: 1.340376, loss_ss: 1.145880, loss_d: 0.194496
0.1608 --- loss: 1.175376, loss_ss: 1.069476, loss_d: 0.105900
0.3215 --- loss: 1.162301, loss_ss: 1.133407, loss_d: 0.028894
0.4823 --- loss: 1.105483, loss_ss: 0.991993, loss_d: 0.113490
0.6431 --- loss: 1.116774, loss_ss: 1.088122, loss_d: 0.028652
0.8039 --- loss: 1.605082, loss_ss: 1.010206, loss_d: 0.594876
0.9646 --- loss: 1.280977, loss_ss: 1.155852, loss_d: 0.125125
Epoch finished! Loss: 1.309783753848845
Starting epoch 5/10.
0.0000 --- loss: 1.169268, loss_ss: 1.103495, loss_d: 0.065773
0.1608 --- loss: 1.083513, loss_ss: 1.068633, loss_d: 0.014880
0.3215 --- loss: 1.488073, loss_ss: 0.945350, loss_d: 0.542723
0.4823 --- loss: 1.162418, loss_ss: 1.120791, loss_d: 0.041627
0.6431 --- loss: 1.284944, loss_ss: 1.192424, loss_d: 0.092520
0.8039 --- loss: 1.336986, loss_ss: 1.284104, loss_d: 0.052882
0.9646 --- loss: 1.054723, loss_ss: 1.032483, loss_d: 0.022240
Epoch finished! Loss: 1.2112528499095672
Starting epoch 6/10.
0.0000 --- loss: 1.006659, loss_ss: 0.992604, loss_d: 0.014055
0.1608 --- loss: 1.042885, loss_ss: 1.037326, loss_d: 0.005559
0.3215 --- loss: 1.040904, loss_ss: 0.917833, loss_d: 0.123071
0.4823 --- loss: 1.043086, loss_ss: 1.025478, loss_d: 0.017607
0.6431 --- loss: 1.516372, loss_ss: 1.053923, loss_d: 0.462449
0.8039 --- loss: 1.050600, loss_ss: 1.027823, loss_d: 0.022778
0.9646 --- loss: 0.958740, loss_ss: 0.873495, loss_d: 0.085245
Epoch finished! Loss: 1.1277656814744395
Starting epoch 7/10.
0.0000 --- loss: 1.125269, loss_ss: 1.043747, loss_d: 0.081522
0.1608 --- loss: 0.975186, loss_ss: 0.974274, loss_d: 0.000912
0.3215 --- loss: 1.178503, loss_ss: 1.039989, loss_d: 0.138514
0.4823 --- loss: 0.959369, loss_ss: 0.956551, loss_d: 0.002818
0.6431 --- loss: 0.889178, loss_ss: 0.881250, loss_d: 0.007928
0.8039 --- loss: 0.981964, loss_ss: 0.977998, loss_d: 0.003966
0.9646 --- loss: 0.959531, loss_ss: 0.952823, loss_d: 0.006708
Epoch finished! Loss: 1.0706524637437635
Starting epoch 8/10.
0.0000 --- loss: 1.182064, loss_ss: 1.145308, loss_d: 0.036756
0.1608 --- loss: 0.980843, loss_ss: 0.962958, loss_d: 0.017885
0.3215 --- loss: 1.016938, loss_ss: 0.931823, loss_d: 0.085115
0.4823 --- loss: 1.007748, loss_ss: 0.961410, loss_d: 0.046338
0.6431 --- loss: 0.854138, loss_ss: 0.845373, loss_d: 0.008765
0.8039 --- loss: 0.936723, loss_ss: 0.904280, loss_d: 0.032443
0.9646 --- loss: 1.093466, loss_ss: 1.021332, loss_d: 0.072134
Epoch finished! Loss: 1.1023625471899587
Starting epoch 9/10.
0.0000 --- loss: 1.066652, loss_ss: 1.011835, loss_d: 0.054817
0.1608 --- loss: 0.903797, loss_ss: 0.870929, loss_d: 0.032868
0.3215 --- loss: 1.114810, loss_ss: 1.111480, loss_d: 0.003330
0.4823 --- loss: 0.912342, loss_ss: 0.900959, loss_d: 0.011383
0.6431 --- loss: 0.897532, loss_ss: 0.886694, loss_d: 0.010838
0.8039 --- loss: 0.800452, loss_ss: 0.799392, loss_d: 0.001060
0.9646 --- loss: 0.766859, loss_ss: 0.760064, loss_d: 0.006794
Epoch finished! Loss: 1.0219467003499307
Starting epoch 10/10.
0.0000 --- loss: 0.976627, loss_ss: 0.975946, loss_d: 0.000681
0.1608 --- loss: 0.889666, loss_ss: 0.884471, loss_d: 0.005194
0.3215 --- loss: 1.177222, loss_ss: 1.169509, loss_d: 0.007714
0.4823 --- loss: 0.979964, loss_ss: 0.976818, loss_d: 0.003146
0.6431 --- loss: 0.963255, loss_ss: 0.948501, loss_d: 0.014754
0.8039 --- loss: 0.977323, loss_ss: 0.975056, loss_d: 0.002268
0.9646 --- loss: 1.126196, loss_ss: 1.123617, loss_d: 0.002579
Epoch finished! Loss: 0.969805089696761
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7708333333333334
             precision    recall  f1-score   support

        0.0       0.56      0.42      0.48        57
        1.0       0.00      0.00      0.00        60
        2.0       0.85      0.89      0.87       496
        3.0       0.96      0.54      0.70        90
        4.0       0.65      0.87      0.75       257

avg / total       0.74      0.77      0.74       960
 


====== chp010-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  94.58  42.11   97.90  55.81     48.00
1  93.75   0.00  100.00   0.00      0.00
2  86.25  89.31   82.97  84.87     87.03
3  95.52  54.44   99.77  96.08     69.50
4  84.06  87.16   82.93  65.12     74.54
Total accuracy: 77.08%
Average sen: 54.60%
Average spec: 92.71%
Macro f1-score: 55.82%
Diagnosis acc on 60mins: 1.0
[0.99993849 0.99985361 0.99971157 0.98522341 0.99997199 0.99573791
 0.99927562 0.99974209]
pred: 0.9974318370223045, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp010-nsrr

=== Test on chp011-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.342422, loss_ss: 1.669474, loss_d: 0.672948
0.1608 --- loss: 2.043861, loss_ss: 1.483480, loss_d: 0.560381
0.3215 --- loss: 1.947006, loss_ss: 1.467383, loss_d: 0.479623
0.4823 --- loss: 1.963652, loss_ss: 1.464267, loss_d: 0.499385
0.6431 --- loss: 2.116803, loss_ss: 1.364445, loss_d: 0.752358
0.8039 --- loss: 1.847495, loss_ss: 1.357156, loss_d: 0.490339
0.9646 --- loss: 2.009627, loss_ss: 1.386430, loss_d: 0.623198
Epoch finished! Loss: 2.0884922838980153
Starting epoch 2/10.
0.0000 --- loss: 1.960125, loss_ss: 1.408014, loss_d: 0.552111
0.1608 --- loss: 1.603750, loss_ss: 1.287579, loss_d: 0.316171
0.3215 --- loss: 1.756938, loss_ss: 1.298636, loss_d: 0.458302
0.4823 --- loss: 1.836401, loss_ss: 1.269059, loss_d: 0.567341
0.6431 --- loss: 1.702288, loss_ss: 1.448311, loss_d: 0.253977
0.8039 --- loss: 1.908351, loss_ss: 1.298753, loss_d: 0.609598
0.9646 --- loss: 1.769766, loss_ss: 1.273926, loss_d: 0.495841
Epoch finished! Loss: 1.8109001978751151
Starting epoch 3/10.
0.0000 --- loss: 1.667183, loss_ss: 1.311715, loss_d: 0.355468
0.1608 --- loss: 1.504431, loss_ss: 1.161322, loss_d: 0.343109
0.3215 --- loss: 1.525919, loss_ss: 1.148667, loss_d: 0.377253
0.4823 --- loss: 1.439920, loss_ss: 1.257482, loss_d: 0.182437
0.6431 --- loss: 1.313677, loss_ss: 1.188344, loss_d: 0.125333
0.8039 --- loss: 1.589277, loss_ss: 1.234205, loss_d: 0.355072
0.9646 --- loss: 1.513569, loss_ss: 1.119558, loss_d: 0.394011
Epoch finished! Loss: 1.553036380198694
Starting epoch 4/10.
0.0000 --- loss: 1.252275, loss_ss: 1.213718, loss_d: 0.038557
0.1608 --- loss: 1.289889, loss_ss: 1.108738, loss_d: 0.181151
0.3215 --- loss: 1.234087, loss_ss: 1.212853, loss_d: 0.021234
0.4823 --- loss: 1.250695, loss_ss: 1.094810, loss_d: 0.155885
0.6431 --- loss: 1.095390, loss_ss: 1.067511, loss_d: 0.027880
0.8039 --- loss: 1.319855, loss_ss: 1.040321, loss_d: 0.279534
0.9646 --- loss: 1.489373, loss_ss: 1.161841, loss_d: 0.327531
Epoch finished! Loss: 1.275460693144029
Starting epoch 5/10.
0.0000 --- loss: 1.170113, loss_ss: 1.163732, loss_d: 0.006381
0.1608 --- loss: 1.083519, loss_ss: 1.027539, loss_d: 0.055980
0.3215 --- loss: 1.079048, loss_ss: 0.945135, loss_d: 0.133912
0.4823 --- loss: 1.059628, loss_ss: 1.030006, loss_d: 0.029622
0.6431 --- loss: 1.414505, loss_ss: 0.960517, loss_d: 0.453988
0.8039 --- loss: 1.036103, loss_ss: 1.028805, loss_d: 0.007298
0.9646 --- loss: 1.094132, loss_ss: 1.086937, loss_d: 0.007195
Epoch finished! Loss: 1.1501159523763964
Starting epoch 6/10.
0.0000 --- loss: 0.898411, loss_ss: 0.873327, loss_d: 0.025084
0.1608 --- loss: 1.427951, loss_ss: 1.141267, loss_d: 0.286683
0.3215 --- loss: 0.937005, loss_ss: 0.932284, loss_d: 0.004721
0.4823 --- loss: 0.924362, loss_ss: 0.922014, loss_d: 0.002348
0.6431 --- loss: 1.009900, loss_ss: 0.966523, loss_d: 0.043378
0.8039 --- loss: 0.939254, loss_ss: 0.899205, loss_d: 0.040049
0.9646 --- loss: 0.978550, loss_ss: 0.963973, loss_d: 0.014577
Epoch finished! Loss: 1.0507404102433113
Starting epoch 7/10.
0.0000 --- loss: 0.983079, loss_ss: 0.980972, loss_d: 0.002106
0.1608 --- loss: 0.974373, loss_ss: 0.973440, loss_d: 0.000933
0.3215 --- loss: 0.852249, loss_ss: 0.850289, loss_d: 0.001960
0.4823 --- loss: 0.976985, loss_ss: 0.973522, loss_d: 0.003463
0.6431 --- loss: 0.973744, loss_ss: 0.952749, loss_d: 0.020995
0.8039 --- loss: 1.298408, loss_ss: 1.034752, loss_d: 0.263657
0.9646 --- loss: 0.932146, loss_ss: 0.902398, loss_d: 0.029747
Epoch finished! Loss: 0.9967262658380693
Starting epoch 8/10.
0.0000 --- loss: 1.086519, loss_ss: 0.854046, loss_d: 0.232472
0.1608 --- loss: 0.895918, loss_ss: 0.888249, loss_d: 0.007669
0.3215 --- loss: 0.813079, loss_ss: 0.770021, loss_d: 0.043058
0.4823 --- loss: 1.107008, loss_ss: 1.104714, loss_d: 0.002295
0.6431 --- loss: 0.874826, loss_ss: 0.870696, loss_d: 0.004131
0.8039 --- loss: 0.909270, loss_ss: 0.869077, loss_d: 0.040193
0.9646 --- loss: 0.951732, loss_ss: 0.948592, loss_d: 0.003140
Epoch finished! Loss: 0.9614724343822848
Starting epoch 9/10.
0.0000 --- loss: 0.872505, loss_ss: 0.862462, loss_d: 0.010043
0.1608 --- loss: 0.899511, loss_ss: 0.869377, loss_d: 0.030134
0.3215 --- loss: 0.795182, loss_ss: 0.791487, loss_d: 0.003695
0.4823 --- loss: 1.013351, loss_ss: 0.948018, loss_d: 0.065333
0.6431 --- loss: 0.950504, loss_ss: 0.940437, loss_d: 0.010067
0.8039 --- loss: 0.984687, loss_ss: 0.908938, loss_d: 0.075749
0.9646 --- loss: 0.886330, loss_ss: 0.877642, loss_d: 0.008689
Epoch finished! Loss: 0.976438203165608
Starting epoch 10/10.
0.0000 --- loss: 0.816150, loss_ss: 0.814798, loss_d: 0.001351
0.1608 --- loss: 0.898571, loss_ss: 0.896137, loss_d: 0.002435
0.3215 --- loss: 0.941178, loss_ss: 0.865873, loss_d: 0.075305
0.4823 --- loss: 0.914858, loss_ss: 0.912528, loss_d: 0.002329
0.6431 --- loss: 0.802522, loss_ss: 0.801835, loss_d: 0.000687
0.8039 --- loss: 0.917653, loss_ss: 0.915559, loss_d: 0.002094
0.9646 --- loss: 0.656707, loss_ss: 0.651244, loss_d: 0.005463
Epoch finished! Loss: 0.9299710864020932
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4666666666666667
             precision    recall  f1-score   support

        0.0       0.79      0.12      0.20       189
        1.0       0.23      0.57      0.33       143
        2.0       0.29      0.12      0.17       221
        3.0       0.98      0.69      0.81       271
        4.0       0.44      0.95      0.61       136

avg / total       0.60      0.47      0.44       960
 


====== chp011-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  81.98  11.64   99.22  78.57     20.28
1  64.79  57.34   66.10  22.84     32.67
2  73.02  12.22   91.20  29.35     17.25
3  91.04  69.37   99.56  98.43     81.39
4  82.50  94.85   80.46  44.48     60.56
Total accuracy: 46.67%
Average sen: 49.09%
Average spec: 87.31%
Macro f1-score: 42.43%
Diagnosis acc on 60mins: 1.0
[0.99999511 1.         0.99999869 0.99998724 1.         0.99999976
 0.9999994  0.99999452]
pred: 0.9999968409538269, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp011-nsrr

=== Test on chp012-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.487733, loss_ss: 1.778106, loss_d: 0.709627
0.1610 --- loss: 2.135097, loss_ss: 1.526483, loss_d: 0.608614
0.3221 --- loss: 2.149436, loss_ss: 1.567187, loss_d: 0.582249
0.4831 --- loss: 2.130669, loss_ss: 1.480057, loss_d: 0.650612
0.6441 --- loss: 2.139473, loss_ss: 1.422724, loss_d: 0.716749
0.8052 --- loss: 1.808646, loss_ss: 1.362656, loss_d: 0.445990
0.9662 --- loss: 1.666522, loss_ss: 1.435689, loss_d: 0.230833
Epoch finished! Loss: 2.1135163211053416
Starting epoch 2/10.
0.0000 --- loss: 1.633675, loss_ss: 1.403162, loss_d: 0.230513
0.1610 --- loss: 2.107345, loss_ss: 1.543113, loss_d: 0.564232
0.3221 --- loss: 2.109762, loss_ss: 1.373156, loss_d: 0.736606
0.4831 --- loss: 1.853522, loss_ss: 1.378272, loss_d: 0.475250
0.6441 --- loss: 2.050414, loss_ss: 1.331008, loss_d: 0.719405
0.8052 --- loss: 1.871770, loss_ss: 1.425653, loss_d: 0.446117
0.9662 --- loss: 2.351811, loss_ss: 1.379194, loss_d: 0.972617
Epoch finished! Loss: 1.9072044895541282
Starting epoch 3/10.
0.0000 --- loss: 1.519975, loss_ss: 1.356757, loss_d: 0.163218
0.1610 --- loss: 1.612174, loss_ss: 1.319793, loss_d: 0.292381
0.3221 --- loss: 1.554045, loss_ss: 1.302576, loss_d: 0.251470
0.4831 --- loss: 1.639249, loss_ss: 1.350408, loss_d: 0.288841
0.6441 --- loss: 1.671999, loss_ss: 1.262705, loss_d: 0.409294
0.8052 --- loss: 1.502542, loss_ss: 1.279188, loss_d: 0.223355
0.9662 --- loss: 1.470698, loss_ss: 1.159235, loss_d: 0.311463
Epoch finished! Loss: 1.6848684030194436
Starting epoch 4/10.
0.0000 --- loss: 1.486943, loss_ss: 1.337492, loss_d: 0.149451
0.1610 --- loss: 1.554826, loss_ss: 1.209270, loss_d: 0.345556
0.3221 --- loss: 1.285141, loss_ss: 1.201820, loss_d: 0.083321
0.4831 --- loss: 1.305269, loss_ss: 1.197139, loss_d: 0.108129
0.6441 --- loss: 1.304664, loss_ss: 1.282972, loss_d: 0.021692
0.8052 --- loss: 1.228839, loss_ss: 1.171548, loss_d: 0.057291
0.9662 --- loss: 1.266711, loss_ss: 1.141720, loss_d: 0.124991
Epoch finished! Loss: 1.4506950859100587
Starting epoch 5/10.
0.0000 --- loss: 1.220263, loss_ss: 1.138257, loss_d: 0.082005
0.1610 --- loss: 1.223975, loss_ss: 1.187128, loss_d: 0.036847
0.3221 --- loss: 1.293022, loss_ss: 1.039926, loss_d: 0.253096
0.4831 --- loss: 1.274629, loss_ss: 1.245655, loss_d: 0.028974
0.6441 --- loss: 1.287110, loss_ss: 1.161268, loss_d: 0.125842
0.8052 --- loss: 1.308138, loss_ss: 1.182946, loss_d: 0.125192
0.9662 --- loss: 1.282491, loss_ss: 1.138579, loss_d: 0.143912
Epoch finished! Loss: 1.3285948230374245
Starting epoch 6/10.
0.0000 --- loss: 1.166987, loss_ss: 1.096750, loss_d: 0.070237
0.1610 --- loss: 1.370186, loss_ss: 1.235163, loss_d: 0.135023
0.3221 --- loss: 1.188506, loss_ss: 1.161822, loss_d: 0.026685
0.4831 --- loss: 1.079504, loss_ss: 0.984413, loss_d: 0.095091
0.6441 --- loss: 1.110121, loss_ss: 1.061260, loss_d: 0.048861
0.8052 --- loss: 1.042086, loss_ss: 1.001225, loss_d: 0.040861
0.9662 --- loss: 1.115565, loss_ss: 1.090948, loss_d: 0.024616
Epoch finished! Loss: 1.1371895901618465
Starting epoch 7/10.
0.0000 --- loss: 1.097476, loss_ss: 1.095486, loss_d: 0.001990
0.1610 --- loss: 1.074119, loss_ss: 1.071123, loss_d: 0.002995
0.3221 --- loss: 1.057898, loss_ss: 1.057001, loss_d: 0.000897
0.4831 --- loss: 1.021192, loss_ss: 1.007481, loss_d: 0.013710
0.6441 --- loss: 0.932652, loss_ss: 0.932150, loss_d: 0.000502
0.8052 --- loss: 1.008723, loss_ss: 1.005178, loss_d: 0.003545
0.9662 --- loss: 0.988980, loss_ss: 0.977696, loss_d: 0.011284
Epoch finished! Loss: 1.021124102415577
Starting epoch 8/10.
0.0000 --- loss: 1.068734, loss_ss: 1.061323, loss_d: 0.007411
0.1610 --- loss: 0.973442, loss_ss: 0.971132, loss_d: 0.002311
0.3221 --- loss: 0.927349, loss_ss: 0.926454, loss_d: 0.000896
0.4831 --- loss: 0.850760, loss_ss: 0.849943, loss_d: 0.000817
0.6441 --- loss: 1.032767, loss_ss: 1.032251, loss_d: 0.000516
0.8052 --- loss: 0.816998, loss_ss: 0.815958, loss_d: 0.001040
0.9662 --- loss: 0.836394, loss_ss: 0.833824, loss_d: 0.002570
Epoch finished! Loss: 0.9498048088242931
Starting epoch 9/10.
0.0000 --- loss: 0.945295, loss_ss: 0.929056, loss_d: 0.016239
0.1610 --- loss: 0.822304, loss_ss: 0.815267, loss_d: 0.007037
0.3221 --- loss: 1.067824, loss_ss: 1.064203, loss_d: 0.003621
0.4831 --- loss: 0.852344, loss_ss: 0.851993, loss_d: 0.000351
0.6441 --- loss: 0.908169, loss_ss: 0.906832, loss_d: 0.001337
0.8052 --- loss: 0.741314, loss_ss: 0.740428, loss_d: 0.000885
0.9662 --- loss: 0.889120, loss_ss: 0.887658, loss_d: 0.001462
Epoch finished! Loss: 0.9089104744695848
Starting epoch 10/10.
0.0000 --- loss: 0.896767, loss_ss: 0.891713, loss_d: 0.005054
0.1610 --- loss: 0.847388, loss_ss: 0.846672, loss_d: 0.000716
0.3221 --- loss: 0.874808, loss_ss: 0.870861, loss_d: 0.003947
0.4831 --- loss: 0.894831, loss_ss: 0.893847, loss_d: 0.000984
0.6441 --- loss: 0.955375, loss_ss: 0.955303, loss_d: 0.000072
0.8052 --- loss: 0.933725, loss_ss: 0.933657, loss_d: 0.000069
0.9662 --- loss: 0.824848, loss_ss: 0.824698, loss_d: 0.000150
Epoch finished! Loss: 0.8997638014055067
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.675
             precision    recall  f1-score   support

        0.0       0.57      0.52      0.55        23
        1.0       0.37      0.41      0.39       178
        2.0       0.73      0.79      0.76       379
        3.0       1.00      0.53      0.69       203
        4.0       0.70      0.80      0.74       297

avg / total       0.71      0.68      0.68      1080
 


====== chp012-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  98.15  52.17   99.15   57.14     54.55
1  78.61  41.01   86.03   36.68     38.73
2  82.13  78.89   83.88   72.57     75.60
3  91.20  53.20  100.00  100.00     69.45
4  84.91  79.80   86.85   69.71     74.41
Total accuracy: 67.50%
Average sen: 61.02%
Average spec: 91.18%
Macro f1-score: 62.55%
Diagnosis acc on 60mins: 1.0
[0.99993849 0.99999046 0.99999988 0.9998486  0.99738806 0.99999905
 0.94585687 0.99979538 0.99999952]
pred: 0.9936462574534946, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp012-nsrr

=== Test on chp013-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.234788, loss_ss: 1.656154, loss_d: 0.578634
0.1608 --- loss: 2.299643, loss_ss: 1.522824, loss_d: 0.776819
0.3215 --- loss: 2.058739, loss_ss: 1.474332, loss_d: 0.584406
0.4823 --- loss: 1.899971, loss_ss: 1.529823, loss_d: 0.370149
0.6431 --- loss: 2.181867, loss_ss: 1.521705, loss_d: 0.660162
0.8039 --- loss: 2.034938, loss_ss: 1.475706, loss_d: 0.559232
0.9646 --- loss: 2.040633, loss_ss: 1.366093, loss_d: 0.674540
Epoch finished! Loss: 2.1748026167192767
Starting epoch 2/10.
0.0000 --- loss: 2.062210, loss_ss: 1.559208, loss_d: 0.503002
0.1608 --- loss: 1.870581, loss_ss: 1.519478, loss_d: 0.351103
0.3215 --- loss: 2.036617, loss_ss: 1.410258, loss_d: 0.626359
0.4823 --- loss: 1.926272, loss_ss: 1.429299, loss_d: 0.496973
0.6431 --- loss: 2.180728, loss_ss: 1.348683, loss_d: 0.832045
0.8039 --- loss: 1.601023, loss_ss: 1.311172, loss_d: 0.289851
0.9646 --- loss: 1.441519, loss_ss: 1.209050, loss_d: 0.232468
Epoch finished! Loss: 1.859788752371265
Starting epoch 3/10.
0.0000 --- loss: 1.331455, loss_ss: 1.202707, loss_d: 0.128747
0.1608 --- loss: 1.761957, loss_ss: 1.266127, loss_d: 0.495829
0.3215 --- loss: 1.889084, loss_ss: 1.350095, loss_d: 0.538990
0.4823 --- loss: 1.709438, loss_ss: 1.165534, loss_d: 0.543904
0.6431 --- loss: 1.487769, loss_ss: 1.305429, loss_d: 0.182340
0.8039 --- loss: 1.217673, loss_ss: 1.180862, loss_d: 0.036810
0.9646 --- loss: 1.475122, loss_ss: 1.228078, loss_d: 0.247044
Epoch finished! Loss: 1.598293504407329
Starting epoch 4/10.
0.0000 --- loss: 1.320548, loss_ss: 1.174908, loss_d: 0.145639
0.1608 --- loss: 1.548534, loss_ss: 1.423873, loss_d: 0.124661
0.3215 --- loss: 1.442650, loss_ss: 1.253874, loss_d: 0.188776
0.4823 --- loss: 1.215317, loss_ss: 1.181095, loss_d: 0.034222
0.6431 --- loss: 1.372298, loss_ss: 1.169600, loss_d: 0.202698
0.8039 --- loss: 2.133912, loss_ss: 1.087372, loss_d: 1.046540
0.9646 --- loss: 1.271761, loss_ss: 1.184377, loss_d: 0.087384
Epoch finished! Loss: 1.362107030807003
Starting epoch 5/10.
0.0000 --- loss: 1.189126, loss_ss: 1.100288, loss_d: 0.088838
0.1608 --- loss: 1.077984, loss_ss: 1.022370, loss_d: 0.055614
0.3215 --- loss: 1.138172, loss_ss: 1.131618, loss_d: 0.006554
0.4823 --- loss: 1.183969, loss_ss: 1.130851, loss_d: 0.053117
0.6431 --- loss: 1.140309, loss_ss: 1.128549, loss_d: 0.011760
0.8039 --- loss: 1.111344, loss_ss: 1.103976, loss_d: 0.007368
0.9646 --- loss: 1.233973, loss_ss: 1.143064, loss_d: 0.090909
Epoch finished! Loss: 1.2038035873443849
Starting epoch 6/10.
0.0000 --- loss: 1.288988, loss_ss: 1.284577, loss_d: 0.004410
0.1608 --- loss: 1.123339, loss_ss: 1.106194, loss_d: 0.017145
0.3215 --- loss: 0.967778, loss_ss: 0.954165, loss_d: 0.013612
0.4823 --- loss: 1.062618, loss_ss: 1.046662, loss_d: 0.015956
0.6431 --- loss: 1.027188, loss_ss: 1.005786, loss_d: 0.021402
0.8039 --- loss: 1.051635, loss_ss: 0.935053, loss_d: 0.116582
0.9646 --- loss: 1.045752, loss_ss: 1.040072, loss_d: 0.005679
Epoch finished! Loss: 1.147081475104055
Starting epoch 7/10.
0.0000 --- loss: 0.985199, loss_ss: 0.974978, loss_d: 0.010221
0.1608 --- loss: 0.947790, loss_ss: 0.936650, loss_d: 0.011140
0.3215 --- loss: 1.256510, loss_ss: 1.207148, loss_d: 0.049361
0.4823 --- loss: 1.096363, loss_ss: 0.938894, loss_d: 0.157469
0.6431 --- loss: 1.022924, loss_ss: 0.929884, loss_d: 0.093039
0.8039 --- loss: 1.056798, loss_ss: 1.050563, loss_d: 0.006235
0.9646 --- loss: 1.087434, loss_ss: 1.047224, loss_d: 0.040209
Epoch finished! Loss: 1.1251351996775596
Starting epoch 8/10.
0.0000 --- loss: 0.858797, loss_ss: 0.853313, loss_d: 0.005484
0.1608 --- loss: 0.940323, loss_ss: 0.930909, loss_d: 0.009414
0.3215 --- loss: 0.863575, loss_ss: 0.860122, loss_d: 0.003453
0.4823 --- loss: 0.891854, loss_ss: 0.883623, loss_d: 0.008232
0.6431 --- loss: 0.876040, loss_ss: 0.854090, loss_d: 0.021950
0.8039 --- loss: 0.977287, loss_ss: 0.962142, loss_d: 0.015146
0.9646 --- loss: 1.098393, loss_ss: 1.094175, loss_d: 0.004218
Epoch finished! Loss: 1.0791048878623593
Starting epoch 9/10.
0.0000 --- loss: 0.880497, loss_ss: 0.868829, loss_d: 0.011669
0.1608 --- loss: 1.202158, loss_ss: 1.145295, loss_d: 0.056863
0.3215 --- loss: 1.111435, loss_ss: 1.089542, loss_d: 0.021893
0.4823 --- loss: 0.963109, loss_ss: 0.957725, loss_d: 0.005384
0.6431 --- loss: 1.023788, loss_ss: 1.012790, loss_d: 0.010998
0.8039 --- loss: 1.224856, loss_ss: 1.197492, loss_d: 0.027364
0.9646 --- loss: 0.859792, loss_ss: 0.833797, loss_d: 0.025995
Epoch finished! Loss: 1.034230362984442
Starting epoch 10/10.
0.0000 --- loss: 1.117692, loss_ss: 1.114824, loss_d: 0.002869
0.1608 --- loss: 0.958473, loss_ss: 0.929115, loss_d: 0.029358
0.3215 --- loss: 0.974350, loss_ss: 0.973140, loss_d: 0.001210
0.4823 --- loss: 1.000785, loss_ss: 0.989999, loss_d: 0.010785
0.6431 --- loss: 0.866256, loss_ss: 0.863954, loss_d: 0.002302
0.8039 --- loss: 0.916843, loss_ss: 0.916479, loss_d: 0.000365
0.9646 --- loss: 0.941969, loss_ss: 0.940508, loss_d: 0.001461
Epoch finished! Loss: 0.9527445531660511
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.73125
             precision    recall  f1-score   support

        0.0       0.29      0.87      0.44        31
        1.0       0.00      0.00      0.00       118
        2.0       0.80      0.85      0.83       433
        3.0       0.88      0.75      0.81       189
        4.0       0.66      0.86      0.75       189

avg / total       0.68      0.73      0.69       960
 


====== chp013-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  92.81  87.10   93.00  29.35     43.90
1  87.71   0.00  100.00   0.00      0.00
2  84.06  85.45   82.92  80.43     82.87
3  93.02  75.13   97.41  87.65     80.91
4  88.65  86.24   89.23  66.26     74.94
Total accuracy: 73.12%
Average sen: 66.78%
Average spec: 92.51%
Macro f1-score: 56.52%
Diagnosis acc on 60mins: 0.875
[0.99753654 0.96864724 0.9933455  0.36914918 0.99975175 0.98886335
 0.9999851  0.99410266]
pred: 0.9139226637780666, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp013-nsrr

=== Test on chp014-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.322927, loss_ss: 1.637512, loss_d: 0.685414
0.1608 --- loss: 2.144485, loss_ss: 1.533427, loss_d: 0.611058
0.3215 --- loss: 2.062206, loss_ss: 1.467814, loss_d: 0.594392
0.4823 --- loss: 2.181703, loss_ss: 1.397922, loss_d: 0.783781
0.6431 --- loss: 1.886334, loss_ss: 1.348597, loss_d: 0.537738
0.8039 --- loss: 1.990382, loss_ss: 1.368576, loss_d: 0.621806
0.9646 --- loss: 1.933326, loss_ss: 1.329384, loss_d: 0.603942
Epoch finished! Loss: 2.100548796115383
Starting epoch 2/10.
0.0000 --- loss: 1.785572, loss_ss: 1.426761, loss_d: 0.358811
0.1608 --- loss: 1.957064, loss_ss: 1.318058, loss_d: 0.639006
0.3215 --- loss: 1.736766, loss_ss: 1.297016, loss_d: 0.439750
0.4823 --- loss: 1.594996, loss_ss: 1.277611, loss_d: 0.317385
0.6431 --- loss: 1.747107, loss_ss: 1.278467, loss_d: 0.468640
0.8039 --- loss: 1.996571, loss_ss: 1.353969, loss_d: 0.642601
0.9646 --- loss: 1.651289, loss_ss: 1.208008, loss_d: 0.443281
Epoch finished! Loss: 1.7919551441746373
Starting epoch 3/10.
0.0000 --- loss: 1.576615, loss_ss: 1.167346, loss_d: 0.409269
0.1608 --- loss: 1.545909, loss_ss: 1.141849, loss_d: 0.404060
0.3215 --- loss: 1.511958, loss_ss: 1.235091, loss_d: 0.276867
0.4823 --- loss: 1.329379, loss_ss: 1.107360, loss_d: 0.222018
0.6431 --- loss: 1.560350, loss_ss: 1.101984, loss_d: 0.458366
0.8039 --- loss: 1.535190, loss_ss: 1.064220, loss_d: 0.470970
0.9646 --- loss: 1.720551, loss_ss: 1.094522, loss_d: 0.626029
Epoch finished! Loss: 1.5697175495086177
Starting epoch 4/10.
0.0000 --- loss: 1.441084, loss_ss: 1.230943, loss_d: 0.210141
0.1608 --- loss: 1.275639, loss_ss: 1.147805, loss_d: 0.127835
0.3215 --- loss: 1.448937, loss_ss: 1.029190, loss_d: 0.419747
0.4823 --- loss: 1.263534, loss_ss: 1.186474, loss_d: 0.077060
0.6431 --- loss: 1.156125, loss_ss: 1.026242, loss_d: 0.129883
0.8039 --- loss: 1.175365, loss_ss: 1.023876, loss_d: 0.151489
0.9646 --- loss: 1.191996, loss_ss: 1.108604, loss_d: 0.083391
Epoch finished! Loss: 1.330083922032387
Starting epoch 5/10.
0.0000 --- loss: 1.243044, loss_ss: 1.221723, loss_d: 0.021321
0.1608 --- loss: 1.193574, loss_ss: 1.170686, loss_d: 0.022888
0.3215 --- loss: 1.061910, loss_ss: 0.971174, loss_d: 0.090736
0.4823 --- loss: 1.406392, loss_ss: 0.909175, loss_d: 0.497217
0.6431 --- loss: 1.166543, loss_ss: 0.987420, loss_d: 0.179123
0.8039 --- loss: 0.953444, loss_ss: 0.900142, loss_d: 0.053302
0.9646 --- loss: 1.066779, loss_ss: 1.028447, loss_d: 0.038331
Epoch finished! Loss: 1.1808776432468044
Starting epoch 6/10.
0.0000 --- loss: 1.027931, loss_ss: 1.013754, loss_d: 0.014177
0.1608 --- loss: 1.010756, loss_ss: 0.972710, loss_d: 0.038046
0.3215 --- loss: 1.259086, loss_ss: 1.101807, loss_d: 0.157279
0.4823 --- loss: 0.907529, loss_ss: 0.891901, loss_d: 0.015629
0.6431 --- loss: 0.992314, loss_ss: 0.979963, loss_d: 0.012352
0.8039 --- loss: 1.100028, loss_ss: 1.049684, loss_d: 0.050344
0.9646 --- loss: 1.184604, loss_ss: 1.046950, loss_d: 0.137655
Epoch finished! Loss: 1.088274541401094
Starting epoch 7/10.
0.0000 --- loss: 0.948613, loss_ss: 0.946199, loss_d: 0.002415
0.1608 --- loss: 0.962275, loss_ss: 0.945292, loss_d: 0.016983
0.3215 --- loss: 0.925341, loss_ss: 0.917969, loss_d: 0.007372
0.4823 --- loss: 0.999504, loss_ss: 0.976204, loss_d: 0.023300
0.6431 --- loss: 0.845556, loss_ss: 0.831161, loss_d: 0.014395
0.8039 --- loss: 0.959780, loss_ss: 0.926859, loss_d: 0.032921
0.9646 --- loss: 0.881830, loss_ss: 0.881288, loss_d: 0.000542
Epoch finished! Loss: 0.9812096117004272
Starting epoch 8/10.
0.0000 --- loss: 0.962614, loss_ss: 0.933975, loss_d: 0.028639
0.1608 --- loss: 0.845046, loss_ss: 0.836571, loss_d: 0.008475
0.3215 --- loss: 0.919253, loss_ss: 0.918968, loss_d: 0.000285
0.4823 --- loss: 0.894658, loss_ss: 0.893312, loss_d: 0.001345
0.6431 --- loss: 0.878837, loss_ss: 0.878494, loss_d: 0.000343
0.8039 --- loss: 0.752246, loss_ss: 0.749103, loss_d: 0.003143
0.9646 --- loss: 0.994242, loss_ss: 0.989906, loss_d: 0.004337
Epoch finished! Loss: 0.9489427035854708
Starting epoch 9/10.
0.0000 --- loss: 0.983821, loss_ss: 0.982114, loss_d: 0.001706
0.1608 --- loss: 0.904826, loss_ss: 0.867949, loss_d: 0.036878
0.3215 --- loss: 1.101321, loss_ss: 0.981981, loss_d: 0.119340
0.4823 --- loss: 1.426063, loss_ss: 1.050824, loss_d: 0.375239
0.6431 --- loss: 0.838264, loss_ss: 0.748631, loss_d: 0.089633
0.8039 --- loss: 0.819713, loss_ss: 0.751386, loss_d: 0.068326
0.9646 --- loss: 1.043415, loss_ss: 0.955239, loss_d: 0.088176
Epoch finished! Loss: 1.0914824480010616
Starting epoch 10/10.
0.0000 --- loss: 0.960235, loss_ss: 0.925858, loss_d: 0.034377
0.1608 --- loss: 0.985675, loss_ss: 0.897159, loss_d: 0.088517
0.3215 --- loss: 0.913601, loss_ss: 0.889839, loss_d: 0.023762
0.4823 --- loss: 1.034699, loss_ss: 1.009623, loss_d: 0.025075
0.6431 --- loss: 1.131916, loss_ss: 0.970081, loss_d: 0.161835
0.8039 --- loss: 0.910886, loss_ss: 0.908202, loss_d: 0.002684
0.9646 --- loss: 0.817062, loss_ss: 0.809281, loss_d: 0.007780
Epoch finished! Loss: 0.9678882821913688
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.646875
             precision    recall  f1-score   support

        0.0       0.94      0.78      0.85       188
        1.0       0.24      0.08      0.12        63
        2.0       0.67      0.75      0.71       397
        3.0       0.80      0.05      0.10       146
        4.0       0.49      0.98      0.66       166

avg / total       0.69      0.65      0.60       960
 


====== chp014-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  94.69  77.66   98.83  94.19     85.13
1  92.29   7.94   98.22  23.81     11.90
2  74.79  75.31   74.42  67.49     71.19
3  85.42   5.48   99.75  80.00     10.26
4  82.19  98.19   78.84  49.24     65.59
Total accuracy: 64.69%
Average sen: 52.92%
Average spec: 90.01%
Macro f1-score: 48.82%
Diagnosis acc on 60mins: 1.0
[0.99999428 0.99999917 0.99991059 0.99999154 0.99997187 0.82388544
 0.99990654 0.9999969 ]
pred: 0.9779570400714874, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp014-nsrr

=== Test on chp015-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.368341, loss_ss: 1.671277, loss_d: 0.697064
0.1610 --- loss: 2.097485, loss_ss: 1.491867, loss_d: 0.605618
0.3221 --- loss: 2.003330, loss_ss: 1.476496, loss_d: 0.526834
0.4831 --- loss: 1.760617, loss_ss: 1.479052, loss_d: 0.281565
0.6441 --- loss: 1.815708, loss_ss: 1.438198, loss_d: 0.377510
0.8052 --- loss: 2.097267, loss_ss: 1.408965, loss_d: 0.688302
0.9662 --- loss: 2.008959, loss_ss: 1.324414, loss_d: 0.684546
Epoch finished! Loss: 2.083319083336861
Starting epoch 2/10.
0.0000 --- loss: 1.883549, loss_ss: 1.300676, loss_d: 0.582873
0.1610 --- loss: 1.776666, loss_ss: 1.264851, loss_d: 0.511815
0.3221 --- loss: 1.847915, loss_ss: 1.339569, loss_d: 0.508346
0.4831 --- loss: 1.741599, loss_ss: 1.305895, loss_d: 0.435704
0.6441 --- loss: 1.972121, loss_ss: 1.196159, loss_d: 0.775962
0.8052 --- loss: 1.755359, loss_ss: 1.240150, loss_d: 0.515209
0.9662 --- loss: 1.679808, loss_ss: 1.238751, loss_d: 0.441057
Epoch finished! Loss: 1.8518428110307263
Starting epoch 3/10.
0.0000 --- loss: 1.760439, loss_ss: 1.203106, loss_d: 0.557333
0.1610 --- loss: 1.489020, loss_ss: 1.329723, loss_d: 0.159297
0.3221 --- loss: 1.599306, loss_ss: 1.230888, loss_d: 0.368417
0.4831 --- loss: 1.565237, loss_ss: 1.198668, loss_d: 0.366569
0.6441 --- loss: 1.562605, loss_ss: 1.268435, loss_d: 0.294170
0.8052 --- loss: 1.975539, loss_ss: 1.232413, loss_d: 0.743125
0.9662 --- loss: 1.844988, loss_ss: 1.255879, loss_d: 0.589110
Epoch finished! Loss: 1.6845473877845272
Starting epoch 4/10.
0.0000 --- loss: 1.279241, loss_ss: 1.148672, loss_d: 0.130569
0.1610 --- loss: 1.610637, loss_ss: 1.331718, loss_d: 0.278919
0.3221 --- loss: 1.757174, loss_ss: 1.219157, loss_d: 0.538017
0.4831 --- loss: 1.153975, loss_ss: 1.055983, loss_d: 0.097992
0.6441 --- loss: 1.731765, loss_ss: 1.080863, loss_d: 0.650903
0.8052 --- loss: 1.142372, loss_ss: 1.056822, loss_d: 0.085550
0.9662 --- loss: 1.531648, loss_ss: 1.150466, loss_d: 0.381183
Epoch finished! Loss: 1.3884446121031238
Starting epoch 5/10.
0.0000 --- loss: 1.066169, loss_ss: 1.008800, loss_d: 0.057370
0.1610 --- loss: 1.086944, loss_ss: 1.068036, loss_d: 0.018908
0.3221 --- loss: 1.232220, loss_ss: 1.194912, loss_d: 0.037309
0.4831 --- loss: 0.989490, loss_ss: 0.980336, loss_d: 0.009153
0.6441 --- loss: 1.434373, loss_ss: 1.022054, loss_d: 0.412319
0.8052 --- loss: 1.356632, loss_ss: 1.094853, loss_d: 0.261778
0.9662 --- loss: 1.108332, loss_ss: 1.068912, loss_d: 0.039420
Epoch finished! Loss: 1.2387271888794438
Starting epoch 6/10.
0.0000 --- loss: 1.443427, loss_ss: 1.093078, loss_d: 0.350348
0.1610 --- loss: 1.042776, loss_ss: 1.021888, loss_d: 0.020888
0.3221 --- loss: 0.931522, loss_ss: 0.919942, loss_d: 0.011580
0.4831 --- loss: 1.067249, loss_ss: 1.060724, loss_d: 0.006526
0.6441 --- loss: 0.956124, loss_ss: 0.949019, loss_d: 0.007105
0.8052 --- loss: 0.953099, loss_ss: 0.937119, loss_d: 0.015980
0.9662 --- loss: 1.205661, loss_ss: 1.114216, loss_d: 0.091445
Epoch finished! Loss: 1.1160099179513994
Starting epoch 7/10.
0.0000 --- loss: 0.943679, loss_ss: 0.922472, loss_d: 0.021207
0.1610 --- loss: 0.978387, loss_ss: 0.965643, loss_d: 0.012744
0.3221 --- loss: 0.976509, loss_ss: 0.971806, loss_d: 0.004703
0.4831 --- loss: 0.946258, loss_ss: 0.941480, loss_d: 0.004779
0.6441 --- loss: 1.213661, loss_ss: 1.210067, loss_d: 0.003594
0.8052 --- loss: 0.952874, loss_ss: 0.933947, loss_d: 0.018926
0.9662 --- loss: 1.009642, loss_ss: 1.005574, loss_d: 0.004068
Epoch finished! Loss: 1.0453807577010124
Starting epoch 8/10.
0.0000 --- loss: 0.953650, loss_ss: 0.912012, loss_d: 0.041638
0.1610 --- loss: 0.947285, loss_ss: 0.946836, loss_d: 0.000449
0.3221 --- loss: 0.888160, loss_ss: 0.885725, loss_d: 0.002434
0.4831 --- loss: 0.894566, loss_ss: 0.890729, loss_d: 0.003837
0.6441 --- loss: 0.977330, loss_ss: 0.971916, loss_d: 0.005414
0.8052 --- loss: 0.944839, loss_ss: 0.880466, loss_d: 0.064373
0.9662 --- loss: 0.876868, loss_ss: 0.864992, loss_d: 0.011877
Epoch finished! Loss: 1.0196623946389844
Starting epoch 9/10.
0.0000 --- loss: 0.857150, loss_ss: 0.854999, loss_d: 0.002151
0.1610 --- loss: 1.007236, loss_ss: 0.958002, loss_d: 0.049234
0.3221 --- loss: 0.829227, loss_ss: 0.826724, loss_d: 0.002503
0.4831 --- loss: 1.014172, loss_ss: 0.918250, loss_d: 0.095922
0.6441 --- loss: 0.946807, loss_ss: 0.931102, loss_d: 0.015705
0.8052 --- loss: 0.882612, loss_ss: 0.853570, loss_d: 0.029042
0.9662 --- loss: 0.964243, loss_ss: 0.946575, loss_d: 0.017668
Epoch finished! Loss: 0.9879905043109771
Starting epoch 10/10.
0.0000 --- loss: 0.839216, loss_ss: 0.838519, loss_d: 0.000697
0.1610 --- loss: 0.985200, loss_ss: 0.944684, loss_d: 0.040516
0.3221 --- loss: 0.866141, loss_ss: 0.824574, loss_d: 0.041567
0.4831 --- loss: 0.782118, loss_ss: 0.741477, loss_d: 0.040640
0.6441 --- loss: 0.809626, loss_ss: 0.809116, loss_d: 0.000509
0.8052 --- loss: 0.940585, loss_ss: 0.940116, loss_d: 0.000469
0.9662 --- loss: 1.007455, loss_ss: 1.004770, loss_d: 0.002685
Epoch finished! Loss: 0.9074822222032854
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6972222222222222
             precision    recall  f1-score   support

        0.0       0.30      0.79      0.44        67
        1.0       0.61      0.38      0.47       257
        2.0       0.80      0.77      0.78       304
        3.0       1.00      0.78      0.88       259
        4.0       0.66      0.86      0.75       193

avg / total       0.75      0.70      0.70      1080
 


====== chp015-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  87.50  79.10   88.06  30.46     43.98
1  79.54  38.13   92.47  61.25     47.00
2  88.15  76.64   92.65  80.34     78.45
3  94.72  78.38   99.88  99.51     87.69
4  89.54  86.01   90.30  65.87     74.61
Total accuracy: 69.72%
Average sen: 71.65%
Average spec: 92.67%
Macro f1-score: 66.35%
Diagnosis acc on 60mins: 1.0
[0.9999007  0.99999952 1.         0.99987829 0.99996662 0.99997842
 0.99998486 0.58061707 0.98406965]
pred: 0.9515994588534037, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp015-nsrr

=== Test on chp016-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.260977, loss_ss: 1.594412, loss_d: 0.666565
0.1613 --- loss: 2.037753, loss_ss: 1.560617, loss_d: 0.477136
0.3226 --- loss: 2.146134, loss_ss: 1.552107, loss_d: 0.594027
0.4839 --- loss: 1.743805, loss_ss: 1.459146, loss_d: 0.284659
0.6452 --- loss: 1.946398, loss_ss: 1.410201, loss_d: 0.536197
0.8065 --- loss: 2.020446, loss_ss: 1.410185, loss_d: 0.610261
0.9677 --- loss: 2.027580, loss_ss: 1.353031, loss_d: 0.674549
Epoch finished! Loss: 2.1150392782492715
Starting epoch 2/10.
0.0000 --- loss: 1.956566, loss_ss: 1.430172, loss_d: 0.526395
0.1613 --- loss: 1.853042, loss_ss: 1.343048, loss_d: 0.509994
0.3226 --- loss: 1.779113, loss_ss: 1.338674, loss_d: 0.440439
0.4839 --- loss: 1.652504, loss_ss: 1.302033, loss_d: 0.350471
0.6452 --- loss: 1.884631, loss_ss: 1.353072, loss_d: 0.531559
0.8065 --- loss: 1.576693, loss_ss: 1.268634, loss_d: 0.308059
0.9677 --- loss: 1.575049, loss_ss: 1.232689, loss_d: 0.342360
Epoch finished! Loss: 1.8187752356294726
Starting epoch 3/10.
0.0000 --- loss: 1.481499, loss_ss: 1.263679, loss_d: 0.217819
0.1613 --- loss: 1.439706, loss_ss: 1.123150, loss_d: 0.316556
0.3226 --- loss: 1.255559, loss_ss: 1.117094, loss_d: 0.138465
0.4839 --- loss: 1.704983, loss_ss: 1.284246, loss_d: 0.420737
0.6452 --- loss: 1.612381, loss_ss: 1.219738, loss_d: 0.392643
0.8065 --- loss: 1.500635, loss_ss: 1.363661, loss_d: 0.136974
0.9677 --- loss: 1.469056, loss_ss: 1.387052, loss_d: 0.082004
Epoch finished! Loss: 1.5589751747787977
Starting epoch 4/10.
0.0000 --- loss: 1.327913, loss_ss: 1.101528, loss_d: 0.226385
0.1613 --- loss: 1.433351, loss_ss: 1.393049, loss_d: 0.040302
0.3226 --- loss: 1.469759, loss_ss: 1.315493, loss_d: 0.154265
0.4839 --- loss: 1.006088, loss_ss: 0.988991, loss_d: 0.017096
0.6452 --- loss: 1.182958, loss_ss: 1.110243, loss_d: 0.072715
0.8065 --- loss: 1.039955, loss_ss: 1.036479, loss_d: 0.003476
0.9677 --- loss: 1.130709, loss_ss: 1.123764, loss_d: 0.006945
Epoch finished! Loss: 1.2677947615013747
Starting epoch 5/10.
0.0000 --- loss: 1.123989, loss_ss: 1.109212, loss_d: 0.014777
0.1613 --- loss: 1.076401, loss_ss: 1.067606, loss_d: 0.008795
0.3226 --- loss: 1.035459, loss_ss: 1.028950, loss_d: 0.006509
0.4839 --- loss: 0.995517, loss_ss: 0.993886, loss_d: 0.001631
0.6452 --- loss: 1.238120, loss_ss: 1.177809, loss_d: 0.060311
0.8065 --- loss: 1.209809, loss_ss: 1.183950, loss_d: 0.025859
0.9677 --- loss: 1.003667, loss_ss: 0.998391, loss_d: 0.005275
Epoch finished! Loss: 1.1498520384069348
Starting epoch 6/10.
0.0000 --- loss: 1.047781, loss_ss: 1.005438, loss_d: 0.042344
0.1613 --- loss: 1.099336, loss_ss: 1.016437, loss_d: 0.082899
0.3226 --- loss: 0.933368, loss_ss: 0.923435, loss_d: 0.009934
0.4839 --- loss: 0.975781, loss_ss: 0.969455, loss_d: 0.006326
0.6452 --- loss: 1.000309, loss_ss: 0.979910, loss_d: 0.020399
0.8065 --- loss: 1.007596, loss_ss: 0.984537, loss_d: 0.023059
0.9677 --- loss: 0.978414, loss_ss: 0.971388, loss_d: 0.007027
Epoch finished! Loss: 1.124621181214442
Starting epoch 7/10.
0.0000 --- loss: 0.994516, loss_ss: 0.964272, loss_d: 0.030244
0.1613 --- loss: 0.913260, loss_ss: 0.905234, loss_d: 0.008027
0.3226 --- loss: 1.111294, loss_ss: 1.099210, loss_d: 0.012084
0.4839 --- loss: 0.908960, loss_ss: 0.907109, loss_d: 0.001852
0.6452 --- loss: 0.980925, loss_ss: 0.956830, loss_d: 0.024095
0.8065 --- loss: 1.020618, loss_ss: 1.017741, loss_d: 0.002877
0.9677 --- loss: 0.922499, loss_ss: 0.915074, loss_d: 0.007424
Epoch finished! Loss: 1.034878249051141
Starting epoch 8/10.
0.0000 --- loss: 1.187271, loss_ss: 0.890965, loss_d: 0.296305
0.1613 --- loss: 1.031955, loss_ss: 1.004554, loss_d: 0.027401
0.3226 --- loss: 0.876238, loss_ss: 0.872554, loss_d: 0.003684
0.4839 --- loss: 1.041840, loss_ss: 1.013126, loss_d: 0.028714
0.6452 --- loss: 0.871866, loss_ss: 0.839149, loss_d: 0.032717
0.8065 --- loss: 0.944377, loss_ss: 0.939283, loss_d: 0.005094
0.9677 --- loss: 1.057786, loss_ss: 1.055139, loss_d: 0.002647
Epoch finished! Loss: 1.0336011521151809
Starting epoch 9/10.
0.0000 --- loss: 1.103792, loss_ss: 0.913500, loss_d: 0.190291
0.1613 --- loss: 0.841499, loss_ss: 0.839761, loss_d: 0.001739
0.3226 --- loss: 0.933745, loss_ss: 0.925734, loss_d: 0.008011
0.4839 --- loss: 0.859942, loss_ss: 0.839286, loss_d: 0.020656
0.6452 --- loss: 0.863509, loss_ss: 0.839791, loss_d: 0.023718
0.8065 --- loss: 0.777788, loss_ss: 0.766547, loss_d: 0.011242
0.9677 --- loss: 0.853145, loss_ss: 0.806408, loss_d: 0.046737
Epoch finished! Loss: 0.9286675521584807
Starting epoch 10/10.
0.0000 --- loss: 0.748124, loss_ss: 0.742627, loss_d: 0.005497
0.1613 --- loss: 0.945725, loss_ss: 0.909965, loss_d: 0.035761
0.3226 --- loss: 0.853967, loss_ss: 0.848939, loss_d: 0.005028
0.4839 --- loss: 0.786601, loss_ss: 0.765469, loss_d: 0.021132
0.6452 --- loss: 1.002763, loss_ss: 1.001601, loss_d: 0.001162
0.8065 --- loss: 0.838098, loss_ss: 0.837681, loss_d: 0.000417
0.9677 --- loss: 0.901837, loss_ss: 0.898956, loss_d: 0.002881
Epoch finished! Loss: 0.9104102801104061
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6075
             precision    recall  f1-score   support

        0.0       0.53      1.00      0.69       295
        1.0       0.28      0.07      0.11       280
        2.0       0.67      0.95      0.78       330
        3.0       1.00      0.41      0.58       133
        4.0       0.98      0.30      0.46       162

avg / total       0.62      0.61      0.54      1200
 


====== chp016-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  78.08  99.66   71.05   52.88     69.10
1  74.00   7.14   94.35   27.78     11.36
2  85.50  94.55   82.07   66.67     78.20
3  93.42  40.60  100.00  100.00     57.75
4  90.50  30.25   99.90   98.00     46.23
Total accuracy: 60.75%
Average sen: 54.44%
Average spec: 89.47%
Macro f1-score: 52.53%
Diagnosis acc on 60mins: 1.0
[0.99964333 0.5617643  0.99762672 0.94922918 0.99816775 0.99995744
 0.99699509 0.99603719 0.99708837 0.98812693]
pred: 0.9484636306762695, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp016-nsrr

=== Test on chp017-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.379648, loss_ss: 1.695318, loss_d: 0.684330
0.1608 --- loss: 2.147864, loss_ss: 1.543394, loss_d: 0.604470
0.3215 --- loss: 2.059027, loss_ss: 1.507402, loss_d: 0.551625
0.4823 --- loss: 1.901128, loss_ss: 1.405450, loss_d: 0.495678
0.6431 --- loss: 1.738598, loss_ss: 1.400120, loss_d: 0.338478
0.8039 --- loss: 1.828552, loss_ss: 1.383147, loss_d: 0.445404
0.9646 --- loss: 1.796091, loss_ss: 1.314673, loss_d: 0.481418
Epoch finished! Loss: 2.1129961052248554
Starting epoch 2/10.
0.0000 --- loss: 1.785443, loss_ss: 1.321281, loss_d: 0.464162
0.1608 --- loss: 2.103484, loss_ss: 1.232011, loss_d: 0.871473
0.3215 --- loss: 1.592999, loss_ss: 1.291368, loss_d: 0.301631
0.4823 --- loss: 1.629132, loss_ss: 1.233617, loss_d: 0.395514
0.6431 --- loss: 1.540427, loss_ss: 1.299104, loss_d: 0.241323
0.8039 --- loss: 1.698800, loss_ss: 1.194945, loss_d: 0.503855
0.9646 --- loss: 1.554775, loss_ss: 1.178768, loss_d: 0.376007
Epoch finished! Loss: 1.764241951127206
Starting epoch 3/10.
0.0000 --- loss: 1.570748, loss_ss: 1.212728, loss_d: 0.358020
0.1608 --- loss: 1.890130, loss_ss: 1.132689, loss_d: 0.757441
0.3215 --- loss: 1.368089, loss_ss: 1.169014, loss_d: 0.199075
0.4823 --- loss: 1.519518, loss_ss: 1.171563, loss_d: 0.347955
0.6431 --- loss: 1.425165, loss_ss: 1.044888, loss_d: 0.380277
0.8039 --- loss: 1.469147, loss_ss: 1.134705, loss_d: 0.334442
0.9646 --- loss: 1.367905, loss_ss: 1.020156, loss_d: 0.347750
Epoch finished! Loss: 1.4705363723539537
Starting epoch 4/10.
0.0000 --- loss: 2.085226, loss_ss: 1.098562, loss_d: 0.986664
0.1608 --- loss: 1.178322, loss_ss: 1.060133, loss_d: 0.118189
0.3215 --- loss: 1.145655, loss_ss: 1.067071, loss_d: 0.078584
0.4823 --- loss: 1.238230, loss_ss: 1.137177, loss_d: 0.101053
0.6431 --- loss: 1.091127, loss_ss: 1.046567, loss_d: 0.044560
0.8039 --- loss: 1.199002, loss_ss: 0.949865, loss_d: 0.249137
0.9646 --- loss: 1.113468, loss_ss: 1.003232, loss_d: 0.110236
Epoch finished! Loss: 1.2588362434218008
Starting epoch 5/10.
0.0000 --- loss: 1.045552, loss_ss: 1.033154, loss_d: 0.012398
0.1608 --- loss: 1.345799, loss_ss: 0.949717, loss_d: 0.396082
0.3215 --- loss: 1.596619, loss_ss: 1.062608, loss_d: 0.534012
0.4823 --- loss: 1.126501, loss_ss: 1.089672, loss_d: 0.036829
0.6431 --- loss: 1.243712, loss_ss: 1.025548, loss_d: 0.218165
0.8039 --- loss: 1.244037, loss_ss: 0.921080, loss_d: 0.322957
0.9646 --- loss: 1.057974, loss_ss: 0.962646, loss_d: 0.095328
Epoch finished! Loss: 1.1726705249278777
Starting epoch 6/10.
0.0000 --- loss: 0.988207, loss_ss: 0.981011, loss_d: 0.007196
0.1608 --- loss: 1.259387, loss_ss: 1.076927, loss_d: 0.182460
0.3215 --- loss: 1.479215, loss_ss: 0.944661, loss_d: 0.534554
0.4823 --- loss: 0.907225, loss_ss: 0.895124, loss_d: 0.012101
0.6431 --- loss: 0.975695, loss_ss: 0.914487, loss_d: 0.061208
0.8039 --- loss: 0.991190, loss_ss: 0.978870, loss_d: 0.012320
0.9646 --- loss: 1.132668, loss_ss: 0.956322, loss_d: 0.176345
Epoch finished! Loss: 1.1203310518495497
Starting epoch 7/10.
0.0000 --- loss: 0.926455, loss_ss: 0.881126, loss_d: 0.045329
0.1608 --- loss: 0.938229, loss_ss: 0.911624, loss_d: 0.026604
0.3215 --- loss: 1.021483, loss_ss: 1.009533, loss_d: 0.011950
0.4823 --- loss: 0.975835, loss_ss: 0.957193, loss_d: 0.018642
0.6431 --- loss: 0.992318, loss_ss: 0.925969, loss_d: 0.066349
0.8039 --- loss: 0.877229, loss_ss: 0.861546, loss_d: 0.015684
0.9646 --- loss: 0.939877, loss_ss: 0.934147, loss_d: 0.005730
Epoch finished! Loss: 1.0062410062359226
Starting epoch 8/10.
0.0000 --- loss: 1.272550, loss_ss: 1.192777, loss_d: 0.079773
0.1608 --- loss: 1.003868, loss_ss: 0.957163, loss_d: 0.046705
0.3215 --- loss: 1.044791, loss_ss: 1.042620, loss_d: 0.002171
0.4823 --- loss: 0.886504, loss_ss: 0.884943, loss_d: 0.001560
0.6431 --- loss: 0.935081, loss_ss: 0.932563, loss_d: 0.002518
0.8039 --- loss: 0.804676, loss_ss: 0.800076, loss_d: 0.004599
0.9646 --- loss: 1.034811, loss_ss: 1.027962, loss_d: 0.006849
Epoch finished! Loss: 0.9568557220120584
Starting epoch 9/10.
0.0000 --- loss: 0.857666, loss_ss: 0.856509, loss_d: 0.001157
0.1608 --- loss: 0.827608, loss_ss: 0.825346, loss_d: 0.002262
0.3215 --- loss: 0.837868, loss_ss: 0.805629, loss_d: 0.032239
0.4823 --- loss: 0.863333, loss_ss: 0.854206, loss_d: 0.009126
0.6431 --- loss: 0.986209, loss_ss: 0.979235, loss_d: 0.006974
0.8039 --- loss: 0.919440, loss_ss: 0.919056, loss_d: 0.000384
0.9646 --- loss: 0.841069, loss_ss: 0.837698, loss_d: 0.003370
Epoch finished! Loss: 0.9277238615097538
Starting epoch 10/10.
0.0000 --- loss: 0.750237, loss_ss: 0.749468, loss_d: 0.000769
0.1608 --- loss: 0.951064, loss_ss: 0.950271, loss_d: 0.000793
0.3215 --- loss: 0.863628, loss_ss: 0.854999, loss_d: 0.008629
0.4823 --- loss: 1.018606, loss_ss: 1.017682, loss_d: 0.000924
0.6431 --- loss: 0.794505, loss_ss: 0.792370, loss_d: 0.002134
0.8039 --- loss: 0.861274, loss_ss: 0.856188, loss_d: 0.005086
0.9646 --- loss: 0.812973, loss_ss: 0.812440, loss_d: 0.000533
Epoch finished! Loss: 0.9052479286347667
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.38645833333333335
             precision    recall  f1-score   support

        0.0       0.68      0.66      0.67       237
        1.0       0.00      0.00      0.00       249
        2.0       0.38      0.50      0.43       210
        3.0       0.98      0.30      0.46       215
        4.0       0.12      0.94      0.21        49

avg / total       0.48      0.39      0.37       960
 


====== chp017-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  83.85  66.24   89.63  67.67     66.95
1  74.06   0.00  100.00   0.00      0.00
2  71.56  49.52   77.73  38.38     43.24
3  84.17  29.77   99.87  98.46     45.71
4  63.65  93.88   62.02  11.73     20.86
Total accuracy: 38.65%
Average sen: 47.88%
Average spec: 85.85%
Macro f1-score: 35.35%
Diagnosis acc on 60mins: 0.75
[0.99949837 0.99937528 0.03575092 0.99991524 0.99953234 0.3696861
 0.99740595 0.99722314]
pred: 0.7997984173707664, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp017-nsrr

=== Test on chp018-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.414280, loss_ss: 1.683782, loss_d: 0.730498
0.1610 --- loss: 1.992666, loss_ss: 1.601366, loss_d: 0.391300
0.3221 --- loss: 2.131376, loss_ss: 1.499144, loss_d: 0.632232
0.4831 --- loss: 2.127495, loss_ss: 1.471329, loss_d: 0.656166
0.6441 --- loss: 1.794688, loss_ss: 1.446424, loss_d: 0.348264
0.8052 --- loss: 2.012401, loss_ss: 1.389651, loss_d: 0.622749
0.9662 --- loss: 1.738214, loss_ss: 1.426711, loss_d: 0.311503
Epoch finished! Loss: 2.122950857685458
Starting epoch 2/10.
0.0000 --- loss: 1.926043, loss_ss: 1.384427, loss_d: 0.541616
0.1610 --- loss: 2.398090, loss_ss: 1.404189, loss_d: 0.993902
0.3221 --- loss: 1.637238, loss_ss: 1.275202, loss_d: 0.362035
0.4831 --- loss: 1.717089, loss_ss: 1.317102, loss_d: 0.399987
0.6441 --- loss: 1.786986, loss_ss: 1.331278, loss_d: 0.455708
0.8052 --- loss: 1.730635, loss_ss: 1.374482, loss_d: 0.356153
0.9662 --- loss: 1.861164, loss_ss: 1.405389, loss_d: 0.455775
Epoch finished! Loss: 1.8562533086346042
Starting epoch 3/10.
0.0000 --- loss: 1.706290, loss_ss: 1.345997, loss_d: 0.360292
0.1610 --- loss: 1.769900, loss_ss: 1.262125, loss_d: 0.507776
0.3221 --- loss: 1.617334, loss_ss: 1.258334, loss_d: 0.359000
0.4831 --- loss: 1.489143, loss_ss: 1.280067, loss_d: 0.209076
0.6441 --- loss: 1.736171, loss_ss: 1.205567, loss_d: 0.530605
0.8052 --- loss: 1.528767, loss_ss: 1.133459, loss_d: 0.395307
0.9662 --- loss: 1.427674, loss_ss: 1.262012, loss_d: 0.165663
Epoch finished! Loss: 1.568993128115131
Starting epoch 4/10.
0.0000 --- loss: 1.779845, loss_ss: 1.295307, loss_d: 0.484538
0.1610 --- loss: 1.240566, loss_ss: 1.079653, loss_d: 0.160913
0.3221 --- loss: 1.215824, loss_ss: 1.137872, loss_d: 0.077952
0.4831 --- loss: 1.444199, loss_ss: 1.207051, loss_d: 0.237148
0.6441 --- loss: 1.398139, loss_ss: 1.260192, loss_d: 0.137946
0.8052 --- loss: 1.262296, loss_ss: 1.166179, loss_d: 0.096117
0.9662 --- loss: 1.202115, loss_ss: 1.140662, loss_d: 0.061453
Epoch finished! Loss: 1.3213436026727
Starting epoch 5/10.
0.0000 --- loss: 1.127951, loss_ss: 1.097045, loss_d: 0.030906
0.1610 --- loss: 1.087189, loss_ss: 1.079517, loss_d: 0.007672
0.3221 --- loss: 1.424584, loss_ss: 1.193812, loss_d: 0.230772
0.4831 --- loss: 1.180415, loss_ss: 1.177629, loss_d: 0.002787
0.6441 --- loss: 1.085274, loss_ss: 1.053272, loss_d: 0.032002
0.8052 --- loss: 1.178223, loss_ss: 1.058141, loss_d: 0.120082
0.9662 --- loss: 1.795990, loss_ss: 1.281299, loss_d: 0.514690
Epoch finished! Loss: 1.1970557926162597
Starting epoch 6/10.
0.0000 --- loss: 1.147100, loss_ss: 1.100296, loss_d: 0.046804
0.1610 --- loss: 1.228746, loss_ss: 1.203821, loss_d: 0.024925
0.3221 --- loss: 1.148922, loss_ss: 1.144789, loss_d: 0.004133
0.4831 --- loss: 1.028700, loss_ss: 1.024824, loss_d: 0.003876
0.6441 --- loss: 0.962507, loss_ss: 0.947039, loss_d: 0.015468
0.8052 --- loss: 1.183924, loss_ss: 1.032889, loss_d: 0.151035
0.9662 --- loss: 1.112600, loss_ss: 0.982622, loss_d: 0.129978
Epoch finished! Loss: 1.107474051175579
Starting epoch 7/10.
0.0000 --- loss: 1.025691, loss_ss: 1.025437, loss_d: 0.000254
0.1610 --- loss: 0.922121, loss_ss: 0.916045, loss_d: 0.006075
0.3221 --- loss: 0.972965, loss_ss: 0.955507, loss_d: 0.017458
0.4831 --- loss: 1.081402, loss_ss: 1.080477, loss_d: 0.000925
0.6441 --- loss: 1.036828, loss_ss: 1.027627, loss_d: 0.009201
0.8052 --- loss: 1.278569, loss_ss: 1.159600, loss_d: 0.118969
0.9662 --- loss: 0.868125, loss_ss: 0.866313, loss_d: 0.001812
Epoch finished! Loss: 1.0537413310620092
Starting epoch 8/10.
0.0000 --- loss: 1.103483, loss_ss: 1.092400, loss_d: 0.011083
0.1610 --- loss: 1.066449, loss_ss: 1.065766, loss_d: 0.000684
0.3221 --- loss: 0.966414, loss_ss: 0.953707, loss_d: 0.012706
0.4831 --- loss: 1.057089, loss_ss: 1.051526, loss_d: 0.005563
0.6441 --- loss: 1.068544, loss_ss: 1.066462, loss_d: 0.002082
0.8052 --- loss: 0.883483, loss_ss: 0.880997, loss_d: 0.002485
0.9662 --- loss: 1.030029, loss_ss: 1.021973, loss_d: 0.008055
Epoch finished! Loss: 0.9869133435910747
Starting epoch 9/10.
0.0000 --- loss: 0.859792, loss_ss: 0.848179, loss_d: 0.011613
0.1610 --- loss: 0.868967, loss_ss: 0.868038, loss_d: 0.000928
0.3221 --- loss: 0.957727, loss_ss: 0.954935, loss_d: 0.002791
0.4831 --- loss: 0.916921, loss_ss: 0.908366, loss_d: 0.008555
0.6441 --- loss: 0.969007, loss_ss: 0.960776, loss_d: 0.008231
0.8052 --- loss: 1.010408, loss_ss: 1.007990, loss_d: 0.002418
0.9662 --- loss: 0.921279, loss_ss: 0.920843, loss_d: 0.000436
Epoch finished! Loss: 0.958566221498674
Starting epoch 10/10.
0.0000 --- loss: 0.975729, loss_ss: 0.975125, loss_d: 0.000604
0.1610 --- loss: 0.766805, loss_ss: 0.766505, loss_d: 0.000300
0.3221 --- loss: 0.828109, loss_ss: 0.821004, loss_d: 0.007105
0.4831 --- loss: 0.806298, loss_ss: 0.803186, loss_d: 0.003112
0.6441 --- loss: 0.740309, loss_ss: 0.739387, loss_d: 0.000922
0.8052 --- loss: 1.013866, loss_ss: 0.914197, loss_d: 0.099669
0.9662 --- loss: 1.262462, loss_ss: 1.262272, loss_d: 0.000190
Epoch finished! Loss: 0.9664354007090291
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4064814814814815
             precision    recall  f1-score   support

        0.0       0.86      0.73      0.79       138
        1.0       0.00      0.00      0.00       117
        2.0       0.16      0.91      0.28       119
        3.0       1.00      0.04      0.08       363
        4.0       0.76      0.62      0.69       343

avg / total       0.71      0.41      0.38      1080
 


====== chp018-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  95.09  73.19   98.30   86.32     79.22
1  89.17   0.00  100.00    0.00      0.00
2  47.31  90.76   41.94   16.22     27.52
3  67.87   4.41  100.00  100.00      8.44
4  81.85  62.39   90.91   76.16     68.59
Total accuracy: 40.65%
Average sen: 46.15%
Average spec: 86.23%
Macro f1-score: 36.75%
Diagnosis acc on 60mins: 1.0
[0.99999845 0.99999654 0.99984181 0.95697963 0.99999988 0.91411448
 0.97403032 0.9993636  0.98477834]
pred: 0.9810114502906799, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp018-nsrr

=== Test on chp019-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.514490, loss_ss: 1.839302, loss_d: 0.675188
0.1605 --- loss: 2.242476, loss_ss: 1.702229, loss_d: 0.540247
0.3210 --- loss: 2.129974, loss_ss: 1.609650, loss_d: 0.520324
0.4815 --- loss: 2.115224, loss_ss: 1.601949, loss_d: 0.513274
0.6421 --- loss: 2.023310, loss_ss: 1.647031, loss_d: 0.376279
0.8026 --- loss: 2.128699, loss_ss: 1.496663, loss_d: 0.632036
0.9631 --- loss: 2.156230, loss_ss: 1.495103, loss_d: 0.661127
Epoch finished! Loss: 2.2175232556558426
Starting epoch 2/10.
0.0000 --- loss: 1.948654, loss_ss: 1.487988, loss_d: 0.460666
0.1605 --- loss: 1.891505, loss_ss: 1.498842, loss_d: 0.392663
0.3210 --- loss: 1.751210, loss_ss: 1.477078, loss_d: 0.274132
0.4815 --- loss: 1.969610, loss_ss: 1.478034, loss_d: 0.491576
0.6421 --- loss: 1.774310, loss_ss: 1.383042, loss_d: 0.391268
0.8026 --- loss: 1.657842, loss_ss: 1.372676, loss_d: 0.285166
0.9631 --- loss: 2.379443, loss_ss: 1.415306, loss_d: 0.964137
Epoch finished! Loss: 1.9619570412943441
Starting epoch 3/10.
0.0000 --- loss: 1.652313, loss_ss: 1.399335, loss_d: 0.252978
0.1605 --- loss: 1.590600, loss_ss: 1.372069, loss_d: 0.218531
0.3210 --- loss: 1.462869, loss_ss: 1.283520, loss_d: 0.179348
0.4815 --- loss: 1.732783, loss_ss: 1.397675, loss_d: 0.335108
0.6421 --- loss: 2.504956, loss_ss: 1.457757, loss_d: 1.047199
0.8026 --- loss: 1.619934, loss_ss: 1.304532, loss_d: 0.315402
0.9631 --- loss: 2.136435, loss_ss: 1.381310, loss_d: 0.755125
Epoch finished! Loss: 1.7177523451466714
Starting epoch 4/10.
0.0000 --- loss: 1.616839, loss_ss: 1.315097, loss_d: 0.301743
0.1605 --- loss: 1.413656, loss_ss: 1.364561, loss_d: 0.049095
0.3210 --- loss: 1.498670, loss_ss: 1.224396, loss_d: 0.274273
0.4815 --- loss: 1.445667, loss_ss: 1.332580, loss_d: 0.113086
0.6421 --- loss: 1.601014, loss_ss: 1.294268, loss_d: 0.306746
0.8026 --- loss: 1.387113, loss_ss: 1.306452, loss_d: 0.080661
0.9631 --- loss: 1.428623, loss_ss: 1.331786, loss_d: 0.096837
Epoch finished! Loss: 1.5240454385357518
Starting epoch 5/10.
0.0000 --- loss: 1.308680, loss_ss: 1.292736, loss_d: 0.015944
0.1605 --- loss: 1.291686, loss_ss: 1.269315, loss_d: 0.022371
0.3210 --- loss: 1.332085, loss_ss: 1.299754, loss_d: 0.032331
0.4815 --- loss: 1.565814, loss_ss: 1.229321, loss_d: 0.336493
0.6421 --- loss: 1.216946, loss_ss: 1.152840, loss_d: 0.064106
0.8026 --- loss: 1.364651, loss_ss: 1.262522, loss_d: 0.102130
0.9631 --- loss: 1.236471, loss_ss: 1.180569, loss_d: 0.055902
Epoch finished! Loss: 1.3865993484374015
Starting epoch 6/10.
0.0000 --- loss: 1.225374, loss_ss: 1.210288, loss_d: 0.015086
0.1605 --- loss: 1.228652, loss_ss: 1.184134, loss_d: 0.044518
0.3210 --- loss: 1.338600, loss_ss: 1.316060, loss_d: 0.022539
0.4815 --- loss: 1.283648, loss_ss: 1.252743, loss_d: 0.030905
0.6421 --- loss: 1.320696, loss_ss: 1.284484, loss_d: 0.036212
0.8026 --- loss: 2.000445, loss_ss: 1.203287, loss_d: 0.797158
0.9631 --- loss: 1.229895, loss_ss: 1.227196, loss_d: 0.002699
Epoch finished! Loss: 1.2968600546160052
Starting epoch 7/10.
0.0000 --- loss: 1.204609, loss_ss: 1.199866, loss_d: 0.004744
0.1605 --- loss: 1.265476, loss_ss: 1.224505, loss_d: 0.040971
0.3210 --- loss: 1.415182, loss_ss: 1.142744, loss_d: 0.272438
0.4815 --- loss: 1.287802, loss_ss: 1.092911, loss_d: 0.194891
0.6421 --- loss: 1.066205, loss_ss: 1.058855, loss_d: 0.007350
0.8026 --- loss: 1.276414, loss_ss: 1.189888, loss_d: 0.086527
0.9631 --- loss: 1.353513, loss_ss: 1.343373, loss_d: 0.010141
Epoch finished! Loss: 1.2412336391787375
Starting epoch 8/10.
0.0000 --- loss: 1.151457, loss_ss: 1.110429, loss_d: 0.041028
0.1605 --- loss: 1.043705, loss_ss: 1.041120, loss_d: 0.002586
0.3210 --- loss: 1.172680, loss_ss: 1.129066, loss_d: 0.043614
0.4815 --- loss: 1.147894, loss_ss: 1.125370, loss_d: 0.022523
0.6421 --- loss: 1.163120, loss_ss: 1.162606, loss_d: 0.000514
0.8026 --- loss: 1.094017, loss_ss: 1.088946, loss_d: 0.005071
0.9631 --- loss: 1.080304, loss_ss: 1.076025, loss_d: 0.004280
Epoch finished! Loss: 1.1694264902222542
Starting epoch 9/10.
0.0000 --- loss: 1.098700, loss_ss: 1.097913, loss_d: 0.000787
0.1605 --- loss: 1.158789, loss_ss: 1.153508, loss_d: 0.005281
0.3210 --- loss: 1.094735, loss_ss: 1.092295, loss_d: 0.002440
0.4815 --- loss: 1.104433, loss_ss: 1.042354, loss_d: 0.062079
0.6421 --- loss: 0.989475, loss_ss: 0.986579, loss_d: 0.002896
0.8026 --- loss: 0.950334, loss_ss: 0.941225, loss_d: 0.009109
0.9631 --- loss: 2.011700, loss_ss: 1.124560, loss_d: 0.887140
Epoch finished! Loss: 1.1232832641370836
Starting epoch 10/10.
0.0000 --- loss: 0.979159, loss_ss: 0.977886, loss_d: 0.001274
0.1605 --- loss: 0.966414, loss_ss: 0.938466, loss_d: 0.027948
0.3210 --- loss: 1.042079, loss_ss: 1.015915, loss_d: 0.026165
0.4815 --- loss: 0.994157, loss_ss: 0.991388, loss_d: 0.002769
0.6421 --- loss: 1.007742, loss_ss: 0.914174, loss_d: 0.093568
0.8026 --- loss: 0.984682, loss_ss: 0.863285, loss_d: 0.121397
0.9631 --- loss: 0.939894, loss_ss: 0.892517, loss_d: 0.047378
Epoch finished! Loss: 1.047890660262877
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6404761904761904
             precision    recall  f1-score   support

        0.0       0.22      0.53      0.31        36
        1.0       0.00      0.00      0.00        96
        2.0       0.64      0.67      0.65       215
        3.0       1.00      0.72      0.84       223
        4.0       0.58      0.80      0.67       270

avg / total       0.63      0.64      0.62       840
 


====== chp019-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  89.88  52.78   91.54   21.84     30.89
1  88.57   0.00  100.00    0.00      0.00
2  82.02  66.51   87.36   64.41     65.45
3  92.62  72.20  100.00  100.00     83.85
4  75.00  79.63   72.81   58.11     67.19
Total accuracy: 64.05%
Average sen: 54.22%
Average spec: 90.34%
Macro f1-score: 49.48%
Diagnosis acc on 60mins: 1.0
[0.99999917 0.98462361 0.99500614 0.57597888 0.98962575 0.97621018
 0.98496765]
pred: 0.9294873390878949, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp019-nsrr

=== Test on chp020-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.418106, loss_ss: 1.727531, loss_d: 0.690575
0.1610 --- loss: 1.819229, loss_ss: 1.561151, loss_d: 0.258078
0.3221 --- loss: 2.341876, loss_ss: 1.533073, loss_d: 0.808803
0.4831 --- loss: 2.147724, loss_ss: 1.444375, loss_d: 0.703349
0.6441 --- loss: 1.978026, loss_ss: 1.404378, loss_d: 0.573648
0.8052 --- loss: 1.704293, loss_ss: 1.316139, loss_d: 0.388153
0.9662 --- loss: 1.890068, loss_ss: 1.395209, loss_d: 0.494859
Epoch finished! Loss: 2.1536051573291903
Starting epoch 2/10.
0.0000 --- loss: 2.008248, loss_ss: 1.533197, loss_d: 0.475051
0.1610 --- loss: 1.810470, loss_ss: 1.369179, loss_d: 0.441291
0.3221 --- loss: 2.030655, loss_ss: 1.363898, loss_d: 0.666757
0.4831 --- loss: 1.556021, loss_ss: 1.212779, loss_d: 0.343242
0.6441 --- loss: 1.904708, loss_ss: 1.491638, loss_d: 0.413070
0.8052 --- loss: 1.680660, loss_ss: 1.264511, loss_d: 0.416149
0.9662 --- loss: 1.509728, loss_ss: 1.200691, loss_d: 0.309038
Epoch finished! Loss: 1.8193022916393895
Starting epoch 3/10.
0.0000 --- loss: 1.440730, loss_ss: 1.248875, loss_d: 0.191855
0.1610 --- loss: 1.537369, loss_ss: 1.165523, loss_d: 0.371847
0.3221 --- loss: 1.686115, loss_ss: 1.291736, loss_d: 0.394380
0.4831 --- loss: 1.801463, loss_ss: 1.185266, loss_d: 0.616196
0.6441 --- loss: 1.690410, loss_ss: 1.303358, loss_d: 0.387051
0.8052 --- loss: 1.382366, loss_ss: 1.099920, loss_d: 0.282447
0.9662 --- loss: 1.498112, loss_ss: 1.164526, loss_d: 0.333587
Epoch finished! Loss: 1.6211382515968815
Starting epoch 4/10.
0.0000 --- loss: 1.349081, loss_ss: 1.186378, loss_d: 0.162703
0.1610 --- loss: 1.202240, loss_ss: 1.141294, loss_d: 0.060946
0.3221 --- loss: 1.659374, loss_ss: 1.275123, loss_d: 0.384251
0.4831 --- loss: 1.200875, loss_ss: 1.150233, loss_d: 0.050643
0.6441 --- loss: 1.110831, loss_ss: 1.077057, loss_d: 0.033774
0.8052 --- loss: 1.209846, loss_ss: 1.196231, loss_d: 0.013615
0.9662 --- loss: 1.643266, loss_ss: 1.536130, loss_d: 0.107136
Epoch finished! Loss: 1.357689876710215
Starting epoch 5/10.
0.0000 --- loss: 1.155327, loss_ss: 1.075635, loss_d: 0.079691
0.1610 --- loss: 1.129723, loss_ss: 1.100966, loss_d: 0.028757
0.3221 --- loss: 1.492238, loss_ss: 1.268438, loss_d: 0.223800
0.4831 --- loss: 1.340928, loss_ss: 1.258876, loss_d: 0.082052
0.6441 --- loss: 1.201222, loss_ss: 1.180861, loss_d: 0.020361
0.8052 --- loss: 1.408371, loss_ss: 0.978391, loss_d: 0.429980
0.9662 --- loss: 1.214734, loss_ss: 1.074368, loss_d: 0.140366
Epoch finished! Loss: 1.3094195627397107
Starting epoch 6/10.
0.0000 --- loss: 0.947351, loss_ss: 0.928442, loss_d: 0.018909
0.1610 --- loss: 1.259350, loss_ss: 1.121169, loss_d: 0.138181
0.3221 --- loss: 1.059879, loss_ss: 1.017693, loss_d: 0.042186
0.4831 --- loss: 1.503973, loss_ss: 1.258830, loss_d: 0.245142
0.6441 --- loss: 0.945962, loss_ss: 0.883120, loss_d: 0.062842
0.8052 --- loss: 1.009311, loss_ss: 1.004447, loss_d: 0.004864
0.9662 --- loss: 1.157888, loss_ss: 1.061899, loss_d: 0.095989
Epoch finished! Loss: 1.1585456450139322
Starting epoch 7/10.
0.0000 --- loss: 1.045225, loss_ss: 1.039759, loss_d: 0.005466
0.1610 --- loss: 1.153727, loss_ss: 1.143490, loss_d: 0.010236
0.3221 --- loss: 1.001969, loss_ss: 0.986750, loss_d: 0.015218
0.4831 --- loss: 1.406994, loss_ss: 1.397054, loss_d: 0.009941
0.6441 --- loss: 1.134644, loss_ss: 1.128439, loss_d: 0.006204
0.8052 --- loss: 0.981822, loss_ss: 0.980096, loss_d: 0.001726
0.9662 --- loss: 1.218137, loss_ss: 1.210159, loss_d: 0.007978
Epoch finished! Loss: 1.0856837841772264
Starting epoch 8/10.
0.0000 --- loss: 0.918130, loss_ss: 0.914411, loss_d: 0.003718
0.1610 --- loss: 1.007941, loss_ss: 1.005145, loss_d: 0.002796
0.3221 --- loss: 0.973889, loss_ss: 0.968147, loss_d: 0.005742
0.4831 --- loss: 0.943187, loss_ss: 0.934232, loss_d: 0.008955
0.6441 --- loss: 1.153624, loss_ss: 1.151954, loss_d: 0.001670
0.8052 --- loss: 0.897285, loss_ss: 0.894798, loss_d: 0.002487
0.9662 --- loss: 1.034936, loss_ss: 1.002467, loss_d: 0.032470
Epoch finished! Loss: 1.0409032010263013
Starting epoch 9/10.
0.0000 --- loss: 0.868838, loss_ss: 0.864976, loss_d: 0.003862
0.1610 --- loss: 1.043672, loss_ss: 1.041685, loss_d: 0.001987
0.3221 --- loss: 0.908808, loss_ss: 0.889252, loss_d: 0.019557
0.4831 --- loss: 0.966520, loss_ss: 0.965612, loss_d: 0.000907
0.6441 --- loss: 0.980211, loss_ss: 0.977030, loss_d: 0.003181
0.8052 --- loss: 1.009578, loss_ss: 1.008213, loss_d: 0.001365
0.9662 --- loss: 0.977427, loss_ss: 0.973726, loss_d: 0.003701
Epoch finished! Loss: 1.0048560567440525
Starting epoch 10/10.
0.0000 --- loss: 0.775825, loss_ss: 0.770827, loss_d: 0.004998
0.1610 --- loss: 0.933719, loss_ss: 0.927044, loss_d: 0.006675
0.3221 --- loss: 0.813247, loss_ss: 0.809551, loss_d: 0.003696
0.4831 --- loss: 0.843494, loss_ss: 0.842080, loss_d: 0.001414
0.6441 --- loss: 1.014117, loss_ss: 1.005147, loss_d: 0.008970
0.8052 --- loss: 1.002477, loss_ss: 0.999495, loss_d: 0.002982
0.9662 --- loss: 0.856478, loss_ss: 0.855744, loss_d: 0.000734
Epoch finished! Loss: 0.9712259836735264
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5398148148148149
             precision    recall  f1-score   support

        0.0       0.95      0.24      0.39       237
        1.0       0.41      0.67      0.51       200
        2.0       0.64      0.87      0.74       354
        3.0       0.33      0.02      0.04       159
        4.0       0.40      0.62      0.49       130

avg / total       0.59      0.54      0.48      1080
 


====== chp020-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  83.15  24.47   99.64  95.08     38.93
1  75.93  67.00   77.95  40.85     50.76
2  79.44  87.01   75.76  63.64     73.51
3  85.00   1.89   99.35  33.33      3.57
4  84.44  61.54   87.58  40.40     48.78
Total accuracy: 53.98%
Average sen: 48.38%
Average spec: 88.06%
Macro f1-score: 43.11%
Diagnosis acc on 60mins: 1.0
[1.         0.99986124 0.99984598 0.99997008 0.99999809 0.99998784
 0.99999738 0.99980146 0.99999988]
pred: 0.9999402165412903, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp020-nsrr

=== Test on chp022-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.432590, loss_ss: 1.758419, loss_d: 0.674172
0.1613 --- loss: 2.385645, loss_ss: 1.649538, loss_d: 0.736108
0.3226 --- loss: 2.566070, loss_ss: 1.641829, loss_d: 0.924241
0.4839 --- loss: 1.836481, loss_ss: 1.575786, loss_d: 0.260695
0.6452 --- loss: 2.125193, loss_ss: 1.579086, loss_d: 0.546107
0.8065 --- loss: 2.047492, loss_ss: 1.442389, loss_d: 0.605103
0.9677 --- loss: 2.316781, loss_ss: 1.472784, loss_d: 0.843998
Epoch finished! Loss: 2.232038374807014
Starting epoch 2/10.
0.0000 --- loss: 1.912629, loss_ss: 1.538136, loss_d: 0.374492
0.1613 --- loss: 1.834722, loss_ss: 1.482572, loss_d: 0.352151
0.3226 --- loss: 2.073091, loss_ss: 1.425197, loss_d: 0.647894
0.4839 --- loss: 1.893075, loss_ss: 1.423801, loss_d: 0.469274
0.6452 --- loss: 1.857776, loss_ss: 1.450196, loss_d: 0.407580
0.8065 --- loss: 1.992614, loss_ss: 1.461706, loss_d: 0.530908
0.9677 --- loss: 1.886689, loss_ss: 1.334847, loss_d: 0.551841
Epoch finished! Loss: 1.9523691544767285
Starting epoch 3/10.
0.0000 --- loss: 1.508706, loss_ss: 1.338386, loss_d: 0.170321
0.1613 --- loss: 1.732021, loss_ss: 1.390875, loss_d: 0.341145
0.3226 --- loss: 1.428132, loss_ss: 1.358848, loss_d: 0.069285
0.4839 --- loss: 1.513435, loss_ss: 1.284792, loss_d: 0.228643
0.6452 --- loss: 1.842058, loss_ss: 1.266381, loss_d: 0.575677
0.8065 --- loss: 1.544820, loss_ss: 1.290394, loss_d: 0.254426
0.9677 --- loss: 1.512951, loss_ss: 1.250578, loss_d: 0.262372
Epoch finished! Loss: 1.672928348916476
Starting epoch 4/10.
0.0000 --- loss: 1.380260, loss_ss: 1.322198, loss_d: 0.058062
0.1613 --- loss: 1.445859, loss_ss: 1.302346, loss_d: 0.143513
0.3226 --- loss: 1.331631, loss_ss: 1.262524, loss_d: 0.069107
0.4839 --- loss: 1.294094, loss_ss: 1.232712, loss_d: 0.061382
0.6452 --- loss: 1.273376, loss_ss: 1.215914, loss_d: 0.057462
0.8065 --- loss: 1.606948, loss_ss: 1.138250, loss_d: 0.468698
0.9677 --- loss: 1.178716, loss_ss: 1.166092, loss_d: 0.012624
Epoch finished! Loss: 1.3869520797104131
Starting epoch 5/10.
0.0000 --- loss: 1.283302, loss_ss: 1.250954, loss_d: 0.032348
0.1613 --- loss: 1.113287, loss_ss: 1.101003, loss_d: 0.012285
0.3226 --- loss: 1.110002, loss_ss: 1.105896, loss_d: 0.004106
0.4839 --- loss: 1.183752, loss_ss: 1.073367, loss_d: 0.110385
0.6452 --- loss: 1.184110, loss_ss: 1.168359, loss_d: 0.015751
0.8065 --- loss: 0.947744, loss_ss: 0.932334, loss_d: 0.015410
0.9677 --- loss: 1.021416, loss_ss: 1.008373, loss_d: 0.013043
Epoch finished! Loss: 1.2027082111014695
Starting epoch 6/10.
0.0000 --- loss: 1.262270, loss_ss: 1.253919, loss_d: 0.008351
0.1613 --- loss: 1.009204, loss_ss: 1.007506, loss_d: 0.001698
0.3226 --- loss: 0.970628, loss_ss: 0.955593, loss_d: 0.015035
0.4839 --- loss: 0.982221, loss_ss: 0.979555, loss_d: 0.002666
0.6452 --- loss: 0.994238, loss_ss: 0.955231, loss_d: 0.039007
0.8065 --- loss: 1.060664, loss_ss: 1.009807, loss_d: 0.050857
0.9677 --- loss: 0.990497, loss_ss: 0.980500, loss_d: 0.009998
Epoch finished! Loss: 1.1390401642830645
Starting epoch 7/10.
0.0000 --- loss: 1.288902, loss_ss: 1.284000, loss_d: 0.004903
0.1613 --- loss: 1.006715, loss_ss: 1.004297, loss_d: 0.002418
0.3226 --- loss: 1.089911, loss_ss: 0.967701, loss_d: 0.122211
0.4839 --- loss: 0.995785, loss_ss: 0.965338, loss_d: 0.030447
0.6452 --- loss: 1.124801, loss_ss: 0.889228, loss_d: 0.235573
0.8065 --- loss: 0.983398, loss_ss: 0.937079, loss_d: 0.046319
0.9677 --- loss: 0.944659, loss_ss: 0.910233, loss_d: 0.034426
Epoch finished! Loss: 1.027361220023671
Starting epoch 8/10.
0.0000 --- loss: 1.081001, loss_ss: 1.080372, loss_d: 0.000628
0.1613 --- loss: 0.955577, loss_ss: 0.951604, loss_d: 0.003973
0.3226 --- loss: 1.045752, loss_ss: 1.037601, loss_d: 0.008152
0.4839 --- loss: 0.884191, loss_ss: 0.883949, loss_d: 0.000242
0.6452 --- loss: 0.867236, loss_ss: 0.864997, loss_d: 0.002240
0.8065 --- loss: 1.117705, loss_ss: 1.117604, loss_d: 0.000101
0.9677 --- loss: 1.054898, loss_ss: 1.054174, loss_d: 0.000724
Epoch finished! Loss: 0.9592879424329663
Starting epoch 9/10.
0.0000 --- loss: 0.867112, loss_ss: 0.866615, loss_d: 0.000497
0.1613 --- loss: 0.876194, loss_ss: 0.876055, loss_d: 0.000139
0.3226 --- loss: 0.808747, loss_ss: 0.797650, loss_d: 0.011097
0.4839 --- loss: 0.983550, loss_ss: 0.914691, loss_d: 0.068858
0.6452 --- loss: 1.180243, loss_ss: 1.179691, loss_d: 0.000552
0.8065 --- loss: 0.845921, loss_ss: 0.844889, loss_d: 0.001033
0.9677 --- loss: 0.993020, loss_ss: 0.992209, loss_d: 0.000811
Epoch finished! Loss: 0.9162486791610718
Starting epoch 10/10.
0.0000 --- loss: 0.869999, loss_ss: 0.869189, loss_d: 0.000810
0.1613 --- loss: 1.049067, loss_ss: 1.039967, loss_d: 0.009100
0.3226 --- loss: 0.761069, loss_ss: 0.759922, loss_d: 0.001147
0.4839 --- loss: 0.861310, loss_ss: 0.859873, loss_d: 0.001437
0.6452 --- loss: 0.770662, loss_ss: 0.768979, loss_d: 0.001683
0.8065 --- loss: 0.821523, loss_ss: 0.821248, loss_d: 0.000274
0.9677 --- loss: 0.800523, loss_ss: 0.766783, loss_d: 0.033741
Epoch finished! Loss: 0.915831127127663
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.64
             precision    recall  f1-score   support

        0.0       0.52      0.96      0.67       246
        1.0       0.76      0.14      0.24       262
        2.0       0.74      0.94      0.83       452
        3.0       0.96      0.23      0.38       107
        4.0       0.46      0.32      0.37       133

avg / total       0.69      0.64      0.58      1200
 


====== chp022-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  80.75  96.34   76.73  51.63     67.23
1  80.25  14.12   98.72  75.51     23.79
2  85.58  94.47   80.21  74.26     83.15
3  93.08  23.36   99.91  96.15     37.59
4  88.33  31.58   95.41  46.15     37.50
Total accuracy: 64.00%
Average sen: 51.98%
Average spec: 90.20%
Macro f1-score: 49.86%
Diagnosis acc on 60mins: 1.0
[1.         0.98667485 0.99997866 0.99964309 0.98263967 0.95297348
 0.99998033 0.982602   0.99677151 0.93715692]
pred: 0.9838420510292053, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp022-nsrr

=== Test on chp024-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.474577, loss_ss: 1.761407, loss_d: 0.713169
0.1610 --- loss: 2.354474, loss_ss: 1.611577, loss_d: 0.742898
0.3221 --- loss: 2.246622, loss_ss: 1.508744, loss_d: 0.737878
0.4831 --- loss: 1.940773, loss_ss: 1.489574, loss_d: 0.451199
0.6441 --- loss: 1.860686, loss_ss: 1.370945, loss_d: 0.489741
0.8052 --- loss: 2.029565, loss_ss: 1.393458, loss_d: 0.636107
0.9662 --- loss: 1.931471, loss_ss: 1.377015, loss_d: 0.554456
Epoch finished! Loss: 2.1627890371507212
Starting epoch 2/10.
0.0000 --- loss: 2.045042, loss_ss: 1.501595, loss_d: 0.543447
0.1610 --- loss: 1.616956, loss_ss: 1.367427, loss_d: 0.249529
0.3221 --- loss: 1.757296, loss_ss: 1.420096, loss_d: 0.337200
0.4831 --- loss: 1.755324, loss_ss: 1.306244, loss_d: 0.449080
0.6441 --- loss: 1.814497, loss_ss: 1.409701, loss_d: 0.404796
0.8052 --- loss: 1.977238, loss_ss: 1.379253, loss_d: 0.597985
0.9662 --- loss: 1.948540, loss_ss: 1.453637, loss_d: 0.494903
Epoch finished! Loss: 1.8766148071135245
Starting epoch 3/10.
0.0000 --- loss: 2.193135, loss_ss: 1.271125, loss_d: 0.922009
0.1610 --- loss: 1.477500, loss_ss: 1.257455, loss_d: 0.220045
0.3221 --- loss: 1.449161, loss_ss: 1.199885, loss_d: 0.249276
0.4831 --- loss: 2.050159, loss_ss: 1.324164, loss_d: 0.725994
0.6441 --- loss: 1.707788, loss_ss: 1.398597, loss_d: 0.309191
0.8052 --- loss: 1.593089, loss_ss: 1.341441, loss_d: 0.251649
0.9662 --- loss: 1.541268, loss_ss: 1.243441, loss_d: 0.297827
Epoch finished! Loss: 1.678754614245507
Starting epoch 4/10.
0.0000 --- loss: 1.369631, loss_ss: 1.304061, loss_d: 0.065570
0.1610 --- loss: 1.458857, loss_ss: 1.180431, loss_d: 0.278426
0.3221 --- loss: 1.710177, loss_ss: 1.250472, loss_d: 0.459704
0.4831 --- loss: 1.391613, loss_ss: 1.290093, loss_d: 0.101520
0.6441 --- loss: 1.443572, loss_ss: 1.144932, loss_d: 0.298639
0.8052 --- loss: 1.174124, loss_ss: 1.132260, loss_d: 0.041865
0.9662 --- loss: 1.194303, loss_ss: 1.135817, loss_d: 0.058486
Epoch finished! Loss: 1.4154860723403193
Starting epoch 5/10.
0.0000 --- loss: 1.118457, loss_ss: 1.088269, loss_d: 0.030188
0.1610 --- loss: 1.145765, loss_ss: 1.123712, loss_d: 0.022053
0.3221 --- loss: 1.382733, loss_ss: 1.366525, loss_d: 0.016209
0.4831 --- loss: 1.131894, loss_ss: 1.060777, loss_d: 0.071117
0.6441 --- loss: 1.033262, loss_ss: 1.022844, loss_d: 0.010418
0.8052 --- loss: 1.163782, loss_ss: 1.157409, loss_d: 0.006373
0.9662 --- loss: 1.167301, loss_ss: 1.153701, loss_d: 0.013600
Epoch finished! Loss: 1.2201446660103337
Starting epoch 6/10.
0.0000 --- loss: 1.170957, loss_ss: 1.080814, loss_d: 0.090143
0.1610 --- loss: 1.200861, loss_ss: 1.090028, loss_d: 0.110833
0.3221 --- loss: 1.134686, loss_ss: 1.085448, loss_d: 0.049238
0.4831 --- loss: 1.163123, loss_ss: 1.147051, loss_d: 0.016073
0.6441 --- loss: 0.938597, loss_ss: 0.937628, loss_d: 0.000969
0.8052 --- loss: 0.913963, loss_ss: 0.895494, loss_d: 0.018469
0.9662 --- loss: 0.989709, loss_ss: 0.988082, loss_d: 0.001628
Epoch finished! Loss: 1.1369996493862522
Starting epoch 7/10.
0.0000 --- loss: 0.956968, loss_ss: 0.919504, loss_d: 0.037464
0.1610 --- loss: 1.153079, loss_ss: 0.953464, loss_d: 0.199615
0.3221 --- loss: 1.035399, loss_ss: 1.032428, loss_d: 0.002971
0.4831 --- loss: 1.169514, loss_ss: 1.163060, loss_d: 0.006454
0.6441 --- loss: 0.933349, loss_ss: 0.909035, loss_d: 0.024314
0.8052 --- loss: 1.172051, loss_ss: 1.135696, loss_d: 0.036355
0.9662 --- loss: 1.138715, loss_ss: 1.121649, loss_d: 0.017066
Epoch finished! Loss: 1.1019564040245549
Starting epoch 8/10.
0.0000 --- loss: 1.108507, loss_ss: 1.052357, loss_d: 0.056150
0.1610 --- loss: 1.173845, loss_ss: 1.116697, loss_d: 0.057148
0.3221 --- loss: 1.042702, loss_ss: 0.942851, loss_d: 0.099851
0.4831 --- loss: 0.826304, loss_ss: 0.823261, loss_d: 0.003043
0.6441 --- loss: 1.049010, loss_ss: 0.864734, loss_d: 0.184276
0.8052 --- loss: 0.968140, loss_ss: 0.966197, loss_d: 0.001943
0.9662 --- loss: 1.065121, loss_ss: 1.038794, loss_d: 0.026328
Epoch finished! Loss: 1.0929703645167812
Starting epoch 9/10.
0.0000 --- loss: 0.925140, loss_ss: 0.919993, loss_d: 0.005147
0.1610 --- loss: 1.115239, loss_ss: 1.062891, loss_d: 0.052348
0.3221 --- loss: 1.454151, loss_ss: 1.152234, loss_d: 0.301917
0.4831 --- loss: 0.938574, loss_ss: 0.830273, loss_d: 0.108301
0.6441 --- loss: 0.856600, loss_ss: 0.847957, loss_d: 0.008643
0.8052 --- loss: 1.162598, loss_ss: 1.088716, loss_d: 0.073882
0.9662 --- loss: 1.031770, loss_ss: 1.004741, loss_d: 0.027029
Epoch finished! Loss: 1.0983613662181362
Starting epoch 10/10.
0.0000 --- loss: 1.026737, loss_ss: 1.019179, loss_d: 0.007558
0.1610 --- loss: 0.943736, loss_ss: 0.924455, loss_d: 0.019281
0.3221 --- loss: 0.962523, loss_ss: 0.946231, loss_d: 0.016292
0.4831 --- loss: 0.947145, loss_ss: 0.911420, loss_d: 0.035725
0.6441 --- loss: 0.836881, loss_ss: 0.834052, loss_d: 0.002829
0.8052 --- loss: 1.114983, loss_ss: 0.948810, loss_d: 0.166174
0.9662 --- loss: 0.867010, loss_ss: 0.846652, loss_d: 0.020358
Epoch finished! Loss: 1.0263074684527613
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.29907407407407405
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       232
        1.0       0.17      0.31      0.22       179
        2.0       0.25      0.25      0.25       216
        3.0       1.00      0.35      0.52       339
        4.0       0.22      0.82      0.35       114

avg / total       0.42      0.30      0.29      1080
 


====== chp024-nsrr ======

The f1-score of  0  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  78.43   0.00   99.88    0.00      0.00
1  63.89  30.73   70.48   17.13     22.00
2  70.19  25.00   81.48   25.23     25.12
3  79.72  35.40  100.00  100.00     52.29
4  67.59  82.46   65.84   22.17     34.94
Total accuracy: 29.91%
Average sen: 34.72%
Average spec: 83.54%
Macro f1-score: 26.87%
Diagnosis acc on 60mins: 1.0
[0.95652604 0.9988488  0.9999342  0.99745935 0.99997747 0.99896383
 0.99997854 0.99993873 0.99998701]
pred: 0.994623773627811, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp024-nsrr

=== Test on chp025-nsrr. train_data(627), test_data(3) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.470580, loss_ss: 1.713303, loss_d: 0.757277
0.1595 --- loss: 2.282856, loss_ss: 1.559985, loss_d: 0.722871
0.3190 --- loss: 2.010953, loss_ss: 1.450975, loss_d: 0.559979
0.4785 --- loss: 1.758021, loss_ss: 1.410993, loss_d: 0.347028
0.6380 --- loss: 1.953572, loss_ss: 1.324628, loss_d: 0.628945
0.7974 --- loss: 2.006085, loss_ss: 1.515174, loss_d: 0.490911
0.9569 --- loss: 1.889416, loss_ss: 1.319200, loss_d: 0.570216
Epoch finished! Loss: 2.112505216752329
Starting epoch 2/10.
0.0000 --- loss: 1.990501, loss_ss: 1.419756, loss_d: 0.570745
0.1595 --- loss: 2.013616, loss_ss: 1.446203, loss_d: 0.567413
0.3190 --- loss: 1.676646, loss_ss: 1.409316, loss_d: 0.267331
0.4785 --- loss: 1.825836, loss_ss: 1.382587, loss_d: 0.443249
0.6380 --- loss: 1.773639, loss_ss: 1.376572, loss_d: 0.397067
0.7974 --- loss: 1.806830, loss_ss: 1.352759, loss_d: 0.454071
0.9569 --- loss: 1.631840, loss_ss: 1.201982, loss_d: 0.429858
Epoch finished! Loss: 1.785914171126581
Starting epoch 3/10.
0.0000 --- loss: 1.532334, loss_ss: 1.250741, loss_d: 0.281593
0.1595 --- loss: 1.304874, loss_ss: 1.194257, loss_d: 0.110617
0.3190 --- loss: 1.745257, loss_ss: 1.253524, loss_d: 0.491733
0.4785 --- loss: 2.107500, loss_ss: 1.237874, loss_d: 0.869626
0.6380 --- loss: 1.521783, loss_ss: 1.266377, loss_d: 0.255407
0.7974 --- loss: 1.419605, loss_ss: 1.256038, loss_d: 0.163567
0.9569 --- loss: 1.611792, loss_ss: 1.319427, loss_d: 0.292366
Epoch finished! Loss: 1.5658480178925298
Starting epoch 4/10.
0.0000 --- loss: 1.427526, loss_ss: 1.262043, loss_d: 0.165483
0.1595 --- loss: 1.213330, loss_ss: 1.131106, loss_d: 0.082224
0.3190 --- loss: 1.360336, loss_ss: 1.199377, loss_d: 0.160958
0.4785 --- loss: 1.263864, loss_ss: 1.207895, loss_d: 0.055969
0.6380 --- loss: 1.292968, loss_ss: 1.127573, loss_d: 0.165394
0.7974 --- loss: 1.367686, loss_ss: 1.235168, loss_d: 0.132518
0.9569 --- loss: 1.216022, loss_ss: 1.207856, loss_d: 0.008166
Epoch finished! Loss: 1.3404355395224787
Starting epoch 5/10.
0.0000 --- loss: 1.416715, loss_ss: 1.124067, loss_d: 0.292648
0.1595 --- loss: 1.298470, loss_ss: 1.188138, loss_d: 0.110332
0.3190 --- loss: 1.203820, loss_ss: 1.161083, loss_d: 0.042737
0.4785 --- loss: 1.122900, loss_ss: 1.114748, loss_d: 0.008153
0.6380 --- loss: 1.203134, loss_ss: 1.173187, loss_d: 0.029947
0.7974 --- loss: 1.216692, loss_ss: 1.202495, loss_d: 0.014198
0.9569 --- loss: 1.294175, loss_ss: 1.099537, loss_d: 0.194638
Epoch finished! Loss: 1.2242009351330418
Starting epoch 6/10.
0.0000 --- loss: 1.174110, loss_ss: 1.172315, loss_d: 0.001795
0.1595 --- loss: 1.134331, loss_ss: 1.096526, loss_d: 0.037805
0.3190 --- loss: 1.223246, loss_ss: 1.105035, loss_d: 0.118211
0.4785 --- loss: 1.127222, loss_ss: 1.105100, loss_d: 0.022123
0.6380 --- loss: 1.076192, loss_ss: 1.073450, loss_d: 0.002741
0.7974 --- loss: 1.035381, loss_ss: 0.985247, loss_d: 0.050134
0.9569 --- loss: 1.035156, loss_ss: 1.029415, loss_d: 0.005741
Epoch finished! Loss: 1.1915148198604584
Starting epoch 7/10.
0.0000 --- loss: 1.019596, loss_ss: 0.987234, loss_d: 0.032362
0.1595 --- loss: 1.057960, loss_ss: 1.055901, loss_d: 0.002059
0.3190 --- loss: 1.086618, loss_ss: 1.063656, loss_d: 0.022962
0.4785 --- loss: 0.996962, loss_ss: 0.971644, loss_d: 0.025319
0.6380 --- loss: 1.061464, loss_ss: 1.030609, loss_d: 0.030855
0.7974 --- loss: 1.062614, loss_ss: 1.058640, loss_d: 0.003974
0.9569 --- loss: 0.963978, loss_ss: 0.953905, loss_d: 0.010073
Epoch finished! Loss: 1.1083755983460335
Starting epoch 8/10.
0.0000 --- loss: 0.941727, loss_ss: 0.929997, loss_d: 0.011731
0.1595 --- loss: 0.891120, loss_ss: 0.889351, loss_d: 0.001769
0.3190 --- loss: 0.966316, loss_ss: 0.952946, loss_d: 0.013370
0.4785 --- loss: 1.119520, loss_ss: 1.041461, loss_d: 0.078059
0.6380 --- loss: 0.971197, loss_ss: 0.951666, loss_d: 0.019531
0.7974 --- loss: 1.036102, loss_ss: 0.931363, loss_d: 0.104739
0.9569 --- loss: 0.965068, loss_ss: 0.958653, loss_d: 0.006416
Epoch finished! Loss: 1.035812880723707
Starting epoch 9/10.
0.0000 --- loss: 1.132633, loss_ss: 1.107130, loss_d: 0.025503
0.1595 --- loss: 0.980571, loss_ss: 0.978763, loss_d: 0.001808
0.3190 --- loss: 0.956296, loss_ss: 0.953924, loss_d: 0.002371
0.4785 --- loss: 0.965558, loss_ss: 0.964714, loss_d: 0.000844
0.6380 --- loss: 0.816420, loss_ss: 0.815876, loss_d: 0.000544
0.7974 --- loss: 0.991617, loss_ss: 0.990589, loss_d: 0.001028
0.9569 --- loss: 0.856886, loss_ss: 0.844791, loss_d: 0.012095
Epoch finished! Loss: 0.982264788881425
Starting epoch 10/10.
0.0000 --- loss: 0.864478, loss_ss: 0.864081, loss_d: 0.000397
0.1595 --- loss: 0.919324, loss_ss: 0.897298, loss_d: 0.022025
0.3190 --- loss: 0.907003, loss_ss: 0.902198, loss_d: 0.004805
0.4785 --- loss: 0.869995, loss_ss: 0.861825, loss_d: 0.008171
0.6380 --- loss: 0.982598, loss_ss: 0.981627, loss_d: 0.000972
0.7974 --- loss: 0.846534, loss_ss: 0.835726, loss_d: 0.010808
0.9569 --- loss: 1.016258, loss_ss: 1.013693, loss_d: 0.002565
Epoch finished! Loss: 0.943006016554371
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7
             precision    recall  f1-score   support

        0.0       1.00      0.68      0.81       249
        1.0       0.50      0.05      0.09        20
        2.0       0.54      0.76      0.63        29
        3.0       1.00      0.95      0.98        62
        4.0       0.00      0.00      0.00         0

avg / total       0.93      0.70      0.78       360
 


====== chp025-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  78.06  68.27  100.00  100.00     81.15
1  94.44   5.00   99.71   50.00      9.09
2  92.78  75.86   94.26   53.66     62.86
3  99.17  95.16  100.00  100.00     97.52
4  75.56    NaN   75.56    0.00       NaN
Total accuracy: 70.00%
Average sen: 61.07%
Average spec: 93.90%
Macro f1-score: 62.65%
Diagnosis acc on 60mins: 1.0
[1.         0.99999452 0.99996519]
pred: 0.9999865690867106, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp025-nsrr

=== Test on chp026-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.338198, loss_ss: 1.657531, loss_d: 0.680668
0.1605 --- loss: 2.234011, loss_ss: 1.549580, loss_d: 0.684431
0.3210 --- loss: 2.416689, loss_ss: 1.524196, loss_d: 0.892492
0.4815 --- loss: 2.006921, loss_ss: 1.453440, loss_d: 0.553481
0.6421 --- loss: 2.291343, loss_ss: 1.477169, loss_d: 0.814174
0.8026 --- loss: 1.907905, loss_ss: 1.413192, loss_d: 0.494712
0.9631 --- loss: 1.930266, loss_ss: 1.403241, loss_d: 0.527025
Epoch finished! Loss: 2.1305745801618023
Starting epoch 2/10.
0.0000 --- loss: 2.115431, loss_ss: 1.406970, loss_d: 0.708461
0.1605 --- loss: 1.825964, loss_ss: 1.339649, loss_d: 0.486315
0.3210 --- loss: 1.839852, loss_ss: 1.287386, loss_d: 0.552466
0.4815 --- loss: 1.799548, loss_ss: 1.275778, loss_d: 0.523769
0.6421 --- loss: 1.727930, loss_ss: 1.299716, loss_d: 0.428214
0.8026 --- loss: 1.674095, loss_ss: 1.241294, loss_d: 0.432801
0.9631 --- loss: 1.507246, loss_ss: 1.180341, loss_d: 0.326905
Epoch finished! Loss: 1.7936299847018333
Starting epoch 3/10.
0.0000 --- loss: 1.792075, loss_ss: 1.251543, loss_d: 0.540533
0.1605 --- loss: 1.511643, loss_ss: 1.282329, loss_d: 0.229314
0.3210 --- loss: 1.739421, loss_ss: 1.192627, loss_d: 0.546795
0.4815 --- loss: 1.637923, loss_ss: 1.241727, loss_d: 0.396196
0.6421 --- loss: 1.940986, loss_ss: 1.182779, loss_d: 0.758207
0.8026 --- loss: 1.437827, loss_ss: 1.119727, loss_d: 0.318100
0.9631 --- loss: 1.475986, loss_ss: 1.120349, loss_d: 0.355637
Epoch finished! Loss: 1.5197077970350943
Starting epoch 4/10.
0.0000 --- loss: 1.193226, loss_ss: 1.108792, loss_d: 0.084434
0.1605 --- loss: 1.263518, loss_ss: 1.197879, loss_d: 0.065640
0.3210 --- loss: 1.215533, loss_ss: 1.186678, loss_d: 0.028855
0.4815 --- loss: 1.284411, loss_ss: 1.235084, loss_d: 0.049327
0.6421 --- loss: 1.085615, loss_ss: 1.039216, loss_d: 0.046399
0.8026 --- loss: 1.048009, loss_ss: 1.035159, loss_d: 0.012850
0.9631 --- loss: 1.070272, loss_ss: 0.996437, loss_d: 0.073835
Epoch finished! Loss: 1.2342483035979732
Starting epoch 5/10.
0.0000 --- loss: 1.120211, loss_ss: 1.108305, loss_d: 0.011907
0.1605 --- loss: 1.238397, loss_ss: 1.123807, loss_d: 0.114591
0.3210 --- loss: 1.228969, loss_ss: 0.985952, loss_d: 0.243017
0.4815 --- loss: 1.181670, loss_ss: 1.050605, loss_d: 0.131065
0.6421 --- loss: 1.083388, loss_ss: 1.047386, loss_d: 0.036002
0.8026 --- loss: 1.311180, loss_ss: 1.018284, loss_d: 0.292896
0.9631 --- loss: 1.118726, loss_ss: 1.028782, loss_d: 0.089944
Epoch finished! Loss: 1.15441708987759
Starting epoch 6/10.
0.0000 --- loss: 1.006803, loss_ss: 1.001058, loss_d: 0.005745
0.1605 --- loss: 1.021908, loss_ss: 1.019885, loss_d: 0.002023
0.3210 --- loss: 1.285551, loss_ss: 1.233232, loss_d: 0.052318
0.4815 --- loss: 0.999050, loss_ss: 0.987294, loss_d: 0.011756
0.6421 --- loss: 1.211774, loss_ss: 1.060553, loss_d: 0.151221
0.8026 --- loss: 0.990625, loss_ss: 0.987439, loss_d: 0.003186
0.9631 --- loss: 0.940289, loss_ss: 0.924257, loss_d: 0.016033
Epoch finished! Loss: 1.0749752502287588
Starting epoch 7/10.
0.0000 --- loss: 1.112748, loss_ss: 1.066764, loss_d: 0.045984
0.1605 --- loss: 0.870675, loss_ss: 0.844270, loss_d: 0.026406
0.3210 --- loss: 0.908809, loss_ss: 0.877035, loss_d: 0.031774
0.4815 --- loss: 0.911721, loss_ss: 0.898719, loss_d: 0.013002
0.6421 --- loss: 0.988756, loss_ss: 0.988103, loss_d: 0.000653
0.8026 --- loss: 0.870782, loss_ss: 0.869345, loss_d: 0.001437
0.9631 --- loss: 1.009266, loss_ss: 0.967589, loss_d: 0.041678
Epoch finished! Loss: 0.9995127502949007
Starting epoch 8/10.
0.0000 --- loss: 0.838664, loss_ss: 0.820526, loss_d: 0.018138
0.1605 --- loss: 0.827208, loss_ss: 0.826604, loss_d: 0.000604
0.3210 --- loss: 0.919199, loss_ss: 0.911729, loss_d: 0.007470
0.4815 --- loss: 0.831036, loss_ss: 0.819520, loss_d: 0.011515
0.6421 --- loss: 1.190896, loss_ss: 1.188989, loss_d: 0.001907
0.8026 --- loss: 0.954938, loss_ss: 0.951520, loss_d: 0.003418
0.9631 --- loss: 0.968857, loss_ss: 0.965391, loss_d: 0.003467
Epoch finished! Loss: 0.9365235326751586
Starting epoch 9/10.
0.0000 --- loss: 0.851174, loss_ss: 0.851119, loss_d: 0.000055
0.1605 --- loss: 1.079735, loss_ss: 0.898448, loss_d: 0.181287
0.3210 --- loss: 1.127529, loss_ss: 1.118481, loss_d: 0.009047
0.4815 --- loss: 1.015523, loss_ss: 1.015267, loss_d: 0.000257
0.6421 --- loss: 0.878315, loss_ss: 0.874405, loss_d: 0.003910
0.8026 --- loss: 0.952135, loss_ss: 0.748509, loss_d: 0.203626
0.9631 --- loss: 1.220996, loss_ss: 0.895884, loss_d: 0.325112
Epoch finished! Loss: 0.9524918833086568
Starting epoch 10/10.
0.0000 --- loss: 0.964866, loss_ss: 0.958256, loss_d: 0.006611
0.1605 --- loss: 0.910550, loss_ss: 0.851343, loss_d: 0.059207
0.3210 --- loss: 1.181203, loss_ss: 1.069797, loss_d: 0.111406
0.4815 --- loss: 1.167671, loss_ss: 1.163446, loss_d: 0.004225
0.6421 --- loss: 1.016925, loss_ss: 0.867878, loss_d: 0.149047
0.8026 --- loss: 1.088516, loss_ss: 1.052708, loss_d: 0.035808
0.9631 --- loss: 1.051741, loss_ss: 1.007364, loss_d: 0.044377
Epoch finished! Loss: 1.0648290043877018
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8083333333333333
             precision    recall  f1-score   support

        0.0       0.75      0.89      0.82        57
        1.0       0.00      0.00      0.00        52
        2.0       0.83      0.84      0.84       383
        3.0       0.94      0.80      0.86       182
        4.0       0.69      0.97      0.81       166

avg / total       0.77      0.81      0.78       840
 


====== chp026-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  97.26  89.47   97.83  75.00     81.60
1  93.81   0.00  100.00   0.00      0.00
2  85.12  84.07   86.00  83.42     83.75
3  94.52  79.67   98.63  94.16     86.31
4  90.95  96.99   89.47  69.40     80.90
Total accuracy: 80.83%
Average sen: 70.04%
Average spec: 94.38%
Macro f1-score: 66.51%
Diagnosis acc on 60mins: 1.0
[0.80764252 0.99989736 0.98668069 0.99972445 0.994735   0.99989533
 0.95474106]
pred: 0.9633309159960065, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp026-nsrr

=== Test on chp028-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.336837, loss_ss: 1.680064, loss_d: 0.656773
0.1608 --- loss: 2.274328, loss_ss: 1.632972, loss_d: 0.641355
0.3215 --- loss: 2.266063, loss_ss: 1.710607, loss_d: 0.555457
0.4823 --- loss: 2.110391, loss_ss: 1.628881, loss_d: 0.481510
0.6431 --- loss: 2.084265, loss_ss: 1.688920, loss_d: 0.395345
0.8039 --- loss: 1.969269, loss_ss: 1.508782, loss_d: 0.460486
0.9646 --- loss: 1.967545, loss_ss: 1.418724, loss_d: 0.548821
Epoch finished! Loss: 2.171372973149823
Starting epoch 2/10.
0.0000 --- loss: 1.805687, loss_ss: 1.384755, loss_d: 0.420932
0.1608 --- loss: 2.021944, loss_ss: 1.460259, loss_d: 0.561684
0.3215 --- loss: 2.024142, loss_ss: 1.460967, loss_d: 0.563175
0.4823 --- loss: 1.891048, loss_ss: 1.321108, loss_d: 0.569940
0.6431 --- loss: 1.891865, loss_ss: 1.496359, loss_d: 0.395506
0.8039 --- loss: 1.732132, loss_ss: 1.356825, loss_d: 0.375307
0.9646 --- loss: 1.941717, loss_ss: 1.608189, loss_d: 0.333528
Epoch finished! Loss: 1.892899046021123
Starting epoch 3/10.
0.0000 --- loss: 1.674502, loss_ss: 1.333409, loss_d: 0.341093
0.1608 --- loss: 1.482527, loss_ss: 1.254762, loss_d: 0.227766
0.3215 --- loss: 1.522146, loss_ss: 1.183609, loss_d: 0.338538
0.4823 --- loss: 1.455671, loss_ss: 1.297756, loss_d: 0.157915
0.6431 --- loss: 1.534701, loss_ss: 1.264515, loss_d: 0.270187
0.8039 --- loss: 1.594910, loss_ss: 1.383471, loss_d: 0.211439
0.9646 --- loss: 1.455664, loss_ss: 1.285663, loss_d: 0.170001
Epoch finished! Loss: 1.6368699669837952
Starting epoch 4/10.
0.0000 --- loss: 1.525809, loss_ss: 1.423063, loss_d: 0.102746
0.1608 --- loss: 1.368797, loss_ss: 1.250947, loss_d: 0.117850
0.3215 --- loss: 1.357321, loss_ss: 1.297039, loss_d: 0.060282
0.4823 --- loss: 1.563909, loss_ss: 1.194478, loss_d: 0.369431
0.6431 --- loss: 1.447146, loss_ss: 1.322037, loss_d: 0.125109
0.8039 --- loss: 1.293059, loss_ss: 1.223703, loss_d: 0.069355
0.9646 --- loss: 1.281619, loss_ss: 1.151505, loss_d: 0.130114
Epoch finished! Loss: 1.4550862966045257
Starting epoch 5/10.
0.0000 --- loss: 1.258640, loss_ss: 1.202465, loss_d: 0.056175
0.1608 --- loss: 1.409616, loss_ss: 1.369525, loss_d: 0.040091
0.3215 --- loss: 1.154069, loss_ss: 1.146956, loss_d: 0.007113
0.4823 --- loss: 1.209648, loss_ss: 1.174050, loss_d: 0.035598
0.6431 --- loss: 1.189798, loss_ss: 1.186816, loss_d: 0.002982
0.8039 --- loss: 1.486214, loss_ss: 1.472299, loss_d: 0.013915
0.9646 --- loss: 1.568953, loss_ss: 1.284189, loss_d: 0.284764
Epoch finished! Loss: 1.2746251677313158
Starting epoch 6/10.
0.0000 --- loss: 1.165631, loss_ss: 1.082602, loss_d: 0.083029
0.1608 --- loss: 1.264306, loss_ss: 1.261304, loss_d: 0.003002
0.3215 --- loss: 1.180622, loss_ss: 1.106823, loss_d: 0.073799
0.4823 --- loss: 1.205671, loss_ss: 1.186502, loss_d: 0.019168
0.6431 --- loss: 1.137461, loss_ss: 1.070351, loss_d: 0.067110
0.8039 --- loss: 1.234120, loss_ss: 1.202644, loss_d: 0.031476
0.9646 --- loss: 1.166557, loss_ss: 1.145251, loss_d: 0.021306
Epoch finished! Loss: 1.2030956187555868
Starting epoch 7/10.
0.0000 --- loss: 1.221059, loss_ss: 1.215961, loss_d: 0.005098
0.1608 --- loss: 1.220823, loss_ss: 1.211031, loss_d: 0.009792
0.3215 --- loss: 1.126323, loss_ss: 1.120275, loss_d: 0.006048
0.4823 --- loss: 1.079692, loss_ss: 1.078691, loss_d: 0.001001
0.6431 --- loss: 0.982089, loss_ss: 0.961486, loss_d: 0.020603
0.8039 --- loss: 1.224356, loss_ss: 1.224189, loss_d: 0.000168
0.9646 --- loss: 1.014701, loss_ss: 1.011470, loss_d: 0.003231
Epoch finished! Loss: 1.1505277618285148
Starting epoch 8/10.
0.0000 --- loss: 1.222484, loss_ss: 1.219282, loss_d: 0.003202
0.1608 --- loss: 0.937294, loss_ss: 0.936951, loss_d: 0.000343
0.3215 --- loss: 0.986796, loss_ss: 0.982424, loss_d: 0.004371
0.4823 --- loss: 1.132660, loss_ss: 1.103487, loss_d: 0.029173
0.6431 --- loss: 1.150272, loss_ss: 1.106919, loss_d: 0.043352
0.8039 --- loss: 1.007595, loss_ss: 1.006735, loss_d: 0.000860
0.9646 --- loss: 1.029743, loss_ss: 1.024066, loss_d: 0.005677
Epoch finished! Loss: 1.1442966441954336
Starting epoch 9/10.
0.0000 --- loss: 1.020406, loss_ss: 1.019025, loss_d: 0.001382
0.1608 --- loss: 1.084246, loss_ss: 1.074473, loss_d: 0.009773
0.3215 --- loss: 0.990105, loss_ss: 0.979483, loss_d: 0.010622
0.4823 --- loss: 1.116040, loss_ss: 1.096220, loss_d: 0.019820
0.6431 --- loss: 1.031745, loss_ss: 0.948144, loss_d: 0.083601
0.8039 --- loss: 1.235315, loss_ss: 1.202854, loss_d: 0.032462
0.9646 --- loss: 1.324739, loss_ss: 1.288404, loss_d: 0.036336
Epoch finished! Loss: 1.1963721869453308
Starting epoch 10/10.
0.0000 --- loss: 1.045496, loss_ss: 1.000588, loss_d: 0.044908
0.1608 --- loss: 0.966438, loss_ss: 0.949700, loss_d: 0.016738
0.3215 --- loss: 1.025863, loss_ss: 1.020002, loss_d: 0.005861
0.4823 --- loss: 0.975337, loss_ss: 0.962822, loss_d: 0.012515
0.6431 --- loss: 1.007350, loss_ss: 1.004157, loss_d: 0.003194
0.8039 --- loss: 1.468708, loss_ss: 0.998606, loss_d: 0.470102
0.9646 --- loss: 1.107469, loss_ss: 0.963011, loss_d: 0.144458
Epoch finished! Loss: 1.17098476617567
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.556830031282586
             precision    recall  f1-score   support

        0.0       0.26      0.88      0.40        90
        1.0       0.00      0.00      0.00        55
        2.0       0.65      0.95      0.77       382
        3.0       0.93      0.41      0.57       191
        4.0       0.88      0.06      0.11       241

avg / total       0.69      0.56      0.49       959
 


====== chp028-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  75.50  87.78   74.22  26.07     40.20
1  94.26   0.00  100.00   0.00      0.00
2  77.89  95.03   66.55  65.29     77.40
3  87.59  40.84   99.22  92.86     56.73
4  76.12   5.81   99.72  87.50     10.89
Total accuracy: 55.68%
Average sen: 45.89%
Average spec: 87.94%
Macro f1-score: 37.04%
Diagnosis acc on 60mins: 1.0
[0.99999964 0.99999559 0.99999654 0.9999994  0.99999964 0.99999797
 0.99999833 0.99999046]
pred: 0.9999971985816956, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp028-nsrr

=== Test on chp029-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.328034, loss_ss: 1.613230, loss_d: 0.714804
0.1608 --- loss: 2.208519, loss_ss: 1.497151, loss_d: 0.711368
0.3215 --- loss: 1.851744, loss_ss: 1.445391, loss_d: 0.406353
0.4823 --- loss: 1.980419, loss_ss: 1.360580, loss_d: 0.619839
0.6431 --- loss: 2.046878, loss_ss: 1.387788, loss_d: 0.659090
0.8039 --- loss: 2.066108, loss_ss: 1.347018, loss_d: 0.719089
0.9646 --- loss: 1.874784, loss_ss: 1.440184, loss_d: 0.434599
Epoch finished! Loss: 2.0951246523088023
Starting epoch 2/10.
0.0000 --- loss: 1.752906, loss_ss: 1.321558, loss_d: 0.431348
0.1608 --- loss: 1.980411, loss_ss: 1.272849, loss_d: 0.707562
0.3215 --- loss: 1.660824, loss_ss: 1.291088, loss_d: 0.369736
0.4823 --- loss: 1.975162, loss_ss: 1.239618, loss_d: 0.735544
0.6431 --- loss: 1.512250, loss_ss: 1.281810, loss_d: 0.230440
0.8039 --- loss: 1.483522, loss_ss: 1.271465, loss_d: 0.212057
0.9646 --- loss: 1.687757, loss_ss: 1.353888, loss_d: 0.333870
Epoch finished! Loss: 1.8178553023645956
Starting epoch 3/10.
0.0000 --- loss: 1.482313, loss_ss: 1.236380, loss_d: 0.245933
0.1608 --- loss: 1.410860, loss_ss: 1.293195, loss_d: 0.117666
0.3215 --- loss: 1.513842, loss_ss: 1.389701, loss_d: 0.124141
0.4823 --- loss: 1.666822, loss_ss: 1.266683, loss_d: 0.400139
0.6431 --- loss: 1.447861, loss_ss: 1.166674, loss_d: 0.281187
0.8039 --- loss: 1.506402, loss_ss: 1.236834, loss_d: 0.269568
0.9646 --- loss: 1.640660, loss_ss: 1.180745, loss_d: 0.459915
Epoch finished! Loss: 1.648394223182432
Starting epoch 4/10.
0.0000 --- loss: 1.701444, loss_ss: 1.232955, loss_d: 0.468489
0.1608 --- loss: 1.332621, loss_ss: 1.191658, loss_d: 0.140964
0.3215 --- loss: 1.286701, loss_ss: 1.153077, loss_d: 0.133624
0.4823 --- loss: 1.351431, loss_ss: 1.258205, loss_d: 0.093225
0.6431 --- loss: 1.344012, loss_ss: 1.283290, loss_d: 0.060722
0.8039 --- loss: 1.366369, loss_ss: 1.246300, loss_d: 0.120069
0.9646 --- loss: 1.186773, loss_ss: 1.079958, loss_d: 0.106815
Epoch finished! Loss: 1.3631713563396084
Starting epoch 5/10.
0.0000 --- loss: 1.134274, loss_ss: 1.118288, loss_d: 0.015986
0.1608 --- loss: 1.255748, loss_ss: 1.053608, loss_d: 0.202140
0.3215 --- loss: 1.284767, loss_ss: 1.269230, loss_d: 0.015537
0.4823 --- loss: 1.374178, loss_ss: 1.108954, loss_d: 0.265224
0.6431 --- loss: 1.524906, loss_ss: 1.171246, loss_d: 0.353660
0.8039 --- loss: 1.082558, loss_ss: 1.044817, loss_d: 0.037741
0.9646 --- loss: 0.985960, loss_ss: 0.969538, loss_d: 0.016423
Epoch finished! Loss: 1.2096303528355015
Starting epoch 6/10.
0.0000 --- loss: 1.075769, loss_ss: 1.059085, loss_d: 0.016683
0.1608 --- loss: 1.164152, loss_ss: 1.072221, loss_d: 0.091931
0.3215 --- loss: 1.089984, loss_ss: 1.077774, loss_d: 0.012210
0.4823 --- loss: 1.025699, loss_ss: 0.988590, loss_d: 0.037109
0.6431 --- loss: 0.951983, loss_ss: 0.919562, loss_d: 0.032421
0.8039 --- loss: 1.113613, loss_ss: 1.106939, loss_d: 0.006673
0.9646 --- loss: 1.034971, loss_ss: 0.978204, loss_d: 0.056767
Epoch finished! Loss: 1.142799472616565
Starting epoch 7/10.
0.0000 --- loss: 1.203084, loss_ss: 1.172157, loss_d: 0.030926
0.1608 --- loss: 0.899100, loss_ss: 0.865824, loss_d: 0.033276
0.3215 --- loss: 1.181947, loss_ss: 1.067644, loss_d: 0.114304
0.4823 --- loss: 0.974019, loss_ss: 0.932886, loss_d: 0.041133
0.6431 --- loss: 1.271466, loss_ss: 1.077232, loss_d: 0.194234
0.8039 --- loss: 1.008670, loss_ss: 0.975200, loss_d: 0.033470
0.9646 --- loss: 0.954484, loss_ss: 0.893257, loss_d: 0.061226
Epoch finished! Loss: 1.086875835734029
Starting epoch 8/10.
0.0000 --- loss: 0.892481, loss_ss: 0.873009, loss_d: 0.019472
0.1608 --- loss: 1.341007, loss_ss: 0.948712, loss_d: 0.392294
0.3215 --- loss: 1.031582, loss_ss: 0.895578, loss_d: 0.136004
0.4823 --- loss: 0.910161, loss_ss: 0.894734, loss_d: 0.015427
0.6431 --- loss: 1.063158, loss_ss: 1.028063, loss_d: 0.035095
0.8039 --- loss: 0.990252, loss_ss: 0.985998, loss_d: 0.004254
0.9646 --- loss: 0.884259, loss_ss: 0.872882, loss_d: 0.011377
Epoch finished! Loss: 1.0538914559348938
Starting epoch 9/10.
0.0000 --- loss: 0.924090, loss_ss: 0.868057, loss_d: 0.056033
0.1608 --- loss: 1.219387, loss_ss: 1.003738, loss_d: 0.215650
0.3215 --- loss: 1.128070, loss_ss: 1.040571, loss_d: 0.087498
0.4823 --- loss: 0.930886, loss_ss: 0.925848, loss_d: 0.005038
0.6431 --- loss: 0.839002, loss_ss: 0.759844, loss_d: 0.079158
0.8039 --- loss: 0.804292, loss_ss: 0.803153, loss_d: 0.001139
0.9646 --- loss: 0.872798, loss_ss: 0.865694, loss_d: 0.007104
Epoch finished! Loss: 1.0104949137856882
Starting epoch 10/10.
0.0000 --- loss: 0.787597, loss_ss: 0.786741, loss_d: 0.000856
0.1608 --- loss: 0.857425, loss_ss: 0.856002, loss_d: 0.001424
0.3215 --- loss: 0.796340, loss_ss: 0.794423, loss_d: 0.001917
0.4823 --- loss: 1.186009, loss_ss: 1.115472, loss_d: 0.070537
0.6431 --- loss: 1.050819, loss_ss: 1.042519, loss_d: 0.008300
0.8039 --- loss: 0.821821, loss_ss: 0.820294, loss_d: 0.001527
0.9646 --- loss: 0.833129, loss_ss: 0.832342, loss_d: 0.000788
Epoch finished! Loss: 0.9047798408615974
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6479166666666667
             precision    recall  f1-score   support

        0.0       0.71      0.56      0.63        66
        1.0       0.00      0.00      0.00        44
        2.0       0.66      0.68      0.67       385
        3.0       1.00      0.58      0.74       334
        4.0       0.40      0.98      0.57       131

avg / total       0.72      0.65      0.65       960
 


====== chp029-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  95.42  56.06   98.32   71.15     62.71
1  95.31   0.00   99.89    0.00      0.00
2  73.33  67.79   77.04   66.41     67.10
3  85.52  58.38  100.00  100.00     73.72
4  80.00  98.47   77.08   40.44     57.33
Total accuracy: 64.79%
Average sen: 56.14%
Average spec: 90.47%
Macro f1-score: 52.17%
Diagnosis acc on 60mins: 1.0
[0.99860829 0.99995637 0.98958182 0.99961025 0.99705756 0.99848074
 0.99179572 0.96817845]
pred: 0.9929086491465569, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp029-nsrr

=== Test on chp030-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.376324, loss_ss: 1.715904, loss_d: 0.660421
0.1613 --- loss: 1.902112, loss_ss: 1.536714, loss_d: 0.365398
0.3226 --- loss: 2.251853, loss_ss: 1.393481, loss_d: 0.858372
0.4839 --- loss: 2.004641, loss_ss: 1.485700, loss_d: 0.518942
0.6452 --- loss: 1.959228, loss_ss: 1.401442, loss_d: 0.557786
0.8065 --- loss: 2.290743, loss_ss: 1.471565, loss_d: 0.819179
0.9677 --- loss: 1.768821, loss_ss: 1.153856, loss_d: 0.614966
Epoch finished! Loss: 2.033994520296816
Starting epoch 2/10.
0.0000 --- loss: 1.735151, loss_ss: 1.156075, loss_d: 0.579076
0.1613 --- loss: 1.696218, loss_ss: 1.320755, loss_d: 0.375464
0.3226 --- loss: 1.626047, loss_ss: 1.169937, loss_d: 0.456110
0.4839 --- loss: 1.895504, loss_ss: 1.137520, loss_d: 0.757984
0.6452 --- loss: 1.514111, loss_ss: 1.076160, loss_d: 0.437951
0.8065 --- loss: 1.426590, loss_ss: 1.203932, loss_d: 0.222657
0.9677 --- loss: 1.600601, loss_ss: 1.226183, loss_d: 0.374418
Epoch finished! Loss: 1.7219864442700246
Starting epoch 3/10.
0.0000 --- loss: 1.281131, loss_ss: 1.111115, loss_d: 0.170016
0.1613 --- loss: 1.365479, loss_ss: 1.206745, loss_d: 0.158734
0.3226 --- loss: 1.396759, loss_ss: 1.151993, loss_d: 0.244766
0.4839 --- loss: 1.383865, loss_ss: 1.144525, loss_d: 0.239340
0.6452 --- loss: 1.849259, loss_ss: 1.175471, loss_d: 0.673788
0.8065 --- loss: 1.258580, loss_ss: 1.165150, loss_d: 0.093430
0.9677 --- loss: 1.389600, loss_ss: 1.341883, loss_d: 0.047717
Epoch finished! Loss: 1.4587905778259527
Starting epoch 4/10.
0.0000 --- loss: 1.278610, loss_ss: 1.130422, loss_d: 0.148188
0.1613 --- loss: 1.191464, loss_ss: 1.107974, loss_d: 0.083490
0.3226 --- loss: 1.250649, loss_ss: 1.179646, loss_d: 0.071003
0.4839 --- loss: 1.196077, loss_ss: 1.088419, loss_d: 0.107657
0.6452 --- loss: 1.174693, loss_ss: 1.063307, loss_d: 0.111386
0.8065 --- loss: 0.959522, loss_ss: 0.930589, loss_d: 0.028933
0.9677 --- loss: 1.237743, loss_ss: 1.207466, loss_d: 0.030277
Epoch finished! Loss: 1.266927815851618
Starting epoch 5/10.
0.0000 --- loss: 0.893717, loss_ss: 0.889634, loss_d: 0.004083
0.1613 --- loss: 1.187685, loss_ss: 1.176052, loss_d: 0.011633
0.3226 --- loss: 1.135143, loss_ss: 1.113953, loss_d: 0.021190
0.4839 --- loss: 1.144012, loss_ss: 1.135988, loss_d: 0.008024
0.6452 --- loss: 1.084718, loss_ss: 1.080970, loss_d: 0.003747
0.8065 --- loss: 1.178877, loss_ss: 1.155275, loss_d: 0.023603
0.9677 --- loss: 1.241077, loss_ss: 1.081126, loss_d: 0.159951
Epoch finished! Loss: 1.1027975492790096
Starting epoch 6/10.
0.0000 --- loss: 0.871330, loss_ss: 0.865718, loss_d: 0.005611
0.1613 --- loss: 1.245967, loss_ss: 1.027339, loss_d: 0.218629
0.3226 --- loss: 1.167387, loss_ss: 1.067740, loss_d: 0.099647
0.4839 --- loss: 0.952970, loss_ss: 0.951989, loss_d: 0.000981
0.6452 --- loss: 0.845372, loss_ss: 0.836932, loss_d: 0.008440
0.8065 --- loss: 1.329785, loss_ss: 1.055806, loss_d: 0.273979
0.9677 --- loss: 0.948247, loss_ss: 0.938407, loss_d: 0.009841
Epoch finished! Loss: 1.0842369384452946
Starting epoch 7/10.
0.0000 --- loss: 0.895321, loss_ss: 0.891745, loss_d: 0.003576
0.1613 --- loss: 1.217908, loss_ss: 1.212182, loss_d: 0.005725
0.3226 --- loss: 0.998887, loss_ss: 0.997397, loss_d: 0.001490
0.4839 --- loss: 1.072757, loss_ss: 1.064438, loss_d: 0.008320
0.6452 --- loss: 1.054069, loss_ss: 1.043078, loss_d: 0.010992
0.8065 --- loss: 1.080380, loss_ss: 1.053421, loss_d: 0.026958
0.9677 --- loss: 1.009007, loss_ss: 1.003804, loss_d: 0.005202
Epoch finished! Loss: 1.063775722120629
Starting epoch 8/10.
0.0000 --- loss: 1.093228, loss_ss: 1.086087, loss_d: 0.007142
0.1613 --- loss: 1.073754, loss_ss: 1.032311, loss_d: 0.041443
0.3226 --- loss: 0.938650, loss_ss: 0.933314, loss_d: 0.005336
0.4839 --- loss: 1.223342, loss_ss: 1.046980, loss_d: 0.176362
0.6452 --- loss: 1.264762, loss_ss: 1.106354, loss_d: 0.158408
0.8065 --- loss: 0.883181, loss_ss: 0.810300, loss_d: 0.072881
0.9677 --- loss: 0.796668, loss_ss: 0.764124, loss_d: 0.032544
Epoch finished! Loss: 1.018269371790964
Starting epoch 9/10.
0.0000 --- loss: 0.780874, loss_ss: 0.780223, loss_d: 0.000651
0.1613 --- loss: 0.949720, loss_ss: 0.946968, loss_d: 0.002752
0.3226 --- loss: 0.971776, loss_ss: 0.965440, loss_d: 0.006336
0.4839 --- loss: 1.156997, loss_ss: 0.947686, loss_d: 0.209311
0.6452 --- loss: 1.020053, loss_ss: 1.016016, loss_d: 0.004038
0.8065 --- loss: 0.842313, loss_ss: 0.839115, loss_d: 0.003199
0.9677 --- loss: 1.251773, loss_ss: 1.176009, loss_d: 0.075764
Epoch finished! Loss: 1.0435597877033422
Starting epoch 10/10.
0.0000 --- loss: 1.044005, loss_ss: 0.941365, loss_d: 0.102640
0.1613 --- loss: 1.142404, loss_ss: 1.137848, loss_d: 0.004556
0.3226 --- loss: 0.830415, loss_ss: 0.828781, loss_d: 0.001634
0.4839 --- loss: 1.245384, loss_ss: 0.929103, loss_d: 0.316281
0.6452 --- loss: 0.851079, loss_ss: 0.751418, loss_d: 0.099661
0.8065 --- loss: 1.064114, loss_ss: 1.038142, loss_d: 0.025972
0.9677 --- loss: 0.936271, loss_ss: 0.886129, loss_d: 0.050143
Epoch finished! Loss: 0.9281772697558168
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.3694745621351126
             precision    recall  f1-score   support

        0.0       0.98      0.35      0.51       350
        1.0       0.39      0.25      0.31       204
        2.0       0.37      0.46      0.41       346
        3.0       0.00      0.00      0.00       179
        4.0       0.22      0.93      0.35       120

avg / total       0.48      0.37      0.36      1199
 


====== chp030-nsrr ======

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  80.82  34.86   99.76  98.39     51.48
1  80.65  25.00   92.06  39.23     30.54
2  61.88  45.66   68.46  37.00     40.88
3  84.99   0.00   99.90   0.00      0.00
4  65.55  93.33   62.47  21.66     35.16
Total accuracy: 36.95%
Average sen: 39.77%
Average spec: 84.53%
Macro f1-score: 31.61%
Diagnosis acc on 60mins: 0.9
[0.99976271 0.99945337 0.84141076 0.99974602 0.98709446 0.99503821
 0.48873308 0.99989319 0.99996746 0.99955148]
pred: 0.9310650736093521, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp030-nsrr

=== Test on chp031-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.443860, loss_ss: 1.691250, loss_d: 0.752609
0.1610 --- loss: 2.372107, loss_ss: 1.610207, loss_d: 0.761900
0.3221 --- loss: 2.071317, loss_ss: 1.512754, loss_d: 0.558563
0.4831 --- loss: 1.855830, loss_ss: 1.487544, loss_d: 0.368286
0.6441 --- loss: 2.019597, loss_ss: 1.517305, loss_d: 0.502292
0.8052 --- loss: 2.179652, loss_ss: 1.449945, loss_d: 0.729707
0.9662 --- loss: 1.869147, loss_ss: 1.434378, loss_d: 0.434769
Epoch finished! Loss: 2.1592331374845197
Starting epoch 2/10.
0.0000 --- loss: 2.053681, loss_ss: 1.364689, loss_d: 0.688992
0.1610 --- loss: 2.013308, loss_ss: 1.449669, loss_d: 0.563638
0.3221 --- loss: 1.620292, loss_ss: 1.347470, loss_d: 0.272822
0.4831 --- loss: 1.792658, loss_ss: 1.355391, loss_d: 0.437267
0.6441 --- loss: 1.756725, loss_ss: 1.356082, loss_d: 0.400643
0.8052 --- loss: 1.747356, loss_ss: 1.337909, loss_d: 0.409447
0.9662 --- loss: 1.711359, loss_ss: 1.412212, loss_d: 0.299147
Epoch finished! Loss: 1.876379837912898
Starting epoch 3/10.
0.0000 --- loss: 1.448103, loss_ss: 1.293703, loss_d: 0.154400
0.1610 --- loss: 1.414102, loss_ss: 1.301895, loss_d: 0.112208
0.3221 --- loss: 1.377497, loss_ss: 1.289411, loss_d: 0.088086
0.4831 --- loss: 1.432892, loss_ss: 1.280916, loss_d: 0.151976
0.6441 --- loss: 1.376540, loss_ss: 1.171866, loss_d: 0.204673
0.8052 --- loss: 1.787921, loss_ss: 1.211463, loss_d: 0.576458
0.9662 --- loss: 1.752141, loss_ss: 1.280218, loss_d: 0.471923
Epoch finished! Loss: 1.5687593298573648
Starting epoch 4/10.
0.0000 --- loss: 1.607063, loss_ss: 1.176362, loss_d: 0.430701
0.1610 --- loss: 1.503143, loss_ss: 1.335914, loss_d: 0.167229
0.3221 --- loss: 1.307743, loss_ss: 1.270439, loss_d: 0.037305
0.4831 --- loss: 1.714335, loss_ss: 1.302325, loss_d: 0.412010
0.6441 --- loss: 1.279732, loss_ss: 1.214131, loss_d: 0.065601
0.8052 --- loss: 1.178746, loss_ss: 1.101669, loss_d: 0.077077
0.9662 --- loss: 1.464660, loss_ss: 1.243024, loss_d: 0.221636
Epoch finished! Loss: 1.3769730502559292
Starting epoch 5/10.
0.0000 --- loss: 1.208845, loss_ss: 1.188347, loss_d: 0.020498
0.1610 --- loss: 1.229987, loss_ss: 1.221931, loss_d: 0.008056
0.3221 --- loss: 1.067129, loss_ss: 1.045688, loss_d: 0.021441
0.4831 --- loss: 1.129473, loss_ss: 1.109568, loss_d: 0.019905
0.6441 --- loss: 1.186366, loss_ss: 1.135673, loss_d: 0.050693
0.8052 --- loss: 1.065273, loss_ss: 1.035496, loss_d: 0.029777
0.9662 --- loss: 1.102891, loss_ss: 1.096450, loss_d: 0.006442
Epoch finished! Loss: 1.2005680088073976
Starting epoch 6/10.
0.0000 --- loss: 1.048587, loss_ss: 1.043901, loss_d: 0.004686
0.1610 --- loss: 1.271961, loss_ss: 0.992768, loss_d: 0.279193
0.3221 --- loss: 1.251288, loss_ss: 1.085950, loss_d: 0.165337
0.4831 --- loss: 1.415885, loss_ss: 1.240135, loss_d: 0.175750
0.6441 --- loss: 1.391989, loss_ss: 1.109859, loss_d: 0.282131
0.8052 --- loss: 1.873936, loss_ss: 0.984568, loss_d: 0.889369
0.9662 --- loss: 1.014176, loss_ss: 0.990095, loss_d: 0.024081
Epoch finished! Loss: 1.1754290490381178
Starting epoch 7/10.
0.0000 --- loss: 1.097964, loss_ss: 0.930912, loss_d: 0.167051
0.1610 --- loss: 1.261925, loss_ss: 1.228903, loss_d: 0.033022
0.3221 --- loss: 0.937362, loss_ss: 0.910869, loss_d: 0.026492
0.4831 --- loss: 0.874126, loss_ss: 0.863796, loss_d: 0.010330
0.6441 --- loss: 1.170623, loss_ss: 1.153906, loss_d: 0.016717
0.8052 --- loss: 1.086409, loss_ss: 1.060156, loss_d: 0.026253
0.9662 --- loss: 1.077071, loss_ss: 1.064929, loss_d: 0.012142
Epoch finished! Loss: 1.060035063374427
Starting epoch 8/10.
0.0000 --- loss: 0.986394, loss_ss: 0.979678, loss_d: 0.006717
0.1610 --- loss: 1.228533, loss_ss: 1.224644, loss_d: 0.003889
0.3221 --- loss: 0.867849, loss_ss: 0.865020, loss_d: 0.002829
0.4831 --- loss: 0.831227, loss_ss: 0.830632, loss_d: 0.000595
0.6441 --- loss: 0.933881, loss_ss: 0.926171, loss_d: 0.007710
0.8052 --- loss: 0.975189, loss_ss: 0.960424, loss_d: 0.014766
0.9662 --- loss: 0.796466, loss_ss: 0.794093, loss_d: 0.002374
Epoch finished! Loss: 0.9590647451339229
Starting epoch 9/10.
0.0000 --- loss: 0.808007, loss_ss: 0.806602, loss_d: 0.001404
0.1610 --- loss: 1.041646, loss_ss: 1.028734, loss_d: 0.012913
0.3221 --- loss: 0.907756, loss_ss: 0.906584, loss_d: 0.001172
0.4831 --- loss: 0.978449, loss_ss: 0.968437, loss_d: 0.010012
0.6441 --- loss: 0.797355, loss_ss: 0.796036, loss_d: 0.001319
0.8052 --- loss: 0.866629, loss_ss: 0.855133, loss_d: 0.011496
0.9662 --- loss: 0.938059, loss_ss: 0.935506, loss_d: 0.002553
Epoch finished! Loss: 0.9205043719660851
Starting epoch 10/10.
0.0000 --- loss: 0.856936, loss_ss: 0.834202, loss_d: 0.022734
0.1610 --- loss: 0.844953, loss_ss: 0.844103, loss_d: 0.000850
0.3221 --- loss: 0.915307, loss_ss: 0.914535, loss_d: 0.000772
0.4831 --- loss: 0.949865, loss_ss: 0.949648, loss_d: 0.000216
0.6441 --- loss: 0.822513, loss_ss: 0.816832, loss_d: 0.005681
0.8052 --- loss: 0.785964, loss_ss: 0.785906, loss_d: 0.000058
0.9662 --- loss: 0.788356, loss_ss: 0.788229, loss_d: 0.000127
Epoch finished! Loss: 0.8850304369003542
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6564814814814814
             precision    recall  f1-score   support

        0.0       0.19      0.69      0.30        51
        1.0       0.00      0.00      0.00        48
        2.0       0.65      0.72      0.68       309
        3.0       1.00      0.56      0.72       229
        4.0       0.76      0.73      0.75       443

avg / total       0.72      0.66      0.67      1080
 


====== chp031-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  84.54  68.63   85.33   18.82     29.54
1  95.56   0.00  100.00    0.00      0.00
2  80.83  71.52   84.57   65.00     68.10
3  90.74  56.33  100.00  100.00     72.07
4  79.63  73.14   84.14   76.24     74.65
Total accuracy: 65.65%
Average sen: 53.92%
Average spec: 90.81%
Macro f1-score: 48.87%
Diagnosis acc on 60mins: 0.6666666666666666
[0.99774712 0.1627849  0.05098049 0.99890256 0.01398528 0.98469746
 0.99700707 0.99982244 0.9997924 ]
pred: 0.6895244137073556, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp031-nsrr

=== Test on chp032-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.403598, loss_ss: 1.640799, loss_d: 0.762798
0.1608 --- loss: 2.144901, loss_ss: 1.502220, loss_d: 0.642681
0.3215 --- loss: 2.209094, loss_ss: 1.437967, loss_d: 0.771127
0.4823 --- loss: 2.303287, loss_ss: 1.485903, loss_d: 0.817384
0.6431 --- loss: 1.933750, loss_ss: 1.342336, loss_d: 0.591413
0.8039 --- loss: 2.119417, loss_ss: 1.445509, loss_d: 0.673908
0.9646 --- loss: 2.082227, loss_ss: 1.465907, loss_d: 0.616321
Epoch finished! Loss: 2.1258278412203633
Starting epoch 2/10.
0.0000 --- loss: 1.753686, loss_ss: 1.380042, loss_d: 0.373645
0.1608 --- loss: 1.635561, loss_ss: 1.295241, loss_d: 0.340320
0.3215 --- loss: 1.829200, loss_ss: 1.235059, loss_d: 0.594140
0.4823 --- loss: 1.717615, loss_ss: 1.339666, loss_d: 0.377950
0.6431 --- loss: 1.519205, loss_ss: 1.258299, loss_d: 0.260907
0.8039 --- loss: 1.823556, loss_ss: 1.395705, loss_d: 0.427851
0.9646 --- loss: 1.505279, loss_ss: 1.328291, loss_d: 0.176988
Epoch finished! Loss: 1.81928369691295
Starting epoch 3/10.
0.0000 --- loss: 1.524963, loss_ss: 1.304840, loss_d: 0.220122
0.1608 --- loss: 1.505554, loss_ss: 1.145674, loss_d: 0.359880
0.3215 --- loss: 1.704676, loss_ss: 1.218308, loss_d: 0.486368
0.4823 --- loss: 1.496009, loss_ss: 1.146717, loss_d: 0.349292
0.6431 --- loss: 1.868479, loss_ss: 1.362318, loss_d: 0.506160
0.8039 --- loss: 1.389158, loss_ss: 1.208750, loss_d: 0.180408
0.9646 --- loss: 1.291225, loss_ss: 1.096581, loss_d: 0.194644
Epoch finished! Loss: 1.5836912066705766
Starting epoch 4/10.
0.0000 --- loss: 1.305910, loss_ss: 1.144472, loss_d: 0.161438
0.1608 --- loss: 1.380020, loss_ss: 1.219429, loss_d: 0.160591
0.3215 --- loss: 1.231019, loss_ss: 1.135836, loss_d: 0.095183
0.4823 --- loss: 1.407479, loss_ss: 1.364149, loss_d: 0.043330
0.6431 --- loss: 1.529506, loss_ss: 1.102734, loss_d: 0.426772
0.8039 --- loss: 1.370703, loss_ss: 1.105861, loss_d: 0.264841
0.9646 --- loss: 1.089482, loss_ss: 0.967164, loss_d: 0.122318
Epoch finished! Loss: 1.345312314648782
Starting epoch 5/10.
0.0000 --- loss: 1.204716, loss_ss: 1.048743, loss_d: 0.155973
0.1608 --- loss: 1.161651, loss_ss: 1.124953, loss_d: 0.036698
0.3215 --- loss: 1.222114, loss_ss: 1.183110, loss_d: 0.039004
0.4823 --- loss: 1.133535, loss_ss: 1.085511, loss_d: 0.048024
0.6431 --- loss: 1.122340, loss_ss: 1.111100, loss_d: 0.011241
0.8039 --- loss: 1.010872, loss_ss: 0.993130, loss_d: 0.017742
0.9646 --- loss: 1.068740, loss_ss: 1.035798, loss_d: 0.032942
Epoch finished! Loss: 1.1811037553894905
Starting epoch 6/10.
0.0000 --- loss: 1.099720, loss_ss: 0.960354, loss_d: 0.139366
0.1608 --- loss: 1.118637, loss_ss: 1.113083, loss_d: 0.005554
0.3215 --- loss: 1.119324, loss_ss: 1.103772, loss_d: 0.015552
0.4823 --- loss: 1.168884, loss_ss: 1.155181, loss_d: 0.013703
0.6431 --- loss: 1.012762, loss_ss: 0.967908, loss_d: 0.044854
0.8039 --- loss: 0.977836, loss_ss: 0.972118, loss_d: 0.005719
0.9646 --- loss: 1.178113, loss_ss: 1.173397, loss_d: 0.004716
Epoch finished! Loss: 1.2136178122412773
Starting epoch 7/10.
0.0000 --- loss: 1.271329, loss_ss: 1.120418, loss_d: 0.150911
0.1608 --- loss: 1.082477, loss_ss: 1.064982, loss_d: 0.017495
0.3215 --- loss: 1.182927, loss_ss: 1.160092, loss_d: 0.022835
0.4823 --- loss: 0.963344, loss_ss: 0.899202, loss_d: 0.064142
0.6431 --- loss: 1.096429, loss_ss: 0.955043, loss_d: 0.141386
0.8039 --- loss: 1.074811, loss_ss: 0.982468, loss_d: 0.092343
0.9646 --- loss: 1.140579, loss_ss: 1.086280, loss_d: 0.054298
Epoch finished! Loss: 1.1678613097436967
Starting epoch 8/10.
0.0000 --- loss: 1.035337, loss_ss: 0.960467, loss_d: 0.074870
0.1608 --- loss: 0.937738, loss_ss: 0.895788, loss_d: 0.041950
0.3215 --- loss: 1.035694, loss_ss: 1.030576, loss_d: 0.005118
0.4823 --- loss: 0.985685, loss_ss: 0.939658, loss_d: 0.046027
0.6431 --- loss: 1.008250, loss_ss: 0.979709, loss_d: 0.028541
0.8039 --- loss: 0.989306, loss_ss: 0.956140, loss_d: 0.033166
0.9646 --- loss: 0.933174, loss_ss: 0.930035, loss_d: 0.003139
Epoch finished! Loss: 1.0607856608206225
Starting epoch 9/10.
0.0000 --- loss: 0.930524, loss_ss: 0.928111, loss_d: 0.002413
0.1608 --- loss: 0.919021, loss_ss: 0.900303, loss_d: 0.018718
0.3215 --- loss: 1.191199, loss_ss: 1.156604, loss_d: 0.034596
0.4823 --- loss: 0.958956, loss_ss: 0.918626, loss_d: 0.040330
0.6431 --- loss: 1.135385, loss_ss: 1.120407, loss_d: 0.014978
0.8039 --- loss: 1.007244, loss_ss: 0.964940, loss_d: 0.042304
0.9646 --- loss: 1.005328, loss_ss: 1.004344, loss_d: 0.000985
Epoch finished! Loss: 1.0210947029052242
Starting epoch 10/10.
0.0000 --- loss: 0.827601, loss_ss: 0.814466, loss_d: 0.013134
0.1608 --- loss: 0.827831, loss_ss: 0.826970, loss_d: 0.000861
0.3215 --- loss: 0.985307, loss_ss: 0.960588, loss_d: 0.024719
0.4823 --- loss: 0.922224, loss_ss: 0.921718, loss_d: 0.000506
0.6431 --- loss: 1.038726, loss_ss: 1.031600, loss_d: 0.007126
0.8039 --- loss: 1.131157, loss_ss: 1.009789, loss_d: 0.121368
0.9646 --- loss: 1.011004, loss_ss: 1.002749, loss_d: 0.008255
Epoch finished! Loss: 1.0691230720089329
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6885416666666667
             precision    recall  f1-score   support

        0.0       0.71      0.26      0.38        46
        1.0       0.00      0.00      0.00        98
        2.0       0.74      0.88      0.80       486
        3.0       1.00      0.60      0.75       150
        4.0       0.48      0.73      0.58       180

avg / total       0.65      0.69      0.65       960
 


====== chp032-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  95.94  26.09   99.45   70.59     38.10
1  89.79   0.00  100.00    0.00      0.00
2  78.23  87.86   68.35   74.00     80.34
3  93.75  60.00  100.00  100.00     75.00
4  80.00  73.33   81.54   47.83     57.89
Total accuracy: 68.85%
Average sen: 49.46%
Average spec: 89.87%
Macro f1-score: 50.27%
Diagnosis acc on 60mins: 0.5
[0.13938345 0.31821865 0.99517703 0.99858141 0.07074716 0.99958366
 0.96752679 0.38545388]
pred: 0.609334004111588, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp032-nsrr

=== Test on chp033-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.388077, loss_ss: 1.654384, loss_d: 0.733693
0.1608 --- loss: 2.021644, loss_ss: 1.545137, loss_d: 0.476508
0.3215 --- loss: 2.461781, loss_ss: 1.377292, loss_d: 1.084489
0.4823 --- loss: 1.882033, loss_ss: 1.410702, loss_d: 0.471331
0.6431 --- loss: 2.145767, loss_ss: 1.327909, loss_d: 0.817858
0.8039 --- loss: 1.942055, loss_ss: 1.306962, loss_d: 0.635094
0.9646 --- loss: 1.687592, loss_ss: 1.357670, loss_d: 0.329923
Epoch finished! Loss: 2.09262881548174
Starting epoch 2/10.
0.0000 --- loss: 1.654843, loss_ss: 1.345578, loss_d: 0.309265
0.1608 --- loss: 2.139904, loss_ss: 1.392386, loss_d: 0.747518
0.3215 --- loss: 1.991580, loss_ss: 1.323735, loss_d: 0.667845
0.4823 --- loss: 1.657510, loss_ss: 1.295008, loss_d: 0.362502
0.6431 --- loss: 1.923496, loss_ss: 1.308633, loss_d: 0.614863
0.8039 --- loss: 1.572532, loss_ss: 1.176348, loss_d: 0.396184
0.9646 --- loss: 1.769496, loss_ss: 1.412117, loss_d: 0.357379
Epoch finished! Loss: 1.826721518270431
Starting epoch 3/10.
0.0000 --- loss: 1.671695, loss_ss: 1.337946, loss_d: 0.333749
0.1608 --- loss: 1.543080, loss_ss: 1.257800, loss_d: 0.285280
0.3215 --- loss: 1.416072, loss_ss: 1.255882, loss_d: 0.160191
0.4823 --- loss: 1.677147, loss_ss: 1.223968, loss_d: 0.453179
0.6431 --- loss: 1.468962, loss_ss: 1.212018, loss_d: 0.256944
0.8039 --- loss: 1.441204, loss_ss: 1.213142, loss_d: 0.228062
0.9646 --- loss: 1.602631, loss_ss: 1.222818, loss_d: 0.379813
Epoch finished! Loss: 1.5815885336168352
Starting epoch 4/10.
0.0000 --- loss: 1.370895, loss_ss: 1.225280, loss_d: 0.145616
0.1608 --- loss: 1.264595, loss_ss: 1.188682, loss_d: 0.075914
0.3215 --- loss: 1.338091, loss_ss: 1.142069, loss_d: 0.196022
0.4823 --- loss: 1.201729, loss_ss: 1.098505, loss_d: 0.103224
0.6431 --- loss: 1.430737, loss_ss: 1.249749, loss_d: 0.180987
0.8039 --- loss: 1.130222, loss_ss: 1.082000, loss_d: 0.048222
0.9646 --- loss: 1.220828, loss_ss: 1.200302, loss_d: 0.020526
Epoch finished! Loss: 1.325292621889422
Starting epoch 5/10.
0.0000 --- loss: 1.308681, loss_ss: 1.295294, loss_d: 0.013387
0.1608 --- loss: 1.246695, loss_ss: 1.233232, loss_d: 0.013463
0.3215 --- loss: 1.240367, loss_ss: 1.089452, loss_d: 0.150915
0.4823 --- loss: 1.150510, loss_ss: 1.107416, loss_d: 0.043094
0.6431 --- loss: 1.307421, loss_ss: 1.173358, loss_d: 0.134063
0.8039 --- loss: 1.304258, loss_ss: 1.283512, loss_d: 0.020746
0.9646 --- loss: 1.218188, loss_ss: 1.191685, loss_d: 0.026504
Epoch finished! Loss: 1.2650484769575057
Starting epoch 6/10.
0.0000 --- loss: 1.104372, loss_ss: 1.099698, loss_d: 0.004675
0.1608 --- loss: 1.121799, loss_ss: 1.058098, loss_d: 0.063701
0.3215 --- loss: 1.068453, loss_ss: 1.065282, loss_d: 0.003171
0.4823 --- loss: 1.012304, loss_ss: 1.007461, loss_d: 0.004842
0.6431 --- loss: 1.147165, loss_ss: 1.111412, loss_d: 0.035754
0.8039 --- loss: 1.199657, loss_ss: 1.182814, loss_d: 0.016844
0.9646 --- loss: 1.079464, loss_ss: 1.077422, loss_d: 0.002043
Epoch finished! Loss: 1.1354494373644552
Starting epoch 7/10.
0.0000 --- loss: 1.111878, loss_ss: 1.110176, loss_d: 0.001701
0.1608 --- loss: 1.220638, loss_ss: 1.211915, loss_d: 0.008723
0.3215 --- loss: 1.079767, loss_ss: 0.930763, loss_d: 0.149004
0.4823 --- loss: 0.990668, loss_ss: 0.985740, loss_d: 0.004928
0.6431 --- loss: 0.961712, loss_ss: 0.953012, loss_d: 0.008699
0.8039 --- loss: 0.913457, loss_ss: 0.912113, loss_d: 0.001344
0.9646 --- loss: 1.022601, loss_ss: 1.021706, loss_d: 0.000895
Epoch finished! Loss: 1.0660999119281769
Starting epoch 8/10.
0.0000 --- loss: 1.040668, loss_ss: 1.037142, loss_d: 0.003526
0.1608 --- loss: 0.881623, loss_ss: 0.878829, loss_d: 0.002794
0.3215 --- loss: 0.952047, loss_ss: 0.945624, loss_d: 0.006423
0.4823 --- loss: 1.084076, loss_ss: 1.071951, loss_d: 0.012125
0.6431 --- loss: 0.980741, loss_ss: 0.980132, loss_d: 0.000609
0.8039 --- loss: 1.023793, loss_ss: 1.021678, loss_d: 0.002115
0.9646 --- loss: 0.769899, loss_ss: 0.768000, loss_d: 0.001898
Epoch finished! Loss: 1.0150033350913756
Starting epoch 9/10.
0.0000 --- loss: 0.937128, loss_ss: 0.936782, loss_d: 0.000347
0.1608 --- loss: 0.907794, loss_ss: 0.907229, loss_d: 0.000565
0.3215 --- loss: 1.171158, loss_ss: 1.042932, loss_d: 0.128226
0.4823 --- loss: 0.935870, loss_ss: 0.927384, loss_d: 0.008486
0.6431 --- loss: 0.904694, loss_ss: 0.904481, loss_d: 0.000213
0.8039 --- loss: 0.817145, loss_ss: 0.811538, loss_d: 0.005608
0.9646 --- loss: 0.726390, loss_ss: 0.725212, loss_d: 0.001178
Epoch finished! Loss: 0.9407652722251031
Starting epoch 10/10.
0.0000 --- loss: 0.748752, loss_ss: 0.748217, loss_d: 0.000535
0.1608 --- loss: 0.970661, loss_ss: 0.931675, loss_d: 0.038986
0.3215 --- loss: 0.876544, loss_ss: 0.875637, loss_d: 0.000907
0.4823 --- loss: 0.764441, loss_ss: 0.763828, loss_d: 0.000613
0.6431 --- loss: 0.863183, loss_ss: 0.863079, loss_d: 0.000104
0.8039 --- loss: 0.912034, loss_ss: 0.911990, loss_d: 0.000044
0.9646 --- loss: 1.092762, loss_ss: 1.091423, loss_d: 0.001338
Epoch finished! Loss: 0.9947227133858588
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.521875
             precision    recall  f1-score   support

        0.0       0.13      0.97      0.23        32
        1.0       0.58      0.18      0.27       251
        2.0       0.48      0.80      0.60       208
        3.0       1.00      0.69      0.81       254
        4.0       0.72      0.40      0.51       215

avg / total       0.68      0.52      0.54       960
 


====== chp033-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  78.02  96.88   77.37   12.86     22.71
1  75.10  17.53   95.49   57.89     26.91
2  76.56  79.81   75.66   47.56     59.61
3  91.67  68.50  100.00  100.00     81.31
4  83.02  40.00   95.44   71.67     51.34
Total accuracy: 52.19%
Average sen: 60.54%
Average spec: 88.79%
Macro f1-score: 48.38%
Diagnosis acc on 60mins: 0.25
[2.49688252e-04 7.00792372e-01 9.29719925e-01 2.02166103e-02
 3.28475572e-02 4.27003473e-01 2.84422249e-01 1.28495783e-01]
pred: 0.3154684571454709, label: 1
Wrong!!! Real Diagnosis: NT1
Save 60mins of subject chp033-nsrr

=== Test on chp034-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.498074, loss_ss: 1.835477, loss_d: 0.662597
0.1608 --- loss: 2.389788, loss_ss: 1.676558, loss_d: 0.713230
0.3215 --- loss: 2.251726, loss_ss: 1.578346, loss_d: 0.673381
0.4823 --- loss: 2.404172, loss_ss: 1.594734, loss_d: 0.809438
0.6431 --- loss: 1.918913, loss_ss: 1.529326, loss_d: 0.389588
0.8039 --- loss: 2.006496, loss_ss: 1.568238, loss_d: 0.438258
0.9646 --- loss: 2.146816, loss_ss: 1.531136, loss_d: 0.615679
Epoch finished! Loss: 2.2560868513199592
Starting epoch 2/10.
0.0000 --- loss: 2.108621, loss_ss: 1.479538, loss_d: 0.629083
0.1608 --- loss: 1.984334, loss_ss: 1.445631, loss_d: 0.538703
0.3215 --- loss: 2.281330, loss_ss: 1.333219, loss_d: 0.948111
0.4823 --- loss: 1.654744, loss_ss: 1.350529, loss_d: 0.304214
0.6431 --- loss: 1.883644, loss_ss: 1.471951, loss_d: 0.411693
0.8039 --- loss: 2.225892, loss_ss: 1.454455, loss_d: 0.771436
0.9646 --- loss: 1.751251, loss_ss: 1.398932, loss_d: 0.352319
Epoch finished! Loss: 1.8635772505114157
Starting epoch 3/10.
0.0000 --- loss: 1.646572, loss_ss: 1.479092, loss_d: 0.167480
0.1608 --- loss: 1.584294, loss_ss: 1.371299, loss_d: 0.212996
0.3215 --- loss: 1.422031, loss_ss: 1.298961, loss_d: 0.123071
0.4823 --- loss: 1.847972, loss_ss: 1.311540, loss_d: 0.536431
0.6431 --- loss: 1.364817, loss_ss: 1.227984, loss_d: 0.136833
0.8039 --- loss: 1.390834, loss_ss: 1.201259, loss_d: 0.189575
0.9646 --- loss: 1.711971, loss_ss: 1.279073, loss_d: 0.432898
Epoch finished! Loss: 1.608985500950967
Starting epoch 4/10.
0.0000 --- loss: 1.419093, loss_ss: 1.222995, loss_d: 0.196098
0.1608 --- loss: 1.360688, loss_ss: 1.249566, loss_d: 0.111121
0.3215 --- loss: 1.371739, loss_ss: 1.216571, loss_d: 0.155168
0.4823 --- loss: 1.116373, loss_ss: 1.035786, loss_d: 0.080587
0.6431 --- loss: 1.231111, loss_ss: 1.174281, loss_d: 0.056829
0.8039 --- loss: 1.189384, loss_ss: 1.110888, loss_d: 0.078496
0.9646 --- loss: 1.297342, loss_ss: 1.137534, loss_d: 0.159808
Epoch finished! Loss: 1.3525151072009918
Starting epoch 5/10.
0.0000 --- loss: 1.054193, loss_ss: 1.049612, loss_d: 0.004581
0.1608 --- loss: 1.457163, loss_ss: 1.106985, loss_d: 0.350178
0.3215 --- loss: 1.157975, loss_ss: 1.054698, loss_d: 0.103277
0.4823 --- loss: 1.182774, loss_ss: 1.173749, loss_d: 0.009025
0.6431 --- loss: 1.059059, loss_ss: 1.023544, loss_d: 0.035515
0.8039 --- loss: 1.317716, loss_ss: 1.164481, loss_d: 0.153235
0.9646 --- loss: 1.609345, loss_ss: 1.021176, loss_d: 0.588169
Epoch finished! Loss: 1.1836797027818617
Starting epoch 6/10.
0.0000 --- loss: 1.066097, loss_ss: 1.057127, loss_d: 0.008970
0.1608 --- loss: 1.088861, loss_ss: 1.017139, loss_d: 0.071722
0.3215 --- loss: 1.372749, loss_ss: 1.338906, loss_d: 0.033843
0.4823 --- loss: 0.906065, loss_ss: 0.904200, loss_d: 0.001865
0.6431 --- loss: 0.984154, loss_ss: 0.975962, loss_d: 0.008192
0.8039 --- loss: 1.036454, loss_ss: 1.013955, loss_d: 0.022499
0.9646 --- loss: 1.056718, loss_ss: 1.041784, loss_d: 0.014935
Epoch finished! Loss: 1.11966257037655
Starting epoch 7/10.
0.0000 --- loss: 0.873009, loss_ss: 0.870242, loss_d: 0.002767
0.1608 --- loss: 0.889096, loss_ss: 0.884539, loss_d: 0.004557
0.3215 --- loss: 0.834085, loss_ss: 0.815618, loss_d: 0.018467
0.4823 --- loss: 0.946236, loss_ss: 0.943527, loss_d: 0.002708
0.6431 --- loss: 0.932362, loss_ss: 0.923446, loss_d: 0.008915
0.8039 --- loss: 0.871470, loss_ss: 0.852051, loss_d: 0.019418
0.9646 --- loss: 0.851440, loss_ss: 0.845190, loss_d: 0.006250
Epoch finished! Loss: 1.0449381095747794
Starting epoch 8/10.
0.0000 --- loss: 0.970659, loss_ss: 0.966648, loss_d: 0.004011
0.1608 --- loss: 1.077997, loss_ss: 1.073063, loss_d: 0.004934
0.3215 --- loss: 1.059923, loss_ss: 1.001027, loss_d: 0.058896
0.4823 --- loss: 0.823082, loss_ss: 0.816123, loss_d: 0.006959
0.6431 --- loss: 1.000900, loss_ss: 0.879397, loss_d: 0.121503
0.8039 --- loss: 0.998047, loss_ss: 0.958981, loss_d: 0.039066
0.9646 --- loss: 0.852785, loss_ss: 0.847732, loss_d: 0.005053
Epoch finished! Loss: 0.9684880760408217
Starting epoch 9/10.
0.0000 --- loss: 0.891617, loss_ss: 0.890122, loss_d: 0.001495
0.1608 --- loss: 0.827239, loss_ss: 0.826706, loss_d: 0.000532
0.3215 --- loss: 0.826170, loss_ss: 0.820431, loss_d: 0.005738
0.4823 --- loss: 0.839140, loss_ss: 0.837755, loss_d: 0.001386
0.6431 --- loss: 0.922108, loss_ss: 0.920709, loss_d: 0.001398
0.8039 --- loss: 0.860946, loss_ss: 0.860129, loss_d: 0.000817
0.9646 --- loss: 0.863143, loss_ss: 0.860447, loss_d: 0.002696
Epoch finished! Loss: 0.9409940117789853
Starting epoch 10/10.
0.0000 --- loss: 0.852724, loss_ss: 0.848600, loss_d: 0.004124
0.1608 --- loss: 0.904559, loss_ss: 0.896317, loss_d: 0.008243
0.3215 --- loss: 0.897327, loss_ss: 0.896662, loss_d: 0.000665
0.4823 --- loss: 0.964233, loss_ss: 0.954783, loss_d: 0.009450
0.6431 --- loss: 0.986020, loss_ss: 0.975820, loss_d: 0.010199
0.8039 --- loss: 0.932904, loss_ss: 0.924484, loss_d: 0.008419
0.9646 --- loss: 0.900287, loss_ss: 0.899022, loss_d: 0.001265
Epoch finished! Loss: 0.9311145774779781
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6291666666666667
             precision    recall  f1-score   support

        0.0       0.10      0.18      0.12        17
        1.0       0.00      0.00      0.00        62
        2.0       0.62      0.58      0.60       345
        3.0       0.97      0.61      0.75       317
        4.0       0.51      0.95      0.66       219

avg / total       0.66      0.63      0.62       960
 


====== chp034-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.62  17.65   97.03   9.68     12.50
1  93.54   0.00  100.00   0.00      0.00
2  72.40  57.97   80.49  62.50     60.15
3  86.56  60.88   99.22  97.47     74.95
4  77.71  94.98   72.60  50.61     66.03
Total accuracy: 62.92%
Average sen: 46.30%
Average spec: 89.87%
Macro f1-score: 42.73%
Diagnosis acc on 60mins: 0.875
[0.99999321 0.99994719 0.99999547 0.99992597 0.99924052 0.02894362
 0.98205316 0.99995482]
pred: 0.8762567441444844, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp034-nsrr

=== Test on chp036-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.411683, loss_ss: 1.718606, loss_d: 0.693077
0.1613 --- loss: 2.088439, loss_ss: 1.554318, loss_d: 0.534121
0.3226 --- loss: 2.323261, loss_ss: 1.598010, loss_d: 0.725250
0.4839 --- loss: 2.045117, loss_ss: 1.511820, loss_d: 0.533296
0.6452 --- loss: 1.838859, loss_ss: 1.409449, loss_d: 0.429410
0.8065 --- loss: 2.141168, loss_ss: 1.449280, loss_d: 0.691888
0.9677 --- loss: 2.038679, loss_ss: 1.482642, loss_d: 0.556037
Epoch finished! Loss: 2.1361942447599818
Starting epoch 2/10.
0.0000 --- loss: 1.774927, loss_ss: 1.347760, loss_d: 0.427166
0.1613 --- loss: 1.761434, loss_ss: 1.270063, loss_d: 0.491372
0.3226 --- loss: 1.639177, loss_ss: 1.292543, loss_d: 0.346633
0.4839 --- loss: 1.873973, loss_ss: 1.258523, loss_d: 0.615450
0.6452 --- loss: 1.504402, loss_ss: 1.296773, loss_d: 0.207629
0.8065 --- loss: 1.684536, loss_ss: 1.249348, loss_d: 0.435188
0.9677 --- loss: 1.582341, loss_ss: 1.231371, loss_d: 0.350970
Epoch finished! Loss: 1.7676958353793035
Starting epoch 3/10.
0.0000 --- loss: 1.468706, loss_ss: 1.283808, loss_d: 0.184897
0.1613 --- loss: 1.356295, loss_ss: 1.181988, loss_d: 0.174306
0.3226 --- loss: 1.416751, loss_ss: 1.208401, loss_d: 0.208349
0.4839 --- loss: 1.419835, loss_ss: 1.169794, loss_d: 0.250040
0.6452 --- loss: 1.190160, loss_ss: 1.176584, loss_d: 0.013575
0.8065 --- loss: 1.781824, loss_ss: 1.293191, loss_d: 0.488634
0.9677 --- loss: 1.182980, loss_ss: 1.069614, loss_d: 0.113366
Epoch finished! Loss: 1.4433245228939369
Starting epoch 4/10.
0.0000 --- loss: 1.227266, loss_ss: 1.154654, loss_d: 0.072613
0.1613 --- loss: 1.152209, loss_ss: 1.105133, loss_d: 0.047076
0.3226 --- loss: 1.217395, loss_ss: 1.076410, loss_d: 0.140986
0.4839 --- loss: 1.338811, loss_ss: 1.053013, loss_d: 0.285798
0.6452 --- loss: 1.190187, loss_ss: 1.148049, loss_d: 0.042138
0.8065 --- loss: 1.147018, loss_ss: 0.994212, loss_d: 0.152806
0.9677 --- loss: 1.485055, loss_ss: 1.101723, loss_d: 0.383332
Epoch finished! Loss: 1.251364115808831
Starting epoch 5/10.
0.0000 --- loss: 1.000660, loss_ss: 0.994859, loss_d: 0.005800
0.1613 --- loss: 1.289130, loss_ss: 1.192217, loss_d: 0.096913
0.3226 --- loss: 1.246335, loss_ss: 1.237219, loss_d: 0.009116
0.4839 --- loss: 1.067275, loss_ss: 0.988472, loss_d: 0.078803
0.6452 --- loss: 1.105628, loss_ss: 1.054646, loss_d: 0.050982
0.8065 --- loss: 0.968149, loss_ss: 0.962477, loss_d: 0.005672
0.9677 --- loss: 1.297498, loss_ss: 1.290131, loss_d: 0.007366
Epoch finished! Loss: 1.1301564427672839
Starting epoch 6/10.
0.0000 --- loss: 1.371891, loss_ss: 0.986250, loss_d: 0.385642
0.1613 --- loss: 1.057775, loss_ss: 0.938165, loss_d: 0.119610
0.3226 --- loss: 1.159317, loss_ss: 1.155909, loss_d: 0.003409
0.4839 --- loss: 1.074166, loss_ss: 1.071402, loss_d: 0.002765
0.6452 --- loss: 0.911753, loss_ss: 0.904543, loss_d: 0.007211
0.8065 --- loss: 0.919076, loss_ss: 0.839498, loss_d: 0.079578
0.9677 --- loss: 0.984910, loss_ss: 0.964991, loss_d: 0.019919
Epoch finished! Loss: 1.0524316185810527
Starting epoch 7/10.
0.0000 --- loss: 1.420537, loss_ss: 1.085060, loss_d: 0.335477
0.1613 --- loss: 0.852880, loss_ss: 0.839866, loss_d: 0.013014
0.3226 --- loss: 1.010276, loss_ss: 0.935019, loss_d: 0.075257
0.4839 --- loss: 1.047384, loss_ss: 1.019716, loss_d: 0.027667
0.6452 --- loss: 0.980724, loss_ss: 0.974450, loss_d: 0.006273
0.8065 --- loss: 1.028167, loss_ss: 0.940053, loss_d: 0.088113
0.9677 --- loss: 0.936144, loss_ss: 0.914958, loss_d: 0.021186
Epoch finished! Loss: 1.0350923372096703
Starting epoch 8/10.
0.0000 --- loss: 0.916529, loss_ss: 0.912955, loss_d: 0.003574
0.1613 --- loss: 0.966345, loss_ss: 0.964166, loss_d: 0.002179
0.3226 --- loss: 0.791215, loss_ss: 0.790552, loss_d: 0.000663
0.4839 --- loss: 1.053168, loss_ss: 1.052656, loss_d: 0.000512
0.6452 --- loss: 1.185526, loss_ss: 1.184666, loss_d: 0.000860
0.8065 --- loss: 0.790279, loss_ss: 0.789337, loss_d: 0.000943
0.9677 --- loss: 0.829983, loss_ss: 0.826606, loss_d: 0.003378
Epoch finished! Loss: 0.970877073827337
Starting epoch 9/10.
0.0000 --- loss: 1.233052, loss_ss: 1.161616, loss_d: 0.071436
0.1613 --- loss: 1.084256, loss_ss: 1.067978, loss_d: 0.016278
0.3226 --- loss: 1.007452, loss_ss: 0.828918, loss_d: 0.178534
0.4839 --- loss: 0.898379, loss_ss: 0.893320, loss_d: 0.005059
0.6452 --- loss: 0.816196, loss_ss: 0.810177, loss_d: 0.006019
0.8065 --- loss: 0.834514, loss_ss: 0.829314, loss_d: 0.005201
0.9677 --- loss: 0.970963, loss_ss: 0.877635, loss_d: 0.093328
Epoch finished! Loss: 0.9435697852588091
Starting epoch 10/10.
0.0000 --- loss: 0.860908, loss_ss: 0.830869, loss_d: 0.030039
0.1613 --- loss: 0.778099, loss_ss: 0.774811, loss_d: 0.003288
0.3226 --- loss: 0.816051, loss_ss: 0.809881, loss_d: 0.006170
0.4839 --- loss: 1.230670, loss_ss: 1.090892, loss_d: 0.139778
0.6452 --- loss: 1.208919, loss_ss: 0.912161, loss_d: 0.296758
0.8065 --- loss: 1.259202, loss_ss: 1.122802, loss_d: 0.136400
0.9677 --- loss: 1.023592, loss_ss: 1.021514, loss_d: 0.002079
Epoch finished! Loss: 0.9517500547112011
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7833333333333333
             precision    recall  f1-score   support

        0.0       0.85      0.76      0.80       226
        1.0       1.00      0.02      0.05       164
        2.0       0.90      0.94      0.92       563
        3.0       0.00      0.00      0.00         8
        4.0       0.58      0.98      0.73       239

avg / total       0.83      0.78      0.73      1200
 


====== chp036-nsrr ======

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  93.00  76.11   96.92   85.15     80.37
1  86.67   2.44  100.00  100.00      4.76
2  92.08  93.96   90.42   89.66     91.76
3  99.25   0.00   99.92    0.00      0.00
4  85.67  98.33   82.52   58.31     73.21
Total accuracy: 78.33%
Average sen: 54.17%
Average spec: 93.96%
Macro f1-score: 50.02%
Diagnosis acc on 60mins: 1.0
[0.99999273 0.99999952 1.         0.99999321 0.99999893 0.99999988
 0.99992013 0.99998403 0.99999917 0.99999905]
pred: 0.9999886631965638, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp036-nsrr

=== Test on chp037-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.487550, loss_ss: 1.848224, loss_d: 0.639326
0.1608 --- loss: 2.113481, loss_ss: 1.694046, loss_d: 0.419435
0.3215 --- loss: 2.163743, loss_ss: 1.512974, loss_d: 0.650769
0.4823 --- loss: 2.356773, loss_ss: 1.701491, loss_d: 0.655282
0.6431 --- loss: 1.930034, loss_ss: 1.597869, loss_d: 0.332165
0.8039 --- loss: 2.158031, loss_ss: 1.584153, loss_d: 0.573878
0.9646 --- loss: 1.962763, loss_ss: 1.595063, loss_d: 0.367700
Epoch finished! Loss: 2.2302080162109865
Starting epoch 2/10.
0.0000 --- loss: 1.946858, loss_ss: 1.439147, loss_d: 0.507710
0.1608 --- loss: 2.225784, loss_ss: 1.562287, loss_d: 0.663497
0.3215 --- loss: 1.914232, loss_ss: 1.565314, loss_d: 0.348918
0.4823 --- loss: 1.989070, loss_ss: 1.539702, loss_d: 0.449369
0.6431 --- loss: 1.850876, loss_ss: 1.495290, loss_d: 0.355586
0.8039 --- loss: 1.773107, loss_ss: 1.434336, loss_d: 0.338771
0.9646 --- loss: 1.743834, loss_ss: 1.389541, loss_d: 0.354293
Epoch finished! Loss: 1.9157945109951882
Starting epoch 3/10.
0.0000 --- loss: 2.158400, loss_ss: 1.454655, loss_d: 0.703745
0.1608 --- loss: 1.603815, loss_ss: 1.475993, loss_d: 0.127821
0.3215 --- loss: 1.460827, loss_ss: 1.367552, loss_d: 0.093275
0.4823 --- loss: 1.658802, loss_ss: 1.401549, loss_d: 0.257252
0.6431 --- loss: 1.868824, loss_ss: 1.334827, loss_d: 0.533997
0.8039 --- loss: 1.281669, loss_ss: 1.237300, loss_d: 0.044369
0.9646 --- loss: 1.464383, loss_ss: 1.283386, loss_d: 0.180997
Epoch finished! Loss: 1.6415038128052988
Starting epoch 4/10.
0.0000 --- loss: 1.400950, loss_ss: 1.258950, loss_d: 0.142000
0.1608 --- loss: 1.288340, loss_ss: 1.270039, loss_d: 0.018301
0.3215 --- loss: 1.234965, loss_ss: 1.198774, loss_d: 0.036191
0.4823 --- loss: 1.291679, loss_ss: 1.203248, loss_d: 0.088431
0.6431 --- loss: 1.363274, loss_ss: 1.240909, loss_d: 0.122365
0.8039 --- loss: 1.396057, loss_ss: 1.286182, loss_d: 0.109875
0.9646 --- loss: 1.443002, loss_ss: 1.138014, loss_d: 0.304987
Epoch finished! Loss: 1.469839411397134
Starting epoch 5/10.
0.0000 --- loss: 1.330277, loss_ss: 1.305574, loss_d: 0.024704
0.1608 --- loss: 1.252267, loss_ss: 1.198436, loss_d: 0.053831
0.3215 --- loss: 1.326026, loss_ss: 1.306133, loss_d: 0.019894
0.4823 --- loss: 1.603371, loss_ss: 1.207713, loss_d: 0.395658
0.6431 --- loss: 1.192628, loss_ss: 1.143120, loss_d: 0.049508
0.8039 --- loss: 1.344714, loss_ss: 1.181865, loss_d: 0.162849
0.9646 --- loss: 1.437336, loss_ss: 1.365553, loss_d: 0.071783
Epoch finished! Loss: 1.319217349252393
Starting epoch 6/10.
0.0000 --- loss: 1.161005, loss_ss: 1.125464, loss_d: 0.035541
0.1608 --- loss: 1.058092, loss_ss: 1.049832, loss_d: 0.008259
0.3215 --- loss: 1.106935, loss_ss: 1.100294, loss_d: 0.006641
0.4823 --- loss: 1.261057, loss_ss: 1.034685, loss_d: 0.226371
0.6431 --- loss: 1.131436, loss_ss: 1.130998, loss_d: 0.000438
0.8039 --- loss: 1.160505, loss_ss: 1.109968, loss_d: 0.050537
0.9646 --- loss: 1.060828, loss_ss: 0.956914, loss_d: 0.103915
Epoch finished! Loss: 1.1579231639062204
Starting epoch 7/10.
0.0000 --- loss: 1.054971, loss_ss: 1.043962, loss_d: 0.011009
0.1608 --- loss: 1.110982, loss_ss: 1.042578, loss_d: 0.068404
0.3215 --- loss: 1.137068, loss_ss: 1.064308, loss_d: 0.072760
0.4823 --- loss: 1.017645, loss_ss: 1.009002, loss_d: 0.008643
0.6431 --- loss: 1.173281, loss_ss: 1.129294, loss_d: 0.043987
0.8039 --- loss: 1.556176, loss_ss: 1.196970, loss_d: 0.359206
0.9646 --- loss: 0.971550, loss_ss: 0.903364, loss_d: 0.068187
Epoch finished! Loss: 1.0935607581369338
Starting epoch 8/10.
0.0000 --- loss: 0.918108, loss_ss: 0.916708, loss_d: 0.001399
0.1608 --- loss: 1.003152, loss_ss: 0.999152, loss_d: 0.004000
0.3215 --- loss: 0.949281, loss_ss: 0.942299, loss_d: 0.006982
0.4823 --- loss: 0.857148, loss_ss: 0.819183, loss_d: 0.037965
0.6431 --- loss: 0.945126, loss_ss: 0.944739, loss_d: 0.000387
0.8039 --- loss: 1.043527, loss_ss: 1.027837, loss_d: 0.015690
0.9646 --- loss: 0.917239, loss_ss: 0.911723, loss_d: 0.005516
Epoch finished! Loss: 1.010917612621861
Starting epoch 9/10.
0.0000 --- loss: 0.850661, loss_ss: 0.849408, loss_d: 0.001253
0.1608 --- loss: 0.960951, loss_ss: 0.959687, loss_d: 0.001264
0.3215 --- loss: 1.114969, loss_ss: 1.086409, loss_d: 0.028560
0.4823 --- loss: 0.913157, loss_ss: 0.824625, loss_d: 0.088532
0.6431 --- loss: 0.874978, loss_ss: 0.855213, loss_d: 0.019765
0.8039 --- loss: 0.884289, loss_ss: 0.883565, loss_d: 0.000724
0.9646 --- loss: 0.940814, loss_ss: 0.912480, loss_d: 0.028335
Epoch finished! Loss: 0.9908936244826163
Starting epoch 10/10.
0.0000 --- loss: 0.907692, loss_ss: 0.888969, loss_d: 0.018723
0.1608 --- loss: 0.859270, loss_ss: 0.853646, loss_d: 0.005624
0.3215 --- loss: 0.779129, loss_ss: 0.778010, loss_d: 0.001119
0.4823 --- loss: 0.824684, loss_ss: 0.823307, loss_d: 0.001376
0.6431 --- loss: 0.897401, loss_ss: 0.893598, loss_d: 0.003803
0.8039 --- loss: 0.885815, loss_ss: 0.880551, loss_d: 0.005264
0.9646 --- loss: 0.786453, loss_ss: 0.785224, loss_d: 0.001229
Epoch finished! Loss: 0.9319443327765311
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.68580375782881
             precision    recall  f1-score   support

        0.0       0.72      0.66      0.69       191
        1.0       0.40      0.43      0.41       161
        2.0       0.73      0.69      0.71       294
        3.0       0.99      0.87      0.93       208
        4.0       0.53      0.75      0.62       104

avg / total       0.71      0.69      0.69       958
 


====== chp037-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  88.20  66.49   93.61  72.16     69.21
1  79.44  42.86   86.83  39.66     41.19
2  82.46  68.71   88.55  72.66     70.63
3  96.97  87.02   99.73  98.91     92.58
4  90.08  75.00   91.92  53.06     62.15
Total accuracy: 68.58%
Average sen: 68.02%
Average spec: 92.13%
Macro f1-score: 67.15%
Diagnosis acc on 60mins: 1.0
[0.99686027 0.99994195 0.99996603 0.99998331 0.99974352 0.99919885
 0.99976581 0.99984741]
pred: 0.9994133934378624, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp037-nsrr

=== Test on chp038-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.303812, loss_ss: 1.612699, loss_d: 0.691113
0.1608 --- loss: 2.119860, loss_ss: 1.516274, loss_d: 0.603586
0.3215 --- loss: 2.219169, loss_ss: 1.468615, loss_d: 0.750554
0.4823 --- loss: 1.765450, loss_ss: 1.571825, loss_d: 0.193625
0.6431 --- loss: 2.076944, loss_ss: 1.388164, loss_d: 0.688780
0.8039 --- loss: 2.013026, loss_ss: 1.395152, loss_d: 0.617875
0.9646 --- loss: 2.001713, loss_ss: 1.315140, loss_d: 0.686573
Epoch finished! Loss: 2.101922388999693
Starting epoch 2/10.
0.0000 --- loss: 1.858994, loss_ss: 1.419513, loss_d: 0.439481
0.1608 --- loss: 1.681673, loss_ss: 1.380832, loss_d: 0.300841
0.3215 --- loss: 1.603252, loss_ss: 1.271073, loss_d: 0.332179
0.4823 --- loss: 1.682714, loss_ss: 1.237251, loss_d: 0.445463
0.6431 --- loss: 1.891038, loss_ss: 1.318731, loss_d: 0.572307
0.8039 --- loss: 1.614559, loss_ss: 1.280154, loss_d: 0.334406
0.9646 --- loss: 1.614927, loss_ss: 1.067354, loss_d: 0.547573
Epoch finished! Loss: 1.8223729691197794
Starting epoch 3/10.
0.0000 --- loss: 1.636287, loss_ss: 1.167775, loss_d: 0.468512
0.1608 --- loss: 1.745423, loss_ss: 1.229262, loss_d: 0.516161
0.3215 --- loss: 2.053658, loss_ss: 1.237339, loss_d: 0.816319
0.4823 --- loss: 1.448575, loss_ss: 1.163500, loss_d: 0.285075
0.6431 --- loss: 1.353562, loss_ss: 1.196640, loss_d: 0.156922
0.8039 --- loss: 1.359177, loss_ss: 1.255210, loss_d: 0.103967
0.9646 --- loss: 1.627756, loss_ss: 1.264223, loss_d: 0.363533
Epoch finished! Loss: 1.535427918357234
Starting epoch 4/10.
0.0000 --- loss: 1.508760, loss_ss: 1.240639, loss_d: 0.268121
0.1608 --- loss: 1.338654, loss_ss: 1.185318, loss_d: 0.153336
0.3215 --- loss: 1.244495, loss_ss: 1.012273, loss_d: 0.232222
0.4823 --- loss: 1.208829, loss_ss: 0.997853, loss_d: 0.210977
0.6431 --- loss: 1.299398, loss_ss: 1.113399, loss_d: 0.185999
0.8039 --- loss: 1.095494, loss_ss: 1.070493, loss_d: 0.025001
0.9646 --- loss: 1.279673, loss_ss: 1.229611, loss_d: 0.050063
Epoch finished! Loss: 1.3319182069070878
Starting epoch 5/10.
0.0000 --- loss: 1.087357, loss_ss: 1.037740, loss_d: 0.049617
0.1608 --- loss: 1.040522, loss_ss: 0.972608, loss_d: 0.067913
0.3215 --- loss: 1.100415, loss_ss: 1.063089, loss_d: 0.037326
0.4823 --- loss: 1.202174, loss_ss: 1.139908, loss_d: 0.062267
0.6431 --- loss: 1.156248, loss_ss: 1.113897, loss_d: 0.042352
0.8039 --- loss: 1.367414, loss_ss: 1.295307, loss_d: 0.072107
0.9646 --- loss: 1.103107, loss_ss: 1.065775, loss_d: 0.037331
Epoch finished! Loss: 1.1653931179354269
Starting epoch 6/10.
0.0000 --- loss: 1.614925, loss_ss: 1.209983, loss_d: 0.404941
0.1608 --- loss: 0.985290, loss_ss: 0.955978, loss_d: 0.029312
0.3215 --- loss: 1.282094, loss_ss: 1.111092, loss_d: 0.171002
0.4823 --- loss: 1.200027, loss_ss: 1.049979, loss_d: 0.150049
0.6431 --- loss: 1.117123, loss_ss: 1.100162, loss_d: 0.016960
0.8039 --- loss: 1.076149, loss_ss: 1.023552, loss_d: 0.052597
0.9646 --- loss: 1.186404, loss_ss: 0.979296, loss_d: 0.207108
Epoch finished! Loss: 1.1282959647717015
Starting epoch 7/10.
0.0000 --- loss: 1.213342, loss_ss: 1.198310, loss_d: 0.015032
0.1608 --- loss: 1.272503, loss_ss: 1.236260, loss_d: 0.036243
0.3215 --- loss: 0.910333, loss_ss: 0.908540, loss_d: 0.001794
0.4823 --- loss: 0.842203, loss_ss: 0.833929, loss_d: 0.008274
0.6431 --- loss: 0.965145, loss_ss: 0.960168, loss_d: 0.004977
0.8039 --- loss: 0.874054, loss_ss: 0.839980, loss_d: 0.034074
0.9646 --- loss: 0.813223, loss_ss: 0.811735, loss_d: 0.001488
Epoch finished! Loss: 1.0484402016285927
Starting epoch 8/10.
0.0000 --- loss: 1.195282, loss_ss: 1.192452, loss_d: 0.002830
0.1608 --- loss: 0.956238, loss_ss: 0.955478, loss_d: 0.000759
0.3215 --- loss: 1.195498, loss_ss: 1.194324, loss_d: 0.001174
0.4823 --- loss: 0.894004, loss_ss: 0.873387, loss_d: 0.020617
0.6431 --- loss: 0.893057, loss_ss: 0.890858, loss_d: 0.002199
0.8039 --- loss: 1.030254, loss_ss: 1.029841, loss_d: 0.000413
0.9646 --- loss: 1.102487, loss_ss: 1.047450, loss_d: 0.055037
Epoch finished! Loss: 0.9968735806403621
Starting epoch 9/10.
0.0000 --- loss: 0.949641, loss_ss: 0.942411, loss_d: 0.007231
0.1608 --- loss: 1.007509, loss_ss: 1.007026, loss_d: 0.000482
0.3215 --- loss: 0.923808, loss_ss: 0.909010, loss_d: 0.014798
0.4823 --- loss: 0.952547, loss_ss: 0.952264, loss_d: 0.000283
0.6431 --- loss: 0.880695, loss_ss: 0.880011, loss_d: 0.000684
0.8039 --- loss: 1.017425, loss_ss: 1.017198, loss_d: 0.000228
0.9646 --- loss: 0.818319, loss_ss: 0.818056, loss_d: 0.000264
Epoch finished! Loss: 0.965877854054974
Starting epoch 10/10.
0.0000 --- loss: 0.940362, loss_ss: 0.934985, loss_d: 0.005377
0.1608 --- loss: 1.148525, loss_ss: 1.148264, loss_d: 0.000261
0.3215 --- loss: 0.931656, loss_ss: 0.931243, loss_d: 0.000413
0.4823 --- loss: 1.048581, loss_ss: 1.048384, loss_d: 0.000197
0.6431 --- loss: 0.759894, loss_ss: 0.759689, loss_d: 0.000205
0.8039 --- loss: 0.883068, loss_ss: 0.882712, loss_d: 0.000356
0.9646 --- loss: 0.954490, loss_ss: 0.954280, loss_d: 0.000210
Epoch finished! Loss: 0.9257276663857121
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6739583333333333
             precision    recall  f1-score   support

        0.0       0.07      0.02      0.03        61
        1.0       0.33      0.08      0.13       157
        2.0       0.69      0.98      0.81       417
        3.0       1.00      0.74      0.85       102
        4.0       0.63      0.67      0.65       223

avg / total       0.61      0.67      0.62       960
 


====== chp038-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  92.29   1.64   98.44    6.67      2.63
1  82.19   8.28   96.64   32.50     13.20
2  80.00  98.08   66.11   68.97     80.99
3  97.19  73.53  100.00  100.00     84.75
4  83.12  66.82   88.06   62.87     64.78
Total accuracy: 67.40%
Average sen: 49.67%
Average spec: 89.85%
Macro f1-score: 49.27%
Diagnosis acc on 60mins: 1.0
[0.99999869 0.99998212 0.99998319 0.99999261 0.99998796 0.99999881
 0.9999969  0.99990213]
pred: 0.9999803006649017, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp038-nsrr

=== Test on chp039-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.333206, loss_ss: 1.671897, loss_d: 0.661309
0.1610 --- loss: 2.346426, loss_ss: 1.723655, loss_d: 0.622770
0.3221 --- loss: 2.168634, loss_ss: 1.607649, loss_d: 0.560985
0.4831 --- loss: 2.130651, loss_ss: 1.533443, loss_d: 0.597208
0.6441 --- loss: 1.929795, loss_ss: 1.448427, loss_d: 0.481368
0.8052 --- loss: 2.317150, loss_ss: 1.448143, loss_d: 0.869008
0.9662 --- loss: 2.086022, loss_ss: 1.445430, loss_d: 0.640592
Epoch finished! Loss: 2.2032470510851954
Starting epoch 2/10.
0.0000 --- loss: 1.959197, loss_ss: 1.392058, loss_d: 0.567139
0.1610 --- loss: 1.920500, loss_ss: 1.392964, loss_d: 0.527536
0.3221 --- loss: 2.121158, loss_ss: 1.489027, loss_d: 0.632131
0.4831 --- loss: 1.886405, loss_ss: 1.418759, loss_d: 0.467645
0.6441 --- loss: 1.928959, loss_ss: 1.316714, loss_d: 0.612246
0.8052 --- loss: 1.856161, loss_ss: 1.421564, loss_d: 0.434597
0.9662 --- loss: 1.991630, loss_ss: 1.482333, loss_d: 0.509297
Epoch finished! Loss: 1.9133622800150225
Starting epoch 3/10.
0.0000 --- loss: 1.638512, loss_ss: 1.319933, loss_d: 0.318579
0.1610 --- loss: 1.320531, loss_ss: 1.234164, loss_d: 0.086367
0.3221 --- loss: 1.656893, loss_ss: 1.290124, loss_d: 0.366770
0.4831 --- loss: 1.560771, loss_ss: 1.239729, loss_d: 0.321042
0.6441 --- loss: 1.445454, loss_ss: 1.262175, loss_d: 0.183278
0.8052 --- loss: 1.615512, loss_ss: 1.288517, loss_d: 0.326995
0.9662 --- loss: 1.358684, loss_ss: 1.192977, loss_d: 0.165707
Epoch finished! Loss: 1.6357514146835572
Starting epoch 4/10.
0.0000 --- loss: 1.460682, loss_ss: 1.288575, loss_d: 0.172107
0.1610 --- loss: 1.130422, loss_ss: 1.028483, loss_d: 0.101939
0.3221 --- loss: 1.576985, loss_ss: 1.359601, loss_d: 0.217384
0.4831 --- loss: 1.264739, loss_ss: 1.127017, loss_d: 0.137722
0.6441 --- loss: 1.278545, loss_ss: 1.068552, loss_d: 0.209994
0.8052 --- loss: 1.203137, loss_ss: 1.152074, loss_d: 0.051063
0.9662 --- loss: 1.136314, loss_ss: 1.100782, loss_d: 0.035533
Epoch finished! Loss: 1.4325517300636537
Starting epoch 5/10.
0.0000 --- loss: 1.025779, loss_ss: 1.012058, loss_d: 0.013721
0.1610 --- loss: 1.164516, loss_ss: 1.144831, loss_d: 0.019685
0.3221 --- loss: 1.259324, loss_ss: 1.171099, loss_d: 0.088226
0.4831 --- loss: 1.386826, loss_ss: 1.277283, loss_d: 0.109543
0.6441 --- loss: 1.233692, loss_ss: 1.156555, loss_d: 0.077137
0.8052 --- loss: 1.216923, loss_ss: 1.019910, loss_d: 0.197014
0.9662 --- loss: 1.105595, loss_ss: 1.099299, loss_d: 0.006296
Epoch finished! Loss: 1.26969561749889
Starting epoch 6/10.
0.0000 --- loss: 1.048414, loss_ss: 0.970395, loss_d: 0.078018
0.1610 --- loss: 1.087217, loss_ss: 1.051217, loss_d: 0.036000
0.3221 --- loss: 1.175447, loss_ss: 1.150300, loss_d: 0.025146
0.4831 --- loss: 0.868311, loss_ss: 0.849860, loss_d: 0.018451
0.6441 --- loss: 1.116667, loss_ss: 1.084823, loss_d: 0.031844
0.8052 --- loss: 1.149497, loss_ss: 1.142721, loss_d: 0.006776
0.9662 --- loss: 1.099795, loss_ss: 1.018576, loss_d: 0.081219
Epoch finished! Loss: 1.0966583259644047
Starting epoch 7/10.
0.0000 --- loss: 0.994927, loss_ss: 0.985705, loss_d: 0.009222
0.1610 --- loss: 0.941066, loss_ss: 0.936037, loss_d: 0.005029
0.3221 --- loss: 1.030128, loss_ss: 0.973292, loss_d: 0.056836
0.4831 --- loss: 0.917575, loss_ss: 0.905635, loss_d: 0.011940
0.6441 --- loss: 0.877349, loss_ss: 0.832525, loss_d: 0.044824
0.8052 --- loss: 1.018803, loss_ss: 0.984675, loss_d: 0.034128
0.9662 --- loss: 0.934495, loss_ss: 0.933824, loss_d: 0.000670
Epoch finished! Loss: 0.999853108198412
Starting epoch 8/10.
0.0000 --- loss: 1.026558, loss_ss: 1.010583, loss_d: 0.015975
0.1610 --- loss: 0.933562, loss_ss: 0.932063, loss_d: 0.001499
0.3221 --- loss: 1.014080, loss_ss: 1.013441, loss_d: 0.000638
0.4831 --- loss: 0.994832, loss_ss: 0.986263, loss_d: 0.008570
0.6441 --- loss: 0.830048, loss_ss: 0.827423, loss_d: 0.002624
0.8052 --- loss: 0.909715, loss_ss: 0.907751, loss_d: 0.001964
0.9662 --- loss: 0.724471, loss_ss: 0.719361, loss_d: 0.005110
Epoch finished! Loss: 0.9559309799824992
Starting epoch 9/10.
0.0000 --- loss: 0.880027, loss_ss: 0.879083, loss_d: 0.000944
0.1610 --- loss: 0.900169, loss_ss: 0.897949, loss_d: 0.002220
0.3221 --- loss: 0.902584, loss_ss: 0.899951, loss_d: 0.002633
0.4831 --- loss: 0.805881, loss_ss: 0.804907, loss_d: 0.000974
0.6441 --- loss: 0.940586, loss_ss: 0.940505, loss_d: 0.000081
0.8052 --- loss: 0.925340, loss_ss: 0.922668, loss_d: 0.002672
0.9662 --- loss: 1.052801, loss_ss: 1.040206, loss_d: 0.012595
Epoch finished! Loss: 0.9501487612724304
Starting epoch 10/10.
0.0000 --- loss: 0.844471, loss_ss: 0.839548, loss_d: 0.004923
0.1610 --- loss: 0.949167, loss_ss: 0.860613, loss_d: 0.088555
0.3221 --- loss: 0.907827, loss_ss: 0.878752, loss_d: 0.029075
0.4831 --- loss: 0.878894, loss_ss: 0.862745, loss_d: 0.016149
0.6441 --- loss: 0.763312, loss_ss: 0.752303, loss_d: 0.011009
0.8052 --- loss: 1.027051, loss_ss: 1.019559, loss_d: 0.007491
0.9662 --- loss: 0.972446, loss_ss: 0.844973, loss_d: 0.127473
Epoch finished! Loss: 0.9702763134433378
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.3287037037037037
             precision    recall  f1-score   support

        0.0       0.05      0.89      0.09        19
        1.0       0.09      0.01      0.02       325
        2.0       0.68      0.30      0.42       376
        3.0       1.00      0.63      0.78       199
        4.0       0.24      0.59      0.34       161

avg / total       0.48      0.33      0.35      1080
 


====== chp039-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  69.17  89.47   68.80    4.89      9.26
1  66.30   1.23   94.30    8.51      2.15
2  70.74  30.05   92.47   68.07     41.70
3  93.24  63.32  100.00  100.00     77.54
4  66.30  59.01   67.57   24.17     34.30
Total accuracy: 32.87%
Average sen: 48.62%
Average spec: 84.63%
Macro f1-score: 32.99%
Diagnosis acc on 60mins: 1.0
[0.9973399  1.         0.99999988 0.99999964 0.99999738 0.99959964
 0.99999976 0.99999964 1.        ]
pred: 0.999659538269043, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp039-nsrr

=== Test on chp040-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.404836, loss_ss: 1.699363, loss_d: 0.705473
0.1608 --- loss: 2.290370, loss_ss: 1.606180, loss_d: 0.684190
0.3215 --- loss: 1.992174, loss_ss: 1.531505, loss_d: 0.460669
0.4823 --- loss: 2.909354, loss_ss: 1.532311, loss_d: 1.377043
0.6431 --- loss: 2.002576, loss_ss: 1.459702, loss_d: 0.542875
0.8039 --- loss: 2.150641, loss_ss: 1.445556, loss_d: 0.705085
0.9646 --- loss: 2.331237, loss_ss: 1.503482, loss_d: 0.827755
Epoch finished! Loss: 2.1771372018321866
Starting epoch 2/10.
0.0000 --- loss: 2.161589, loss_ss: 1.495596, loss_d: 0.665993
0.1608 --- loss: 2.186771, loss_ss: 1.564850, loss_d: 0.621921
0.3215 --- loss: 1.729646, loss_ss: 1.339036, loss_d: 0.390610
0.4823 --- loss: 1.768385, loss_ss: 1.291475, loss_d: 0.476909
0.6431 --- loss: 1.660777, loss_ss: 1.244935, loss_d: 0.415843
0.8039 --- loss: 1.733352, loss_ss: 1.299643, loss_d: 0.433709
0.9646 --- loss: 1.748121, loss_ss: 1.310212, loss_d: 0.437908
Epoch finished! Loss: 1.909071158978247
Starting epoch 3/10.
0.0000 --- loss: 1.892045, loss_ss: 1.442760, loss_d: 0.449285
0.1608 --- loss: 1.620009, loss_ss: 1.507346, loss_d: 0.112663
0.3215 --- loss: 1.649481, loss_ss: 1.275054, loss_d: 0.374428
0.4823 --- loss: 1.565528, loss_ss: 1.238499, loss_d: 0.327029
0.6431 --- loss: 1.463657, loss_ss: 1.201294, loss_d: 0.262363
0.8039 --- loss: 1.741527, loss_ss: 1.214862, loss_d: 0.526665
0.9646 --- loss: 1.730085, loss_ss: 1.435789, loss_d: 0.294296
Epoch finished! Loss: 1.6847051285928296
Starting epoch 4/10.
0.0000 --- loss: 1.658533, loss_ss: 1.197567, loss_d: 0.460966
0.1608 --- loss: 1.903978, loss_ss: 1.254619, loss_d: 0.649358
0.3215 --- loss: 1.256718, loss_ss: 1.151789, loss_d: 0.104928
0.4823 --- loss: 1.707951, loss_ss: 1.288466, loss_d: 0.419485
0.6431 --- loss: 1.386824, loss_ss: 1.202599, loss_d: 0.184225
0.8039 --- loss: 1.331955, loss_ss: 1.193431, loss_d: 0.138524
0.9646 --- loss: 1.305151, loss_ss: 1.146320, loss_d: 0.158831
Epoch finished! Loss: 1.4865237705169185
Starting epoch 5/10.
0.0000 --- loss: 1.150553, loss_ss: 1.084095, loss_d: 0.066458
0.1608 --- loss: 1.184055, loss_ss: 1.140742, loss_d: 0.043313
0.3215 --- loss: 1.278066, loss_ss: 1.177078, loss_d: 0.100988
0.4823 --- loss: 1.037204, loss_ss: 1.007962, loss_d: 0.029242
0.6431 --- loss: 1.121206, loss_ss: 1.101051, loss_d: 0.020156
0.8039 --- loss: 1.113652, loss_ss: 1.058801, loss_d: 0.054851
0.9646 --- loss: 1.188354, loss_ss: 1.124581, loss_d: 0.063772
Epoch finished! Loss: 1.2295557548922877
Starting epoch 6/10.
0.0000 --- loss: 1.037645, loss_ss: 1.014670, loss_d: 0.022975
0.1608 --- loss: 1.012058, loss_ss: 0.998320, loss_d: 0.013739
0.3215 --- loss: 1.283270, loss_ss: 1.180725, loss_d: 0.102546
0.4823 --- loss: 1.160048, loss_ss: 1.142642, loss_d: 0.017406
0.6431 --- loss: 1.081358, loss_ss: 1.073042, loss_d: 0.008316
0.8039 --- loss: 0.995725, loss_ss: 0.980541, loss_d: 0.015184
0.9646 --- loss: 1.101935, loss_ss: 1.101194, loss_d: 0.000741
Epoch finished! Loss: 1.1670117868531136
Starting epoch 7/10.
0.0000 --- loss: 1.134220, loss_ss: 1.102473, loss_d: 0.031747
0.1608 --- loss: 1.002802, loss_ss: 0.954436, loss_d: 0.048366
0.3215 --- loss: 1.044426, loss_ss: 1.023063, loss_d: 0.021362
0.4823 --- loss: 1.009636, loss_ss: 0.975160, loss_d: 0.034475
0.6431 --- loss: 1.272601, loss_ss: 1.116510, loss_d: 0.156092
0.8039 --- loss: 1.064548, loss_ss: 1.036667, loss_d: 0.027881
0.9646 --- loss: 1.174954, loss_ss: 1.004594, loss_d: 0.170359
Epoch finished! Loss: 1.1689815973081896
Starting epoch 8/10.
0.0000 --- loss: 1.131361, loss_ss: 1.127473, loss_d: 0.003888
0.1608 --- loss: 0.982462, loss_ss: 0.930071, loss_d: 0.052391
0.3215 --- loss: 0.996969, loss_ss: 0.987188, loss_d: 0.009781
0.4823 --- loss: 1.063812, loss_ss: 0.988821, loss_d: 0.074991
0.6431 --- loss: 1.136305, loss_ss: 1.114775, loss_d: 0.021529
0.8039 --- loss: 1.108498, loss_ss: 1.106374, loss_d: 0.002123
0.9646 --- loss: 1.473079, loss_ss: 1.371993, loss_d: 0.101086
Epoch finished! Loss: 1.1221959879321437
Starting epoch 9/10.
0.0000 --- loss: 1.167734, loss_ss: 1.055908, loss_d: 0.111826
0.1608 --- loss: 1.083876, loss_ss: 1.063909, loss_d: 0.019967
0.3215 --- loss: 1.036824, loss_ss: 0.965042, loss_d: 0.071782
0.4823 --- loss: 0.949744, loss_ss: 0.949022, loss_d: 0.000722
0.6431 --- loss: 0.949116, loss_ss: 0.947873, loss_d: 0.001243
0.8039 --- loss: 1.297304, loss_ss: 1.290603, loss_d: 0.006701
0.9646 --- loss: 1.055100, loss_ss: 1.053867, loss_d: 0.001233
Epoch finished! Loss: 1.0824920515860281
Starting epoch 10/10.
0.0000 --- loss: 0.990232, loss_ss: 0.982156, loss_d: 0.008076
0.1608 --- loss: 1.125689, loss_ss: 1.009709, loss_d: 0.115980
0.3215 --- loss: 0.910392, loss_ss: 0.794847, loss_d: 0.115545
0.4823 --- loss: 1.200630, loss_ss: 0.917445, loss_d: 0.283184
0.6431 --- loss: 0.912708, loss_ss: 0.898122, loss_d: 0.014586
0.8039 --- loss: 1.237221, loss_ss: 1.192537, loss_d: 0.044683
0.9646 --- loss: 1.011330, loss_ss: 1.008018, loss_d: 0.003312
Epoch finished! Loss: 1.0712206257927803
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6729166666666667
             precision    recall  f1-score   support

        0.0       0.99      0.47      0.64       159
        1.0       0.00      0.00      0.00       124
        2.0       0.65      0.93      0.76       269
        3.0       0.94      0.57      0.71       192
        4.0       0.55      0.98      0.71       216

avg / total       0.66      0.67      0.62       960
 


====== chp040-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  91.15  47.17   99.88  98.68     63.83
1  87.08   0.00  100.00   0.00      0.00
2  83.85  92.57   80.46  64.84     76.26
3  90.73  57.29   99.09  94.02     71.20
4  81.77  98.15   77.02  55.35     70.78
Total accuracy: 67.29%
Average sen: 59.03%
Average spec: 91.29%
Macro f1-score: 56.42%
Diagnosis acc on 60mins: 1.0
[1.         0.99825519 0.97707182 0.9998796  0.99979824 0.99989641
 0.99148726 0.99987304]
pred: 0.995782695710659, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp040-nsrr

=== Test on chp041-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.354455, loss_ss: 1.674883, loss_d: 0.679572
0.1610 --- loss: 2.068137, loss_ss: 1.620747, loss_d: 0.447390
0.3221 --- loss: 2.178143, loss_ss: 1.532531, loss_d: 0.645612
0.4831 --- loss: 2.013224, loss_ss: 1.511013, loss_d: 0.502211
0.6441 --- loss: 2.569670, loss_ss: 1.498323, loss_d: 1.071347
0.8052 --- loss: 1.995166, loss_ss: 1.308643, loss_d: 0.686524
0.9662 --- loss: 1.973393, loss_ss: 1.347151, loss_d: 0.626243
Epoch finished! Loss: 2.0941705780644573
Starting epoch 2/10.
0.0000 --- loss: 2.118163, loss_ss: 1.368227, loss_d: 0.749936
0.1610 --- loss: 1.794161, loss_ss: 1.363807, loss_d: 0.430354
0.3221 --- loss: 1.649843, loss_ss: 1.299524, loss_d: 0.350319
0.4831 --- loss: 1.548762, loss_ss: 1.297836, loss_d: 0.250926
0.6441 --- loss: 1.913998, loss_ss: 1.319067, loss_d: 0.594930
0.8052 --- loss: 2.058316, loss_ss: 1.497125, loss_d: 0.561191
0.9662 --- loss: 1.552238, loss_ss: 1.250953, loss_d: 0.301286
Epoch finished! Loss: 1.8557053381396877
Starting epoch 3/10.
0.0000 --- loss: 1.904668, loss_ss: 1.207253, loss_d: 0.697415
0.1610 --- loss: 1.606838, loss_ss: 1.356022, loss_d: 0.250817
0.3221 --- loss: 1.595157, loss_ss: 1.280666, loss_d: 0.314491
0.4831 --- loss: 1.360534, loss_ss: 1.173394, loss_d: 0.187140
0.6441 --- loss: 1.920581, loss_ss: 1.123492, loss_d: 0.797089
0.8052 --- loss: 2.000343, loss_ss: 1.291165, loss_d: 0.709177
0.9662 --- loss: 1.485285, loss_ss: 1.312793, loss_d: 0.172491
Epoch finished! Loss: 1.6788611162093379
Starting epoch 4/10.
0.0000 --- loss: 1.715785, loss_ss: 1.340452, loss_d: 0.375333
0.1610 --- loss: 1.493551, loss_ss: 1.238757, loss_d: 0.254794
0.3221 --- loss: 1.733622, loss_ss: 1.379289, loss_d: 0.354333
0.4831 --- loss: 1.308050, loss_ss: 1.239792, loss_d: 0.068258
0.6441 --- loss: 1.659485, loss_ss: 1.149041, loss_d: 0.510444
0.8052 --- loss: 1.739245, loss_ss: 1.282988, loss_d: 0.456257
0.9662 --- loss: 1.736881, loss_ss: 1.114013, loss_d: 0.622868
Epoch finished! Loss: 1.4706948341861847
Starting epoch 5/10.
0.0000 --- loss: 1.253790, loss_ss: 1.121422, loss_d: 0.132369
0.1610 --- loss: 1.344400, loss_ss: 1.296350, loss_d: 0.048049
0.3221 --- loss: 1.166651, loss_ss: 1.118708, loss_d: 0.047944
0.4831 --- loss: 1.133148, loss_ss: 1.103677, loss_d: 0.029471
0.6441 --- loss: 1.268787, loss_ss: 1.256115, loss_d: 0.012672
0.8052 --- loss: 1.078075, loss_ss: 1.068462, loss_d: 0.009613
0.9662 --- loss: 1.142438, loss_ss: 1.125790, loss_d: 0.016648
Epoch finished! Loss: 1.2382474676255257
Starting epoch 6/10.
0.0000 --- loss: 1.102442, loss_ss: 1.096730, loss_d: 0.005712
0.1610 --- loss: 1.304511, loss_ss: 1.122593, loss_d: 0.181919
0.3221 --- loss: 1.384405, loss_ss: 1.267394, loss_d: 0.117012
0.4831 --- loss: 1.194578, loss_ss: 1.127864, loss_d: 0.066715
0.6441 --- loss: 1.197025, loss_ss: 1.112699, loss_d: 0.084327
0.8052 --- loss: 1.133468, loss_ss: 1.017646, loss_d: 0.115821
0.9662 --- loss: 1.235243, loss_ss: 1.188042, loss_d: 0.047201
Epoch finished! Loss: 1.2381428412852749
Starting epoch 7/10.
0.0000 --- loss: 1.072250, loss_ss: 1.051626, loss_d: 0.020624
0.1610 --- loss: 1.110207, loss_ss: 1.046527, loss_d: 0.063679
0.3221 --- loss: 1.147300, loss_ss: 0.965935, loss_d: 0.181364
0.4831 --- loss: 1.263018, loss_ss: 1.089306, loss_d: 0.173712
0.6441 --- loss: 1.138986, loss_ss: 0.989691, loss_d: 0.149295
0.8052 --- loss: 1.060037, loss_ss: 1.048876, loss_d: 0.011161
0.9662 --- loss: 0.932623, loss_ss: 0.923488, loss_d: 0.009135
Epoch finished! Loss: 1.1076854823097106
Starting epoch 8/10.
0.0000 --- loss: 0.959418, loss_ss: 0.957339, loss_d: 0.002078
0.1610 --- loss: 1.217784, loss_ss: 1.093401, loss_d: 0.124383
0.3221 --- loss: 0.918596, loss_ss: 0.912996, loss_d: 0.005601
0.4831 --- loss: 0.900358, loss_ss: 0.898858, loss_d: 0.001500
0.6441 --- loss: 0.969074, loss_ss: 0.950266, loss_d: 0.018808
0.8052 --- loss: 0.847560, loss_ss: 0.804992, loss_d: 0.042569
0.9662 --- loss: 1.057653, loss_ss: 1.054786, loss_d: 0.002867
Epoch finished! Loss: 1.024697659477111
Starting epoch 9/10.
0.0000 --- loss: 1.015468, loss_ss: 1.013123, loss_d: 0.002345
0.1610 --- loss: 1.012600, loss_ss: 1.011133, loss_d: 0.001467
0.3221 --- loss: 0.949475, loss_ss: 0.859768, loss_d: 0.089706
0.4831 --- loss: 0.811302, loss_ss: 0.810753, loss_d: 0.000549
0.6441 --- loss: 0.901440, loss_ss: 0.898860, loss_d: 0.002580
0.8052 --- loss: 1.349019, loss_ss: 1.067396, loss_d: 0.281623
0.9662 --- loss: 0.818262, loss_ss: 0.807896, loss_d: 0.010366
Epoch finished! Loss: 0.9878640184479375
Starting epoch 10/10.
0.0000 --- loss: 1.201308, loss_ss: 1.195951, loss_d: 0.005356
0.1610 --- loss: 0.789562, loss_ss: 0.769940, loss_d: 0.019622
0.3221 --- loss: 0.884650, loss_ss: 0.814645, loss_d: 0.070005
0.4831 --- loss: 1.206520, loss_ss: 1.150613, loss_d: 0.055908
0.6441 --- loss: 0.954539, loss_ss: 0.953087, loss_d: 0.001452
0.8052 --- loss: 1.073961, loss_ss: 1.072463, loss_d: 0.001498
0.9662 --- loss: 0.931501, loss_ss: 0.927978, loss_d: 0.003523
Epoch finished! Loss: 0.9604426939641276
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7240740740740741
             precision    recall  f1-score   support

        0.0       0.53      0.88      0.66       196
        1.0       0.20      0.02      0.03        58
        2.0       0.86      0.83      0.84       527
        3.0       0.67      0.06      0.11        33
        4.0       0.71      0.64      0.67       266

avg / total       0.72      0.72      0.70      1080
 


====== chp041-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  83.70  88.27   82.69  53.07     66.28
1  94.35   1.72   99.61  20.00      3.17
2  85.09  82.73   87.34  86.17     84.41
3  97.04   6.06   99.90  66.67     11.11
4  84.63  63.91   91.40  70.83     67.19
Total accuracy: 72.41%
Average sen: 48.54%
Average spec: 92.19%
Macro f1-score: 46.44%
Diagnosis acc on 60mins: 0.8888888888888888
[0.99207085 0.37308809 0.9851414  0.99999917 0.99862385 0.99836403
 0.99999392 0.99799699 0.99999309]
pred: 0.9272523754172854, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp041-nsrr

=== Test on chp042-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.510497, loss_ss: 1.734246, loss_d: 0.776251
0.1610 --- loss: 2.050179, loss_ss: 1.498427, loss_d: 0.551752
0.3221 --- loss: 2.067741, loss_ss: 1.541940, loss_d: 0.525802
0.4831 --- loss: 1.912581, loss_ss: 1.470609, loss_d: 0.441972
0.6441 --- loss: 2.066213, loss_ss: 1.395866, loss_d: 0.670346
0.8052 --- loss: 1.889613, loss_ss: 1.439889, loss_d: 0.449724
0.9662 --- loss: 2.306073, loss_ss: 1.348060, loss_d: 0.958014
Epoch finished! Loss: 2.1483421460274728
Starting epoch 2/10.
0.0000 --- loss: 2.025216, loss_ss: 1.302961, loss_d: 0.722255
0.1610 --- loss: 1.911350, loss_ss: 1.338606, loss_d: 0.572743
0.3221 --- loss: 1.735985, loss_ss: 1.327809, loss_d: 0.408176
0.4831 --- loss: 1.782210, loss_ss: 1.203630, loss_d: 0.578580
0.6441 --- loss: 2.229004, loss_ss: 1.255164, loss_d: 0.973841
0.8052 --- loss: 1.798695, loss_ss: 1.321789, loss_d: 0.476906
0.9662 --- loss: 1.659091, loss_ss: 1.282644, loss_d: 0.376447
Epoch finished! Loss: 1.849963253544223
Starting epoch 3/10.
0.0000 --- loss: 1.648920, loss_ss: 1.255490, loss_d: 0.393430
0.1610 --- loss: 1.532690, loss_ss: 1.142322, loss_d: 0.390368
0.3221 --- loss: 1.691196, loss_ss: 1.220589, loss_d: 0.470607
0.4831 --- loss: 1.427125, loss_ss: 1.094313, loss_d: 0.332813
0.6441 --- loss: 1.778949, loss_ss: 1.124206, loss_d: 0.654742
0.8052 --- loss: 2.238591, loss_ss: 1.128781, loss_d: 1.109810
0.9662 --- loss: 1.684251, loss_ss: 1.268651, loss_d: 0.415600
Epoch finished! Loss: 1.6467148334749284
Starting epoch 4/10.
0.0000 --- loss: 1.398983, loss_ss: 1.221934, loss_d: 0.177048
0.1610 --- loss: 1.239803, loss_ss: 1.055965, loss_d: 0.183838
0.3221 --- loss: 1.277774, loss_ss: 1.165602, loss_d: 0.112172
0.4831 --- loss: 1.171412, loss_ss: 1.073695, loss_d: 0.097716
0.6441 --- loss: 1.274014, loss_ss: 1.052194, loss_d: 0.221820
0.8052 --- loss: 1.502259, loss_ss: 1.287670, loss_d: 0.214589
0.9662 --- loss: 1.366444, loss_ss: 1.106701, loss_d: 0.259743
Epoch finished! Loss: 1.4087212643315714
Starting epoch 5/10.
0.0000 --- loss: 1.141092, loss_ss: 1.063833, loss_d: 0.077259
0.1610 --- loss: 1.408335, loss_ss: 1.002245, loss_d: 0.406089
0.3221 --- loss: 1.081202, loss_ss: 1.040054, loss_d: 0.041148
0.4831 --- loss: 1.281489, loss_ss: 1.120813, loss_d: 0.160675
0.6441 --- loss: 1.113443, loss_ss: 1.057124, loss_d: 0.056319
0.8052 --- loss: 1.044254, loss_ss: 0.961530, loss_d: 0.082724
0.9662 --- loss: 1.227497, loss_ss: 1.024439, loss_d: 0.203059
Epoch finished! Loss: 1.323789435048257
Starting epoch 6/10.
0.0000 --- loss: 1.216885, loss_ss: 1.058158, loss_d: 0.158728
0.1610 --- loss: 0.964021, loss_ss: 0.954413, loss_d: 0.009608
0.3221 --- loss: 1.263470, loss_ss: 1.054239, loss_d: 0.209230
0.4831 --- loss: 1.053473, loss_ss: 0.992625, loss_d: 0.060848
0.6441 --- loss: 0.984741, loss_ss: 0.976190, loss_d: 0.008551
0.8052 --- loss: 0.965339, loss_ss: 0.941049, loss_d: 0.024290
0.9662 --- loss: 1.073400, loss_ss: 0.955695, loss_d: 0.117706
Epoch finished! Loss: 1.1346260982175027
Starting epoch 7/10.
0.0000 --- loss: 1.107754, loss_ss: 1.088867, loss_d: 0.018887
0.1610 --- loss: 0.970563, loss_ss: 0.959099, loss_d: 0.011464
0.3221 --- loss: 1.163265, loss_ss: 1.135863, loss_d: 0.027402
0.4831 --- loss: 1.021167, loss_ss: 0.868996, loss_d: 0.152171
0.6441 --- loss: 0.892331, loss_ss: 0.888362, loss_d: 0.003969
0.8052 --- loss: 0.856293, loss_ss: 0.838407, loss_d: 0.017886
0.9662 --- loss: 0.947437, loss_ss: 0.937820, loss_d: 0.009617
Epoch finished! Loss: 1.0529201126867724
Starting epoch 8/10.
0.0000 --- loss: 1.065597, loss_ss: 0.993134, loss_d: 0.072463
0.1610 --- loss: 0.976349, loss_ss: 0.972296, loss_d: 0.004053
0.3221 --- loss: 0.960520, loss_ss: 0.783735, loss_d: 0.176785
0.4831 --- loss: 0.999029, loss_ss: 0.995534, loss_d: 0.003495
0.6441 --- loss: 1.006266, loss_ss: 0.992346, loss_d: 0.013920
0.8052 --- loss: 0.895120, loss_ss: 0.890528, loss_d: 0.004592
0.9662 --- loss: 0.876370, loss_ss: 0.871535, loss_d: 0.004834
Epoch finished! Loss: 0.984179921688572
Starting epoch 9/10.
0.0000 --- loss: 0.924095, loss_ss: 0.879853, loss_d: 0.044242
0.1610 --- loss: 1.084428, loss_ss: 1.068503, loss_d: 0.015925
0.3221 --- loss: 0.912276, loss_ss: 0.883442, loss_d: 0.028834
0.4831 --- loss: 0.896023, loss_ss: 0.884575, loss_d: 0.011448
0.6441 --- loss: 0.963765, loss_ss: 0.962738, loss_d: 0.001027
0.8052 --- loss: 0.998338, loss_ss: 0.994401, loss_d: 0.003936
0.9662 --- loss: 1.000597, loss_ss: 0.972962, loss_d: 0.027635
Epoch finished! Loss: 0.9753618173060878
Starting epoch 10/10.
0.0000 --- loss: 1.097465, loss_ss: 1.096964, loss_d: 0.000501
0.1610 --- loss: 0.949660, loss_ss: 0.945449, loss_d: 0.004210
0.3221 --- loss: 0.824770, loss_ss: 0.823866, loss_d: 0.000904
0.4831 --- loss: 0.883383, loss_ss: 0.876152, loss_d: 0.007231
0.6441 --- loss: 0.808562, loss_ss: 0.806633, loss_d: 0.001929
0.8052 --- loss: 0.917882, loss_ss: 0.915012, loss_d: 0.002870
0.9662 --- loss: 0.919211, loss_ss: 0.908287, loss_d: 0.010924
Epoch finished! Loss: 0.9292618920726161
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5638888888888889
             precision    recall  f1-score   support

        0.0       0.39      0.86      0.53       152
        1.0       0.27      0.18      0.21       230
        2.0       0.73      0.62      0.67       414
        3.0       1.00      0.17      0.29        93
        4.0       0.74      0.86      0.80       191

avg / total       0.61      0.56      0.54      1080
 


====== chp042-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  78.98  85.53   77.91   38.81     53.39
1  72.04  17.83   86.71   26.62     21.35
2  76.57  62.08   85.59   72.80     67.01
3  92.87  17.20  100.00  100.00     29.36
4  92.31  86.39   93.59   74.32     79.90
Total accuracy: 56.39%
Average sen: 53.80%
Average spec: 88.76%
Macro f1-score: 50.20%
Diagnosis acc on 60mins: 1.0
[0.99999642 0.99999785 0.99999976 0.9999994  0.99999928 0.99999523
 0.99999452 0.99951136 0.9999944 ]
pred: 0.9999431371688843, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp042-nsrr

=== Test on chp043-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.503058, loss_ss: 1.810461, loss_d: 0.692597
0.1613 --- loss: 2.030894, loss_ss: 1.617828, loss_d: 0.413067
0.3226 --- loss: 2.643963, loss_ss: 1.682876, loss_d: 0.961087
0.4839 --- loss: 2.232145, loss_ss: 1.572680, loss_d: 0.659465
0.6452 --- loss: 2.188427, loss_ss: 1.501447, loss_d: 0.686980
0.8065 --- loss: 2.010611, loss_ss: 1.523212, loss_d: 0.487398
0.9677 --- loss: 1.978243, loss_ss: 1.488327, loss_d: 0.489916
Epoch finished! Loss: 2.221454211922943
Starting epoch 2/10.
0.0000 --- loss: 2.054631, loss_ss: 1.614989, loss_d: 0.439642
0.1613 --- loss: 1.743612, loss_ss: 1.389481, loss_d: 0.354130
0.3226 --- loss: 1.746806, loss_ss: 1.368679, loss_d: 0.378127
0.4839 --- loss: 1.921800, loss_ss: 1.486605, loss_d: 0.435196
0.6452 --- loss: 2.139060, loss_ss: 1.399468, loss_d: 0.739592
0.8065 --- loss: 1.727241, loss_ss: 1.331771, loss_d: 0.395469
0.9677 --- loss: 2.583510, loss_ss: 1.338062, loss_d: 1.245448
Epoch finished! Loss: 1.8666283087652238
Starting epoch 3/10.
0.0000 --- loss: 1.787285, loss_ss: 1.253270, loss_d: 0.534015
0.1613 --- loss: 1.577615, loss_ss: 1.323491, loss_d: 0.254124
0.3226 --- loss: 1.407957, loss_ss: 1.292587, loss_d: 0.115370
0.4839 --- loss: 1.304871, loss_ss: 1.266019, loss_d: 0.038852
0.6452 --- loss: 1.412521, loss_ss: 1.258283, loss_d: 0.154238
0.8065 --- loss: 1.542780, loss_ss: 1.230477, loss_d: 0.312303
0.9677 --- loss: 1.445881, loss_ss: 1.184690, loss_d: 0.261191
Epoch finished! Loss: 1.6230990671720662
Starting epoch 4/10.
0.0000 --- loss: 1.247161, loss_ss: 1.149381, loss_d: 0.097780
0.1613 --- loss: 1.320094, loss_ss: 1.279832, loss_d: 0.040262
0.3226 --- loss: 1.139095, loss_ss: 1.127440, loss_d: 0.011655
0.4839 --- loss: 1.217337, loss_ss: 1.174143, loss_d: 0.043194
0.6452 --- loss: 1.519195, loss_ss: 1.210846, loss_d: 0.308348
0.8065 --- loss: 1.250740, loss_ss: 1.192788, loss_d: 0.057951
0.9677 --- loss: 1.408163, loss_ss: 1.223509, loss_d: 0.184654
Epoch finished! Loss: 1.279853277519101
Starting epoch 5/10.
0.0000 --- loss: 1.183789, loss_ss: 1.172123, loss_d: 0.011666
0.1613 --- loss: 1.261631, loss_ss: 1.058068, loss_d: 0.203563
0.3226 --- loss: 1.199207, loss_ss: 1.058694, loss_d: 0.140513
0.4839 --- loss: 1.338594, loss_ss: 0.963566, loss_d: 0.375028
0.6452 --- loss: 1.010046, loss_ss: 0.964356, loss_d: 0.045690
0.8065 --- loss: 1.556936, loss_ss: 1.130602, loss_d: 0.426334
0.9677 --- loss: 1.114823, loss_ss: 1.106980, loss_d: 0.007843
Epoch finished! Loss: 1.2019978292652818
Starting epoch 6/10.
0.0000 --- loss: 1.221000, loss_ss: 1.212334, loss_d: 0.008666
0.1613 --- loss: 1.043429, loss_ss: 1.031035, loss_d: 0.012394
0.3226 --- loss: 1.130343, loss_ss: 1.029566, loss_d: 0.100778
0.4839 --- loss: 0.979624, loss_ss: 0.974715, loss_d: 0.004909
0.6452 --- loss: 1.027902, loss_ss: 1.013141, loss_d: 0.014762
0.8065 --- loss: 1.015193, loss_ss: 1.004678, loss_d: 0.010515
0.9677 --- loss: 0.861870, loss_ss: 0.845593, loss_d: 0.016277
Epoch finished! Loss: 1.0884229110889747
Starting epoch 7/10.
0.0000 --- loss: 0.951309, loss_ss: 0.950884, loss_d: 0.000425
0.1613 --- loss: 1.164617, loss_ss: 1.075289, loss_d: 0.089328
0.3226 --- loss: 0.967451, loss_ss: 0.966828, loss_d: 0.000623
0.4839 --- loss: 0.992622, loss_ss: 0.992207, loss_d: 0.000415
0.6452 --- loss: 0.935447, loss_ss: 0.882656, loss_d: 0.052792
0.8065 --- loss: 0.862951, loss_ss: 0.861914, loss_d: 0.001037
0.9677 --- loss: 1.116719, loss_ss: 0.924342, loss_d: 0.192378
Epoch finished! Loss: 1.0012271843972753
Starting epoch 8/10.
0.0000 --- loss: 0.929153, loss_ss: 0.928457, loss_d: 0.000696
0.1613 --- loss: 1.010116, loss_ss: 1.007833, loss_d: 0.002283
0.3226 --- loss: 0.933347, loss_ss: 0.930841, loss_d: 0.002507
0.4839 --- loss: 0.947765, loss_ss: 0.906482, loss_d: 0.041283
0.6452 --- loss: 0.923668, loss_ss: 0.919706, loss_d: 0.003962
0.8065 --- loss: 0.879446, loss_ss: 0.876427, loss_d: 0.003019
0.9677 --- loss: 0.923318, loss_ss: 0.922928, loss_d: 0.000390
Epoch finished! Loss: 0.9817185655969088
Starting epoch 9/10.
0.0000 --- loss: 0.859084, loss_ss: 0.856419, loss_d: 0.002664
0.1613 --- loss: 0.739055, loss_ss: 0.732958, loss_d: 0.006097
0.3226 --- loss: 0.916569, loss_ss: 0.913311, loss_d: 0.003258
0.4839 --- loss: 0.801821, loss_ss: 0.800335, loss_d: 0.001486
0.6452 --- loss: 0.855452, loss_ss: 0.854043, loss_d: 0.001409
0.8065 --- loss: 0.851597, loss_ss: 0.847548, loss_d: 0.004049
0.9677 --- loss: 0.952469, loss_ss: 0.949941, loss_d: 0.002528
Epoch finished! Loss: 0.950792453328117
Starting epoch 10/10.
0.0000 --- loss: 0.999191, loss_ss: 0.995973, loss_d: 0.003219
0.1613 --- loss: 1.039232, loss_ss: 1.038895, loss_d: 0.000337
0.3226 --- loss: 1.001301, loss_ss: 1.000779, loss_d: 0.000522
0.4839 --- loss: 0.780725, loss_ss: 0.779722, loss_d: 0.001003
0.6452 --- loss: 0.918420, loss_ss: 0.891603, loss_d: 0.026817
0.8065 --- loss: 0.776180, loss_ss: 0.758510, loss_d: 0.017670
0.9677 --- loss: 0.925528, loss_ss: 0.811322, loss_d: 0.114205
Epoch finished! Loss: 0.9509214416879123
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7125
             precision    recall  f1-score   support

        0.0       0.81      0.73      0.77       143
        1.0       0.00      0.00      0.00       197
        2.0       0.85      0.88      0.87       506
        3.0       0.94      0.45      0.61        64
        4.0       0.53      0.95      0.68       290

avg / total       0.63      0.71      0.65      1200
 


====== chp043-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  94.75  72.73   97.73  81.25     76.75
1  83.58   0.00  100.00   0.00      0.00
2  88.67  88.34   88.90  85.31     86.80
3  96.92  45.31   99.82  93.55     61.05
4  78.58  94.83   73.41  53.19     68.15
Total accuracy: 71.25%
Average sen: 60.24%
Average spec: 91.97%
Macro f1-score: 58.55%
Diagnosis acc on 60mins: 1.0
[0.99998748 0.99821055 0.99952662 0.99809009 0.99988449 0.84752369
 0.99896526 0.9592669  0.99999964 0.99994695]
pred: 0.9801401674747467, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp043-nsrr

=== Test on chp044-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.341005, loss_ss: 1.629069, loss_d: 0.711936
0.1608 --- loss: 2.031938, loss_ss: 1.466116, loss_d: 0.565822
0.3215 --- loss: 1.743605, loss_ss: 1.499621, loss_d: 0.243984
0.4823 --- loss: 2.262723, loss_ss: 1.340596, loss_d: 0.922127
0.6431 --- loss: 1.852033, loss_ss: 1.403862, loss_d: 0.448171
0.8039 --- loss: 1.932284, loss_ss: 1.417754, loss_d: 0.514530
0.9646 --- loss: 1.802865, loss_ss: 1.311164, loss_d: 0.491700
Epoch finished! Loss: 2.033894988798326
Starting epoch 2/10.
0.0000 --- loss: 1.945752, loss_ss: 1.304892, loss_d: 0.640860
0.1608 --- loss: 1.787163, loss_ss: 1.301823, loss_d: 0.485340
0.3215 --- loss: 1.782952, loss_ss: 1.275297, loss_d: 0.507655
0.4823 --- loss: 1.757910, loss_ss: 1.222554, loss_d: 0.535356
0.6431 --- loss: 1.629699, loss_ss: 1.327776, loss_d: 0.301924
0.8039 --- loss: 1.790005, loss_ss: 1.206496, loss_d: 0.583509
0.9646 --- loss: 1.562478, loss_ss: 1.266090, loss_d: 0.296388
Epoch finished! Loss: 1.767366305474312
Starting epoch 3/10.
0.0000 --- loss: 1.345809, loss_ss: 1.115079, loss_d: 0.230731
0.1608 --- loss: 1.548204, loss_ss: 1.409943, loss_d: 0.138261
0.3215 --- loss: 1.619501, loss_ss: 1.243576, loss_d: 0.375925
0.4823 --- loss: 1.813609, loss_ss: 1.215708, loss_d: 0.597901
0.6431 --- loss: 1.468420, loss_ss: 1.325671, loss_d: 0.142749
0.8039 --- loss: 1.503303, loss_ss: 1.087462, loss_d: 0.415841
0.9646 --- loss: 1.576856, loss_ss: 1.152509, loss_d: 0.424347
Epoch finished! Loss: 1.545297799571868
Starting epoch 4/10.
0.0000 --- loss: 1.285964, loss_ss: 1.136705, loss_d: 0.149259
0.1608 --- loss: 1.308852, loss_ss: 1.120080, loss_d: 0.188772
0.3215 --- loss: 1.105423, loss_ss: 1.035848, loss_d: 0.069575
0.4823 --- loss: 1.514130, loss_ss: 1.443989, loss_d: 0.070141
0.6431 --- loss: 1.307705, loss_ss: 1.210071, loss_d: 0.097634
0.8039 --- loss: 1.547997, loss_ss: 1.070969, loss_d: 0.477028
0.9646 --- loss: 1.351594, loss_ss: 1.238654, loss_d: 0.112941
Epoch finished! Loss: 1.3039056793335946
Starting epoch 5/10.
0.0000 --- loss: 1.169933, loss_ss: 1.150423, loss_d: 0.019510
0.1608 --- loss: 1.141748, loss_ss: 1.102288, loss_d: 0.039460
0.3215 --- loss: 1.036604, loss_ss: 0.993363, loss_d: 0.043241
0.4823 --- loss: 1.221690, loss_ss: 1.206967, loss_d: 0.014724
0.6431 --- loss: 1.193302, loss_ss: 1.167733, loss_d: 0.025569
0.8039 --- loss: 1.088681, loss_ss: 0.991026, loss_d: 0.097655
0.9646 --- loss: 1.140485, loss_ss: 1.110698, loss_d: 0.029787
Epoch finished! Loss: 1.1921460167054208
Starting epoch 6/10.
0.0000 --- loss: 1.069038, loss_ss: 0.951178, loss_d: 0.117860
0.1608 --- loss: 1.048518, loss_ss: 0.957166, loss_d: 0.091351
0.3215 --- loss: 1.019384, loss_ss: 1.001460, loss_d: 0.017924
0.4823 --- loss: 1.159624, loss_ss: 1.068318, loss_d: 0.091306
0.6431 --- loss: 1.076381, loss_ss: 1.073853, loss_d: 0.002528
0.8039 --- loss: 1.005033, loss_ss: 0.980214, loss_d: 0.024819
0.9646 --- loss: 1.011819, loss_ss: 0.938950, loss_d: 0.072869
Epoch finished! Loss: 1.1095118282302734
Starting epoch 7/10.
0.0000 --- loss: 1.201051, loss_ss: 1.038627, loss_d: 0.162424
0.1608 --- loss: 1.050442, loss_ss: 0.931243, loss_d: 0.119199
0.3215 --- loss: 0.977597, loss_ss: 0.877550, loss_d: 0.100047
0.4823 --- loss: 1.149359, loss_ss: 1.121466, loss_d: 0.027892
0.6431 --- loss: 0.993707, loss_ss: 0.976405, loss_d: 0.017302
0.8039 --- loss: 1.269681, loss_ss: 0.990020, loss_d: 0.279661
0.9646 --- loss: 1.102841, loss_ss: 0.919037, loss_d: 0.183805
Epoch finished! Loss: 1.0967141476369673
Starting epoch 8/10.
0.0000 --- loss: 1.043640, loss_ss: 1.015755, loss_d: 0.027885
0.1608 --- loss: 1.160399, loss_ss: 1.156223, loss_d: 0.004176
0.3215 --- loss: 1.009281, loss_ss: 0.997528, loss_d: 0.011753
0.4823 --- loss: 0.849999, loss_ss: 0.834348, loss_d: 0.015651
0.6431 --- loss: 0.917379, loss_ss: 0.913828, loss_d: 0.003552
0.8039 --- loss: 1.033261, loss_ss: 1.026530, loss_d: 0.006731
0.9646 --- loss: 0.945100, loss_ss: 0.939147, loss_d: 0.005954
Epoch finished! Loss: 1.0181494807043383
Starting epoch 9/10.
0.0000 --- loss: 0.832153, loss_ss: 0.825633, loss_d: 0.006520
0.1608 --- loss: 1.024788, loss_ss: 1.004216, loss_d: 0.020573
0.3215 --- loss: 1.169203, loss_ss: 1.040604, loss_d: 0.128599
0.4823 --- loss: 1.241629, loss_ss: 0.979110, loss_d: 0.262519
0.6431 --- loss: 1.037550, loss_ss: 0.877275, loss_d: 0.160275
0.8039 --- loss: 0.957373, loss_ss: 0.827170, loss_d: 0.130204
0.9646 --- loss: 0.976803, loss_ss: 0.975722, loss_d: 0.001081
Epoch finished! Loss: 1.0804101411373384
Starting epoch 10/10.
0.0000 --- loss: 1.270237, loss_ss: 0.894137, loss_d: 0.376101
0.1608 --- loss: 0.965359, loss_ss: 0.942268, loss_d: 0.023091
0.3215 --- loss: 0.797951, loss_ss: 0.780112, loss_d: 0.017839
0.4823 --- loss: 1.044087, loss_ss: 1.017678, loss_d: 0.026409
0.6431 --- loss: 0.998213, loss_ss: 0.808186, loss_d: 0.190027
0.8039 --- loss: 0.940233, loss_ss: 0.921963, loss_d: 0.018270
0.9646 --- loss: 0.857812, loss_ss: 0.849631, loss_d: 0.008181
Epoch finished! Loss: 1.042203527304434
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4427083333333333
             precision    recall  f1-score   support

        0.0       0.20      0.76      0.32        21
        1.0       0.00      0.00      0.00        89
        2.0       0.35      0.46      0.40       299
        3.0       1.00      0.40      0.57       438
        4.0       0.30      0.84      0.44       113

avg / total       0.61      0.44      0.45       960
 


====== chp044-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  92.92  76.19   93.29   20.25     32.00
1  90.73   0.00  100.00    0.00      0.00
2  56.98  46.15   61.88   35.38     40.06
3  72.71  40.18  100.00  100.00     57.33
4  75.21  84.07   74.03   30.16     44.39
Total accuracy: 44.27%
Average sen: 49.32%
Average spec: 85.84%
Macro f1-score: 34.76%
Diagnosis acc on 60mins: 1.0
[0.99163997 0.99982673 0.99319673 0.85043144 0.9997974  0.99805766
 0.99963546 0.998604  ]
pred: 0.978898674249649, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp044-nsrr

=== Test on chp045-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.507706, loss_ss: 1.743214, loss_d: 0.764492
0.1613 --- loss: 2.156765, loss_ss: 1.540688, loss_d: 0.616078
0.3226 --- loss: 2.069861, loss_ss: 1.491472, loss_d: 0.578390
0.4839 --- loss: 2.082573, loss_ss: 1.379731, loss_d: 0.702842
0.6452 --- loss: 2.091820, loss_ss: 1.542001, loss_d: 0.549819
0.8065 --- loss: 2.408282, loss_ss: 1.610781, loss_d: 0.797501
0.9677 --- loss: 1.786267, loss_ss: 1.274246, loss_d: 0.512021
Epoch finished! Loss: 2.118896245956421
Starting epoch 2/10.
0.0000 --- loss: 1.861690, loss_ss: 1.265847, loss_d: 0.595842
0.1613 --- loss: 2.116047, loss_ss: 1.194344, loss_d: 0.921703
0.3226 --- loss: 1.852264, loss_ss: 1.155362, loss_d: 0.696902
0.4839 --- loss: 1.855467, loss_ss: 1.238280, loss_d: 0.617188
0.6452 --- loss: 1.660651, loss_ss: 1.206715, loss_d: 0.453936
0.8065 --- loss: 1.639361, loss_ss: 1.107747, loss_d: 0.531614
0.9677 --- loss: 1.563882, loss_ss: 1.277956, loss_d: 0.285926
Epoch finished! Loss: 1.8199468362526816
Starting epoch 3/10.
0.0000 --- loss: 1.653621, loss_ss: 1.323405, loss_d: 0.330216
0.1613 --- loss: 1.378417, loss_ss: 1.108486, loss_d: 0.269931
0.3226 --- loss: 1.494481, loss_ss: 1.181941, loss_d: 0.312540
0.4839 --- loss: 1.521397, loss_ss: 1.145290, loss_d: 0.376107
0.6452 --- loss: 1.362036, loss_ss: 1.204106, loss_d: 0.157930
0.8065 --- loss: 1.495754, loss_ss: 1.236111, loss_d: 0.259643
0.9677 --- loss: 1.662491, loss_ss: 1.143801, loss_d: 0.518690
Epoch finished! Loss: 1.5453584760916037
Starting epoch 4/10.
0.0000 --- loss: 1.330687, loss_ss: 1.228775, loss_d: 0.101913
0.1613 --- loss: 1.506380, loss_ss: 1.147237, loss_d: 0.359143
0.3226 --- loss: 1.214050, loss_ss: 1.144964, loss_d: 0.069087
0.4839 --- loss: 1.336905, loss_ss: 1.174341, loss_d: 0.162564
0.6452 --- loss: 1.219474, loss_ss: 1.146690, loss_d: 0.072784
0.8065 --- loss: 1.259720, loss_ss: 1.017124, loss_d: 0.242596
0.9677 --- loss: 1.373146, loss_ss: 1.242646, loss_d: 0.130500
Epoch finished! Loss: 1.3582070127862398
Starting epoch 5/10.
0.0000 --- loss: 1.166912, loss_ss: 1.079913, loss_d: 0.087000
0.1613 --- loss: 1.184304, loss_ss: 1.158816, loss_d: 0.025488
0.3226 --- loss: 1.126624, loss_ss: 1.021610, loss_d: 0.105014
0.4839 --- loss: 1.295431, loss_ss: 1.271003, loss_d: 0.024429
0.6452 --- loss: 1.075234, loss_ss: 1.061476, loss_d: 0.013758
0.8065 --- loss: 1.041725, loss_ss: 1.037010, loss_d: 0.004715
0.9677 --- loss: 1.099159, loss_ss: 1.081628, loss_d: 0.017530
Epoch finished! Loss: 1.1328556039294257
Starting epoch 6/10.
0.0000 --- loss: 0.963965, loss_ss: 0.952759, loss_d: 0.011206
0.1613 --- loss: 1.158281, loss_ss: 1.149965, loss_d: 0.008316
0.3226 --- loss: 0.965646, loss_ss: 0.953016, loss_d: 0.012630
0.4839 --- loss: 1.031147, loss_ss: 0.951777, loss_d: 0.079370
0.6452 --- loss: 0.920206, loss_ss: 0.898217, loss_d: 0.021989
0.8065 --- loss: 0.927952, loss_ss: 0.925337, loss_d: 0.002615
0.9677 --- loss: 1.369511, loss_ss: 0.858631, loss_d: 0.510880
Epoch finished! Loss: 1.0287348823469193
Starting epoch 7/10.
0.0000 --- loss: 1.148848, loss_ss: 1.040681, loss_d: 0.108167
0.1613 --- loss: 0.957330, loss_ss: 0.953865, loss_d: 0.003465
0.3226 --- loss: 0.865760, loss_ss: 0.852115, loss_d: 0.013645
0.4839 --- loss: 1.135745, loss_ss: 1.110263, loss_d: 0.025481
0.6452 --- loss: 1.154683, loss_ss: 1.133839, loss_d: 0.020845
0.8065 --- loss: 0.943153, loss_ss: 0.942767, loss_d: 0.000386
0.9677 --- loss: 0.808579, loss_ss: 0.784346, loss_d: 0.024234
Epoch finished! Loss: 0.9907597313161756
Starting epoch 8/10.
0.0000 --- loss: 0.974566, loss_ss: 0.917883, loss_d: 0.056683
0.1613 --- loss: 0.835582, loss_ss: 0.835258, loss_d: 0.000323
0.3226 --- loss: 0.946202, loss_ss: 0.945647, loss_d: 0.000555
0.4839 --- loss: 0.872543, loss_ss: 0.872134, loss_d: 0.000409
0.6452 --- loss: 1.088240, loss_ss: 0.897127, loss_d: 0.191113
0.8065 --- loss: 1.082961, loss_ss: 1.073131, loss_d: 0.009830
0.9677 --- loss: 0.911697, loss_ss: 0.899888, loss_d: 0.011809
Epoch finished! Loss: 0.9406450078135631
Starting epoch 9/10.
0.0000 --- loss: 0.822719, loss_ss: 0.820713, loss_d: 0.002006
0.1613 --- loss: 1.073613, loss_ss: 0.765281, loss_d: 0.308332
0.3226 --- loss: 0.859135, loss_ss: 0.834607, loss_d: 0.024528
0.4839 --- loss: 0.991464, loss_ss: 0.867980, loss_d: 0.123484
0.6452 --- loss: 1.440502, loss_ss: 0.854195, loss_d: 0.586307
0.8065 --- loss: 0.763337, loss_ss: 0.727838, loss_d: 0.035499
0.9677 --- loss: 0.888831, loss_ss: 0.826284, loss_d: 0.062547
Epoch finished! Loss: 0.9610858823432297
Starting epoch 10/10.
0.0000 --- loss: 0.824997, loss_ss: 0.821415, loss_d: 0.003582
0.1613 --- loss: 0.761150, loss_ss: 0.756755, loss_d: 0.004395
0.3226 --- loss: 0.843391, loss_ss: 0.840532, loss_d: 0.002859
0.4839 --- loss: 1.380975, loss_ss: 0.993165, loss_d: 0.387809
0.6452 --- loss: 1.047100, loss_ss: 0.800949, loss_d: 0.246152
0.8065 --- loss: 0.816899, loss_ss: 0.805131, loss_d: 0.011768
0.9677 --- loss: 0.887523, loss_ss: 0.884308, loss_d: 0.003215
Epoch finished! Loss: 0.930468246585033
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5037531276063386
             precision    recall  f1-score   support

        0.0       0.69      0.64      0.66       151
        1.0       0.00      0.00      0.00       135
        2.0       0.53      0.62      0.57       442
        3.0       0.80      0.02      0.04       221
        4.0       0.43      0.93      0.59       250

avg / total       0.52      0.50      0.42      1199
 


====== chp045-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  91.74  63.58   95.80  68.57     65.98
1  88.74   0.00  100.00   0.00      0.00
2  65.55  61.54   67.90  52.82     56.84
3  81.82   1.81   99.90  80.00      3.54
4  72.89  92.80   67.65  43.04     58.81
Total accuracy: 50.38%
Average sen: 43.94%
Average spec: 86.25%
Macro f1-score: 37.03%
Diagnosis acc on 60mins: 1.0
[0.97095507 0.97118312 0.9998548  0.9997856  0.99887592 0.99930489
 0.99999654 0.92260087 0.99999094 0.99885309]
pred: 0.9861400842666626, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp045-nsrr

=== Test on chp046-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.337480, loss_ss: 1.635401, loss_d: 0.702079
0.1610 --- loss: 2.094710, loss_ss: 1.409392, loss_d: 0.685318
0.3221 --- loss: 2.122772, loss_ss: 1.386667, loss_d: 0.736105
0.4831 --- loss: 1.977515, loss_ss: 1.341763, loss_d: 0.635752
0.6441 --- loss: 1.747710, loss_ss: 1.192676, loss_d: 0.555034
0.8052 --- loss: 1.933774, loss_ss: 1.344550, loss_d: 0.589224
0.9662 --- loss: 1.669634, loss_ss: 1.344538, loss_d: 0.325096
Epoch finished! Loss: 1.9937372188414297
Starting epoch 2/10.
0.0000 --- loss: 1.822199, loss_ss: 1.171648, loss_d: 0.650551
0.1610 --- loss: 1.927282, loss_ss: 1.226408, loss_d: 0.700875
0.3221 --- loss: 1.894906, loss_ss: 1.286535, loss_d: 0.608371
0.4831 --- loss: 1.479891, loss_ss: 1.185941, loss_d: 0.293951
0.6441 --- loss: 1.842190, loss_ss: 1.172326, loss_d: 0.669864
0.8052 --- loss: 1.733514, loss_ss: 1.244493, loss_d: 0.489020
0.9662 --- loss: 1.577869, loss_ss: 1.159246, loss_d: 0.418623
Epoch finished! Loss: 1.7207491301721143
Starting epoch 3/10.
0.0000 --- loss: 1.544070, loss_ss: 1.120334, loss_d: 0.423736
0.1610 --- loss: 1.395377, loss_ss: 1.157566, loss_d: 0.237811
0.3221 --- loss: 1.674317, loss_ss: 1.206788, loss_d: 0.467528
0.4831 --- loss: 1.630953, loss_ss: 1.211675, loss_d: 0.419278
0.6441 --- loss: 1.230355, loss_ss: 1.046726, loss_d: 0.183630
0.8052 --- loss: 1.408225, loss_ss: 0.934986, loss_d: 0.473239
0.9662 --- loss: 1.672690, loss_ss: 1.128207, loss_d: 0.544482
Epoch finished! Loss: 1.5378660290471968
Starting epoch 4/10.
0.0000 --- loss: 1.408939, loss_ss: 1.148254, loss_d: 0.260685
0.1610 --- loss: 1.126825, loss_ss: 1.074488, loss_d: 0.052337
0.3221 --- loss: 1.266627, loss_ss: 1.065312, loss_d: 0.201315
0.4831 --- loss: 1.054422, loss_ss: 1.034231, loss_d: 0.020191
0.6441 --- loss: 1.079303, loss_ss: 1.007045, loss_d: 0.072258
0.8052 --- loss: 1.228579, loss_ss: 1.150096, loss_d: 0.078484
0.9662 --- loss: 1.377990, loss_ss: 1.001991, loss_d: 0.375999
Epoch finished! Loss: 1.2475170733467225
Starting epoch 5/10.
0.0000 --- loss: 0.966673, loss_ss: 0.955114, loss_d: 0.011559
0.1610 --- loss: 1.081760, loss_ss: 1.035334, loss_d: 0.046427
0.3221 --- loss: 1.058088, loss_ss: 0.959722, loss_d: 0.098365
0.4831 --- loss: 1.170460, loss_ss: 1.113652, loss_d: 0.056808
0.6441 --- loss: 0.991814, loss_ss: 0.920830, loss_d: 0.070984
0.8052 --- loss: 1.043791, loss_ss: 1.041861, loss_d: 0.001931
0.9662 --- loss: 1.091928, loss_ss: 1.080186, loss_d: 0.011742
Epoch finished! Loss: 1.1125381319753584
Starting epoch 6/10.
0.0000 --- loss: 1.410683, loss_ss: 1.109746, loss_d: 0.300937
0.1610 --- loss: 0.935039, loss_ss: 0.908787, loss_d: 0.026252
0.3221 --- loss: 0.952495, loss_ss: 0.917347, loss_d: 0.035148
0.4831 --- loss: 1.051493, loss_ss: 1.049290, loss_d: 0.002203
0.6441 --- loss: 1.266208, loss_ss: 1.026958, loss_d: 0.239250
0.8052 --- loss: 1.002461, loss_ss: 0.997822, loss_d: 0.004639
0.9662 --- loss: 0.946263, loss_ss: 0.905149, loss_d: 0.041113
Epoch finished! Loss: 1.160647431688924
Starting epoch 7/10.
0.0000 --- loss: 0.921372, loss_ss: 0.894227, loss_d: 0.027145
0.1610 --- loss: 1.230476, loss_ss: 1.159429, loss_d: 0.071047
0.3221 --- loss: 1.289172, loss_ss: 0.970570, loss_d: 0.318602
0.4831 --- loss: 1.036325, loss_ss: 0.984083, loss_d: 0.052242
0.6441 --- loss: 0.958306, loss_ss: 0.882390, loss_d: 0.075916
0.8052 --- loss: 1.199942, loss_ss: 0.956441, loss_d: 0.243501
0.9662 --- loss: 0.960557, loss_ss: 0.942403, loss_d: 0.018153
Epoch finished! Loss: 1.1351266618697875
Starting epoch 8/10.
0.0000 --- loss: 1.047107, loss_ss: 1.000886, loss_d: 0.046221
0.1610 --- loss: 0.944617, loss_ss: 0.886870, loss_d: 0.057747
0.3221 --- loss: 1.093289, loss_ss: 0.915983, loss_d: 0.177306
0.4831 --- loss: 0.978091, loss_ss: 0.976912, loss_d: 0.001179
0.6441 --- loss: 0.738640, loss_ss: 0.731807, loss_d: 0.006833
0.8052 --- loss: 1.075354, loss_ss: 1.066236, loss_d: 0.009118
0.9662 --- loss: 0.946827, loss_ss: 0.903524, loss_d: 0.043303
Epoch finished! Loss: 1.020817872978026
Starting epoch 9/10.
0.0000 --- loss: 0.987168, loss_ss: 0.930866, loss_d: 0.056302
0.1610 --- loss: 1.204734, loss_ss: 1.160227, loss_d: 0.044507
0.3221 --- loss: 0.922388, loss_ss: 0.917664, loss_d: 0.004724
0.4831 --- loss: 0.940415, loss_ss: 0.938453, loss_d: 0.001962
0.6441 --- loss: 0.913444, loss_ss: 0.891369, loss_d: 0.022075
0.8052 --- loss: 0.820891, loss_ss: 0.801284, loss_d: 0.019607
0.9662 --- loss: 0.836845, loss_ss: 0.804820, loss_d: 0.032025
Epoch finished! Loss: 0.9775772229317696
Starting epoch 10/10.
0.0000 --- loss: 0.777882, loss_ss: 0.776526, loss_d: 0.001356
0.1610 --- loss: 0.937332, loss_ss: 0.932400, loss_d: 0.004932
0.3221 --- loss: 1.028631, loss_ss: 1.027977, loss_d: 0.000654
0.4831 --- loss: 0.881240, loss_ss: 0.879819, loss_d: 0.001421
0.6441 --- loss: 1.068049, loss_ss: 1.033716, loss_d: 0.034334
0.8052 --- loss: 0.835322, loss_ss: 0.833245, loss_d: 0.002077
0.9662 --- loss: 0.792810, loss_ss: 0.791662, loss_d: 0.001148
Epoch finished! Loss: 0.9476459853110775
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4222222222222222
             precision    recall  f1-score   support

        0.0       0.70      0.94      0.80       226
        1.0       0.43      0.01      0.02       357
        2.0       0.27      0.98      0.42       192
        3.0       0.50      0.50      0.50         2
        4.0       0.91      0.17      0.28       303

avg / total       0.59      0.42      0.33      1080
 


====== chp046-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  90.19  94.25   89.11  69.61     80.08
1  66.85   0.84   99.45  42.86      1.65
2  51.39  97.92   41.33  26.52     41.73
3  99.81  50.00   99.91  50.00     50.00
4  76.20  16.83   99.36  91.07     28.41
Total accuracy: 42.22%
Average sen: 51.97%
Average spec: 85.83%
Macro f1-score: 40.37%
Diagnosis acc on 60mins: 1.0
[0.99999952 0.99999976 0.99999547 0.99999988 0.99999988 1.
 1.         0.99999678 1.        ]
pred: 0.999999033080207, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp046-nsrr

=== Test on chp047-nsrr. train_data(623), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.262615, loss_ss: 1.550374, loss_d: 0.712242
0.1605 --- loss: 2.157135, loss_ss: 1.563540, loss_d: 0.593595
0.3210 --- loss: 1.982889, loss_ss: 1.520069, loss_d: 0.462821
0.4815 --- loss: 1.949777, loss_ss: 1.428129, loss_d: 0.521648
0.6421 --- loss: 1.888156, loss_ss: 1.426481, loss_d: 0.461675
0.8026 --- loss: 1.563642, loss_ss: 1.297025, loss_d: 0.266617
0.9631 --- loss: 1.715387, loss_ss: 1.338456, loss_d: 0.376931
Epoch finished! Loss: 2.053856643938249
Starting epoch 2/10.
0.0000 --- loss: 1.686832, loss_ss: 1.278563, loss_d: 0.408269
0.1605 --- loss: 1.716842, loss_ss: 1.314515, loss_d: 0.402326
0.3210 --- loss: 1.610981, loss_ss: 1.210681, loss_d: 0.400300
0.4815 --- loss: 1.729760, loss_ss: 1.212484, loss_d: 0.517276
0.6421 --- loss: 1.675624, loss_ss: 1.172810, loss_d: 0.502815
0.8026 --- loss: 1.420664, loss_ss: 1.156861, loss_d: 0.263804
0.9631 --- loss: 1.621099, loss_ss: 1.239722, loss_d: 0.381376
Epoch finished! Loss: 1.7893294999676366
Starting epoch 3/10.
0.0000 --- loss: 1.776693, loss_ss: 1.282332, loss_d: 0.494361
0.1605 --- loss: 1.801700, loss_ss: 1.199580, loss_d: 0.602119
0.3210 --- loss: 1.471880, loss_ss: 1.153947, loss_d: 0.317933
0.4815 --- loss: 1.402122, loss_ss: 1.202360, loss_d: 0.199761
0.6421 --- loss: 1.357754, loss_ss: 1.142387, loss_d: 0.215367
0.8026 --- loss: 1.283233, loss_ss: 1.051386, loss_d: 0.231847
0.9631 --- loss: 1.709054, loss_ss: 1.332059, loss_d: 0.376995
Epoch finished! Loss: 1.587239355810227
Starting epoch 4/10.
0.0000 --- loss: 1.255859, loss_ss: 1.167575, loss_d: 0.088283
0.1605 --- loss: 1.421464, loss_ss: 1.193535, loss_d: 0.227930
0.3210 --- loss: 1.745692, loss_ss: 1.090675, loss_d: 0.655017
0.4815 --- loss: 1.116319, loss_ss: 0.983737, loss_d: 0.132582
0.6421 --- loss: 1.725792, loss_ss: 1.008751, loss_d: 0.717041
0.8026 --- loss: 1.497634, loss_ss: 1.156524, loss_d: 0.341110
0.9631 --- loss: 1.355564, loss_ss: 1.077846, loss_d: 0.277718
Epoch finished! Loss: 1.3623951173597766
Starting epoch 5/10.
0.0000 --- loss: 1.106955, loss_ss: 1.027548, loss_d: 0.079407
0.1605 --- loss: 1.215470, loss_ss: 1.145935, loss_d: 0.069535
0.3210 --- loss: 1.247827, loss_ss: 0.998377, loss_d: 0.249450
0.4815 --- loss: 0.982432, loss_ss: 0.927328, loss_d: 0.055104
0.6421 --- loss: 1.227017, loss_ss: 1.040063, loss_d: 0.186954
0.8026 --- loss: 1.022126, loss_ss: 0.990692, loss_d: 0.031434
0.9631 --- loss: 1.098252, loss_ss: 1.033240, loss_d: 0.065012
Epoch finished! Loss: 1.171106191412095
Starting epoch 6/10.
0.0000 --- loss: 1.190769, loss_ss: 0.996534, loss_d: 0.194235
0.1605 --- loss: 1.025367, loss_ss: 1.018020, loss_d: 0.007347
0.3210 --- loss: 1.025753, loss_ss: 1.015068, loss_d: 0.010685
0.4815 --- loss: 0.886441, loss_ss: 0.794511, loss_d: 0.091929
0.6421 --- loss: 0.989004, loss_ss: 0.981611, loss_d: 0.007394
0.8026 --- loss: 1.102602, loss_ss: 1.094083, loss_d: 0.008520
0.9631 --- loss: 0.942358, loss_ss: 0.924107, loss_d: 0.018252
Epoch finished! Loss: 1.0250226845664363
Starting epoch 7/10.
0.0000 --- loss: 1.181952, loss_ss: 1.025062, loss_d: 0.156889
0.1605 --- loss: 0.993893, loss_ss: 0.965877, loss_d: 0.028016
0.3210 --- loss: 0.983647, loss_ss: 0.981662, loss_d: 0.001986
0.4815 --- loss: 1.106219, loss_ss: 1.048140, loss_d: 0.058080
0.6421 --- loss: 1.064215, loss_ss: 1.026424, loss_d: 0.037791
0.8026 --- loss: 0.953528, loss_ss: 0.948829, loss_d: 0.004698
0.9631 --- loss: 0.935195, loss_ss: 0.931628, loss_d: 0.003568
Epoch finished! Loss: 0.9989865047316397
Starting epoch 8/10.
0.0000 --- loss: 1.004924, loss_ss: 0.996762, loss_d: 0.008162
0.1605 --- loss: 0.859478, loss_ss: 0.834065, loss_d: 0.025413
0.3210 --- loss: 1.067454, loss_ss: 0.949132, loss_d: 0.118323
0.4815 --- loss: 0.975202, loss_ss: 0.924874, loss_d: 0.050328
0.6421 --- loss: 0.788157, loss_ss: 0.787508, loss_d: 0.000649
0.8026 --- loss: 0.806492, loss_ss: 0.776660, loss_d: 0.029832
0.9631 --- loss: 0.907632, loss_ss: 0.907061, loss_d: 0.000571
Epoch finished! Loss: 0.9310737031121408
Starting epoch 9/10.
0.0000 --- loss: 0.953459, loss_ss: 0.950505, loss_d: 0.002954
0.1605 --- loss: 0.819432, loss_ss: 0.770045, loss_d: 0.049386
0.3210 --- loss: 1.022591, loss_ss: 0.960135, loss_d: 0.062456
0.4815 --- loss: 0.932567, loss_ss: 0.929054, loss_d: 0.003513
0.6421 --- loss: 0.884677, loss_ss: 0.859129, loss_d: 0.025548
0.8026 --- loss: 0.956467, loss_ss: 0.952416, loss_d: 0.004052
0.9631 --- loss: 0.834119, loss_ss: 0.829722, loss_d: 0.004398
Epoch finished! Loss: 0.9370338551459774
Starting epoch 10/10.
0.0000 --- loss: 0.818700, loss_ss: 0.790963, loss_d: 0.027737
0.1605 --- loss: 0.850823, loss_ss: 0.850033, loss_d: 0.000790
0.3210 --- loss: 0.924618, loss_ss: 0.753762, loss_d: 0.170856
0.4815 --- loss: 0.888346, loss_ss: 0.841084, loss_d: 0.047263
0.6421 --- loss: 0.707778, loss_ss: 0.696763, loss_d: 0.011015
0.8026 --- loss: 0.840328, loss_ss: 0.839904, loss_d: 0.000423
0.9631 --- loss: 0.821710, loss_ss: 0.821484, loss_d: 0.000226
Epoch finished! Loss: 0.8668691612059071
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5214285714285715
             precision    recall  f1-score   support

        0.0       0.49      0.91      0.64       281
        1.0       0.32      0.18      0.23       213
        2.0       0.71      0.62      0.66       233
        3.0       0.00      0.00      0.00        25
        4.0       0.00      0.00      0.00        88

avg / total       0.44      0.52      0.46       840
 


====== chp047-nsrr ======

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.

The ppr of  4  has ZeroDivisionError.

The f1-score of  4  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  65.83  90.75   53.31  49.42     63.99
1  69.40  17.84   86.92  31.67     22.82
2  82.50  62.23   90.28  71.08     66.36
3  97.02   0.00  100.00   0.00      0.00
4  89.52   0.00  100.00   0.00      0.00
Total accuracy: 52.14%
Average sen: 34.16%
Average spec: 86.10%
Macro f1-score: 30.63%
Diagnosis acc on 60mins: 1.0
[0.99659246 0.99704009 0.99990225 0.9956578  0.99258024 0.99989474
 0.99998748]
pred: 0.9973792944635663, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp047-nsrr

=== Test on chp048-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.379539, loss_ss: 1.685997, loss_d: 0.693541
0.1608 --- loss: 2.130705, loss_ss: 1.505780, loss_d: 0.624925
0.3215 --- loss: 2.111112, loss_ss: 1.521575, loss_d: 0.589537
0.4823 --- loss: 2.067468, loss_ss: 1.574189, loss_d: 0.493279
0.6431 --- loss: 2.133599, loss_ss: 1.411515, loss_d: 0.722084
0.8039 --- loss: 1.811270, loss_ss: 1.287321, loss_d: 0.523950
0.9646 --- loss: 2.110756, loss_ss: 1.260127, loss_d: 0.850629
Epoch finished! Loss: 2.055059817529494
Starting epoch 2/10.
0.0000 --- loss: 1.808285, loss_ss: 1.276108, loss_d: 0.532177
0.1608 --- loss: 1.712648, loss_ss: 1.311076, loss_d: 0.401572
0.3215 --- loss: 1.852708, loss_ss: 1.265097, loss_d: 0.587611
0.4823 --- loss: 1.646418, loss_ss: 1.237506, loss_d: 0.408911
0.6431 --- loss: 1.672341, loss_ss: 1.513203, loss_d: 0.159138
0.8039 --- loss: 1.600839, loss_ss: 1.192139, loss_d: 0.408700
0.9646 --- loss: 1.748753, loss_ss: 1.290461, loss_d: 0.458292
Epoch finished! Loss: 1.7621225926183886
Starting epoch 3/10.
0.0000 --- loss: 1.878763, loss_ss: 1.129445, loss_d: 0.749319
0.1608 --- loss: 1.391711, loss_ss: 1.238543, loss_d: 0.153168
0.3215 --- loss: 1.381173, loss_ss: 1.114360, loss_d: 0.266812
0.4823 --- loss: 1.318607, loss_ss: 1.084463, loss_d: 0.234144
0.6431 --- loss: 1.408865, loss_ss: 1.096765, loss_d: 0.312100
0.8039 --- loss: 1.268859, loss_ss: 1.117737, loss_d: 0.151122
0.9646 --- loss: 1.573014, loss_ss: 1.172771, loss_d: 0.400243
Epoch finished! Loss: 1.5075840065556187
Starting epoch 4/10.
0.0000 --- loss: 1.330311, loss_ss: 1.198489, loss_d: 0.131822
0.1608 --- loss: 1.903552, loss_ss: 1.135386, loss_d: 0.768166
0.3215 --- loss: 1.355048, loss_ss: 1.213351, loss_d: 0.141697
0.4823 --- loss: 1.224078, loss_ss: 1.204986, loss_d: 0.019092
0.6431 --- loss: 1.381948, loss_ss: 1.046426, loss_d: 0.335522
0.8039 --- loss: 1.258988, loss_ss: 1.084850, loss_d: 0.174138
0.9646 --- loss: 1.114985, loss_ss: 1.079000, loss_d: 0.035985
Epoch finished! Loss: 1.3158854361503356
Starting epoch 5/10.
0.0000 --- loss: 1.107723, loss_ss: 1.068352, loss_d: 0.039371
0.1608 --- loss: 1.136485, loss_ss: 1.121147, loss_d: 0.015338
0.3215 --- loss: 1.015228, loss_ss: 0.983934, loss_d: 0.031294
0.4823 --- loss: 1.385102, loss_ss: 1.071704, loss_d: 0.313397
0.6431 --- loss: 1.112541, loss_ss: 1.085505, loss_d: 0.027037
0.8039 --- loss: 1.189730, loss_ss: 1.144001, loss_d: 0.045729
0.9646 --- loss: 1.598692, loss_ss: 1.339161, loss_d: 0.259532
Epoch finished! Loss: 1.2052015556443123
Starting epoch 6/10.
0.0000 --- loss: 1.012150, loss_ss: 0.939726, loss_d: 0.072424
0.1608 --- loss: 1.039895, loss_ss: 1.020281, loss_d: 0.019615
0.3215 --- loss: 0.980291, loss_ss: 0.971613, loss_d: 0.008678
0.4823 --- loss: 1.065163, loss_ss: 1.062625, loss_d: 0.002538
0.6431 --- loss: 1.018483, loss_ss: 0.988851, loss_d: 0.029632
0.8039 --- loss: 0.951255, loss_ss: 0.949994, loss_d: 0.001262
0.9646 --- loss: 0.922520, loss_ss: 0.919675, loss_d: 0.002845
Epoch finished! Loss: 1.0906616862743133
Starting epoch 7/10.
0.0000 --- loss: 0.940282, loss_ss: 0.938944, loss_d: 0.001338
0.1608 --- loss: 1.084853, loss_ss: 1.084363, loss_d: 0.000490
0.3215 --- loss: 1.001807, loss_ss: 0.974338, loss_d: 0.027469
0.4823 --- loss: 0.994297, loss_ss: 0.987961, loss_d: 0.006336
0.6431 --- loss: 0.922376, loss_ss: 0.917851, loss_d: 0.004525
0.8039 --- loss: 1.213379, loss_ss: 1.143073, loss_d: 0.070306
0.9646 --- loss: 1.060245, loss_ss: 1.054985, loss_d: 0.005260
Epoch finished! Loss: 1.043905194728605
Starting epoch 8/10.
0.0000 --- loss: 1.090480, loss_ss: 1.089256, loss_d: 0.001223
0.1608 --- loss: 0.986141, loss_ss: 0.977420, loss_d: 0.008721
0.3215 --- loss: 0.921569, loss_ss: 0.920762, loss_d: 0.000808
0.4823 --- loss: 0.829772, loss_ss: 0.818998, loss_d: 0.010774
0.6431 --- loss: 0.980183, loss_ss: 0.978681, loss_d: 0.001502
0.8039 --- loss: 0.942835, loss_ss: 0.937253, loss_d: 0.005582
0.9646 --- loss: 1.074925, loss_ss: 1.070223, loss_d: 0.004702
Epoch finished! Loss: 1.0186299479776812
Starting epoch 9/10.
0.0000 --- loss: 0.997238, loss_ss: 0.996811, loss_d: 0.000427
0.1608 --- loss: 1.099094, loss_ss: 1.098438, loss_d: 0.000655
0.3215 --- loss: 1.147534, loss_ss: 1.147162, loss_d: 0.000372
0.4823 --- loss: 0.864088, loss_ss: 0.863151, loss_d: 0.000936
0.6431 --- loss: 1.099908, loss_ss: 0.957035, loss_d: 0.142872
0.8039 --- loss: 0.750271, loss_ss: 0.749412, loss_d: 0.000859
0.9646 --- loss: 0.917148, loss_ss: 0.915239, loss_d: 0.001908
Epoch finished! Loss: 0.957289045856845
Starting epoch 10/10.
0.0000 --- loss: 0.917023, loss_ss: 0.915060, loss_d: 0.001963
0.1608 --- loss: 0.903622, loss_ss: 0.902753, loss_d: 0.000869
0.3215 --- loss: 0.827128, loss_ss: 0.826411, loss_d: 0.000718
0.4823 --- loss: 0.814403, loss_ss: 0.806237, loss_d: 0.008166
0.6431 --- loss: 0.786701, loss_ss: 0.784726, loss_d: 0.001975
0.8039 --- loss: 0.896549, loss_ss: 0.896317, loss_d: 0.000232
0.9646 --- loss: 0.855055, loss_ss: 0.854808, loss_d: 0.000247
Epoch finished! Loss: 0.9247319909834093
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.578125
             precision    recall  f1-score   support

        0.0       0.12      1.00      0.22        37
        1.0       0.00      0.00      0.00       129
        2.0       0.83      0.77      0.80       492
        3.0       0.71      0.50      0.59       107
        4.0       0.69      0.44      0.54       195

avg / total       0.65      0.58      0.59       960
 


====== chp048-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  72.29  100.00   71.18  12.21     21.76
1  86.56    0.00  100.00   0.00      0.00
2  80.00   76.83   83.33  82.89     79.75
3  92.19   50.47   97.42  71.05     59.02
4  84.58   44.10   94.90  68.80     53.75
Total accuracy: 57.81%
Average sen: 54.28%
Average spec: 89.37%
Macro f1-score: 42.86%
Diagnosis acc on 60mins: 0.125
[1.45474616e-02 1.04256086e-01 1.31019056e-04 2.54420757e-01
 4.83406737e-04 1.05702937e-01 9.99947548e-01 3.85069221e-01]
pred: 0.2330698045752797, label: 1
Wrong!!! Real Diagnosis: NT1
Save 60mins of subject chp048-nsrr

=== Test on chp049-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.310487, loss_ss: 1.577949, loss_d: 0.732537
0.1610 --- loss: 2.333101, loss_ss: 1.515022, loss_d: 0.818079
0.3221 --- loss: 2.150626, loss_ss: 1.487523, loss_d: 0.663103
0.4831 --- loss: 2.279371, loss_ss: 1.545143, loss_d: 0.734228
0.6441 --- loss: 1.842880, loss_ss: 1.370076, loss_d: 0.472804
0.8052 --- loss: 1.909927, loss_ss: 1.383765, loss_d: 0.526161
0.9662 --- loss: 1.836272, loss_ss: 1.384436, loss_d: 0.451835
Epoch finished! Loss: 2.133825215601152
Starting epoch 2/10.
0.0000 --- loss: 1.832947, loss_ss: 1.340708, loss_d: 0.492239
0.1610 --- loss: 1.892308, loss_ss: 1.349899, loss_d: 0.542409
0.3221 --- loss: 1.701996, loss_ss: 1.323659, loss_d: 0.378337
0.4831 --- loss: 1.759603, loss_ss: 1.329582, loss_d: 0.430021
0.6441 --- loss: 1.722735, loss_ss: 1.169042, loss_d: 0.553693
0.8052 --- loss: 1.840400, loss_ss: 1.281521, loss_d: 0.558878
0.9662 --- loss: 1.862923, loss_ss: 1.270166, loss_d: 0.592756
Epoch finished! Loss: 1.8286805383620723
Starting epoch 3/10.
0.0000 --- loss: 1.652425, loss_ss: 1.168161, loss_d: 0.484264
0.1610 --- loss: 1.618993, loss_ss: 1.247526, loss_d: 0.371467
0.3221 --- loss: 1.963208, loss_ss: 1.215068, loss_d: 0.748141
0.4831 --- loss: 1.802108, loss_ss: 1.531604, loss_d: 0.270504
0.6441 --- loss: 1.613805, loss_ss: 1.550908, loss_d: 0.062897
0.8052 --- loss: 1.299380, loss_ss: 1.115874, loss_d: 0.183506
0.9662 --- loss: 1.771810, loss_ss: 1.173100, loss_d: 0.598711
Epoch finished! Loss: 1.5624401377093406
Starting epoch 4/10.
0.0000 --- loss: 1.792637, loss_ss: 1.224938, loss_d: 0.567699
0.1610 --- loss: 1.635773, loss_ss: 1.254295, loss_d: 0.381478
0.3221 --- loss: 1.245455, loss_ss: 1.104471, loss_d: 0.140985
0.4831 --- loss: 1.227965, loss_ss: 1.059969, loss_d: 0.167996
0.6441 --- loss: 1.373433, loss_ss: 1.153982, loss_d: 0.219451
0.8052 --- loss: 1.361536, loss_ss: 1.025837, loss_d: 0.335699
0.9662 --- loss: 1.366057, loss_ss: 1.216985, loss_d: 0.149073
Epoch finished! Loss: 1.4804885387420654
Starting epoch 5/10.
0.0000 --- loss: 1.370715, loss_ss: 1.038813, loss_d: 0.331902
0.1610 --- loss: 1.306727, loss_ss: 1.056524, loss_d: 0.250203
0.3221 --- loss: 1.554471, loss_ss: 1.320705, loss_d: 0.233766
0.4831 --- loss: 1.029325, loss_ss: 0.966247, loss_d: 0.063078
0.6441 --- loss: 1.261555, loss_ss: 1.183853, loss_d: 0.077702
0.8052 --- loss: 1.241474, loss_ss: 1.049596, loss_d: 0.191878
0.9662 --- loss: 1.267590, loss_ss: 1.047776, loss_d: 0.219814
Epoch finished! Loss: 1.285302432314042
Starting epoch 6/10.
0.0000 --- loss: 1.134073, loss_ss: 1.068496, loss_d: 0.065577
0.1610 --- loss: 1.113079, loss_ss: 1.071431, loss_d: 0.041648
0.3221 --- loss: 1.043318, loss_ss: 0.993542, loss_d: 0.049777
0.4831 --- loss: 1.110929, loss_ss: 1.087134, loss_d: 0.023795
0.6441 --- loss: 1.161105, loss_ss: 1.130460, loss_d: 0.030645
0.8052 --- loss: 1.023974, loss_ss: 1.009678, loss_d: 0.014296
0.9662 --- loss: 1.018182, loss_ss: 0.940185, loss_d: 0.077996
Epoch finished! Loss: 1.1787610140538984
Starting epoch 7/10.
0.0000 --- loss: 1.087162, loss_ss: 1.065119, loss_d: 0.022042
0.1610 --- loss: 0.994836, loss_ss: 0.987735, loss_d: 0.007101
0.3221 --- loss: 1.194511, loss_ss: 1.056983, loss_d: 0.137528
0.4831 --- loss: 0.987190, loss_ss: 0.984136, loss_d: 0.003055
0.6441 --- loss: 1.226338, loss_ss: 0.997395, loss_d: 0.228943
0.8052 --- loss: 1.629112, loss_ss: 1.522119, loss_d: 0.106993
0.9662 --- loss: 1.054146, loss_ss: 0.951565, loss_d: 0.102581
Epoch finished! Loss: 1.1489306976718288
Starting epoch 8/10.
0.0000 --- loss: 1.163029, loss_ss: 1.155851, loss_d: 0.007177
0.1610 --- loss: 1.122631, loss_ss: 1.036861, loss_d: 0.085769
0.3221 --- loss: 1.033304, loss_ss: 1.012524, loss_d: 0.020779
0.4831 --- loss: 0.964142, loss_ss: 0.929999, loss_d: 0.034143
0.6441 --- loss: 1.393855, loss_ss: 1.349045, loss_d: 0.044810
0.8052 --- loss: 0.819198, loss_ss: 0.818005, loss_d: 0.001193
0.9662 --- loss: 1.238071, loss_ss: 1.226984, loss_d: 0.011088
Epoch finished! Loss: 1.0955367655523363
Starting epoch 9/10.
0.0000 --- loss: 1.081938, loss_ss: 1.078881, loss_d: 0.003056
0.1610 --- loss: 1.334738, loss_ss: 1.043043, loss_d: 0.291695
0.3221 --- loss: 1.026022, loss_ss: 1.019631, loss_d: 0.006391
0.4831 --- loss: 1.223929, loss_ss: 1.205672, loss_d: 0.018256
0.6441 --- loss: 1.099433, loss_ss: 1.079455, loss_d: 0.019978
0.8052 --- loss: 0.929690, loss_ss: 0.892497, loss_d: 0.037194
0.9662 --- loss: 1.283930, loss_ss: 0.999875, loss_d: 0.284055
Epoch finished! Loss: 1.0582364845660426
Starting epoch 10/10.
0.0000 --- loss: 1.146670, loss_ss: 1.126150, loss_d: 0.020520
0.1610 --- loss: 0.958122, loss_ss: 0.952717, loss_d: 0.005405
0.3221 --- loss: 0.818719, loss_ss: 0.797131, loss_d: 0.021588
0.4831 --- loss: 0.954089, loss_ss: 0.952997, loss_d: 0.001092
0.6441 --- loss: 1.060858, loss_ss: 1.057653, loss_d: 0.003205
0.8052 --- loss: 0.887055, loss_ss: 0.885912, loss_d: 0.001142
0.9662 --- loss: 1.065222, loss_ss: 0.907029, loss_d: 0.158193
Epoch finished! Loss: 1.0371391446359697
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.46296296296296297
             precision    recall  f1-score   support

        0.0       0.50      0.05      0.08       108
        1.0       0.46      0.07      0.12       387
        2.0       0.49      0.76      0.60       360
        3.0       0.99      0.73      0.84        95
        4.0       0.32      0.97      0.49       130

avg / total       0.51      0.46      0.38      1080
 


====== chp049-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  90.00   4.63   99.49  50.00      8.47
1  63.80   6.72   95.67  46.43     11.74
2  66.02  76.11   60.97  49.37     59.89
3  97.50  72.63   99.90  98.57     83.64
4  75.28  96.92   72.32  32.39     48.55
Total accuracy: 46.30%
Average sen: 51.40%
Average spec: 85.67%
Macro f1-score: 42.46%
Diagnosis acc on 60mins: 1.0
[0.99999988 1.         1.         0.99999928 1.         1.
 0.99999928 1.         1.        ]
pred: 0.999999827808804, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp049-nsrr

=== Test on chp051-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.394042, loss_ss: 1.690257, loss_d: 0.703785
0.1610 --- loss: 2.216884, loss_ss: 1.638476, loss_d: 0.578408
0.3221 --- loss: 2.039822, loss_ss: 1.506323, loss_d: 0.533499
0.4831 --- loss: 2.083180, loss_ss: 1.571024, loss_d: 0.512157
0.6441 --- loss: 2.138659, loss_ss: 1.390461, loss_d: 0.748198
0.8052 --- loss: 2.324813, loss_ss: 1.458562, loss_d: 0.866251
0.9662 --- loss: 1.968653, loss_ss: 1.408958, loss_d: 0.559695
Epoch finished! Loss: 2.1834579590828187
Starting epoch 2/10.
0.0000 --- loss: 2.053308, loss_ss: 1.431586, loss_d: 0.621722
0.1610 --- loss: 1.857928, loss_ss: 1.436626, loss_d: 0.421302
0.3221 --- loss: 1.733738, loss_ss: 1.386298, loss_d: 0.347439
0.4831 --- loss: 2.033098, loss_ss: 1.371049, loss_d: 0.662049
0.6441 --- loss: 1.629984, loss_ss: 1.322392, loss_d: 0.307592
0.8052 --- loss: 1.550441, loss_ss: 1.307741, loss_d: 0.242700
0.9662 --- loss: 1.943611, loss_ss: 1.273251, loss_d: 0.670360
Epoch finished! Loss: 1.8914358904284816
Starting epoch 3/10.
0.0000 --- loss: 1.732781, loss_ss: 1.305568, loss_d: 0.427213
0.1610 --- loss: 1.617285, loss_ss: 1.282671, loss_d: 0.334614
0.3221 --- loss: 1.550974, loss_ss: 1.260200, loss_d: 0.290774
0.4831 --- loss: 1.420370, loss_ss: 1.205075, loss_d: 0.215295
0.6441 --- loss: 1.353531, loss_ss: 1.190233, loss_d: 0.163298
0.8052 --- loss: 1.610082, loss_ss: 1.363046, loss_d: 0.247036
0.9662 --- loss: 1.583083, loss_ss: 1.225627, loss_d: 0.357456
Epoch finished! Loss: 1.6127938301332536
Starting epoch 4/10.
0.0000 --- loss: 1.427661, loss_ss: 1.225062, loss_d: 0.202599
0.1610 --- loss: 1.370205, loss_ss: 1.302821, loss_d: 0.067384
0.3221 --- loss: 1.173816, loss_ss: 1.147137, loss_d: 0.026679
0.4831 --- loss: 1.190152, loss_ss: 1.169399, loss_d: 0.020753
0.6441 --- loss: 1.341859, loss_ss: 1.256058, loss_d: 0.085801
0.8052 --- loss: 1.280636, loss_ss: 1.234261, loss_d: 0.046375
0.9662 --- loss: 1.381678, loss_ss: 1.105569, loss_d: 0.276109
Epoch finished! Loss: 1.3249517948396745
Starting epoch 5/10.
0.0000 --- loss: 1.108689, loss_ss: 1.066541, loss_d: 0.042148
0.1610 --- loss: 1.107161, loss_ss: 1.090237, loss_d: 0.016925
0.3221 --- loss: 1.132042, loss_ss: 1.097113, loss_d: 0.034929
0.4831 --- loss: 1.041997, loss_ss: 1.035824, loss_d: 0.006173
0.6441 --- loss: 1.141100, loss_ss: 1.131618, loss_d: 0.009481
0.8052 --- loss: 1.100868, loss_ss: 1.035019, loss_d: 0.065849
0.9662 --- loss: 1.179830, loss_ss: 0.996430, loss_d: 0.183400
Epoch finished! Loss: 1.1794141300262944
Starting epoch 6/10.
0.0000 --- loss: 1.192128, loss_ss: 1.065950, loss_d: 0.126178
0.1610 --- loss: 1.137233, loss_ss: 1.122442, loss_d: 0.014791
0.3221 --- loss: 1.228731, loss_ss: 1.223851, loss_d: 0.004880
0.4831 --- loss: 1.036574, loss_ss: 1.018635, loss_d: 0.017939
0.6441 --- loss: 1.127035, loss_ss: 1.057692, loss_d: 0.069343
0.8052 --- loss: 1.045908, loss_ss: 1.031944, loss_d: 0.013964
0.9662 --- loss: 0.968728, loss_ss: 0.967539, loss_d: 0.001189
Epoch finished! Loss: 1.125499931073958
Starting epoch 7/10.
0.0000 --- loss: 0.913549, loss_ss: 0.910226, loss_d: 0.003323
0.1610 --- loss: 1.186957, loss_ss: 1.174477, loss_d: 0.012480
0.3221 --- loss: 1.584278, loss_ss: 1.209534, loss_d: 0.374744
0.4831 --- loss: 1.596235, loss_ss: 1.191206, loss_d: 0.405030
0.6441 --- loss: 0.987769, loss_ss: 0.959021, loss_d: 0.028747
0.8052 --- loss: 0.927652, loss_ss: 0.921184, loss_d: 0.006469
0.9662 --- loss: 0.999299, loss_ss: 0.936704, loss_d: 0.062595
Epoch finished! Loss: 1.0728257702242943
Starting epoch 8/10.
0.0000 --- loss: 1.098466, loss_ss: 1.077986, loss_d: 0.020480
0.1610 --- loss: 1.015415, loss_ss: 1.012988, loss_d: 0.002427
0.3221 --- loss: 0.933202, loss_ss: 0.930350, loss_d: 0.002852
0.4831 --- loss: 1.150515, loss_ss: 1.127407, loss_d: 0.023107
0.6441 --- loss: 0.990202, loss_ss: 0.968454, loss_d: 0.021749
0.8052 --- loss: 1.056413, loss_ss: 1.048392, loss_d: 0.008021
0.9662 --- loss: 0.925995, loss_ss: 0.906459, loss_d: 0.019535
Epoch finished! Loss: 0.9944299046070345
Starting epoch 9/10.
0.0000 --- loss: 0.922507, loss_ss: 0.914033, loss_d: 0.008474
0.1610 --- loss: 0.856141, loss_ss: 0.853091, loss_d: 0.003050
0.3221 --- loss: 0.968728, loss_ss: 0.963898, loss_d: 0.004830
0.4831 --- loss: 0.879957, loss_ss: 0.878716, loss_d: 0.001241
0.6441 --- loss: 0.911451, loss_ss: 0.910264, loss_d: 0.001187
0.8052 --- loss: 0.946713, loss_ss: 0.943783, loss_d: 0.002930
0.9662 --- loss: 0.854636, loss_ss: 0.834894, loss_d: 0.019742
Epoch finished! Loss: 0.9734750851508109
Starting epoch 10/10.
0.0000 --- loss: 0.911828, loss_ss: 0.892623, loss_d: 0.019204
0.1610 --- loss: 0.929878, loss_ss: 0.926706, loss_d: 0.003172
0.3221 --- loss: 0.937808, loss_ss: 0.935914, loss_d: 0.001894
0.4831 --- loss: 0.821237, loss_ss: 0.810553, loss_d: 0.010685
0.6441 --- loss: 0.798151, loss_ss: 0.796743, loss_d: 0.001407
0.8052 --- loss: 0.938119, loss_ss: 0.874793, loss_d: 0.063326
0.9662 --- loss: 0.904760, loss_ss: 0.902757, loss_d: 0.002004
Epoch finished! Loss: 0.9316048054925857
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6222222222222222
             precision    recall  f1-score   support

        0.0       0.37      0.73      0.49        30
        1.0       0.14      0.07      0.09       136
        2.0       0.72      0.53      0.61       404
        3.0       0.92      0.74      0.82       239
        4.0       0.54      0.93      0.68       271

avg / total       0.64      0.62      0.60      1080
 


====== chp051-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  95.74  73.33   96.38  36.67     48.89
1  83.15   6.62   94.17  14.06      9.00
2  74.81  52.72   88.02  72.45     61.03
3  92.78  73.64   98.22  92.15     81.86
4  77.96  92.99   72.93  53.50     67.92
Total accuracy: 62.22%
Average sen: 59.86%
Average spec: 89.94%
Macro f1-score: 53.74%
Diagnosis acc on 60mins: 1.0
[0.99999547 0.9999094  0.99950433 0.99977762 0.99996388 0.99998999
 0.99984181 0.99999869 0.99998295]
pred: 0.9998849034309387, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp051-nsrr

=== Test on chp052-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.316566, loss_ss: 1.638835, loss_d: 0.677731
0.1608 --- loss: 1.951814, loss_ss: 1.526017, loss_d: 0.425797
0.3215 --- loss: 2.378318, loss_ss: 1.549160, loss_d: 0.829158
0.4823 --- loss: 2.036576, loss_ss: 1.451035, loss_d: 0.585541
0.6431 --- loss: 2.100392, loss_ss: 1.387351, loss_d: 0.713041
0.8039 --- loss: 2.307170, loss_ss: 1.502488, loss_d: 0.804682
0.9646 --- loss: 1.941733, loss_ss: 1.295676, loss_d: 0.646057
Epoch finished! Loss: 2.120100259780884
Starting epoch 2/10.
0.0000 --- loss: 1.832210, loss_ss: 1.321536, loss_d: 0.510673
0.1608 --- loss: 1.802865, loss_ss: 1.291667, loss_d: 0.511198
0.3215 --- loss: 1.691501, loss_ss: 1.423976, loss_d: 0.267524
0.4823 --- loss: 1.713393, loss_ss: 1.312632, loss_d: 0.400761
0.6431 --- loss: 1.597204, loss_ss: 1.271993, loss_d: 0.325211
0.8039 --- loss: 1.799361, loss_ss: 1.245981, loss_d: 0.553380
0.9646 --- loss: 1.654772, loss_ss: 1.185256, loss_d: 0.469516
Epoch finished! Loss: 1.8342560298981205
Starting epoch 3/10.
0.0000 --- loss: 1.805859, loss_ss: 1.269796, loss_d: 0.536062
0.1608 --- loss: 1.679334, loss_ss: 1.139213, loss_d: 0.540121
0.3215 --- loss: 1.408827, loss_ss: 1.143602, loss_d: 0.265225
0.4823 --- loss: 1.640967, loss_ss: 1.208058, loss_d: 0.432908
0.6431 --- loss: 1.639847, loss_ss: 1.352205, loss_d: 0.287642
0.8039 --- loss: 1.166540, loss_ss: 1.053800, loss_d: 0.112739
0.9646 --- loss: 1.268218, loss_ss: 1.058237, loss_d: 0.209981
Epoch finished! Loss: 1.5861103861562666
Starting epoch 4/10.
0.0000 --- loss: 1.373127, loss_ss: 1.204788, loss_d: 0.168339
0.1608 --- loss: 1.457775, loss_ss: 1.297402, loss_d: 0.160373
0.3215 --- loss: 1.237128, loss_ss: 1.139489, loss_d: 0.097639
0.4823 --- loss: 1.276706, loss_ss: 1.134189, loss_d: 0.142517
0.6431 --- loss: 1.145065, loss_ss: 1.106297, loss_d: 0.038768
0.8039 --- loss: 1.106328, loss_ss: 1.009897, loss_d: 0.096430
0.9646 --- loss: 1.396835, loss_ss: 1.285392, loss_d: 0.111443
Epoch finished! Loss: 1.3080191035424509
Starting epoch 5/10.
0.0000 --- loss: 1.165177, loss_ss: 1.088057, loss_d: 0.077120
0.1608 --- loss: 0.957595, loss_ss: 0.941522, loss_d: 0.016073
0.3215 --- loss: 1.263283, loss_ss: 1.015913, loss_d: 0.247370
0.4823 --- loss: 1.286283, loss_ss: 1.235570, loss_d: 0.050713
0.6431 --- loss: 1.121380, loss_ss: 1.104271, loss_d: 0.017109
0.8039 --- loss: 1.069523, loss_ss: 0.994219, loss_d: 0.075304
0.9646 --- loss: 1.044792, loss_ss: 1.027085, loss_d: 0.017706
Epoch finished! Loss: 1.205063203650136
Starting epoch 6/10.
0.0000 --- loss: 1.097745, loss_ss: 1.026740, loss_d: 0.071005
0.1608 --- loss: 0.988949, loss_ss: 0.982491, loss_d: 0.006458
0.3215 --- loss: 1.248441, loss_ss: 1.059164, loss_d: 0.189277
0.4823 --- loss: 1.250008, loss_ss: 1.233949, loss_d: 0.016059
0.6431 --- loss: 0.978124, loss_ss: 0.941837, loss_d: 0.036286
0.8039 --- loss: 1.161331, loss_ss: 1.089131, loss_d: 0.072200
0.9646 --- loss: 1.044507, loss_ss: 1.010806, loss_d: 0.033702
Epoch finished! Loss: 1.1644688392839124
Starting epoch 7/10.
0.0000 --- loss: 1.056100, loss_ss: 1.050603, loss_d: 0.005497
0.1608 --- loss: 0.982876, loss_ss: 0.952393, loss_d: 0.030483
0.3215 --- loss: 1.055017, loss_ss: 1.048293, loss_d: 0.006724
0.4823 --- loss: 1.045214, loss_ss: 0.939836, loss_d: 0.105378
0.6431 --- loss: 1.024408, loss_ss: 1.017237, loss_d: 0.007170
0.8039 --- loss: 0.925640, loss_ss: 0.924423, loss_d: 0.001217
0.9646 --- loss: 1.143672, loss_ss: 0.865741, loss_d: 0.277931
Epoch finished! Loss: 1.0774256798528856
Starting epoch 8/10.
0.0000 --- loss: 0.879145, loss_ss: 0.877368, loss_d: 0.001776
0.1608 --- loss: 0.967251, loss_ss: 0.959577, loss_d: 0.007673
0.3215 --- loss: 1.117887, loss_ss: 1.116245, loss_d: 0.001642
0.4823 --- loss: 0.945175, loss_ss: 0.941988, loss_d: 0.003187
0.6431 --- loss: 0.985172, loss_ss: 0.908748, loss_d: 0.076425
0.8039 --- loss: 0.928977, loss_ss: 0.908427, loss_d: 0.020550
0.9646 --- loss: 0.856080, loss_ss: 0.855589, loss_d: 0.000491
Epoch finished! Loss: 1.0300158262252808
Starting epoch 9/10.
0.0000 --- loss: 0.834695, loss_ss: 0.833222, loss_d: 0.001474
0.1608 --- loss: 1.010351, loss_ss: 1.007455, loss_d: 0.002896
0.3215 --- loss: 0.930374, loss_ss: 0.929042, loss_d: 0.001332
0.4823 --- loss: 1.003877, loss_ss: 1.003041, loss_d: 0.000836
0.6431 --- loss: 0.827222, loss_ss: 0.819791, loss_d: 0.007431
0.8039 --- loss: 0.864169, loss_ss: 0.863880, loss_d: 0.000289
0.9646 --- loss: 1.097429, loss_ss: 1.096700, loss_d: 0.000729
Epoch finished! Loss: 0.9595985191483651
Starting epoch 10/10.
0.0000 --- loss: 0.852163, loss_ss: 0.851583, loss_d: 0.000580
0.1608 --- loss: 0.843869, loss_ss: 0.843339, loss_d: 0.000530
0.3215 --- loss: 0.956007, loss_ss: 0.953492, loss_d: 0.002515
0.4823 --- loss: 0.875611, loss_ss: 0.875028, loss_d: 0.000583
0.6431 --- loss: 0.899202, loss_ss: 0.884670, loss_d: 0.014532
0.8039 --- loss: 0.944466, loss_ss: 0.939074, loss_d: 0.005392
0.9646 --- loss: 0.818174, loss_ss: 0.788877, loss_d: 0.029297
Epoch finished! Loss: 0.9579998004821039
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6697916666666667
             precision    recall  f1-score   support

        0.0       0.86      0.04      0.07       159
        1.0       0.20      0.02      0.04        87
        2.0       0.89      0.88      0.88       439
        3.0       0.89      0.68      0.77        69
        4.0       0.44      0.98      0.61       206

avg / total       0.72      0.67      0.61       960
 


====== chp052-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  83.96   3.77   99.88  85.71      7.23
1  90.31   2.30   99.08  20.00      4.12
2  89.48  88.15   90.60  88.76     88.46
3  97.08  68.12   99.33  88.68     77.05
4  73.12  97.57   66.45  44.27     60.91
Total accuracy: 66.98%
Average sen: 51.98%
Average spec: 91.07%
Macro f1-score: 47.55%
Diagnosis acc on 60mins: 1.0
[0.99999976 0.99196482 0.89965796 0.99398613 0.99235004 0.99997985
 0.99996889 0.99955767]
pred: 0.9846831411123276, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp052-nsrr

=== Test on chp053-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.535643, loss_ss: 1.854822, loss_d: 0.680820
0.1610 --- loss: 2.183379, loss_ss: 1.605949, loss_d: 0.577430
0.3221 --- loss: 2.126045, loss_ss: 1.617564, loss_d: 0.508482
0.4831 --- loss: 2.152493, loss_ss: 1.557699, loss_d: 0.594794
0.6441 --- loss: 2.194513, loss_ss: 1.483317, loss_d: 0.711196
0.8052 --- loss: 2.082850, loss_ss: 1.497234, loss_d: 0.585616
0.9662 --- loss: 1.960123, loss_ss: 1.378263, loss_d: 0.581860
Epoch finished! Loss: 2.189968482140572
Starting epoch 2/10.
0.0000 --- loss: 1.853935, loss_ss: 1.373291, loss_d: 0.480643
0.1610 --- loss: 1.970404, loss_ss: 1.416123, loss_d: 0.554281
0.3221 --- loss: 1.793844, loss_ss: 1.313461, loss_d: 0.480383
0.4831 --- loss: 1.796557, loss_ss: 1.271141, loss_d: 0.525416
0.6441 --- loss: 1.822305, loss_ss: 1.280879, loss_d: 0.541426
0.8052 --- loss: 1.742867, loss_ss: 1.363950, loss_d: 0.378917
0.9662 --- loss: 1.905598, loss_ss: 1.370093, loss_d: 0.535505
Epoch finished! Loss: 1.8688752881942257
Starting epoch 3/10.
0.0000 --- loss: 1.476956, loss_ss: 1.174011, loss_d: 0.302945
0.1610 --- loss: 1.579712, loss_ss: 1.290023, loss_d: 0.289689
0.3221 --- loss: 1.296905, loss_ss: 1.157208, loss_d: 0.139697
0.4831 --- loss: 1.281638, loss_ss: 1.163230, loss_d: 0.118408
0.6441 --- loss: 1.411882, loss_ss: 1.198149, loss_d: 0.213733
0.8052 --- loss: 1.471223, loss_ss: 1.221834, loss_d: 0.249389
0.9662 --- loss: 1.416949, loss_ss: 1.264395, loss_d: 0.152554
Epoch finished! Loss: 1.563078882232789
Starting epoch 4/10.
0.0000 --- loss: 1.364906, loss_ss: 1.224516, loss_d: 0.140390
0.1610 --- loss: 1.249280, loss_ss: 1.204018, loss_d: 0.045262
0.3221 --- loss: 1.397015, loss_ss: 1.228482, loss_d: 0.168532
0.4831 --- loss: 1.317862, loss_ss: 1.135887, loss_d: 0.181975
0.6441 --- loss: 1.311566, loss_ss: 1.175239, loss_d: 0.136327
0.8052 --- loss: 1.289358, loss_ss: 1.075259, loss_d: 0.214099
0.9662 --- loss: 1.203470, loss_ss: 1.089903, loss_d: 0.113567
Epoch finished! Loss: 1.333552139420663
Starting epoch 5/10.
0.0000 --- loss: 1.098341, loss_ss: 1.070534, loss_d: 0.027807
0.1610 --- loss: 1.130570, loss_ss: 1.097128, loss_d: 0.033442
0.3221 --- loss: 1.212924, loss_ss: 1.099409, loss_d: 0.113515
0.4831 --- loss: 1.216941, loss_ss: 1.091089, loss_d: 0.125852
0.6441 --- loss: 1.412881, loss_ss: 1.169910, loss_d: 0.242971
0.8052 --- loss: 1.604668, loss_ss: 1.253287, loss_d: 0.351382
0.9662 --- loss: 1.065768, loss_ss: 1.008751, loss_d: 0.057017
Epoch finished! Loss: 1.1768535962027888
Starting epoch 6/10.
0.0000 --- loss: 1.010763, loss_ss: 1.004360, loss_d: 0.006403
0.1610 --- loss: 1.154885, loss_ss: 1.045638, loss_d: 0.109247
0.3221 --- loss: 1.039865, loss_ss: 1.037151, loss_d: 0.002714
0.4831 --- loss: 1.051421, loss_ss: 1.046136, loss_d: 0.005285
0.6441 --- loss: 1.071561, loss_ss: 1.007187, loss_d: 0.064375
0.8052 --- loss: 1.305202, loss_ss: 1.179300, loss_d: 0.125903
0.9662 --- loss: 1.024587, loss_ss: 1.006279, loss_d: 0.018307
Epoch finished! Loss: 1.0744623032308394
Starting epoch 7/10.
0.0000 --- loss: 0.976229, loss_ss: 0.938998, loss_d: 0.037230
0.1610 --- loss: 1.021114, loss_ss: 1.015893, loss_d: 0.005220
0.3221 --- loss: 0.872172, loss_ss: 0.866158, loss_d: 0.006014
0.4831 --- loss: 1.073753, loss_ss: 1.054876, loss_d: 0.018877
0.6441 --- loss: 0.834425, loss_ss: 0.830427, loss_d: 0.003998
0.8052 --- loss: 1.258395, loss_ss: 1.244374, loss_d: 0.014021
0.9662 --- loss: 0.828624, loss_ss: 0.825541, loss_d: 0.003083
Epoch finished! Loss: 0.9968605493345568
Starting epoch 8/10.
0.0000 --- loss: 0.833236, loss_ss: 0.828206, loss_d: 0.005030
0.1610 --- loss: 0.853310, loss_ss: 0.852745, loss_d: 0.000565
0.3221 --- loss: 0.877715, loss_ss: 0.877317, loss_d: 0.000397
0.4831 --- loss: 0.849540, loss_ss: 0.848165, loss_d: 0.001374
0.6441 --- loss: 0.866172, loss_ss: 0.863530, loss_d: 0.002642
0.8052 --- loss: 0.821265, loss_ss: 0.820541, loss_d: 0.000723
0.9662 --- loss: 1.007001, loss_ss: 0.991074, loss_d: 0.015927
Epoch finished! Loss: 0.9291108096799543
Starting epoch 9/10.
0.0000 --- loss: 0.823569, loss_ss: 0.820719, loss_d: 0.002850
0.1610 --- loss: 0.854953, loss_ss: 0.852906, loss_d: 0.002047
0.3221 --- loss: 1.014793, loss_ss: 1.013182, loss_d: 0.001612
0.4831 --- loss: 0.835406, loss_ss: 0.834761, loss_d: 0.000645
0.6441 --- loss: 0.884558, loss_ss: 0.884302, loss_d: 0.000256
0.8052 --- loss: 0.898243, loss_ss: 0.897828, loss_d: 0.000415
0.9662 --- loss: 0.916737, loss_ss: 0.916166, loss_d: 0.000571
Epoch finished! Loss: 0.9170951843261719
Starting epoch 10/10.
0.0000 --- loss: 0.758781, loss_ss: 0.758351, loss_d: 0.000430
0.1610 --- loss: 0.885658, loss_ss: 0.881379, loss_d: 0.004279
0.3221 --- loss: 0.846651, loss_ss: 0.838799, loss_d: 0.007852
0.4831 --- loss: 0.813808, loss_ss: 0.813599, loss_d: 0.000209
0.6441 --- loss: 0.991891, loss_ss: 0.990970, loss_d: 0.000920
0.8052 --- loss: 0.839209, loss_ss: 0.838934, loss_d: 0.000275
0.9662 --- loss: 0.916917, loss_ss: 0.910717, loss_d: 0.006200
Epoch finished! Loss: 0.9174775087064312
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7277777777777777
             precision    recall  f1-score   support

        0.0       0.88      0.78      0.82       251
        1.0       0.44      0.14      0.22       147
        2.0       0.74      0.88      0.81       305
        3.0       0.99      0.76      0.86       250
        4.0       0.43      0.88      0.58       127

avg / total       0.75      0.73      0.72      1080
 


====== chp053-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  92.31  77.69   96.74  87.84     82.45
1  85.83  14.29   97.11  43.75     21.54
2  88.06  87.87   88.13  74.44     80.60
3  94.26  76.00   99.76  98.96     85.97
4  85.09  88.19   84.68  43.41     58.18
Total accuracy: 72.78%
Average sen: 68.81%
Average spec: 93.28%
Macro f1-score: 65.75%
Diagnosis acc on 60mins: 1.0
[0.99990702 0.99999666 1.         0.99999976 0.97399783 0.99973649
 0.99993885 0.99993908 0.99999344]
pred: 0.9970565703180101, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp053-nsrr

=== Test on chp054-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.399302, loss_ss: 1.753592, loss_d: 0.645710
0.1610 --- loss: 3.021449, loss_ss: 1.554538, loss_d: 1.466911
0.3221 --- loss: 2.050394, loss_ss: 1.505539, loss_d: 0.544855
0.4831 --- loss: 2.133814, loss_ss: 1.525690, loss_d: 0.608125
0.6441 --- loss: 2.101516, loss_ss: 1.402251, loss_d: 0.699266
0.8052 --- loss: 2.076470, loss_ss: 1.432181, loss_d: 0.644289
0.9662 --- loss: 1.791869, loss_ss: 1.342578, loss_d: 0.449290
Epoch finished! Loss: 2.150431458027132
Starting epoch 2/10.
0.0000 --- loss: 1.963044, loss_ss: 1.366079, loss_d: 0.596965
0.1610 --- loss: 1.556878, loss_ss: 1.283066, loss_d: 0.273813
0.3221 --- loss: 1.723087, loss_ss: 1.228466, loss_d: 0.494621
0.4831 --- loss: 1.571070, loss_ss: 1.271858, loss_d: 0.299212
0.6441 --- loss: 1.892844, loss_ss: 1.415197, loss_d: 0.477647
0.8052 --- loss: 1.691719, loss_ss: 1.304088, loss_d: 0.387631
0.9662 --- loss: 1.822958, loss_ss: 1.183891, loss_d: 0.639067
Epoch finished! Loss: 1.8073649560251543
Starting epoch 3/10.
0.0000 --- loss: 1.677417, loss_ss: 1.389877, loss_d: 0.287541
0.1610 --- loss: 1.631033, loss_ss: 1.311842, loss_d: 0.319191
0.3221 --- loss: 1.224164, loss_ss: 1.059853, loss_d: 0.164310
0.4831 --- loss: 1.388282, loss_ss: 1.211457, loss_d: 0.176826
0.6441 --- loss: 1.484828, loss_ss: 1.147010, loss_d: 0.337818
0.8052 --- loss: 1.774005, loss_ss: 1.209584, loss_d: 0.564421
0.9662 --- loss: 1.618883, loss_ss: 1.246490, loss_d: 0.372394
Epoch finished! Loss: 1.6172960227535618
Starting epoch 4/10.
0.0000 --- loss: 1.213806, loss_ss: 1.136053, loss_d: 0.077753
0.1610 --- loss: 1.485037, loss_ss: 1.261082, loss_d: 0.223955
0.3221 --- loss: 1.272052, loss_ss: 1.171232, loss_d: 0.100820
0.4831 --- loss: 1.346688, loss_ss: 1.216728, loss_d: 0.129960
0.6441 --- loss: 1.225217, loss_ss: 1.085289, loss_d: 0.139929
0.8052 --- loss: 1.266046, loss_ss: 1.142135, loss_d: 0.123910
0.9662 --- loss: 1.282669, loss_ss: 1.021181, loss_d: 0.261488
Epoch finished! Loss: 1.348919233968181
Starting epoch 5/10.
0.0000 --- loss: 1.123122, loss_ss: 1.100970, loss_d: 0.022153
0.1610 --- loss: 1.189474, loss_ss: 1.162946, loss_d: 0.026528
0.3221 --- loss: 1.127383, loss_ss: 1.106570, loss_d: 0.020813
0.4831 --- loss: 1.015327, loss_ss: 0.980118, loss_d: 0.035209
0.6441 --- loss: 1.048102, loss_ss: 1.042187, loss_d: 0.005915
0.8052 --- loss: 1.332523, loss_ss: 1.241111, loss_d: 0.091413
0.9662 --- loss: 1.045548, loss_ss: 0.996156, loss_d: 0.049392
Epoch finished! Loss: 1.1559657790968496
Starting epoch 6/10.
0.0000 --- loss: 0.934523, loss_ss: 0.930990, loss_d: 0.003533
0.1610 --- loss: 1.000740, loss_ss: 0.999352, loss_d: 0.001388
0.3221 --- loss: 0.979017, loss_ss: 0.969510, loss_d: 0.009507
0.4831 --- loss: 1.156702, loss_ss: 1.154695, loss_d: 0.002008
0.6441 --- loss: 1.054294, loss_ss: 1.049347, loss_d: 0.004947
0.8052 --- loss: 1.042521, loss_ss: 0.919722, loss_d: 0.122799
0.9662 --- loss: 0.934082, loss_ss: 0.916745, loss_d: 0.017336
Epoch finished! Loss: 1.0885278976732684
Starting epoch 7/10.
0.0000 --- loss: 0.866704, loss_ss: 0.864468, loss_d: 0.002236
0.1610 --- loss: 0.931785, loss_ss: 0.929159, loss_d: 0.002626
0.3221 --- loss: 1.059221, loss_ss: 1.035193, loss_d: 0.024028
0.4831 --- loss: 0.948980, loss_ss: 0.906810, loss_d: 0.042170
0.6441 --- loss: 1.048847, loss_ss: 1.042965, loss_d: 0.005882
0.8052 --- loss: 1.107549, loss_ss: 1.103594, loss_d: 0.003955
0.9662 --- loss: 1.017683, loss_ss: 1.010794, loss_d: 0.006889
Epoch finished! Loss: 1.0439728921459568
Starting epoch 8/10.
0.0000 --- loss: 1.034401, loss_ss: 1.031188, loss_d: 0.003213
0.1610 --- loss: 0.924641, loss_ss: 0.918997, loss_d: 0.005644
0.3221 --- loss: 1.004261, loss_ss: 1.002727, loss_d: 0.001534
0.4831 --- loss: 0.818325, loss_ss: 0.813379, loss_d: 0.004945
0.6441 --- loss: 0.985860, loss_ss: 0.960712, loss_d: 0.025148
0.8052 --- loss: 0.971095, loss_ss: 0.967975, loss_d: 0.003119
0.9662 --- loss: 0.862089, loss_ss: 0.842770, loss_d: 0.019319
Epoch finished! Loss: 0.988234487272078
Starting epoch 9/10.
0.0000 --- loss: 0.938016, loss_ss: 0.934965, loss_d: 0.003051
0.1610 --- loss: 1.008302, loss_ss: 0.998206, loss_d: 0.010096
0.3221 --- loss: 0.864516, loss_ss: 0.862827, loss_d: 0.001689
0.4831 --- loss: 1.048658, loss_ss: 1.013996, loss_d: 0.034662
0.6441 --- loss: 0.928918, loss_ss: 0.918527, loss_d: 0.010391
0.8052 --- loss: 0.840959, loss_ss: 0.839000, loss_d: 0.001959
0.9662 --- loss: 0.941952, loss_ss: 0.940488, loss_d: 0.001464
Epoch finished! Loss: 0.9193159207221
Starting epoch 10/10.
0.0000 --- loss: 0.819199, loss_ss: 0.818749, loss_d: 0.000449
0.1610 --- loss: 0.766703, loss_ss: 0.766245, loss_d: 0.000458
0.3221 --- loss: 0.795538, loss_ss: 0.794188, loss_d: 0.001350
0.4831 --- loss: 1.305098, loss_ss: 1.303740, loss_d: 0.001358
0.6441 --- loss: 0.958603, loss_ss: 0.957975, loss_d: 0.000628
0.8052 --- loss: 0.915408, loss_ss: 0.915293, loss_d: 0.000115
0.9662 --- loss: 1.043039, loss_ss: 1.041837, loss_d: 0.001203
Epoch finished! Loss: 0.8877464504011215
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6444444444444445
             precision    recall  f1-score   support

        0.0       0.83      0.26      0.39       228
        1.0       0.13      0.08      0.10        86
        2.0       0.91      0.74      0.81       451
        3.0       0.97      0.94      0.95        99
        4.0       0.41      0.95      0.58       216

avg / total       0.74      0.64      0.63      1080
 


====== chp054-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  83.24  25.88   98.59  83.10     39.46
1  88.52   8.14   95.47  13.46     10.14
2  85.93  73.61   94.75  90.96     81.37
3  99.17  93.94   99.69  96.88     95.38
4  72.04  94.91   66.32  41.33     57.58
Total accuracy: 64.44%
Average sen: 59.30%
Average spec: 90.97%
Macro f1-score: 56.79%
Diagnosis acc on 60mins: 1.0
[0.99998116 0.99999976 0.97020906 0.99948186 0.99999833 0.99985421
 0.99998033 0.99999952 0.99999964]
pred: 0.9966115421719022, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp054-nsrr

=== Test on chp055-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.354304, loss_ss: 1.675022, loss_d: 0.679282
0.1610 --- loss: 2.129822, loss_ss: 1.650540, loss_d: 0.479283
0.3221 --- loss: 2.152173, loss_ss: 1.608966, loss_d: 0.543207
0.4831 --- loss: 2.166438, loss_ss: 1.577265, loss_d: 0.589173
0.6441 --- loss: 2.054690, loss_ss: 1.502160, loss_d: 0.552530
0.8052 --- loss: 2.202072, loss_ss: 1.375416, loss_d: 0.826656
0.9662 --- loss: 1.890077, loss_ss: 1.396601, loss_d: 0.493476
Epoch finished! Loss: 2.1876473542182677
Starting epoch 2/10.
0.0000 --- loss: 2.053272, loss_ss: 1.509934, loss_d: 0.543338
0.1610 --- loss: 1.952559, loss_ss: 1.408136, loss_d: 0.544422
0.3221 --- loss: 1.795025, loss_ss: 1.357080, loss_d: 0.437944
0.4831 --- loss: 1.854635, loss_ss: 1.502134, loss_d: 0.352502
0.6441 --- loss: 1.754483, loss_ss: 1.421908, loss_d: 0.332575
0.8052 --- loss: 1.715648, loss_ss: 1.327765, loss_d: 0.387883
0.9662 --- loss: 1.759826, loss_ss: 1.480053, loss_d: 0.279773
Epoch finished! Loss: 1.9116997045855368
Starting epoch 3/10.
0.0000 --- loss: 1.800794, loss_ss: 1.369808, loss_d: 0.430985
0.1610 --- loss: 1.733370, loss_ss: 1.404309, loss_d: 0.329061
0.3221 --- loss: 2.376828, loss_ss: 1.318418, loss_d: 1.058411
0.4831 --- loss: 1.307197, loss_ss: 1.207053, loss_d: 0.100144
0.6441 --- loss: 1.611677, loss_ss: 1.271167, loss_d: 0.340511
0.8052 --- loss: 1.438150, loss_ss: 1.314812, loss_d: 0.123338
0.9662 --- loss: 1.377937, loss_ss: 1.284824, loss_d: 0.093113
Epoch finished! Loss: 1.6926360264901192
Starting epoch 4/10.
0.0000 --- loss: 1.475560, loss_ss: 1.317746, loss_d: 0.157814
0.1610 --- loss: 1.283504, loss_ss: 1.190632, loss_d: 0.092872
0.3221 --- loss: 1.239414, loss_ss: 1.220310, loss_d: 0.019104
0.4831 --- loss: 1.200841, loss_ss: 1.148172, loss_d: 0.052669
0.6441 --- loss: 1.236903, loss_ss: 1.173871, loss_d: 0.063032
0.8052 --- loss: 1.472802, loss_ss: 1.217374, loss_d: 0.255428
0.9662 --- loss: 1.320995, loss_ss: 1.297211, loss_d: 0.023784
Epoch finished! Loss: 1.4051872049608538
Starting epoch 5/10.
0.0000 --- loss: 1.274200, loss_ss: 1.240292, loss_d: 0.033908
0.1610 --- loss: 1.257499, loss_ss: 1.244526, loss_d: 0.012972
0.3221 --- loss: 1.460646, loss_ss: 1.159201, loss_d: 0.301445
0.4831 --- loss: 1.239210, loss_ss: 1.168540, loss_d: 0.070669
0.6441 --- loss: 1.358055, loss_ss: 1.213777, loss_d: 0.144278
0.8052 --- loss: 1.167596, loss_ss: 1.129023, loss_d: 0.038572
0.9662 --- loss: 1.341082, loss_ss: 1.152194, loss_d: 0.188888
Epoch finished! Loss: 1.335151122462365
Starting epoch 6/10.
0.0000 --- loss: 1.419749, loss_ss: 1.235181, loss_d: 0.184567
0.1610 --- loss: 1.119988, loss_ss: 1.044661, loss_d: 0.075327
0.3221 --- loss: 1.146024, loss_ss: 1.141988, loss_d: 0.004037
0.4831 --- loss: 1.088910, loss_ss: 1.027976, loss_d: 0.060934
0.6441 --- loss: 0.970946, loss_ss: 0.927095, loss_d: 0.043851
0.8052 --- loss: 1.056912, loss_ss: 1.042537, loss_d: 0.014375
0.9662 --- loss: 1.147979, loss_ss: 1.116300, loss_d: 0.031679
Epoch finished! Loss: 1.2081675298752323
Starting epoch 7/10.
0.0000 --- loss: 1.154497, loss_ss: 1.145042, loss_d: 0.009456
0.1610 --- loss: 1.097024, loss_ss: 1.094349, loss_d: 0.002675
0.3221 --- loss: 1.145973, loss_ss: 1.144685, loss_d: 0.001288
0.4831 --- loss: 1.078972, loss_ss: 1.076670, loss_d: 0.002302
0.6441 --- loss: 1.129655, loss_ss: 1.126250, loss_d: 0.003406
0.8052 --- loss: 1.149207, loss_ss: 1.142335, loss_d: 0.006873
0.9662 --- loss: 1.057221, loss_ss: 1.046041, loss_d: 0.011180
Epoch finished! Loss: 1.11322069937183
Starting epoch 8/10.
0.0000 --- loss: 1.042681, loss_ss: 1.040553, loss_d: 0.002128
0.1610 --- loss: 0.992325, loss_ss: 0.913835, loss_d: 0.078491
0.3221 --- loss: 1.023969, loss_ss: 1.017785, loss_d: 0.006184
0.4831 --- loss: 0.999849, loss_ss: 0.958237, loss_d: 0.041612
0.6441 --- loss: 1.043913, loss_ss: 1.042934, loss_d: 0.000979
0.8052 --- loss: 1.002090, loss_ss: 1.001262, loss_d: 0.000827
0.9662 --- loss: 1.200622, loss_ss: 1.196729, loss_d: 0.003893
Epoch finished! Loss: 1.0622461034405617
Starting epoch 9/10.
0.0000 --- loss: 0.903353, loss_ss: 0.902074, loss_d: 0.001279
0.1610 --- loss: 0.915334, loss_ss: 0.911996, loss_d: 0.003338
0.3221 --- loss: 0.936687, loss_ss: 0.936129, loss_d: 0.000558
0.4831 --- loss: 0.976132, loss_ss: 0.937732, loss_d: 0.038400
0.6441 --- loss: 0.991196, loss_ss: 0.990919, loss_d: 0.000277
0.8052 --- loss: 0.921646, loss_ss: 0.901138, loss_d: 0.020508
0.9662 --- loss: 0.947432, loss_ss: 0.941022, loss_d: 0.006410
Epoch finished! Loss: 1.0049320949662117
Starting epoch 10/10.
0.0000 --- loss: 0.972321, loss_ss: 0.971835, loss_d: 0.000486
0.1610 --- loss: 0.871114, loss_ss: 0.870547, loss_d: 0.000567
0.3221 --- loss: 0.928295, loss_ss: 0.927751, loss_d: 0.000544
0.4831 --- loss: 0.961545, loss_ss: 0.960568, loss_d: 0.000976
0.6441 --- loss: 0.854618, loss_ss: 0.854547, loss_d: 0.000071
0.8052 --- loss: 0.832549, loss_ss: 0.828030, loss_d: 0.004519
0.9662 --- loss: 1.189970, loss_ss: 1.189831, loss_d: 0.000138
Epoch finished! Loss: 0.9881350994110107
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5277777777777778
             precision    recall  f1-score   support

        0.0       1.00      0.29      0.45       211
        1.0       0.00      0.00      0.00       154
        2.0       0.60      0.85      0.70       408
        3.0       0.00      0.00      0.00       130
        4.0       0.37      0.93      0.53       177

avg / total       0.48      0.53      0.44      1080
 


====== chp055-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  86.11  28.91  100.00  100.00     44.85
1  85.74   0.00  100.00    0.00      0.00
2  72.50  84.56   65.18   59.59     69.91
3  87.96   0.00  100.00    0.00      0.00
4  73.24  92.66   69.44   37.27     53.16
Total accuracy: 52.78%
Average sen: 41.22%
Average spec: 86.92%
Macro f1-score: 33.58%
Diagnosis acc on 60mins: 0.7777777777777778
[0.93390119 0.00246258 0.97077203 0.95560932 0.99258763 0.93964571
 0.74509698 0.23128043 0.99727386]
pred: 0.7520699699461046, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp055-nsrr

=== Test on chp056-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.407933, loss_ss: 1.714367, loss_d: 0.693566
0.1610 --- loss: 2.008770, loss_ss: 1.513318, loss_d: 0.495451
0.3221 --- loss: 2.103571, loss_ss: 1.460995, loss_d: 0.642576
0.4831 --- loss: 1.656330, loss_ss: 1.327746, loss_d: 0.328584
0.6441 --- loss: 1.740580, loss_ss: 1.373655, loss_d: 0.366925
0.8052 --- loss: 2.154665, loss_ss: 1.303228, loss_d: 0.851436
0.9662 --- loss: 2.086809, loss_ss: 1.383185, loss_d: 0.703624
Epoch finished! Loss: 2.0674014610628926
Starting epoch 2/10.
0.0000 --- loss: 1.947116, loss_ss: 1.428910, loss_d: 0.518205
0.1610 --- loss: 1.782764, loss_ss: 1.172865, loss_d: 0.609899
0.3221 --- loss: 1.726510, loss_ss: 1.204757, loss_d: 0.521752
0.4831 --- loss: 1.758604, loss_ss: 1.300762, loss_d: 0.457841
0.6441 --- loss: 1.699405, loss_ss: 1.159149, loss_d: 0.540256
0.8052 --- loss: 1.583268, loss_ss: 1.106505, loss_d: 0.476762
0.9662 --- loss: 1.883503, loss_ss: 1.134485, loss_d: 0.749018
Epoch finished! Loss: 1.7659630064041383
Starting epoch 3/10.
0.0000 --- loss: 1.535992, loss_ss: 1.126622, loss_d: 0.409370
0.1610 --- loss: 1.320611, loss_ss: 1.168863, loss_d: 0.151748
0.3221 --- loss: 1.412558, loss_ss: 1.089280, loss_d: 0.323278
0.4831 --- loss: 1.632749, loss_ss: 1.097262, loss_d: 0.535487
0.6441 --- loss: 1.249962, loss_ss: 1.121698, loss_d: 0.128265
0.8052 --- loss: 1.441046, loss_ss: 1.249617, loss_d: 0.191429
0.9662 --- loss: 1.343223, loss_ss: 1.069465, loss_d: 0.273758
Epoch finished! Loss: 1.452731938131394
Starting epoch 4/10.
0.0000 --- loss: 1.283793, loss_ss: 1.206370, loss_d: 0.077423
0.1610 --- loss: 1.075955, loss_ss: 0.955701, loss_d: 0.120254
0.3221 --- loss: 1.244656, loss_ss: 1.089609, loss_d: 0.155048
0.4831 --- loss: 1.049993, loss_ss: 0.986650, loss_d: 0.063343
0.6441 --- loss: 0.965326, loss_ss: 0.881824, loss_d: 0.083503
0.8052 --- loss: 1.281831, loss_ss: 1.132384, loss_d: 0.149447
0.9662 --- loss: 1.271714, loss_ss: 1.145798, loss_d: 0.125917
Epoch finished! Loss: 1.283517490471563
Starting epoch 5/10.
0.0000 --- loss: 1.003270, loss_ss: 0.972982, loss_d: 0.030287
0.1610 --- loss: 1.093656, loss_ss: 0.975104, loss_d: 0.118552
0.3221 --- loss: 1.146769, loss_ss: 1.061871, loss_d: 0.084898
0.4831 --- loss: 1.165979, loss_ss: 1.074715, loss_d: 0.091264
0.6441 --- loss: 1.028482, loss_ss: 0.980393, loss_d: 0.048089
0.8052 --- loss: 1.035608, loss_ss: 1.027012, loss_d: 0.008596
0.9662 --- loss: 1.118212, loss_ss: 1.109064, loss_d: 0.009149
Epoch finished! Loss: 1.1581230519279357
Starting epoch 6/10.
0.0000 --- loss: 0.967654, loss_ss: 0.949268, loss_d: 0.018386
0.1610 --- loss: 1.096650, loss_ss: 1.080398, loss_d: 0.016252
0.3221 --- loss: 0.980665, loss_ss: 0.934378, loss_d: 0.046287
0.4831 --- loss: 1.179304, loss_ss: 0.957295, loss_d: 0.222009
0.6441 --- loss: 0.922428, loss_ss: 0.914027, loss_d: 0.008401
0.8052 --- loss: 0.919869, loss_ss: 0.916131, loss_d: 0.003738
0.9662 --- loss: 1.108269, loss_ss: 1.103238, loss_d: 0.005031
Epoch finished! Loss: 1.1058520482432457
Starting epoch 7/10.
0.0000 --- loss: 1.014966, loss_ss: 0.990951, loss_d: 0.024015
0.1610 --- loss: 1.004341, loss_ss: 0.987272, loss_d: 0.017069
0.3221 --- loss: 0.918604, loss_ss: 0.910637, loss_d: 0.007967
0.4831 --- loss: 1.065334, loss_ss: 1.056833, loss_d: 0.008501
0.6441 --- loss: 0.872401, loss_ss: 0.851465, loss_d: 0.020936
0.8052 --- loss: 0.864220, loss_ss: 0.857767, loss_d: 0.006453
0.9662 --- loss: 0.944273, loss_ss: 0.939289, loss_d: 0.004983
Epoch finished! Loss: 1.0429750786673637
Starting epoch 8/10.
0.0000 --- loss: 1.043742, loss_ss: 1.041023, loss_d: 0.002718
0.1610 --- loss: 1.234654, loss_ss: 1.226794, loss_d: 0.007859
0.3221 --- loss: 1.050120, loss_ss: 1.039093, loss_d: 0.011027
0.4831 --- loss: 1.172752, loss_ss: 0.999773, loss_d: 0.172980
0.6441 --- loss: 1.008869, loss_ss: 0.973483, loss_d: 0.035386
0.8052 --- loss: 1.006974, loss_ss: 0.757003, loss_d: 0.249970
0.9662 --- loss: 0.941471, loss_ss: 0.938750, loss_d: 0.002721
Epoch finished! Loss: 1.0147299583881133
Starting epoch 9/10.
0.0000 --- loss: 0.887212, loss_ss: 0.877201, loss_d: 0.010011
0.1610 --- loss: 1.010481, loss_ss: 0.999584, loss_d: 0.010896
0.3221 --- loss: 1.021832, loss_ss: 1.020386, loss_d: 0.001446
0.4831 --- loss: 0.867959, loss_ss: 0.858888, loss_d: 0.009071
0.6441 --- loss: 0.855109, loss_ss: 0.839974, loss_d: 0.015135
0.8052 --- loss: 0.939508, loss_ss: 0.919087, loss_d: 0.020420
0.9662 --- loss: 1.021702, loss_ss: 0.971510, loss_d: 0.050192
Epoch finished! Loss: 0.9967743840909773
Starting epoch 10/10.
0.0000 --- loss: 0.871994, loss_ss: 0.871640, loss_d: 0.000354
0.1610 --- loss: 1.231561, loss_ss: 1.126581, loss_d: 0.104980
0.3221 --- loss: 1.199642, loss_ss: 0.869504, loss_d: 0.330138
0.4831 --- loss: 1.035405, loss_ss: 1.002783, loss_d: 0.032622
0.6441 --- loss: 0.988971, loss_ss: 0.921152, loss_d: 0.067819
0.8052 --- loss: 1.032844, loss_ss: 1.018207, loss_d: 0.014637
0.9662 --- loss: 0.983436, loss_ss: 0.972855, loss_d: 0.010581
Epoch finished! Loss: 1.1271267975530317
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6851851851851852
             precision    recall  f1-score   support

        0.0       0.42      0.14      0.21        78
        1.0       0.52      0.64      0.57       284
        2.0       0.80      0.83      0.82       258
        3.0       0.97      0.93      0.95       185
        4.0       0.62      0.59      0.60       275

avg / total       0.68      0.69      0.68      1080
 


====== chp056-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  92.41  14.10   98.50  42.31     21.15
1  75.00  64.08   78.89  52.00     57.41
2  91.11  82.95   93.67  80.45     81.68
3  98.24  92.97   99.33  96.63     94.77
4  80.28  58.55   87.70  61.92     60.19
Total accuracy: 68.52%
Average sen: 62.53%
Average spec: 91.62%
Macro f1-score: 63.04%
Diagnosis acc on 60mins: 1.0
[0.98494613 0.99999642 0.9999994  0.99999595 0.99999571 0.99997532
 0.99997759 0.9999994  0.99997938]
pred: 0.9983183675342135, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp056-nsrr

=== Test on chp057-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.469206, loss_ss: 1.749208, loss_d: 0.719998
0.1610 --- loss: 2.010883, loss_ss: 1.528918, loss_d: 0.481965
0.3221 --- loss: 1.991992, loss_ss: 1.472517, loss_d: 0.519476
0.4831 --- loss: 2.088632, loss_ss: 1.418554, loss_d: 0.670078
0.6441 --- loss: 1.831813, loss_ss: 1.326877, loss_d: 0.504936
0.8052 --- loss: 1.713153, loss_ss: 1.288305, loss_d: 0.424848
0.9662 --- loss: 1.739158, loss_ss: 1.229929, loss_d: 0.509229
Epoch finished! Loss: 2.070459367767457
Starting epoch 2/10.
0.0000 --- loss: 1.688745, loss_ss: 1.284139, loss_d: 0.404606
0.1610 --- loss: 1.881227, loss_ss: 1.301006, loss_d: 0.580221
0.3221 --- loss: 1.675824, loss_ss: 1.287882, loss_d: 0.387942
0.4831 --- loss: 1.649190, loss_ss: 1.251588, loss_d: 0.397602
0.6441 --- loss: 1.716199, loss_ss: 1.370634, loss_d: 0.345565
0.8052 --- loss: 1.732032, loss_ss: 1.170745, loss_d: 0.561287
0.9662 --- loss: 1.478989, loss_ss: 1.199506, loss_d: 0.279483
Epoch finished! Loss: 1.7774313399868626
Starting epoch 3/10.
0.0000 --- loss: 1.433262, loss_ss: 1.135076, loss_d: 0.298186
0.1610 --- loss: 1.386061, loss_ss: 1.158687, loss_d: 0.227374
0.3221 --- loss: 1.444073, loss_ss: 1.065546, loss_d: 0.378528
0.4831 --- loss: 1.174636, loss_ss: 1.007643, loss_d: 0.166993
0.6441 --- loss: 1.315692, loss_ss: 1.117703, loss_d: 0.197989
0.8052 --- loss: 1.395509, loss_ss: 1.081501, loss_d: 0.314009
0.9662 --- loss: 1.187642, loss_ss: 1.084601, loss_d: 0.103041
Epoch finished! Loss: 1.4525170172414472
Starting epoch 4/10.
0.0000 --- loss: 1.255639, loss_ss: 1.088865, loss_d: 0.166774
0.1610 --- loss: 1.066715, loss_ss: 1.033517, loss_d: 0.033198
0.3221 --- loss: 1.027174, loss_ss: 0.982458, loss_d: 0.044716
0.4831 --- loss: 1.128983, loss_ss: 1.105536, loss_d: 0.023447
0.6441 --- loss: 1.016581, loss_ss: 0.969757, loss_d: 0.046824
0.8052 --- loss: 1.010176, loss_ss: 0.972628, loss_d: 0.037548
0.9662 --- loss: 1.227365, loss_ss: 1.151019, loss_d: 0.076346
Epoch finished! Loss: 1.1842285625396236
Starting epoch 5/10.
0.0000 --- loss: 1.080865, loss_ss: 1.079232, loss_d: 0.001632
0.1610 --- loss: 1.131488, loss_ss: 1.062198, loss_d: 0.069291
0.3221 --- loss: 1.507714, loss_ss: 0.967936, loss_d: 0.539778
0.4831 --- loss: 0.988996, loss_ss: 0.963627, loss_d: 0.025370
0.6441 --- loss: 1.104113, loss_ss: 1.045363, loss_d: 0.058750
0.8052 --- loss: 1.101505, loss_ss: 1.075997, loss_d: 0.025508
0.9662 --- loss: 1.017294, loss_ss: 1.008101, loss_d: 0.009193
Epoch finished! Loss: 1.1357308818447975
Starting epoch 6/10.
0.0000 --- loss: 1.048806, loss_ss: 0.872610, loss_d: 0.176196
0.1610 --- loss: 0.978644, loss_ss: 0.923223, loss_d: 0.055422
0.3221 --- loss: 1.028365, loss_ss: 1.019036, loss_d: 0.009329
0.4831 --- loss: 1.306224, loss_ss: 1.173682, loss_d: 0.132543
0.6441 --- loss: 1.131188, loss_ss: 1.058643, loss_d: 0.072545
0.8052 --- loss: 1.003091, loss_ss: 0.992180, loss_d: 0.010910
0.9662 --- loss: 1.107032, loss_ss: 0.963064, loss_d: 0.143967
Epoch finished! Loss: 1.1524631948240343
Starting epoch 7/10.
0.0000 --- loss: 0.858949, loss_ss: 0.842221, loss_d: 0.016728
0.1610 --- loss: 0.828479, loss_ss: 0.811205, loss_d: 0.017274
0.3221 --- loss: 1.031850, loss_ss: 1.009611, loss_d: 0.022239
0.4831 --- loss: 0.990720, loss_ss: 0.987604, loss_d: 0.003116
0.6441 --- loss: 1.192973, loss_ss: 1.086338, loss_d: 0.106635
0.8052 --- loss: 0.970058, loss_ss: 0.950501, loss_d: 0.019557
0.9662 --- loss: 1.043193, loss_ss: 1.039341, loss_d: 0.003852
Epoch finished! Loss: 1.0727734315779902
Starting epoch 8/10.
0.0000 --- loss: 0.942522, loss_ss: 0.901279, loss_d: 0.041242
0.1610 --- loss: 0.938782, loss_ss: 0.927231, loss_d: 0.011551
0.3221 --- loss: 0.891564, loss_ss: 0.880005, loss_d: 0.011559
0.4831 --- loss: 0.855354, loss_ss: 0.852489, loss_d: 0.002865
0.6441 --- loss: 1.205407, loss_ss: 1.205035, loss_d: 0.000372
0.8052 --- loss: 0.820244, loss_ss: 0.794289, loss_d: 0.025955
0.9662 --- loss: 0.881261, loss_ss: 0.875906, loss_d: 0.005354
Epoch finished! Loss: 0.9862050779404179
Starting epoch 9/10.
0.0000 --- loss: 0.826036, loss_ss: 0.783678, loss_d: 0.042358
0.1610 --- loss: 0.903922, loss_ss: 0.872485, loss_d: 0.031437
0.3221 --- loss: 0.810710, loss_ss: 0.743287, loss_d: 0.067422
0.4831 --- loss: 0.925289, loss_ss: 0.922541, loss_d: 0.002747
0.6441 --- loss: 1.182920, loss_ss: 1.180903, loss_d: 0.002017
0.8052 --- loss: 0.849986, loss_ss: 0.845125, loss_d: 0.004861
0.9662 --- loss: 0.839165, loss_ss: 0.837239, loss_d: 0.001926
Epoch finished! Loss: 0.9509238543048981
Starting epoch 10/10.
0.0000 --- loss: 0.725465, loss_ss: 0.725261, loss_d: 0.000204
0.1610 --- loss: 1.020825, loss_ss: 1.020294, loss_d: 0.000531
0.3221 --- loss: 0.779489, loss_ss: 0.765372, loss_d: 0.014116
0.4831 --- loss: 0.964208, loss_ss: 0.963311, loss_d: 0.000897
0.6441 --- loss: 0.778995, loss_ss: 0.778165, loss_d: 0.000830
0.8052 --- loss: 0.753388, loss_ss: 0.753289, loss_d: 0.000099
0.9662 --- loss: 0.868357, loss_ss: 0.866032, loss_d: 0.002325
Epoch finished! Loss: 0.9114791097179535
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7099165894346617
             precision    recall  f1-score   support

        0.0       0.60      0.90      0.72       260
        1.0       0.00      0.00      0.00       142
        2.0       0.77      0.95      0.85       423
        3.0       0.97      0.38      0.54        74
        4.0       0.76      0.57      0.65       180

avg / total       0.64      0.71      0.65      1079
 


====== chp057-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  82.95  90.00   80.71  59.69     71.78
1  86.84   0.00  100.00   0.00      0.00
2  86.75  94.80   81.55  76.82     84.87
3  95.64  37.84   99.90  96.55     54.37
4  89.81  57.22   96.33  75.74     65.19
Total accuracy: 70.99%
Average sen: 55.97%
Average spec: 91.70%
Macro f1-score: 55.24%
Diagnosis acc on 60mins: 1.0
[1.         0.99999189 0.99965894 0.99999988 0.99996006 0.99981636
 0.99994195 0.9999572  0.99998641]
pred: 0.9999236332045661, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp057-nsrr

=== Test on chp058-nsrr. train_data(622), test_data(8) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.535376, loss_ss: 1.807400, loss_d: 0.727976
0.1608 --- loss: 2.068686, loss_ss: 1.598542, loss_d: 0.470144
0.3215 --- loss: 2.227974, loss_ss: 1.669300, loss_d: 0.558674
0.4823 --- loss: 2.361557, loss_ss: 1.585790, loss_d: 0.775767
0.6431 --- loss: 2.302450, loss_ss: 1.579528, loss_d: 0.722922
0.8039 --- loss: 2.134850, loss_ss: 1.592489, loss_d: 0.542361
0.9646 --- loss: 2.078500, loss_ss: 1.482426, loss_d: 0.596074
Epoch finished! Loss: 2.3193702928481565
Starting epoch 2/10.
0.0000 --- loss: 2.264552, loss_ss: 1.547759, loss_d: 0.716793
0.1608 --- loss: 2.131034, loss_ss: 1.589906, loss_d: 0.541128
0.3215 --- loss: 2.105207, loss_ss: 1.468538, loss_d: 0.636669
0.4823 --- loss: 1.849901, loss_ss: 1.452880, loss_d: 0.397020
0.6431 --- loss: 1.604293, loss_ss: 1.349558, loss_d: 0.254734
0.8039 --- loss: 1.521297, loss_ss: 1.325609, loss_d: 0.195688
0.9646 --- loss: 1.818068, loss_ss: 1.363730, loss_d: 0.454338
Epoch finished! Loss: 1.9099830177522474
Starting epoch 3/10.
0.0000 --- loss: 1.452371, loss_ss: 1.302235, loss_d: 0.150135
0.1608 --- loss: 1.461859, loss_ss: 1.330458, loss_d: 0.131401
0.3215 --- loss: 1.796305, loss_ss: 1.321645, loss_d: 0.474660
0.4823 --- loss: 1.564935, loss_ss: 1.452612, loss_d: 0.112323
0.6431 --- loss: 1.531072, loss_ss: 1.238159, loss_d: 0.292912
0.8039 --- loss: 1.366647, loss_ss: 1.270962, loss_d: 0.095685
0.9646 --- loss: 1.472011, loss_ss: 1.220931, loss_d: 0.251080
Epoch finished! Loss: 1.606643178770619
Starting epoch 4/10.
0.0000 --- loss: 1.452866, loss_ss: 1.216902, loss_d: 0.235963
0.1608 --- loss: 1.333342, loss_ss: 1.275114, loss_d: 0.058228
0.3215 --- loss: 1.272257, loss_ss: 1.197628, loss_d: 0.074629
0.4823 --- loss: 1.287256, loss_ss: 1.182022, loss_d: 0.105234
0.6431 --- loss: 1.497673, loss_ss: 1.108286, loss_d: 0.389388
0.8039 --- loss: 1.448873, loss_ss: 1.221459, loss_d: 0.227413
0.9646 --- loss: 1.379470, loss_ss: 1.172530, loss_d: 0.206940
Epoch finished! Loss: 1.3761851249202606
Starting epoch 5/10.
0.0000 --- loss: 2.100677, loss_ss: 1.066925, loss_d: 1.033752
0.1608 --- loss: 1.433170, loss_ss: 1.251351, loss_d: 0.181819
0.3215 --- loss: 1.207698, loss_ss: 1.124306, loss_d: 0.083392
0.4823 --- loss: 1.571871, loss_ss: 1.200121, loss_d: 0.371750
0.6431 --- loss: 1.115265, loss_ss: 1.075261, loss_d: 0.040004
0.8039 --- loss: 1.026608, loss_ss: 1.008458, loss_d: 0.018150
0.9646 --- loss: 1.166965, loss_ss: 1.130394, loss_d: 0.036571
Epoch finished! Loss: 1.2930947926736647
Starting epoch 6/10.
0.0000 --- loss: 1.084465, loss_ss: 1.063563, loss_d: 0.020902
0.1608 --- loss: 1.198685, loss_ss: 1.131424, loss_d: 0.067261
0.3215 --- loss: 1.149472, loss_ss: 1.036073, loss_d: 0.113399
0.4823 --- loss: 1.126611, loss_ss: 1.025014, loss_d: 0.101596
0.6431 --- loss: 1.057291, loss_ss: 1.039551, loss_d: 0.017741
0.8039 --- loss: 1.179576, loss_ss: 1.020604, loss_d: 0.158972
0.9646 --- loss: 0.990384, loss_ss: 0.947998, loss_d: 0.042386
Epoch finished! Loss: 1.138514248594161
Starting epoch 7/10.
0.0000 --- loss: 0.990601, loss_ss: 0.987775, loss_d: 0.002825
0.1608 --- loss: 1.075369, loss_ss: 1.060716, loss_d: 0.014653
0.3215 --- loss: 0.970494, loss_ss: 0.967803, loss_d: 0.002691
0.4823 --- loss: 0.888468, loss_ss: 0.877240, loss_d: 0.011228
0.6431 --- loss: 0.961189, loss_ss: 0.958641, loss_d: 0.002548
0.8039 --- loss: 0.940245, loss_ss: 0.902337, loss_d: 0.037908
0.9646 --- loss: 0.934609, loss_ss: 0.907939, loss_d: 0.026671
Epoch finished! Loss: 1.0031522185571733
Starting epoch 8/10.
0.0000 --- loss: 0.876596, loss_ss: 0.842442, loss_d: 0.034153
0.1608 --- loss: 0.951780, loss_ss: 0.911263, loss_d: 0.040517
0.3215 --- loss: 0.945430, loss_ss: 0.943207, loss_d: 0.002223
0.4823 --- loss: 0.973789, loss_ss: 0.963520, loss_d: 0.010269
0.6431 --- loss: 0.869151, loss_ss: 0.851626, loss_d: 0.017524
0.8039 --- loss: 1.078082, loss_ss: 1.075861, loss_d: 0.002220
0.9646 --- loss: 0.857131, loss_ss: 0.854643, loss_d: 0.002488
Epoch finished! Loss: 0.975825104021257
Starting epoch 9/10.
0.0000 --- loss: 1.035415, loss_ss: 1.024983, loss_d: 0.010432
0.1608 --- loss: 0.780028, loss_ss: 0.779871, loss_d: 0.000157
0.3215 --- loss: 0.884565, loss_ss: 0.880179, loss_d: 0.004386
0.4823 --- loss: 0.920926, loss_ss: 0.912274, loss_d: 0.008652
0.6431 --- loss: 1.175654, loss_ss: 1.115220, loss_d: 0.060433
0.8039 --- loss: 0.917298, loss_ss: 0.843120, loss_d: 0.074178
0.9646 --- loss: 0.900971, loss_ss: 0.808052, loss_d: 0.092920
Epoch finished! Loss: 0.981389477368324
Starting epoch 10/10.
0.0000 --- loss: 0.838454, loss_ss: 0.833294, loss_d: 0.005160
0.1608 --- loss: 0.972450, loss_ss: 0.918857, loss_d: 0.053593
0.3215 --- loss: 1.382599, loss_ss: 1.031952, loss_d: 0.350648
0.4823 --- loss: 1.041305, loss_ss: 0.926640, loss_d: 0.114666
0.6431 --- loss: 0.947648, loss_ss: 0.923893, loss_d: 0.023755
0.8039 --- loss: 0.864341, loss_ss: 0.862368, loss_d: 0.001973
0.9646 --- loss: 0.894032, loss_ss: 0.884324, loss_d: 0.009708
Epoch finished! Loss: 0.9690806634964482
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5958333333333333
             precision    recall  f1-score   support

        0.0       0.86      0.67      0.75       105
        1.0       0.16      0.70      0.26        44
        2.0       0.55      0.70      0.62       290
        3.0       1.00      0.34      0.50       228
        4.0       0.80      0.65      0.72       293

avg / total       0.75      0.60      0.62       960
 


====== chp058-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  95.21  66.67   98.71   86.42     75.27
1  81.46  70.45   81.99   15.82     25.83
2  73.85  70.34   75.37   55.28     61.91
3  84.27  33.77  100.00  100.00     50.49
4  84.38  64.85   92.95   80.17     71.70
Total accuracy: 59.58%
Average sen: 61.22%
Average spec: 89.81%
Macro f1-score: 57.04%
Diagnosis acc on 60mins: 1.0
[0.99994588 0.99507636 0.99991369 0.99974889 0.9954384  0.99983883
 0.99998343 0.98993123]
pred: 0.9974845871329308, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp058-nsrr

=== Test on chp059-nsrr. train_data(621), test_data(9) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.321434, loss_ss: 1.682524, loss_d: 0.638910
0.1610 --- loss: 2.327863, loss_ss: 1.468299, loss_d: 0.859564
0.3221 --- loss: 1.897383, loss_ss: 1.394413, loss_d: 0.502969
0.4831 --- loss: 2.026589, loss_ss: 1.401660, loss_d: 0.624929
0.6441 --- loss: 2.023392, loss_ss: 1.348444, loss_d: 0.674947
0.8052 --- loss: 1.947092, loss_ss: 1.454896, loss_d: 0.492196
0.9662 --- loss: 1.772189, loss_ss: 1.348371, loss_d: 0.423818
Epoch finished! Loss: 2.074144467230766
Starting epoch 2/10.
0.0000 --- loss: 1.749217, loss_ss: 1.314624, loss_d: 0.434593
0.1610 --- loss: 1.729695, loss_ss: 1.307323, loss_d: 0.422372
0.3221 --- loss: 1.716243, loss_ss: 1.239329, loss_d: 0.476914
0.4831 --- loss: 1.618927, loss_ss: 1.350328, loss_d: 0.268598
0.6441 --- loss: 1.613243, loss_ss: 1.212264, loss_d: 0.400979
0.8052 --- loss: 1.949415, loss_ss: 1.266170, loss_d: 0.683245
0.9662 --- loss: 2.121880, loss_ss: 1.293726, loss_d: 0.828154
Epoch finished! Loss: 1.8172783390168221
Starting epoch 3/10.
0.0000 --- loss: 1.824323, loss_ss: 1.382762, loss_d: 0.441561
0.1610 --- loss: 1.755991, loss_ss: 1.408560, loss_d: 0.347432
0.3221 --- loss: 1.514127, loss_ss: 1.275243, loss_d: 0.238884
0.4831 --- loss: 1.440606, loss_ss: 1.194196, loss_d: 0.246410
0.6441 --- loss: 1.390213, loss_ss: 1.187201, loss_d: 0.203012
0.8052 --- loss: 1.787222, loss_ss: 1.040728, loss_d: 0.746494
0.9662 --- loss: 1.450561, loss_ss: 1.091304, loss_d: 0.359257
Epoch finished! Loss: 1.6428994594081756
Starting epoch 4/10.
0.0000 --- loss: 1.473373, loss_ss: 1.230888, loss_d: 0.242485
0.1610 --- loss: 1.498505, loss_ss: 1.360730, loss_d: 0.137775
0.3221 --- loss: 1.443448, loss_ss: 1.159182, loss_d: 0.284266
0.4831 --- loss: 1.280396, loss_ss: 1.124773, loss_d: 0.155623
0.6441 --- loss: 1.260669, loss_ss: 1.131270, loss_d: 0.129398
0.8052 --- loss: 1.099571, loss_ss: 1.001022, loss_d: 0.098549
0.9662 --- loss: 1.393894, loss_ss: 1.055696, loss_d: 0.338198
Epoch finished! Loss: 1.3802252681024614
Starting epoch 5/10.
0.0000 --- loss: 1.120983, loss_ss: 1.088652, loss_d: 0.032331
0.1610 --- loss: 1.086884, loss_ss: 0.991401, loss_d: 0.095483
0.3221 --- loss: 1.235448, loss_ss: 1.124962, loss_d: 0.110486
0.4831 --- loss: 1.045020, loss_ss: 0.971415, loss_d: 0.073606
0.6441 --- loss: 1.054583, loss_ss: 0.950532, loss_d: 0.104052
0.8052 --- loss: 1.122427, loss_ss: 1.106228, loss_d: 0.016199
0.9662 --- loss: 1.085807, loss_ss: 1.055369, loss_d: 0.030438
Epoch finished! Loss: 1.204548542537997
Starting epoch 6/10.
0.0000 --- loss: 1.372109, loss_ss: 1.128128, loss_d: 0.243981
0.1610 --- loss: 1.046558, loss_ss: 1.042001, loss_d: 0.004557
0.3221 --- loss: 0.986733, loss_ss: 0.940132, loss_d: 0.046600
0.4831 --- loss: 1.078675, loss_ss: 1.018987, loss_d: 0.059689
0.6441 --- loss: 1.086234, loss_ss: 1.063320, loss_d: 0.022914
0.8052 --- loss: 1.055943, loss_ss: 0.993276, loss_d: 0.062667
0.9662 --- loss: 1.112102, loss_ss: 1.049808, loss_d: 0.062294
Epoch finished! Loss: 1.1157209709767373
Starting epoch 7/10.
0.0000 --- loss: 1.098453, loss_ss: 0.995066, loss_d: 0.103387
0.1610 --- loss: 1.019109, loss_ss: 0.953546, loss_d: 0.065563
0.3221 --- loss: 0.987963, loss_ss: 0.982362, loss_d: 0.005601
0.4831 --- loss: 0.966671, loss_ss: 0.961263, loss_d: 0.005408
0.6441 --- loss: 1.206265, loss_ss: 1.191027, loss_d: 0.015238
0.8052 --- loss: 1.112656, loss_ss: 1.104249, loss_d: 0.008406
0.9662 --- loss: 1.032019, loss_ss: 1.028577, loss_d: 0.003442
Epoch finished! Loss: 1.0316863732953225
Starting epoch 8/10.
0.0000 --- loss: 1.006785, loss_ss: 0.980306, loss_d: 0.026479
0.1610 --- loss: 0.868423, loss_ss: 0.864388, loss_d: 0.004035
0.3221 --- loss: 0.810767, loss_ss: 0.806244, loss_d: 0.004523
0.4831 --- loss: 1.048104, loss_ss: 1.047043, loss_d: 0.001060
0.6441 --- loss: 1.146843, loss_ss: 1.145402, loss_d: 0.001441
0.8052 --- loss: 0.975179, loss_ss: 0.820053, loss_d: 0.155126
0.9662 --- loss: 1.033253, loss_ss: 1.032758, loss_d: 0.000495
Epoch finished! Loss: 1.090671431633734
Starting epoch 9/10.
0.0000 --- loss: 0.939253, loss_ss: 0.882157, loss_d: 0.057096
0.1610 --- loss: 1.296466, loss_ss: 0.901645, loss_d: 0.394820
0.3221 --- loss: 0.997343, loss_ss: 0.893181, loss_d: 0.104162
0.4831 --- loss: 0.988717, loss_ss: 0.946317, loss_d: 0.042400
0.6441 --- loss: 1.309398, loss_ss: 1.244568, loss_d: 0.064830
0.8052 --- loss: 1.122613, loss_ss: 0.988244, loss_d: 0.134369
0.9662 --- loss: 1.135746, loss_ss: 0.880356, loss_d: 0.255390
Epoch finished! Loss: 1.1737421933681733
Starting epoch 10/10.
0.0000 --- loss: 1.043423, loss_ss: 1.022452, loss_d: 0.020971
0.1610 --- loss: 1.124166, loss_ss: 1.114916, loss_d: 0.009250
0.3221 --- loss: 1.152788, loss_ss: 0.985936, loss_d: 0.166852
0.4831 --- loss: 0.912695, loss_ss: 0.901978, loss_d: 0.010717
0.6441 --- loss: 0.941038, loss_ss: 0.909190, loss_d: 0.031849
0.8052 --- loss: 0.964873, loss_ss: 0.959564, loss_d: 0.005309
0.9662 --- loss: 0.897934, loss_ss: 0.887775, loss_d: 0.010159
Epoch finished! Loss: 1.006937095234471
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5361111111111111
             precision    recall  f1-score   support

        0.0       0.89      0.17      0.29       233
        1.0       0.43      0.85      0.57       238
        2.0       0.84      0.54      0.66       355
        3.0       0.76      0.68      0.72        87
        4.0       0.34      0.51      0.41       167

avg / total       0.68      0.54      0.52      1080
 


====== chp059-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  81.67  17.17   99.41  88.89     28.78
1  71.48  84.87   67.70  42.62     56.74
2  81.57  54.08   95.03  84.21     65.87
3  95.65  67.82   98.09  75.64     71.52
4  76.85  51.50   81.49  33.73     40.76
Total accuracy: 53.61%
Average sen: 55.09%
Average spec: 88.34%
Macro f1-score: 52.73%
Diagnosis acc on 60mins: 1.0
[0.99992514 0.99992907 0.99997282 0.99995732 0.99999285 0.99988079
 0.99993956 0.99998307 0.99953532]
pred: 0.9999017715454102, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp059-nsrr

=== Test on chp060-nsrr. train_data(620), test_data(10) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.380941, loss_ss: 1.650280, loss_d: 0.730661
0.1613 --- loss: 2.125414, loss_ss: 1.485708, loss_d: 0.639706
0.3226 --- loss: 2.025449, loss_ss: 1.493126, loss_d: 0.532322
0.4839 --- loss: 2.050717, loss_ss: 1.390751, loss_d: 0.659966
0.6452 --- loss: 1.785903, loss_ss: 1.349164, loss_d: 0.436739
0.8065 --- loss: 2.092323, loss_ss: 1.321741, loss_d: 0.770582
0.9677 --- loss: 1.812929, loss_ss: 1.326415, loss_d: 0.486514
Epoch finished! Loss: 2.085357247805986
Starting epoch 2/10.
0.0000 --- loss: 1.900005, loss_ss: 1.368669, loss_d: 0.531336
0.1613 --- loss: 1.889817, loss_ss: 1.334424, loss_d: 0.555393
0.3226 --- loss: 1.590566, loss_ss: 1.255043, loss_d: 0.335523
0.4839 --- loss: 1.712113, loss_ss: 1.221786, loss_d: 0.490327
0.6452 --- loss: 1.897316, loss_ss: 1.293726, loss_d: 0.603590
0.8065 --- loss: 1.903732, loss_ss: 1.169330, loss_d: 0.734402
0.9677 --- loss: 1.578533, loss_ss: 1.307716, loss_d: 0.270817
Epoch finished! Loss: 1.8181365357070673
Starting epoch 3/10.
0.0000 --- loss: 1.532377, loss_ss: 1.284873, loss_d: 0.247504
0.1613 --- loss: 1.406231, loss_ss: 1.229061, loss_d: 0.177170
0.3226 --- loss: 1.594916, loss_ss: 1.127063, loss_d: 0.467853
0.4839 --- loss: 1.583307, loss_ss: 1.203570, loss_d: 0.379737
0.6452 --- loss: 1.662344, loss_ss: 1.223825, loss_d: 0.438520
0.8065 --- loss: 1.315651, loss_ss: 1.093958, loss_d: 0.221693
0.9677 --- loss: 1.432639, loss_ss: 1.024411, loss_d: 0.408228
Epoch finished! Loss: 1.5769798306168104
Starting epoch 4/10.
0.0000 --- loss: 1.273940, loss_ss: 1.186273, loss_d: 0.087666
0.1613 --- loss: 1.367276, loss_ss: 1.165948, loss_d: 0.201328
0.3226 --- loss: 1.288626, loss_ss: 1.185375, loss_d: 0.103251
0.4839 --- loss: 1.322639, loss_ss: 1.028493, loss_d: 0.294145
0.6452 --- loss: 1.363956, loss_ss: 1.200407, loss_d: 0.163549
0.8065 --- loss: 1.335809, loss_ss: 1.199211, loss_d: 0.136598
0.9677 --- loss: 1.190159, loss_ss: 1.156925, loss_d: 0.033234
Epoch finished! Loss: 1.2909490065496476
Starting epoch 5/10.
0.0000 --- loss: 1.155266, loss_ss: 1.127489, loss_d: 0.027777
0.1613 --- loss: 1.287522, loss_ss: 1.250606, loss_d: 0.036916
0.3226 --- loss: 1.140857, loss_ss: 1.127639, loss_d: 0.013218
0.4839 --- loss: 1.001993, loss_ss: 0.989137, loss_d: 0.012856
0.6452 --- loss: 0.976867, loss_ss: 0.965030, loss_d: 0.011837
0.8065 --- loss: 0.959897, loss_ss: 0.953606, loss_d: 0.006291
0.9677 --- loss: 0.962658, loss_ss: 0.956147, loss_d: 0.006510
Epoch finished! Loss: 1.1260758267074336
Starting epoch 6/10.
0.0000 --- loss: 1.284251, loss_ss: 1.227335, loss_d: 0.056916
0.1613 --- loss: 1.002172, loss_ss: 0.977932, loss_d: 0.024239
0.3226 --- loss: 1.016208, loss_ss: 0.988455, loss_d: 0.027753
0.4839 --- loss: 0.928211, loss_ss: 0.916446, loss_d: 0.011765
0.6452 --- loss: 1.024668, loss_ss: 1.022306, loss_d: 0.002362
0.8065 --- loss: 0.955177, loss_ss: 0.946694, loss_d: 0.008483
0.9677 --- loss: 1.186822, loss_ss: 1.006271, loss_d: 0.180551
Epoch finished! Loss: 1.0554144226136755
Starting epoch 7/10.
0.0000 --- loss: 0.831437, loss_ss: 0.814337, loss_d: 0.017100
0.1613 --- loss: 1.289817, loss_ss: 0.909709, loss_d: 0.380108
0.3226 --- loss: 0.801996, loss_ss: 0.795893, loss_d: 0.006103
0.4839 --- loss: 0.978189, loss_ss: 0.957358, loss_d: 0.020831
0.6452 --- loss: 1.022949, loss_ss: 1.007769, loss_d: 0.015180
0.8065 --- loss: 0.882163, loss_ss: 0.878118, loss_d: 0.004045
0.9677 --- loss: 0.982418, loss_ss: 0.947065, loss_d: 0.035353
Epoch finished! Loss: 1.0147178710484115
Starting epoch 8/10.
0.0000 --- loss: 0.876391, loss_ss: 0.805461, loss_d: 0.070930
0.1613 --- loss: 0.984614, loss_ss: 0.983552, loss_d: 0.001062
0.3226 --- loss: 0.789589, loss_ss: 0.765003, loss_d: 0.024586
0.4839 --- loss: 0.820293, loss_ss: 0.816089, loss_d: 0.004204
0.6452 --- loss: 1.071275, loss_ss: 1.070391, loss_d: 0.000883
0.8065 --- loss: 1.447958, loss_ss: 1.340027, loss_d: 0.107932
0.9677 --- loss: 0.767829, loss_ss: 0.757531, loss_d: 0.010298
Epoch finished! Loss: 0.976561333312363
Starting epoch 9/10.
0.0000 --- loss: 1.032511, loss_ss: 0.883626, loss_d: 0.148885
0.1613 --- loss: 0.964915, loss_ss: 0.957779, loss_d: 0.007136
0.3226 --- loss: 0.835918, loss_ss: 0.835642, loss_d: 0.000276
0.4839 --- loss: 0.885950, loss_ss: 0.882188, loss_d: 0.003762
0.6452 --- loss: 0.892047, loss_ss: 0.847098, loss_d: 0.044949
0.8065 --- loss: 1.004430, loss_ss: 0.958879, loss_d: 0.045551
0.9677 --- loss: 0.774742, loss_ss: 0.748313, loss_d: 0.026428
Epoch finished! Loss: 1.041386471420038
Starting epoch 10/10.
0.0000 --- loss: 0.884144, loss_ss: 0.880884, loss_d: 0.003260
0.1613 --- loss: 1.027521, loss_ss: 1.010386, loss_d: 0.017135
0.3226 --- loss: 0.880419, loss_ss: 0.869022, loss_d: 0.011397
0.4839 --- loss: 0.841238, loss_ss: 0.832026, loss_d: 0.009212
0.6452 --- loss: 0.659918, loss_ss: 0.656371, loss_d: 0.003547
0.8065 --- loss: 0.813730, loss_ss: 0.808565, loss_d: 0.005166
0.9677 --- loss: 1.467239, loss_ss: 1.413925, loss_d: 0.053314
Epoch finished! Loss: 0.9766796504864927
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.44666666666666666
             precision    recall  f1-score   support

        0.0       0.99      0.29      0.45       478
        1.0       0.35      0.64      0.46       184
        2.0       0.49      0.81      0.61       226
        3.0       1.00      0.04      0.08       158
        4.0       0.26      0.58      0.36       154

avg / total       0.70      0.45      0.42      1200
 


====== chp060-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  71.50  28.87   99.72   98.57     44.66
1  76.58  64.13   78.84   35.44     45.65
2  80.58  81.42   80.39   49.07     61.23
3  87.42   4.43  100.00  100.00      8.48
4  73.25  57.79   75.53   25.80     35.67
Total accuracy: 44.67%
Average sen: 47.33%
Average spec: 86.90%
Macro f1-score: 39.14%
Diagnosis acc on 60mins: 1.0
[0.99999869 0.99994874 0.99994743 0.99990594 0.99999702 0.99999964
 0.99999559 0.99993134 0.99999559 0.9997707 ]
pred: 0.9999490678310394, label: 1
Right! Diagnosis: NT1
Save 60mins of subject chp060-nsrr

====== all ======
   acc %  sen %  spec %  ppr %  f1-score
0  88.55  61.33   92.91  58.06     59.65
1  84.88  18.33   94.51  32.56     23.46
2  78.49  77.64   79.02  69.20     73.18
3  91.08  51.83   99.67  97.17     67.61
4  81.79  72.80   83.74  49.25     58.75
Total accuracy: 62.40%
Average sen: 56.39%
Average spec: 89.97%
Macro f1-score: 56.53%
Diagnosis acc on patients: 0.7435897435897436

====== all ======
   acc %  sen %  spec %  ppr %  f1-score
0  74.36  21.74   96.36  71.43     33.33
1  74.36  96.36   21.74  74.65     84.13
Total accuracy: 74.36%
Average sen: 59.05%
Average spec: 59.05%
Macro f1-score: 58.73%
fpr: 0.0, tpr: 0.01818181818181818, threshold: 0.999999827808804, 
fpr: 0.0, tpr: 0.41818181818181815, threshold: 0.9966115421719022, 
fpr: 0.043478260869565216, tpr: 0.41818181818181815, threshold: 0.9963464566639492, 
fpr: 0.043478260869565216, tpr: 0.4909090909090909, threshold: 0.9936462574534946, 
fpr: 0.08695652173913043, tpr: 0.4909090909090909, threshold: 0.9931816458702087, 
fpr: 0.08695652173913043, tpr: 0.509090909090909, threshold: 0.9929086491465569, 
fpr: 0.13043478260869565, tpr: 0.509090909090909, threshold: 0.9884507656097412, 
fpr: 0.13043478260869565, tpr: 0.6181818181818182, threshold: 0.9801401674747467, 
fpr: 0.17391304347826086, tpr: 0.6181818181818182, threshold: 0.9794245262940725, 
fpr: 0.17391304347826086, tpr: 0.7090909090909091, threshold: 0.9515994588534037, 
fpr: 0.21739130434782608, tpr: 0.7090909090909091, threshold: 0.9506430796214512, 
fpr: 0.21739130434782608, tpr: 0.8, threshold: 0.9139226637780666, 
fpr: 0.2608695652173913, tpr: 0.8, threshold: 0.9072138241359166, 
fpr: 0.2608695652173913, tpr: 0.8363636363636363, threshold: 0.8921798318624496, 
fpr: 0.30434782608695654, tpr: 0.8363636363636363, threshold: 0.8779565649373191, 
fpr: 0.30434782608695654, tpr: 0.8727272727272727, threshold: 0.8749929898315005, 
fpr: 0.43478260869565216, tpr: 0.8727272727272727, threshold: 0.805956800468266, 
fpr: 0.43478260869565216, tpr: 0.8909090909090909, threshold: 0.7997984173707664, 
fpr: 0.5217391304347826, tpr: 0.8909090909090909, threshold: 0.7578618054588636, 
fpr: 0.5217391304347826, tpr: 0.9272727272727272, threshold: 0.6895244137073556, 
fpr: 0.6956521739130435, tpr: 0.9272727272727272, threshold: 0.6303522098543388, 
fpr: 0.6956521739130435, tpr: 0.9454545454545454, threshold: 0.609334004111588, 
fpr: 0.7391304347826086, tpr: 0.9454545454545454, threshold: 0.5992803948465735, 
fpr: 0.7391304347826086, tpr: 0.9636363636363636, threshold: 0.5882982524732748, 
fpr: 0.9130434782608695, tpr: 0.9636363636363636, threshold: 0.3264208535464214, 
fpr: 0.9130434782608695, tpr: 1.0, threshold: 0.2330698045752797, 
fpr: 1.0, tpr: 1.0, threshold: 0.13092689758819429, 

=== best_threshold: 0.9139226637780666, best_fpr: 0.21739130434782608, best_tpr: 0.8 ===
fpr: 0.0, tpr: 0.0, threshold: 2.0, 
fpr: 0.006211180124223602, tpr: 0.046908315565031986, threshold: 1.0, 
fpr: 0.012422360248447204, tpr: 0.07036247334754797, threshold: 0.9999998807907104, 
fpr: 0.012422360248447204, tpr: 0.09168443496801706, threshold: 0.9999997615814209, 
fpr: 0.012422360248447204, tpr: 0.10874200426439233, threshold: 0.9999996423721313, 
fpr: 0.024844720496894408, tpr: 0.1300639658848614, threshold: 0.9999994039535522, 
fpr: 0.024844720496894408, tpr: 0.14712153518123666, threshold: 0.9999991655349731, 
fpr: 0.024844720496894408, tpr: 0.1513859275053305, threshold: 0.9999990463256836, 
fpr: 0.024844720496894408, tpr: 0.15565031982942432, threshold: 0.9999988079071045, 
fpr: 0.024844720496894408, tpr: 0.16631130063965885, threshold: 0.9999986886978149, 
fpr: 0.024844720496894408, tpr: 0.16844349680170576, threshold: 0.9999984502792358, 
fpr: 0.024844720496894408, tpr: 0.17484008528784648, threshold: 0.9999983310699463, 
fpr: 0.024844720496894408, tpr: 0.17697228144989338, threshold: 0.9999982118606567, 
fpr: 0.024844720496894408, tpr: 0.18336886993603413, threshold: 0.9999980926513672, 
fpr: 0.024844720496894408, tpr: 0.18763326226012794, threshold: 0.9999978542327881, 
fpr: 0.031055900621118012, tpr: 0.18763326226012794, threshold: 0.9999974966049194, 
fpr: 0.031055900621118012, tpr: 0.19189765458422176, threshold: 0.9999973773956299, 
fpr: 0.037267080745341616, tpr: 0.19402985074626866, threshold: 0.9999972581863403, 
fpr: 0.037267080745341616, tpr: 0.19616204690831557, threshold: 0.9999970197677612, 
fpr: 0.037267080745341616, tpr: 0.2025586353944563, threshold: 0.9999969005584717, 
fpr: 0.037267080745341616, tpr: 0.2068230277185501, threshold: 0.9999967813491821, 
fpr: 0.037267080745341616, tpr: 0.208955223880597, threshold: 0.9999966621398926, 
fpr: 0.037267080745341616, tpr: 0.21535181236673773, threshold: 0.999996542930603, 
fpr: 0.037267080745341616, tpr: 0.21961620469083157, threshold: 0.9999964237213135, 
fpr: 0.043478260869565216, tpr: 0.21961620469083157, threshold: 0.9999963045120239, 
fpr: 0.043478260869565216, tpr: 0.22174840085287847, threshold: 0.9999959468841553, 
fpr: 0.049689440993788817, tpr: 0.22388059701492538, threshold: 0.9999957084655762, 
fpr: 0.049689440993788817, tpr: 0.23667377398720682, threshold: 0.9999954700469971, 
fpr: 0.049689440993788817, tpr: 0.24093816631130063, threshold: 0.9999951124191284, 
fpr: 0.049689440993788817, tpr: 0.24733475479744135, threshold: 0.9999945163726807, 
fpr: 0.049689440993788817, tpr: 0.255863539445629, threshold: 0.9999934434890747, 
fpr: 0.049689440993788817, tpr: 0.26439232409381663, threshold: 0.999993085861206, 
fpr: 0.049689440993788817, tpr: 0.2771855010660981, threshold: 0.9999909400939941, 
fpr: 0.049689440993788817, tpr: 0.2814498933901919, threshold: 0.9999904632568359, 
fpr: 0.049689440993788817, tpr: 0.2899786780383795, threshold: 0.9999878406524658, 
fpr: 0.049689440993788817, tpr: 0.2942430703624733, threshold: 0.9999874830245972, 
fpr: 0.049689440993788817, tpr: 0.32196162046908317, threshold: 0.9999821186065674, 
fpr: 0.055900621118012424, tpr: 0.32196162046908317, threshold: 0.9999818801879883, 
fpr: 0.055900621118012424, tpr: 0.32409381663113007, threshold: 0.999981164932251, 
fpr: 0.055900621118012424, tpr: 0.3283582089552239, threshold: 0.9999803304672241, 
fpr: 0.055900621118012424, tpr: 0.3411513859275053, threshold: 0.9999784231185913, 
fpr: 0.062111801242236024, tpr: 0.3411513859275053, threshold: 0.9999783039093018, 
fpr: 0.062111801242236024, tpr: 0.3582089552238806, threshold: 0.9999699592590332, 
fpr: 0.07453416149068323, tpr: 0.3603411513859275, threshold: 0.9999688863754272, 
fpr: 0.07453416149068323, tpr: 0.39872068230277186, threshold: 0.9999469518661499, 
fpr: 0.08074534161490683, tpr: 0.39872068230277186, threshold: 0.9999462366104126, 
fpr: 0.08074534161490683, tpr: 0.40085287846481876, threshold: 0.999945878982544, 
fpr: 0.09316770186335403, tpr: 0.40085287846481876, threshold: 0.9999438524246216, 
fpr: 0.09316770186335403, tpr: 0.40298507462686567, threshold: 0.9999433755874634, 
fpr: 0.09316770186335403, tpr: 0.4072494669509595, threshold: 0.9999419450759888, 
fpr: 0.09316770186335403, tpr: 0.4115138592750533, threshold: 0.9999390840530396, 
fpr: 0.09937888198757763, tpr: 0.4136460554371002, threshold: 0.9999388456344604, 
fpr: 0.09937888198757763, tpr: 0.4157782515991471, threshold: 0.9999387264251709, 
fpr: 0.09937888198757763, tpr: 0.4200426439232409, threshold: 0.9999384880065918, 
fpr: 0.09937888198757763, tpr: 0.4541577825159915, threshold: 0.9999065399169922, 
fpr: 0.10559006211180125, tpr: 0.4541577825159915, threshold: 0.9999061822891235, 
fpr: 0.10559006211180125, tpr: 0.4562899786780384, threshold: 0.9999059438705444, 
fpr: 0.11180124223602485, tpr: 0.4562899786780384, threshold: 0.9999030828475952, 
fpr: 0.11180124223602485, tpr: 0.4626865671641791, threshold: 0.9999006986618042, 
fpr: 0.12422360248447205, tpr: 0.4626865671641791, threshold: 0.99989914894104, 
fpr: 0.12422360248447205, tpr: 0.4861407249466951, threshold: 0.9998770952224731, 
fpr: 0.13043478260869565, tpr: 0.4861407249466951, threshold: 0.9998759031295776, 
fpr: 0.13043478260869565, tpr: 0.488272921108742, threshold: 0.9998730421066284, 
fpr: 0.14285714285714285, tpr: 0.488272921108742, threshold: 0.9998631477355957, 
fpr: 0.14285714285714285, tpr: 0.4904051172707889, threshold: 0.9998612403869629, 
fpr: 0.14906832298136646, tpr: 0.4904051172707889, threshold: 0.999855637550354, 
fpr: 0.14906832298136646, tpr: 0.5031982942430704, threshold: 0.9998459815979004, 
fpr: 0.14906832298136646, tpr: 0.5074626865671642, threshold: 0.9998418092727661, 
fpr: 0.14906832298136646, tpr: 0.5202558635394456, threshold: 0.9998014569282532, 
fpr: 0.15527950310559005, tpr: 0.5202558635394456, threshold: 0.9997996687889099, 
fpr: 0.15527950310559005, tpr: 0.5266524520255863, threshold: 0.9997953772544861, 
fpr: 0.16149068322981366, tpr: 0.5266524520255863, threshold: 0.9997943043708801, 
fpr: 0.16149068322981366, tpr: 0.5287846481876333, threshold: 0.9997923970222473, 
fpr: 0.16770186335403728, tpr: 0.5287846481876333, threshold: 0.999790370464325, 
fpr: 0.16770186335403728, tpr: 0.5415778251599147, threshold: 0.9997627139091492, 
fpr: 0.17391304347826086, tpr: 0.5415778251599147, threshold: 0.999754011631012, 
fpr: 0.17391304347826086, tpr: 0.5479744136460555, threshold: 0.9997460246086121, 
fpr: 0.18012422360248448, tpr: 0.5479744136460555, threshold: 0.9997449517250061, 
fpr: 0.18012422360248448, tpr: 0.603411513859275, threshold: 0.9994533658027649, 
fpr: 0.18633540372670807, tpr: 0.603411513859275, threshold: 0.9994408488273621, 
fpr: 0.18633540372670807, tpr: 0.6140724946695096, threshold: 0.999359667301178, 
fpr: 0.19875776397515527, tpr: 0.6140724946695096, threshold: 0.9993106126785278, 
fpr: 0.19875776397515527, tpr: 0.6183368869936035, threshold: 0.9992996454238892, 
fpr: 0.2111801242236025, tpr: 0.6183368869936035, threshold: 0.999285876750946, 
fpr: 0.2111801242236025, tpr: 0.6204690831556503, threshold: 0.9992756247520447, 
fpr: 0.21739130434782608, tpr: 0.6204690831556503, threshold: 0.999267041683197, 
fpr: 0.21739130434782608, tpr: 0.6247334754797441, threshold: 0.999240517616272, 
fpr: 0.22981366459627328, tpr: 0.6247334754797441, threshold: 0.999204695224762, 
fpr: 0.22981366459627328, tpr: 0.6417910447761194, threshold: 0.9988487958908081, 
fpr: 0.2360248447204969, tpr: 0.6417910447761194, threshold: 0.9987770915031433, 
fpr: 0.2360248447204969, tpr: 0.6545842217484008, threshold: 0.9984807372093201, 
fpr: 0.2422360248447205, tpr: 0.6545842217484008, threshold: 0.9984418749809265, 
fpr: 0.2422360248447205, tpr: 0.6673773987206824, threshold: 0.9981677532196045, 
fpr: 0.2484472049689441, tpr: 0.6673773987206824, threshold: 0.9981168508529663, 
fpr: 0.2484472049689441, tpr: 0.67590618336887, threshold: 0.997873067855835, 
fpr: 0.2546583850931677, tpr: 0.67590618336887, threshold: 0.9978633522987366, 
fpr: 0.2546583850931677, tpr: 0.6844349680170576, threshold: 0.9976267218589783, 
fpr: 0.2608695652173913, tpr: 0.6844349680170576, threshold: 0.9976077079772949, 
fpr: 0.2608695652173913, tpr: 0.7100213219616205, threshold: 0.9969950914382935, 
fpr: 0.2795031055900621, tpr: 0.7100213219616205, threshold: 0.9968637228012085, 
fpr: 0.2795031055900621, tpr: 0.7185501066098081, threshold: 0.9963498115539551, 
fpr: 0.2919254658385093, tpr: 0.7185501066098081, threshold: 0.9961189031600952, 
fpr: 0.2919254658385093, tpr: 0.7249466950959488, threshold: 0.9956578016281128, 
fpr: 0.2981366459627329, tpr: 0.7249466950959488, threshold: 0.9956300258636475, 
fpr: 0.2981366459627329, tpr: 0.7377398720682303, threshold: 0.9950382113456726, 
fpr: 0.30434782608695654, tpr: 0.7377398720682303, threshold: 0.9950295090675354, 
fpr: 0.30434782608695654, tpr: 0.7420042643923241, threshold: 0.9947350025177002, 
fpr: 0.3105590062111801, tpr: 0.7420042643923241, threshold: 0.9944050312042236, 
fpr: 0.3105590062111801, tpr: 0.744136460554371, threshold: 0.9941026568412781, 
fpr: 0.3167701863354037, tpr: 0.744136460554371, threshold: 0.994012176990509, 
fpr: 0.3167701863354037, tpr: 0.7505330490405118, threshold: 0.9931967258453369, 
fpr: 0.32298136645962733, tpr: 0.7505330490405118, threshold: 0.992662787437439, 
fpr: 0.32298136645962733, tpr: 0.7611940298507462, threshold: 0.9920708537101746, 
fpr: 0.32919254658385094, tpr: 0.7611940298507462, threshold: 0.991982638835907, 
fpr: 0.32919254658385094, tpr: 0.7654584221748401, threshold: 0.9917957186698914, 
fpr: 0.33540372670807456, tpr: 0.7654584221748401, threshold: 0.991643488407135, 
fpr: 0.33540372670807456, tpr: 0.767590618336887, threshold: 0.9916399717330933, 
fpr: 0.3416149068322981, tpr: 0.767590618336887, threshold: 0.9915961623191833, 
fpr: 0.3416149068322981, tpr: 0.7718550106609808, threshold: 0.9914872646331787, 
fpr: 0.36024844720496896, tpr: 0.7718550106609808, threshold: 0.9899954795837402, 
fpr: 0.36024844720496896, tpr: 0.7782515991471215, threshold: 0.989581823348999, 
fpr: 0.36645962732919257, tpr: 0.7782515991471215, threshold: 0.9895213842391968, 
fpr: 0.36645962732919257, tpr: 0.7803837953091685, threshold: 0.9888633489608765, 
fpr: 0.37267080745341613, tpr: 0.7803837953091685, threshold: 0.9882867932319641, 
fpr: 0.37267080745341613, tpr: 0.7825159914712153, threshold: 0.9881269335746765, 
fpr: 0.37888198757763975, tpr: 0.7825159914712153, threshold: 0.9872942566871643, 
fpr: 0.37888198757763975, tpr: 0.7846481876332623, threshold: 0.9870944619178772, 
fpr: 0.38509316770186336, tpr: 0.7846481876332623, threshold: 0.9869056344032288, 
fpr: 0.38509316770186336, tpr: 0.7889125799573561, threshold: 0.9866748452186584, 
fpr: 0.39751552795031053, tpr: 0.7889125799573561, threshold: 0.9858431220054626, 
fpr: 0.39751552795031053, tpr: 0.7931769722814499, threshold: 0.9852964282035828, 
fpr: 0.40372670807453415, tpr: 0.7931769722814499, threshold: 0.9852622151374817, 
fpr: 0.40372670807453415, tpr: 0.8102345415778252, threshold: 0.9844667911529541, 
fpr: 0.40993788819875776, tpr: 0.8102345415778252, threshold: 0.98445063829422, 
fpr: 0.40993788819875776, tpr: 0.8123667377398721, threshold: 0.9840696454048157, 
fpr: 0.4161490683229814, tpr: 0.8123667377398721, threshold: 0.9826552867889404, 
fpr: 0.4161490683229814, tpr: 0.8187633262260128, threshold: 0.9820531606674194, 
fpr: 0.43478260869565216, tpr: 0.8187633262260128, threshold: 0.9815285205841064, 
fpr: 0.43478260869565216, tpr: 0.8208955223880597, threshold: 0.9799010753631592, 
fpr: 0.4472049689440994, tpr: 0.8208955223880597, threshold: 0.9780632853507996, 
fpr: 0.4472049689440994, tpr: 0.8272921108742004, threshold: 0.9762101769447327, 
fpr: 0.453416149068323, tpr: 0.8272921108742004, threshold: 0.9755178689956665, 
fpr: 0.453416149068323, tpr: 0.8315565031982942, threshold: 0.9739978313446045, 
fpr: 0.45962732919254656, tpr: 0.8315565031982942, threshold: 0.9725360870361328, 
fpr: 0.45962732919254656, tpr: 0.837953091684435, threshold: 0.9707720279693604, 
fpr: 0.4658385093167702, tpr: 0.837953091684435, threshold: 0.9704902172088623, 
fpr: 0.4658385093167702, tpr: 0.8507462686567164, threshold: 0.9663380980491638, 
fpr: 0.484472049689441, tpr: 0.8507462686567164, threshold: 0.9593856334686279, 
fpr: 0.484472049689441, tpr: 0.8528784648187633, threshold: 0.9592669010162354, 
fpr: 0.4906832298136646, tpr: 0.8528784648187633, threshold: 0.9590713977813721, 
fpr: 0.4906832298136646, tpr: 0.8571428571428571, threshold: 0.9565260410308838, 
fpr: 0.4968944099378882, tpr: 0.8571428571428571, threshold: 0.9562638998031616, 
fpr: 0.4968944099378882, tpr: 0.8592750533049041, threshold: 0.9556093215942383, 
fpr: 0.5031055900621118, tpr: 0.8592750533049041, threshold: 0.955143392086029, 
fpr: 0.5031055900621118, tpr: 0.8678038379530917, threshold: 0.9492291808128357, 
fpr: 0.5093167701863354, tpr: 0.8678038379530917, threshold: 0.9465816020965576, 
fpr: 0.5093167701863354, tpr: 0.8699360341151386, threshold: 0.9458568692207336, 
fpr: 0.515527950310559, tpr: 0.8699360341151386, threshold: 0.9456573724746704, 
fpr: 0.515527950310559, tpr: 0.8784648187633263, threshold: 0.9339011907577515, 
fpr: 0.5217391304347826, tpr: 0.8784648187633263, threshold: 0.9309605360031128, 
fpr: 0.5217391304347826, tpr: 0.8891257995735607, threshold: 0.9141144752502441, 
fpr: 0.5279503105590062, tpr: 0.8891257995735607, threshold: 0.9091008305549622, 
fpr: 0.5279503105590062, tpr: 0.8933901918976546, threshold: 0.8996579647064209, 
fpr: 0.5590062111801242, tpr: 0.8933901918976546, threshold: 0.8529033660888672, 
fpr: 0.5590062111801242, tpr: 0.8955223880597015, threshold: 0.8504314422607422, 
fpr: 0.5652173913043478, tpr: 0.8955223880597015, threshold: 0.8499422669410706, 
fpr: 0.5652173913043478, tpr: 0.9019189765458422, threshold: 0.8370317220687866, 
fpr: 0.5714285714285714, tpr: 0.9019189765458422, threshold: 0.8267724514007568, 
fpr: 0.5714285714285714, tpr: 0.9040511727078892, threshold: 0.823885440826416, 
fpr: 0.577639751552795, tpr: 0.9040511727078892, threshold: 0.8098220229148865, 
fpr: 0.577639751552795, tpr: 0.908315565031983, threshold: 0.7982633709907532, 
fpr: 0.6086956521739131, tpr: 0.908315565031983, threshold: 0.7543063759803772, 
fpr: 0.6086956521739131, tpr: 0.9125799573560768, threshold: 0.7443242073059082, 
fpr: 0.6273291925465838, tpr: 0.9125799573560768, threshold: 0.7010185718536377, 
fpr: 0.6273291925465838, tpr: 0.9147121535181236, threshold: 0.7007923722267151, 
fpr: 0.6645962732919255, tpr: 0.9147121535181236, threshold: 0.6224576830863953, 
fpr: 0.6645962732919255, tpr: 0.9168443496801706, threshold: 0.6017298698425293, 
fpr: 0.6832298136645962, tpr: 0.9168443496801706, threshold: 0.5820331573486328, 
fpr: 0.6832298136645962, tpr: 0.9211087420042644, threshold: 0.5759788751602173, 
fpr: 0.6956521739130435, tpr: 0.9211087420042644, threshold: 0.5622555613517761, 
fpr: 0.6956521739130435, tpr: 0.9253731343283582, threshold: 0.5517938733100891, 
fpr: 0.7018633540372671, tpr: 0.9253731343283582, threshold: 0.5500349998474121, 
fpr: 0.7018633540372671, tpr: 0.9275053304904051, threshold: 0.5324116945266724, 
fpr: 0.7142857142857143, tpr: 0.9275053304904051, threshold: 0.49409979581832886, 
fpr: 0.7142857142857143, tpr: 0.929637526652452, threshold: 0.48873308300971985, 
fpr: 0.7391304347826086, tpr: 0.929637526652452, threshold: 0.44308385252952576, 
fpr: 0.7391304347826086, tpr: 0.9360341151385928, threshold: 0.40412747859954834, 
fpr: 0.7515527950310559, tpr: 0.9360341151385928, threshold: 0.3857962489128113, 
fpr: 0.7515527950310559, tpr: 0.9402985074626866, threshold: 0.38506922125816345, 
fpr: 0.7577639751552795, tpr: 0.9402985074626866, threshold: 0.38030847907066345, 
fpr: 0.7577639751552795, tpr: 0.9466950959488273, threshold: 0.36914917826652527, 
fpr: 0.7639751552795031, tpr: 0.9466950959488273, threshold: 0.3480347692966461, 
fpr: 0.7639751552795031, tpr: 0.9488272921108742, threshold: 0.3182186484336853, 
fpr: 0.7701863354037267, tpr: 0.9488272921108742, threshold: 0.2987440228462219, 
fpr: 0.7701863354037267, tpr: 0.9530916844349681, threshold: 0.27343112230300903, 
fpr: 0.782608695652174, tpr: 0.9530916844349681, threshold: 0.269609272480011, 
fpr: 0.782608695652174, tpr: 0.9552238805970149, threshold: 0.25442075729370117, 
fpr: 0.7888198757763976, tpr: 0.9552238805970149, threshold: 0.24493007361888885, 
fpr: 0.7888198757763976, tpr: 0.9573560767590619, threshold: 0.24167940020561218, 
fpr: 0.7950310559006211, tpr: 0.9573560767590619, threshold: 0.2405431568622589, 
fpr: 0.7950310559006211, tpr: 0.9594882729211087, threshold: 0.23128043115139008, 
fpr: 0.8136645962732919, tpr: 0.9594882729211087, threshold: 0.17118622362613678, 
fpr: 0.8136645962732919, tpr: 0.9616204690831557, threshold: 0.1627849042415619, 
fpr: 0.8260869565217391, tpr: 0.9616204690831557, threshold: 0.14271344244480133, 
fpr: 0.8260869565217391, tpr: 0.9637526652452025, threshold: 0.1393834501504898, 
fpr: 0.8322981366459627, tpr: 0.9637526652452025, threshold: 0.12883269786834717, 
fpr: 0.8322981366459627, tpr: 0.9658848614072495, threshold: 0.12849578261375427, 
fpr: 0.8509316770186336, tpr: 0.9658848614072495, threshold: 0.1201537474989891, 
fpr: 0.8509316770186336, tpr: 0.9701492537313433, threshold: 0.10425608605146408, 
fpr: 0.8633540372670807, tpr: 0.9701492537313433, threshold: 0.07772324979305267, 
fpr: 0.8633540372670807, tpr: 0.9722814498933902, threshold: 0.07074715942144394, 
fpr: 0.8695652173913043, tpr: 0.9722814498933902, threshold: 0.06997368484735489, 
fpr: 0.8695652173913043, tpr: 0.9744136460554371, threshold: 0.05098048597574234, 
fpr: 0.8819875776397516, tpr: 0.9744136460554371, threshold: 0.04033317044377327, 
fpr: 0.8819875776397516, tpr: 0.9808102345415778, threshold: 0.0289436187595129, 
fpr: 0.8944099378881988, tpr: 0.9808102345415778, threshold: 0.028611019253730774, 
fpr: 0.8944099378881988, tpr: 0.9872068230277186, threshold: 0.02006329782307148, 
fpr: 0.9006211180124224, tpr: 0.9872068230277186, threshold: 0.01680879108607769, 
fpr: 0.9006211180124224, tpr: 0.9893390191897654, threshold: 0.01454746164381504, 
fpr: 0.9130434782608695, tpr: 0.9893390191897654, threshold: 0.013991194777190685, 
fpr: 0.9130434782608695, tpr: 0.9914712153518124, threshold: 0.013985282741487026, 
fpr: 0.9503105590062112, tpr: 0.9914712153518124, threshold: 0.002647069049999118, 
fpr: 0.9503105590062112, tpr: 0.9936034115138592, threshold: 0.002462580567225814, 
fpr: 0.9813664596273292, tpr: 0.9936034115138592, threshold: 0.0005601539160124958, 
fpr: 0.9813664596273292, tpr: 0.997867803837953, threshold: 0.0002496882516425103, 
fpr: 0.9875776397515528, tpr: 0.997867803837953, threshold: 0.0001318638096563518, 
fpr: 0.9875776397515528, tpr: 1.0, threshold: 0.00013101905642542988, 
fpr: 1.0, tpr: 1.0, threshold: 3.2740274036768824e-05, 

=== best_threshold: 0.9969950914382935, best_fpr: 0.2608695652173913, best_tpr: 0.7100213219616205 ===
