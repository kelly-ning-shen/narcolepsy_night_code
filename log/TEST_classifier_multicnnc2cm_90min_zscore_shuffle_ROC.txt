cuda:2
Subjects num: 78

90min inputs: chc001-nsrr (4)
90min inputs: chc004-nsrr (5)
90min inputs: chc005-nsrr (5)
90min inputs: chc006-nsrr (4)
90min inputs: chc008-nsrr (5)
90min inputs: chc009-nsrr (4)
90min inputs: chc010-nsrr (4)
90min inputs: chc012-nsrr (5)
90min inputs: chc013-nsrr (5)
90min inputs: chc014-nsrr (5)
90min inputs: chc015-nsrr (5)
90min inputs: chc016-nsrr (5)
90min inputs: chc022-nsrr (4)
90min inputs: chc025-nsrr (4)
90min inputs: chc027-nsrr (5)
90min inputs: chc028-nsrr (4)
90min inputs: chc033-nsrr (4)
90min inputs: chc035-nsrr (5)
90min inputs: chc037-nsrr (4)
90min inputs: chc040-nsrr (6)
90min inputs: chc041-nsrr (4)
90min inputs: chc052-nsrr (5)
90min inputs: chc056-nsrr (5)
90min inputs: chp001-nsrr (6)
90min inputs: chp002-nsrr (6)
90min inputs: chp003-nsrr (5)
90min inputs: chp004-nsrr (5)
90min inputs: chp005-nsrr (7)
90min inputs: chp006-nsrr (6)
90min inputs: chp007-nsrr (6)
90min inputs: chp008-nsrr (5)
90min inputs: chp009-nsrr (5)
90min inputs: chp010-nsrr (5)
90min inputs: chp011-nsrr (5)
90min inputs: chp012-nsrr (6)
90min inputs: chp013-nsrr (5)
90min inputs: chp014-nsrr (5)
90min inputs: chp015-nsrr (6)
90min inputs: chp016-nsrr (7)
90min inputs: chp017-nsrr (5)
90min inputs: chp018-nsrr (6)
90min inputs: chp019-nsrr (5)
90min inputs: chp020-nsrr (6)
90min inputs: chp022-nsrr (7)
90min inputs: chp024-nsrr (6)
90min inputs: chp025-nsrr (2)
90min inputs: chp026-nsrr (5)
90min inputs: chp028-nsrr (5)
90min inputs: chp029-nsrr (5)
90min inputs: chp030-nsrr (6)
90min inputs: chp031-nsrr (6)
90min inputs: chp032-nsrr (5)
90min inputs: chp033-nsrr (5)
90min inputs: chp034-nsrr (5)
90min inputs: chp036-nsrr (7)
90min inputs: chp037-nsrr (5)
90min inputs: chp038-nsrr (5)
90min inputs: chp039-nsrr (6)
90min inputs: chp040-nsrr (5)
90min inputs: chp041-nsrr (6)
90min inputs: chp042-nsrr (6)
90min inputs: chp043-nsrr (6)
90min inputs: chp044-nsrr (5)
90min inputs: chp045-nsrr (6)
90min inputs: chp046-nsrr (6)
90min inputs: chp047-nsrr (4)
90min inputs: chp048-nsrr (5)
90min inputs: chp049-nsrr (6)
90min inputs: chp051-nsrr (6)
90min inputs: chp052-nsrr (5)
90min inputs: chp053-nsrr (6)
90min inputs: chp054-nsrr (6)
90min inputs: chp055-nsrr (6)
90min inputs: chp056-nsrr (6)
90min inputs: chp057-nsrr (6)
90min inputs: chp058-nsrr (5)
90min inputs: chp059-nsrr (6)
90min inputs: chp060-nsrr (7)

=== Test on chc001-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.437674, loss_ss: 1.707488, loss_d: 0.730186
0.2451 --- loss: 2.035456, loss_ss: 1.461438, loss_d: 0.574018
0.4902 --- loss: 2.175037, loss_ss: 1.612545, loss_d: 0.562492
0.7353 --- loss: 1.826306, loss_ss: 1.340601, loss_d: 0.485705
0.9804 --- loss: 1.779703, loss_ss: 1.277478, loss_d: 0.502225
Epoch finished! Loss: 2.1220406889915466
Starting epoch 2/10.
0.0000 --- loss: 1.708121, loss_ss: 1.299497, loss_d: 0.408625
0.2451 --- loss: 1.782763, loss_ss: 1.376812, loss_d: 0.405950
0.4902 --- loss: 1.791414, loss_ss: 1.311816, loss_d: 0.479598
0.7353 --- loss: 1.665306, loss_ss: 1.355540, loss_d: 0.309767
0.9804 --- loss: 1.487843, loss_ss: 1.181238, loss_d: 0.306605
Epoch finished! Loss: 1.7392018169164658
Starting epoch 3/10.
0.0000 --- loss: 1.498065, loss_ss: 1.267298, loss_d: 0.230768
0.2451 --- loss: 1.623268, loss_ss: 1.291117, loss_d: 0.332151
0.4902 --- loss: 1.466145, loss_ss: 1.255969, loss_d: 0.210176
0.7353 --- loss: 1.335418, loss_ss: 1.138177, loss_d: 0.197241
0.9804 --- loss: 1.536199, loss_ss: 1.277456, loss_d: 0.258743
Epoch finished! Loss: 1.4925547748804093
Starting epoch 4/10.
0.0000 --- loss: 1.173607, loss_ss: 1.159477, loss_d: 0.014130
0.2451 --- loss: 1.269325, loss_ss: 1.100026, loss_d: 0.169300
0.4902 --- loss: 1.402662, loss_ss: 1.365446, loss_d: 0.037215
0.7353 --- loss: 1.211665, loss_ss: 1.094384, loss_d: 0.117281
0.9804 --- loss: 1.203806, loss_ss: 1.058427, loss_d: 0.145379
Epoch finished! Loss: 1.2569738686084748
Starting epoch 5/10.
0.0000 --- loss: 1.011208, loss_ss: 1.001815, loss_d: 0.009393
0.2451 --- loss: 1.072542, loss_ss: 1.062644, loss_d: 0.009898
0.4902 --- loss: 1.324345, loss_ss: 1.289786, loss_d: 0.034559
0.7353 --- loss: 1.127811, loss_ss: 1.023021, loss_d: 0.104791
0.9804 --- loss: 1.050287, loss_ss: 1.047750, loss_d: 0.002537
Epoch finished! Loss: 1.1316956594586371
Starting epoch 6/10.
0.0000 --- loss: 1.010691, loss_ss: 1.005324, loss_d: 0.005367
0.2451 --- loss: 1.023707, loss_ss: 1.021714, loss_d: 0.001993
0.4902 --- loss: 1.048358, loss_ss: 1.008875, loss_d: 0.039483
0.7353 --- loss: 1.022844, loss_ss: 1.019544, loss_d: 0.003300
0.9804 --- loss: 1.051015, loss_ss: 1.050922, loss_d: 0.000093
Epoch finished! Loss: 1.0600810036063195
Starting epoch 7/10.
0.0000 --- loss: 0.961970, loss_ss: 0.959809, loss_d: 0.002161
0.2451 --- loss: 1.024783, loss_ss: 0.933162, loss_d: 0.091621
0.4902 --- loss: 0.904800, loss_ss: 0.903619, loss_d: 0.001180
0.7353 --- loss: 0.844500, loss_ss: 0.827729, loss_d: 0.016771
0.9804 --- loss: 0.953102, loss_ss: 0.951982, loss_d: 0.001120
Epoch finished! Loss: 1.0076113909482955
Starting epoch 8/10.
0.0000 --- loss: 0.903869, loss_ss: 0.902653, loss_d: 0.001216
0.2451 --- loss: 0.920061, loss_ss: 0.919417, loss_d: 0.000644
0.4902 --- loss: 0.981105, loss_ss: 0.980828, loss_d: 0.000277
0.7353 --- loss: 0.966219, loss_ss: 0.964776, loss_d: 0.001443
0.9804 --- loss: 0.866577, loss_ss: 0.821667, loss_d: 0.044910
Epoch finished! Loss: 0.9657952040433884
Starting epoch 9/10.
0.0000 --- loss: 0.971146, loss_ss: 0.970580, loss_d: 0.000566
0.2451 --- loss: 0.988483, loss_ss: 0.977626, loss_d: 0.010857
0.4902 --- loss: 1.007887, loss_ss: 1.007372, loss_d: 0.000515
0.7353 --- loss: 0.925684, loss_ss: 0.882231, loss_d: 0.043453
0.9804 --- loss: 0.765518, loss_ss: 0.764239, loss_d: 0.001278
Epoch finished! Loss: 0.9307967633008957
Starting epoch 10/10.
0.0000 --- loss: 0.881807, loss_ss: 0.871861, loss_d: 0.009946
0.2451 --- loss: 0.837319, loss_ss: 0.805981, loss_d: 0.031337
0.4902 --- loss: 0.981102, loss_ss: 0.977452, loss_d: 0.003650
0.7353 --- loss: 0.950744, loss_ss: 0.948932, loss_d: 0.001812
0.9804 --- loss: 0.780543, loss_ss: 0.778278, loss_d: 0.002265
Epoch finished! Loss: 0.8956581115722656
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8111111111111111
             precision    recall  f1-score   support

        0.0       0.61      1.00      0.76        77
        1.0       0.00      0.00      0.00        48
        2.0       0.84      0.90      0.87       340
        3.0       1.00      0.64      0.78       143
        4.0       0.80      0.97      0.88       112

avg / total       0.78      0.81      0.78       720
 


====== chc001-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  93.19  100.00   92.38   61.11     75.86
1  93.33    0.00  100.00    0.00      0.00
2  86.94   90.00   84.21   83.61     86.69
3  92.92   64.34  100.00  100.00     78.30
4  95.83   97.32   95.56   80.15     87.90
Total accuracy: 81.11%
Average sen: 70.33%
Average spec: 94.43%
Macro f1-score: 65.75%
Diagnosis acc on 90mins: 0.0
[0.96607125 0.99983346 0.99998057 0.99998593]
pred: 0.9914678037166595, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc001-nsrr

=== Test on chc004-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.289310, loss_ss: 1.611923, loss_d: 0.677387
0.2457 --- loss: 2.125814, loss_ss: 1.544675, loss_d: 0.581139
0.4914 --- loss: 2.157060, loss_ss: 1.481058, loss_d: 0.676002
0.7371 --- loss: 1.883394, loss_ss: 1.449853, loss_d: 0.433541
0.9828 --- loss: 1.551214, loss_ss: 1.360155, loss_d: 0.191058
Epoch finished! Loss: 2.1448467463254928
Starting epoch 2/10.
0.0000 --- loss: 1.521985, loss_ss: 1.339820, loss_d: 0.182165
0.2457 --- loss: 1.824315, loss_ss: 1.295801, loss_d: 0.528514
0.4914 --- loss: 1.598574, loss_ss: 1.233138, loss_d: 0.365436
0.7371 --- loss: 1.515221, loss_ss: 1.331856, loss_d: 0.183365
0.9828 --- loss: 2.662870, loss_ss: 1.238442, loss_d: 1.424428
Epoch finished! Loss: 1.7893330782651902
Starting epoch 3/10.
0.0000 --- loss: 1.668549, loss_ss: 1.295050, loss_d: 0.373500
0.2457 --- loss: 1.565130, loss_ss: 1.281386, loss_d: 0.283744
0.4914 --- loss: 1.372564, loss_ss: 1.316921, loss_d: 0.055643
0.7371 --- loss: 1.512943, loss_ss: 1.185543, loss_d: 0.327401
0.9828 --- loss: 1.490299, loss_ss: 1.176975, loss_d: 0.313324
Epoch finished! Loss: 1.4981097638607026
Starting epoch 4/10.
0.0000 --- loss: 1.204896, loss_ss: 1.181919, loss_d: 0.022977
0.2457 --- loss: 1.144869, loss_ss: 1.129749, loss_d: 0.015120
0.4914 --- loss: 1.187680, loss_ss: 1.130959, loss_d: 0.056721
0.7371 --- loss: 1.103837, loss_ss: 1.100371, loss_d: 0.003467
0.9828 --- loss: 1.098233, loss_ss: 1.078327, loss_d: 0.019906
Epoch finished! Loss: 1.233082300424576
Starting epoch 5/10.
0.0000 --- loss: 1.240420, loss_ss: 1.184913, loss_d: 0.055507
0.2457 --- loss: 1.124938, loss_ss: 1.107645, loss_d: 0.017292
0.4914 --- loss: 1.139325, loss_ss: 1.136204, loss_d: 0.003121
0.7371 --- loss: 1.112149, loss_ss: 1.107344, loss_d: 0.004805
0.9828 --- loss: 1.196185, loss_ss: 1.195440, loss_d: 0.000745
Epoch finished! Loss: 1.1547197356820107
Starting epoch 6/10.
0.0000 --- loss: 1.124896, loss_ss: 1.123555, loss_d: 0.001341
0.2457 --- loss: 1.083694, loss_ss: 1.081417, loss_d: 0.002277
0.4914 --- loss: 1.032696, loss_ss: 1.028696, loss_d: 0.004000
0.7371 --- loss: 1.123462, loss_ss: 1.122111, loss_d: 0.001350
0.9828 --- loss: 0.977421, loss_ss: 0.973809, loss_d: 0.003612
Epoch finished! Loss: 1.1235284954309464
Starting epoch 7/10.
0.0000 --- loss: 1.119421, loss_ss: 1.092593, loss_d: 0.026828
0.2457 --- loss: 0.952020, loss_ss: 0.950461, loss_d: 0.001559
0.4914 --- loss: 1.041744, loss_ss: 1.037940, loss_d: 0.003805
0.7371 --- loss: 1.054250, loss_ss: 1.052274, loss_d: 0.001976
0.9828 --- loss: 0.928339, loss_ss: 0.925823, loss_d: 0.002515
Epoch finished! Loss: 1.0758586943149566
Starting epoch 8/10.
0.0000 --- loss: 1.021465, loss_ss: 1.008442, loss_d: 0.013023
0.2457 --- loss: 0.884895, loss_ss: 0.884649, loss_d: 0.000246
0.4914 --- loss: 0.981350, loss_ss: 0.978664, loss_d: 0.002686
0.7371 --- loss: 1.023850, loss_ss: 1.022465, loss_d: 0.001385
0.9828 --- loss: 0.925655, loss_ss: 0.925551, loss_d: 0.000103
Epoch finished! Loss: 1.0291053786873818
Starting epoch 9/10.
0.0000 --- loss: 1.003932, loss_ss: 1.003635, loss_d: 0.000296
0.2457 --- loss: 0.956704, loss_ss: 0.956090, loss_d: 0.000614
0.4914 --- loss: 0.956746, loss_ss: 0.955307, loss_d: 0.001439
0.7371 --- loss: 1.034231, loss_ss: 1.033951, loss_d: 0.000280
0.9828 --- loss: 1.182039, loss_ss: 1.181445, loss_d: 0.000595
Epoch finished! Loss: 1.0044946894049644
Starting epoch 10/10.
0.0000 --- loss: 1.068208, loss_ss: 1.067928, loss_d: 0.000280
0.2457 --- loss: 0.885908, loss_ss: 0.885645, loss_d: 0.000263
0.4914 --- loss: 1.059483, loss_ss: 1.059270, loss_d: 0.000213
0.7371 --- loss: 1.012182, loss_ss: 1.012108, loss_d: 0.000075
0.9828 --- loss: 0.895414, loss_ss: 0.895098, loss_d: 0.000316
Epoch finished! Loss: 0.9804877504706383
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7388888888888889
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00        74
        1.0       0.00      0.00      0.00        41
        2.0       0.78      0.94      0.85       467
        3.0       0.99      0.56      0.71       203
        4.0       0.50      0.98      0.66       115

avg / total       0.69      0.74      0.69       900
 


====== chc004-nsrr ======

The ppr of  0  has ZeroDivisionError.

The f1-score of  0  has ZeroDivisionError.

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  91.78   0.00  100.00   0.00      0.00
1  95.44   0.00  100.00   0.00      0.00
2  83.33  94.00   71.82  78.25     85.41
3  89.89  55.67   99.86  99.12     71.29
4  87.33  98.26   85.73  50.22     66.47
Total accuracy: 73.89%
Average sen: 49.59%
Average spec: 91.48%
Macro f1-score: 44.63%
Diagnosis acc on 90mins: 0.0
[0.99999988 0.98215163 0.9998703  0.99925619 0.99628168]
pred: 0.9955119371414185, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc004-nsrr

=== Test on chc005-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.371909, loss_ss: 1.585702, loss_d: 0.786207
0.2457 --- loss: 1.997718, loss_ss: 1.579169, loss_d: 0.418549
0.4914 --- loss: 2.127244, loss_ss: 1.481127, loss_d: 0.646116
0.7371 --- loss: 2.539699, loss_ss: 1.542796, loss_d: 0.996903
0.9828 --- loss: 1.900643, loss_ss: 1.410505, loss_d: 0.490137
Epoch finished! Loss: 2.2015339016914366
Starting epoch 2/10.
0.0000 --- loss: 1.950696, loss_ss: 1.490432, loss_d: 0.460264
0.2457 --- loss: 2.241282, loss_ss: 1.427867, loss_d: 0.813415
0.4914 --- loss: 1.954282, loss_ss: 1.355012, loss_d: 0.599270
0.7371 --- loss: 1.644023, loss_ss: 1.310882, loss_d: 0.333142
0.9828 --- loss: 2.147787, loss_ss: 1.318347, loss_d: 0.829440
Epoch finished! Loss: 1.9125392943620683
Starting epoch 3/10.
0.0000 --- loss: 1.623732, loss_ss: 1.346776, loss_d: 0.276957
0.2457 --- loss: 1.770947, loss_ss: 1.427618, loss_d: 0.343329
0.4914 --- loss: 1.595858, loss_ss: 1.286240, loss_d: 0.309618
0.7371 --- loss: 1.479105, loss_ss: 1.306653, loss_d: 0.172452
0.9828 --- loss: 1.618217, loss_ss: 1.284057, loss_d: 0.334159
Epoch finished! Loss: 1.6820977240800858
Starting epoch 4/10.
0.0000 --- loss: 1.394253, loss_ss: 1.286230, loss_d: 0.108023
0.2457 --- loss: 1.587556, loss_ss: 1.278790, loss_d: 0.308766
0.4914 --- loss: 1.292111, loss_ss: 1.167039, loss_d: 0.125072
0.7371 --- loss: 1.317154, loss_ss: 1.217147, loss_d: 0.100007
0.9828 --- loss: 1.228462, loss_ss: 1.122902, loss_d: 0.105560
Epoch finished! Loss: 1.4197432279586792
Starting epoch 5/10.
0.0000 --- loss: 1.297531, loss_ss: 1.206511, loss_d: 0.091020
0.2457 --- loss: 1.272367, loss_ss: 1.204002, loss_d: 0.068365
0.4914 --- loss: 1.188856, loss_ss: 1.172415, loss_d: 0.016441
0.7371 --- loss: 1.140442, loss_ss: 1.138598, loss_d: 0.001844
0.9828 --- loss: 1.219777, loss_ss: 1.199804, loss_d: 0.019973
Epoch finished! Loss: 1.2381001740694046
Starting epoch 6/10.
0.0000 --- loss: 1.174783, loss_ss: 1.168645, loss_d: 0.006138
0.2457 --- loss: 1.202187, loss_ss: 1.200604, loss_d: 0.001583
0.4914 --- loss: 1.150074, loss_ss: 1.149689, loss_d: 0.000385
0.7371 --- loss: 1.075650, loss_ss: 1.074803, loss_d: 0.000847
0.9828 --- loss: 1.205531, loss_ss: 1.203897, loss_d: 0.001634
Epoch finished! Loss: 1.1460606366395951
Starting epoch 7/10.
0.0000 --- loss: 1.131835, loss_ss: 1.131582, loss_d: 0.000253
0.2457 --- loss: 1.054932, loss_ss: 1.040763, loss_d: 0.014170
0.4914 --- loss: 1.014629, loss_ss: 1.010682, loss_d: 0.003948
0.7371 --- loss: 0.989592, loss_ss: 0.988970, loss_d: 0.000622
0.9828 --- loss: 1.084652, loss_ss: 1.084311, loss_d: 0.000341
Epoch finished! Loss: 1.0656082704663277
Starting epoch 8/10.
0.0000 --- loss: 1.061947, loss_ss: 1.061271, loss_d: 0.000676
0.2457 --- loss: 0.925686, loss_ss: 0.924926, loss_d: 0.000760
0.4914 --- loss: 1.047631, loss_ss: 1.047234, loss_d: 0.000397
0.7371 --- loss: 0.878976, loss_ss: 0.878412, loss_d: 0.000565
0.9828 --- loss: 0.886844, loss_ss: 0.884956, loss_d: 0.001888
Epoch finished! Loss: 0.9989409416913986
Starting epoch 9/10.
0.0000 --- loss: 0.993080, loss_ss: 0.992455, loss_d: 0.000625
0.2457 --- loss: 0.886609, loss_ss: 0.886318, loss_d: 0.000291
0.4914 --- loss: 0.905218, loss_ss: 0.905032, loss_d: 0.000186
0.7371 --- loss: 0.794798, loss_ss: 0.793822, loss_d: 0.000977
0.9828 --- loss: 1.125793, loss_ss: 1.125095, loss_d: 0.000698
Epoch finished! Loss: 0.9442343905568122
Starting epoch 10/10.
0.0000 --- loss: 0.872468, loss_ss: 0.872383, loss_d: 0.000084
0.2457 --- loss: 0.892211, loss_ss: 0.892142, loss_d: 0.000069
0.4914 --- loss: 0.828962, loss_ss: 0.828873, loss_d: 0.000090
0.7371 --- loss: 0.889784, loss_ss: 0.889598, loss_d: 0.000186
0.9828 --- loss: 0.918675, loss_ss: 0.918229, loss_d: 0.000446
Epoch finished! Loss: 0.9054046586155892
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7288888888888889
             precision    recall  f1-score   support

        0.0       0.49      1.00      0.66        40
        1.0       0.00      0.00      0.00        30
        2.0       0.76      0.85      0.80       504
        3.0       1.00      0.42      0.59       236
        4.0       0.59      0.99      0.74        90

avg / total       0.77      0.73      0.70       900
 


====== chc005-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  95.33  100.00   95.12   48.78     65.57
1  96.67    0.00  100.00    0.00      0.00
2  76.22   85.12   64.90   75.53     80.04
3  84.67   41.53  100.00  100.00     58.68
4  92.89   98.89   92.22   58.55     73.55
Total accuracy: 72.89%
Average sen: 65.11%
Average spec: 90.45%
Macro f1-score: 55.57%
Diagnosis acc on 90mins: 0.8
[0.06112096 0.0594449  0.03538009 0.77580452 0.18194805]
pred: 0.22273970320820807, label: 0
Right! Diagnosis: Other
Save 90mins of subject chc005-nsrr

=== Test on chc006-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.241808, loss_ss: 1.589376, loss_d: 0.652433
0.2451 --- loss: 2.009480, loss_ss: 1.421177, loss_d: 0.588303
0.4902 --- loss: 2.018627, loss_ss: 1.430707, loss_d: 0.587920
0.7353 --- loss: 1.985891, loss_ss: 1.498156, loss_d: 0.487735
0.9804 --- loss: 1.866295, loss_ss: 1.458096, loss_d: 0.408199
Epoch finished! Loss: 2.2145530462265013
Starting epoch 2/10.
0.0000 --- loss: 2.032712, loss_ss: 1.450731, loss_d: 0.581981
0.2451 --- loss: 1.865299, loss_ss: 1.320823, loss_d: 0.544476
0.4902 --- loss: 1.764538, loss_ss: 1.346249, loss_d: 0.418289
0.7353 --- loss: 2.652333, loss_ss: 1.407015, loss_d: 1.245317
0.9804 --- loss: 1.840327, loss_ss: 1.393488, loss_d: 0.446839
Epoch finished! Loss: 1.9309876352548598
Starting epoch 3/10.
0.0000 --- loss: 1.818697, loss_ss: 1.295948, loss_d: 0.522749
0.2451 --- loss: 1.646187, loss_ss: 1.295181, loss_d: 0.351006
0.4902 --- loss: 1.561133, loss_ss: 1.210282, loss_d: 0.350850
0.7353 --- loss: 1.536946, loss_ss: 1.279002, loss_d: 0.257944
0.9804 --- loss: 1.491420, loss_ss: 1.252792, loss_d: 0.238628
Epoch finished! Loss: 1.6642930269241334
Starting epoch 4/10.
0.0000 --- loss: 1.428425, loss_ss: 1.202160, loss_d: 0.226264
0.2451 --- loss: 1.634243, loss_ss: 1.263325, loss_d: 0.370918
0.4902 --- loss: 1.435131, loss_ss: 1.331069, loss_d: 0.104062
0.7353 --- loss: 1.285798, loss_ss: 1.150667, loss_d: 0.135131
0.9804 --- loss: 1.238171, loss_ss: 1.159613, loss_d: 0.078558
Epoch finished! Loss: 1.4197207599878312
Starting epoch 5/10.
0.0000 --- loss: 1.214520, loss_ss: 1.149532, loss_d: 0.064988
0.2451 --- loss: 1.115878, loss_ss: 1.078067, loss_d: 0.037812
0.4902 --- loss: 1.076687, loss_ss: 1.051030, loss_d: 0.025656
0.7353 --- loss: 1.259755, loss_ss: 1.185080, loss_d: 0.074675
0.9804 --- loss: 1.304027, loss_ss: 1.117231, loss_d: 0.186797
Epoch finished! Loss: 1.202595978975296
Starting epoch 6/10.
0.0000 --- loss: 1.078058, loss_ss: 1.072564, loss_d: 0.005494
0.2451 --- loss: 1.146610, loss_ss: 1.119935, loss_d: 0.026675
0.4902 --- loss: 1.058276, loss_ss: 1.052718, loss_d: 0.005557
0.7353 --- loss: 1.106703, loss_ss: 1.103253, loss_d: 0.003451
0.9804 --- loss: 0.936862, loss_ss: 0.933779, loss_d: 0.003082
Epoch finished! Loss: 1.0722432672977447
Starting epoch 7/10.
0.0000 --- loss: 1.144410, loss_ss: 1.141345, loss_d: 0.003065
0.2451 --- loss: 0.972077, loss_ss: 0.950854, loss_d: 0.021224
0.4902 --- loss: 1.038500, loss_ss: 1.033541, loss_d: 0.004960
0.7353 --- loss: 1.067829, loss_ss: 1.065766, loss_d: 0.002063
0.9804 --- loss: 0.877144, loss_ss: 0.874721, loss_d: 0.002423
Epoch finished! Loss: 1.0230920791625977
Starting epoch 8/10.
0.0000 --- loss: 0.929134, loss_ss: 0.911383, loss_d: 0.017751
0.2451 --- loss: 0.972967, loss_ss: 0.970511, loss_d: 0.002456
0.4902 --- loss: 1.388963, loss_ss: 1.097529, loss_d: 0.291434
0.7353 --- loss: 1.325605, loss_ss: 0.958629, loss_d: 0.366976
0.9804 --- loss: 0.894803, loss_ss: 0.885302, loss_d: 0.009501
Epoch finished! Loss: 1.0244828686118126
Starting epoch 9/10.
0.0000 --- loss: 0.821911, loss_ss: 0.817153, loss_d: 0.004759
0.2451 --- loss: 1.089503, loss_ss: 1.079946, loss_d: 0.009557
0.4902 --- loss: 0.880095, loss_ss: 0.860208, loss_d: 0.019888
0.7353 --- loss: 0.795696, loss_ss: 0.794461, loss_d: 0.001235
0.9804 --- loss: 0.891618, loss_ss: 0.807546, loss_d: 0.084072
Epoch finished! Loss: 0.9487253561615944
Starting epoch 10/10.
0.0000 --- loss: 0.960970, loss_ss: 0.866886, loss_d: 0.094084
0.2451 --- loss: 0.884979, loss_ss: 0.884187, loss_d: 0.000792
0.4902 --- loss: 0.929767, loss_ss: 0.774902, loss_d: 0.154865
0.7353 --- loss: 0.931578, loss_ss: 0.707958, loss_d: 0.223621
0.9804 --- loss: 1.316032, loss_ss: 0.917339, loss_d: 0.398694
Epoch finished! Loss: 0.9326929926872254
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6208333333333333
             precision    recall  f1-score   support

        0.0       0.94      0.82      0.87       103
        1.0       0.17      0.02      0.04        87
        2.0       0.75      0.72      0.74       300
        3.0       1.00      0.35      0.52       133
        4.0       0.34      1.00      0.51        97

avg / total       0.70      0.62      0.60       720
 


====== chc006-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  96.67   81.55   99.19   94.38     87.50
1  86.81    2.30   98.42   16.67      4.04
2  78.47   72.33   82.86   75.09     73.68
3  88.06   35.34  100.00  100.00     52.22
4  74.17  100.00   70.14   34.28     51.05
Total accuracy: 62.08%
Average sen: 58.30%
Average spec: 90.12%
Macro f1-score: 53.70%
Diagnosis acc on 90mins: 0.0
[0.99999893 0.99999487 0.94959217 0.76383764]
pred: 0.9283559024333954, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc006-nsrr

=== Test on chc008-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.420285, loss_ss: 1.694435, loss_d: 0.725850
0.2457 --- loss: 2.406568, loss_ss: 1.700110, loss_d: 0.706458
0.4914 --- loss: 2.155294, loss_ss: 1.647316, loss_d: 0.507979
0.7371 --- loss: 2.439435, loss_ss: 1.602284, loss_d: 0.837151
0.9828 --- loss: 2.318382, loss_ss: 1.699081, loss_d: 0.619301
Epoch finished! Loss: 2.42732410132885
Starting epoch 2/10.
0.0000 --- loss: 2.175312, loss_ss: 1.661672, loss_d: 0.513640
0.2457 --- loss: 2.311047, loss_ss: 1.625464, loss_d: 0.685583
0.4914 --- loss: 2.179652, loss_ss: 1.567245, loss_d: 0.612407
0.7371 --- loss: 1.830272, loss_ss: 1.552593, loss_d: 0.277680
0.9828 --- loss: 2.288110, loss_ss: 1.495481, loss_d: 0.792629
Epoch finished! Loss: 2.1079546213150024
Starting epoch 3/10.
0.0000 --- loss: 1.938508, loss_ss: 1.525476, loss_d: 0.413031
0.2457 --- loss: 2.143477, loss_ss: 1.484291, loss_d: 0.659186
0.4914 --- loss: 1.795034, loss_ss: 1.488024, loss_d: 0.307010
0.7371 --- loss: 1.648901, loss_ss: 1.454656, loss_d: 0.194245
0.9828 --- loss: 1.855011, loss_ss: 1.373857, loss_d: 0.481154
Epoch finished! Loss: 1.8310010224580764
Starting epoch 4/10.
0.0000 --- loss: 1.649244, loss_ss: 1.380536, loss_d: 0.268707
0.2457 --- loss: 1.453191, loss_ss: 1.315258, loss_d: 0.137933
0.4914 --- loss: 1.364078, loss_ss: 1.269148, loss_d: 0.094930
0.7371 --- loss: 1.450391, loss_ss: 1.273419, loss_d: 0.176973
0.9828 --- loss: 1.293179, loss_ss: 1.262169, loss_d: 0.031010
Epoch finished! Loss: 1.483780488371849
Starting epoch 5/10.
0.0000 --- loss: 1.222462, loss_ss: 1.215065, loss_d: 0.007397
0.2457 --- loss: 1.157236, loss_ss: 1.149630, loss_d: 0.007606
0.4914 --- loss: 1.820259, loss_ss: 1.193503, loss_d: 0.626756
0.7371 --- loss: 1.276452, loss_ss: 1.267929, loss_d: 0.008522
0.9828 --- loss: 1.140262, loss_ss: 1.130390, loss_d: 0.009872
Epoch finished! Loss: 1.3146339058876038
Starting epoch 6/10.
0.0000 --- loss: 1.226313, loss_ss: 1.196922, loss_d: 0.029390
0.2457 --- loss: 1.173873, loss_ss: 1.133721, loss_d: 0.040152
0.4914 --- loss: 1.253828, loss_ss: 1.198549, loss_d: 0.055278
0.7371 --- loss: 1.082302, loss_ss: 1.031387, loss_d: 0.050915
0.9828 --- loss: 1.082942, loss_ss: 1.053753, loss_d: 0.029189
Epoch finished! Loss: 1.1855488210916518
Starting epoch 7/10.
0.0000 --- loss: 1.145379, loss_ss: 1.140739, loss_d: 0.004640
0.2457 --- loss: 1.062747, loss_ss: 1.060742, loss_d: 0.002005
0.4914 --- loss: 1.103084, loss_ss: 1.102075, loss_d: 0.001009
0.7371 --- loss: 0.984310, loss_ss: 0.962066, loss_d: 0.022244
0.9828 --- loss: 1.085545, loss_ss: 0.902330, loss_d: 0.183216
Epoch finished! Loss: 1.0648143947124482
Starting epoch 8/10.
0.0000 --- loss: 0.962834, loss_ss: 0.960532, loss_d: 0.002301
0.2457 --- loss: 0.953584, loss_ss: 0.947289, loss_d: 0.006295
0.4914 --- loss: 0.964843, loss_ss: 0.960044, loss_d: 0.004799
0.7371 --- loss: 0.906161, loss_ss: 0.899916, loss_d: 0.006246
0.9828 --- loss: 0.976228, loss_ss: 0.973187, loss_d: 0.003041
Epoch finished! Loss: 1.0259836480021476
Starting epoch 9/10.
0.0000 --- loss: 0.958563, loss_ss: 0.949027, loss_d: 0.009535
0.2457 --- loss: 1.007837, loss_ss: 1.006094, loss_d: 0.001743
0.4914 --- loss: 0.945223, loss_ss: 0.900703, loss_d: 0.044520
0.7371 --- loss: 1.124147, loss_ss: 1.035457, loss_d: 0.088689
0.9828 --- loss: 0.970943, loss_ss: 0.962383, loss_d: 0.008561
Epoch finished! Loss: 0.9847074657678604
Starting epoch 10/10.
0.0000 --- loss: 0.804492, loss_ss: 0.801480, loss_d: 0.003012
0.2457 --- loss: 0.835180, loss_ss: 0.825589, loss_d: 0.009590
0.4914 --- loss: 0.907931, loss_ss: 0.881060, loss_d: 0.026871
0.7371 --- loss: 0.907830, loss_ss: 0.834382, loss_d: 0.073448
0.9828 --- loss: 0.916011, loss_ss: 0.906185, loss_d: 0.009826
Epoch finished! Loss: 0.9356924027204514
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.59
             precision    recall  f1-score   support

        0.0       0.81      0.99      0.89       144
        1.0       1.00      0.01      0.02        80
        2.0       0.54      0.84      0.66       344
        3.0       0.00      0.00      0.00       227
        4.0       0.54      0.93      0.68       105

avg / total       0.49      0.59      0.47       900
 


====== chc008-nsrr ======

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  96.00  98.61   95.50   80.68     88.75
1  91.22   1.25  100.00  100.00      2.47
2  66.11  84.30   54.86   53.60     65.54
3  74.78   0.00  100.00    0.00      0.00
4  89.89  93.33   89.43   53.85     68.29
Total accuracy: 59.00%
Average sen: 55.50%
Average spec: 87.96%
Macro f1-score: 45.01%
Diagnosis acc on 90mins: 0.4
[0.99995863 0.24015796 0.05943241 0.67692178 0.92891407]
pred: 0.5810769721865654, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc008-nsrr

=== Test on chc009-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.356454, loss_ss: 1.613449, loss_d: 0.743005
0.2451 --- loss: 2.178082, loss_ss: 1.560391, loss_d: 0.617691
0.4902 --- loss: 1.987491, loss_ss: 1.492328, loss_d: 0.495163
0.7353 --- loss: 1.996419, loss_ss: 1.457253, loss_d: 0.539166
0.9804 --- loss: 1.936136, loss_ss: 1.422852, loss_d: 0.513284
Epoch finished! Loss: 2.186569294333458
Starting epoch 2/10.
0.0000 --- loss: 1.898627, loss_ss: 1.379876, loss_d: 0.518751
0.2451 --- loss: 2.008824, loss_ss: 1.380262, loss_d: 0.628562
0.4902 --- loss: 2.017700, loss_ss: 1.413647, loss_d: 0.604054
0.7353 --- loss: 1.810911, loss_ss: 1.330908, loss_d: 0.480003
0.9804 --- loss: 1.585279, loss_ss: 1.319065, loss_d: 0.266213
Epoch finished! Loss: 1.877924370765686
Starting epoch 3/10.
0.0000 --- loss: 1.577161, loss_ss: 1.299852, loss_d: 0.277309
0.2451 --- loss: 1.693786, loss_ss: 1.281393, loss_d: 0.412393
0.4902 --- loss: 1.541605, loss_ss: 1.229019, loss_d: 0.312586
0.7353 --- loss: 1.494537, loss_ss: 1.275343, loss_d: 0.219194
0.9804 --- loss: 1.434621, loss_ss: 1.291190, loss_d: 0.143431
Epoch finished! Loss: 1.579638260602951
Starting epoch 4/10.
0.0000 --- loss: 1.477493, loss_ss: 1.224383, loss_d: 0.253110
0.2451 --- loss: 1.234173, loss_ss: 1.184842, loss_d: 0.049331
0.4902 --- loss: 1.274694, loss_ss: 1.230578, loss_d: 0.044116
0.7353 --- loss: 1.290742, loss_ss: 1.176658, loss_d: 0.114084
0.9804 --- loss: 1.196189, loss_ss: 1.189276, loss_d: 0.006913
Epoch finished! Loss: 1.3267378509044647
Starting epoch 5/10.
0.0000 --- loss: 1.205645, loss_ss: 1.202023, loss_d: 0.003622
0.2451 --- loss: 1.199989, loss_ss: 1.122537, loss_d: 0.077453
0.4902 --- loss: 1.100711, loss_ss: 1.097554, loss_d: 0.003157
0.7353 --- loss: 1.075126, loss_ss: 1.071103, loss_d: 0.004023
0.9804 --- loss: 1.068716, loss_ss: 1.057582, loss_d: 0.011135
Epoch finished! Loss: 1.1908255845308304
Starting epoch 6/10.
0.0000 --- loss: 1.036770, loss_ss: 1.027422, loss_d: 0.009349
0.2451 --- loss: 1.098028, loss_ss: 1.080853, loss_d: 0.017175
0.4902 --- loss: 1.172922, loss_ss: 1.037542, loss_d: 0.135381
0.7353 --- loss: 1.195050, loss_ss: 1.170108, loss_d: 0.024942
0.9804 --- loss: 1.088599, loss_ss: 0.911955, loss_d: 0.176645
Epoch finished! Loss: 1.1779219686985016
Starting epoch 7/10.
0.0000 --- loss: 1.011942, loss_ss: 1.010256, loss_d: 0.001685
0.2451 --- loss: 1.154573, loss_ss: 0.999178, loss_d: 0.155395
0.4902 --- loss: 1.056067, loss_ss: 1.053088, loss_d: 0.002978
0.7353 --- loss: 1.047344, loss_ss: 1.043311, loss_d: 0.004033
0.9804 --- loss: 1.047425, loss_ss: 1.005008, loss_d: 0.042416
Epoch finished! Loss: 1.0665595009922981
Starting epoch 8/10.
0.0000 --- loss: 0.969525, loss_ss: 0.966707, loss_d: 0.002817
0.2451 --- loss: 1.113374, loss_ss: 1.054084, loss_d: 0.059290
0.4902 --- loss: 0.986606, loss_ss: 0.981402, loss_d: 0.005205
0.7353 --- loss: 0.897520, loss_ss: 0.894457, loss_d: 0.003063
0.9804 --- loss: 1.051184, loss_ss: 1.003959, loss_d: 0.047225
Epoch finished! Loss: 1.000506055355072
Starting epoch 9/10.
0.0000 --- loss: 0.928374, loss_ss: 0.911458, loss_d: 0.016915
0.2451 --- loss: 0.941939, loss_ss: 0.941831, loss_d: 0.000109
0.4902 --- loss: 0.834693, loss_ss: 0.809615, loss_d: 0.025077
0.7353 --- loss: 1.091615, loss_ss: 0.985848, loss_d: 0.105768
0.9804 --- loss: 0.870292, loss_ss: 0.869244, loss_d: 0.001048
Epoch finished! Loss: 0.9582900986075401
Starting epoch 10/10.
0.0000 --- loss: 0.818885, loss_ss: 0.818267, loss_d: 0.000618
0.2451 --- loss: 0.854827, loss_ss: 0.854294, loss_d: 0.000533
0.4902 --- loss: 0.790743, loss_ss: 0.790653, loss_d: 0.000090
0.7353 --- loss: 1.010678, loss_ss: 1.010324, loss_d: 0.000354
0.9804 --- loss: 0.961067, loss_ss: 0.960943, loss_d: 0.000124
Epoch finished! Loss: 0.908078807592392
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8375
             precision    recall  f1-score   support

        0.0       0.90      0.98      0.94        57
        1.0       0.00      0.00      0.00        36
        2.0       0.87      0.90      0.88       376
        3.0       0.98      0.88      0.92       196
        4.0       0.40      0.69      0.51        55

avg / total       0.82      0.84      0.83       720
 


====== chc009-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  99.03  98.25   99.10  90.32     94.12
1  95.00   0.00  100.00   0.00      0.00
2  87.64  89.63   85.47  87.08     88.34
3  96.11  87.76   99.24  97.73     92.47
4  89.72  69.09   91.43  40.00     50.67
Total accuracy: 83.75%
Average sen: 68.94%
Average spec: 95.05%
Macro f1-score: 65.12%
Diagnosis acc on 90mins: 0.25
[0.5780403  0.41889107 0.97149956 0.70003653]
pred: 0.6671168655157089, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc009-nsrr

=== Test on chc010-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.307242, loss_ss: 1.665524, loss_d: 0.641718
0.2451 --- loss: 2.507550, loss_ss: 1.391052, loss_d: 1.116498
0.4902 --- loss: 2.149250, loss_ss: 1.417599, loss_d: 0.731650
0.7353 --- loss: 1.915662, loss_ss: 1.286335, loss_d: 0.629327
0.9804 --- loss: 1.759629, loss_ss: 1.313281, loss_d: 0.446349
Epoch finished! Loss: 2.068733686208725
Starting epoch 2/10.
0.0000 --- loss: 1.800302, loss_ss: 1.298675, loss_d: 0.501628
0.2451 --- loss: 1.569812, loss_ss: 1.208456, loss_d: 0.361356
0.4902 --- loss: 1.623052, loss_ss: 1.220510, loss_d: 0.402541
0.7353 --- loss: 1.492548, loss_ss: 1.218426, loss_d: 0.274122
0.9804 --- loss: 1.638547, loss_ss: 1.210956, loss_d: 0.427591
Epoch finished! Loss: 1.7166333734989165
Starting epoch 3/10.
0.0000 --- loss: 1.475894, loss_ss: 1.253344, loss_d: 0.222550
0.2451 --- loss: 1.242590, loss_ss: 1.140549, loss_d: 0.102042
0.4902 --- loss: 1.287609, loss_ss: 1.143671, loss_d: 0.143938
0.7353 --- loss: 1.283087, loss_ss: 1.222147, loss_d: 0.060940
0.9804 --- loss: 1.663003, loss_ss: 1.208080, loss_d: 0.454924
Epoch finished! Loss: 1.455871868133545
Starting epoch 4/10.
0.0000 --- loss: 1.201024, loss_ss: 1.180525, loss_d: 0.020499
0.2451 --- loss: 1.256718, loss_ss: 1.196083, loss_d: 0.060634
0.4902 --- loss: 1.129418, loss_ss: 1.111849, loss_d: 0.017569
0.7353 --- loss: 1.109977, loss_ss: 1.059672, loss_d: 0.050305
0.9804 --- loss: 1.427159, loss_ss: 1.224169, loss_d: 0.202991
Epoch finished! Loss: 1.2809797883033753
Starting epoch 5/10.
0.0000 --- loss: 1.054950, loss_ss: 1.041520, loss_d: 0.013430
0.2451 --- loss: 1.275851, loss_ss: 1.124773, loss_d: 0.151079
0.4902 --- loss: 1.110538, loss_ss: 1.085326, loss_d: 0.025213
0.7353 --- loss: 1.039470, loss_ss: 1.023447, loss_d: 0.016023
0.9804 --- loss: 0.994349, loss_ss: 0.959378, loss_d: 0.034971
Epoch finished! Loss: 1.13533556163311
Starting epoch 6/10.
0.0000 --- loss: 1.057274, loss_ss: 1.035069, loss_d: 0.022205
0.2451 --- loss: 1.000909, loss_ss: 0.998393, loss_d: 0.002516
0.4902 --- loss: 1.131178, loss_ss: 1.094025, loss_d: 0.037153
0.7353 --- loss: 0.986861, loss_ss: 0.985550, loss_d: 0.001311
0.9804 --- loss: 1.026615, loss_ss: 1.024803, loss_d: 0.001812
Epoch finished! Loss: 1.0441203385591507
Starting epoch 7/10.
0.0000 --- loss: 1.011857, loss_ss: 1.006145, loss_d: 0.005712
0.2451 --- loss: 0.879075, loss_ss: 0.878320, loss_d: 0.000755
0.4902 --- loss: 0.929789, loss_ss: 0.927243, loss_d: 0.002546
0.7353 --- loss: 0.930232, loss_ss: 0.929057, loss_d: 0.001175
0.9804 --- loss: 0.891628, loss_ss: 0.882241, loss_d: 0.009387
Epoch finished! Loss: 0.9838035434484482
Starting epoch 8/10.
0.0000 --- loss: 0.866723, loss_ss: 0.864558, loss_d: 0.002165
0.2451 --- loss: 0.748288, loss_ss: 0.747558, loss_d: 0.000730
0.4902 --- loss: 0.977543, loss_ss: 0.977383, loss_d: 0.000160
0.7353 --- loss: 0.879306, loss_ss: 0.879083, loss_d: 0.000224
0.9804 --- loss: 0.926928, loss_ss: 0.926465, loss_d: 0.000463
Epoch finished! Loss: 0.9229391038417816
Starting epoch 9/10.
0.0000 --- loss: 0.875341, loss_ss: 0.875186, loss_d: 0.000154
0.2451 --- loss: 1.020716, loss_ss: 1.020085, loss_d: 0.000631
0.4902 --- loss: 0.814638, loss_ss: 0.814026, loss_d: 0.000612
0.7353 --- loss: 0.809573, loss_ss: 0.809172, loss_d: 0.000401
0.9804 --- loss: 0.882773, loss_ss: 0.882548, loss_d: 0.000225
Epoch finished! Loss: 0.8936327457427978
Starting epoch 10/10.
0.0000 --- loss: 0.773081, loss_ss: 0.772998, loss_d: 0.000083
0.2451 --- loss: 0.826151, loss_ss: 0.825544, loss_d: 0.000607
0.4902 --- loss: 0.827812, loss_ss: 0.827751, loss_d: 0.000061
0.7353 --- loss: 0.821518, loss_ss: 0.820913, loss_d: 0.000605
0.9804 --- loss: 0.837254, loss_ss: 0.836996, loss_d: 0.000258
Epoch finished! Loss: 0.8400291949510574
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7055555555555556
             precision    recall  f1-score   support

        0.0       0.72      0.87      0.79       123
        1.0       0.50      0.02      0.04        43
        2.0       0.68      0.92      0.78       324
        3.0       0.91      0.14      0.24       149
        4.0       0.75      0.99      0.86        81

avg / total       0.73      0.71      0.64       720
 


====== chc010-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  92.08  86.99   93.13  72.30     78.97
1  94.03   2.33   99.85  50.00      4.44
2  76.81  92.28   64.14  67.80     78.17
3  81.94  14.09   99.65  91.30     24.42
4  96.25  98.77   95.93  75.47     85.56
Total accuracy: 70.56%
Average sen: 58.89%
Average spec: 90.54%
Macro f1-score: 54.31%
Diagnosis acc on 90mins: 0.0
[0.99959153 0.99115515 0.9998399  0.99791318]
pred: 0.9971249401569366, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc010-nsrr

=== Test on chc012-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.397864, loss_ss: 1.708509, loss_d: 0.689355
0.2457 --- loss: 2.064822, loss_ss: 1.391739, loss_d: 0.673083
0.4914 --- loss: 1.880983, loss_ss: 1.323120, loss_d: 0.557863
0.7371 --- loss: 1.930365, loss_ss: 1.420058, loss_d: 0.510307
0.9828 --- loss: 1.741810, loss_ss: 1.323573, loss_d: 0.418237
Epoch finished! Loss: 2.0612139642238616
Starting epoch 2/10.
0.0000 --- loss: 1.790981, loss_ss: 1.283012, loss_d: 0.507969
0.2457 --- loss: 1.746894, loss_ss: 1.276274, loss_d: 0.470620
0.4914 --- loss: 1.649080, loss_ss: 1.350093, loss_d: 0.298987
0.7371 --- loss: 1.689086, loss_ss: 1.185785, loss_d: 0.503301
0.9828 --- loss: 1.746614, loss_ss: 1.281877, loss_d: 0.464737
Epoch finished! Loss: 1.7681366801261902
Starting epoch 3/10.
0.0000 --- loss: 1.567608, loss_ss: 1.189229, loss_d: 0.378379
0.2457 --- loss: 1.378933, loss_ss: 1.213764, loss_d: 0.165169
0.4914 --- loss: 1.435789, loss_ss: 1.228990, loss_d: 0.206798
0.7371 --- loss: 1.307355, loss_ss: 1.205131, loss_d: 0.102224
0.9828 --- loss: 1.487578, loss_ss: 1.204623, loss_d: 0.282955
Epoch finished! Loss: 1.4986664682626725
Starting epoch 4/10.
0.0000 --- loss: 1.462300, loss_ss: 1.328403, loss_d: 0.133897
0.2457 --- loss: 1.317012, loss_ss: 1.223313, loss_d: 0.093699
0.4914 --- loss: 1.328995, loss_ss: 1.247094, loss_d: 0.081901
0.7371 --- loss: 1.186276, loss_ss: 1.131967, loss_d: 0.054309
0.9828 --- loss: 1.353059, loss_ss: 1.262113, loss_d: 0.090946
Epoch finished! Loss: 1.361053439974785
Starting epoch 5/10.
0.0000 --- loss: 1.140062, loss_ss: 1.123622, loss_d: 0.016440
0.2457 --- loss: 1.150395, loss_ss: 1.105672, loss_d: 0.044723
0.4914 --- loss: 1.146415, loss_ss: 1.140951, loss_d: 0.005465
0.7371 --- loss: 1.222349, loss_ss: 1.164951, loss_d: 0.057398
0.9828 --- loss: 1.049184, loss_ss: 1.048761, loss_d: 0.000423
Epoch finished! Loss: 1.2238713681697846
Starting epoch 6/10.
0.0000 --- loss: 1.262698, loss_ss: 1.260826, loss_d: 0.001872
0.2457 --- loss: 1.156626, loss_ss: 1.155687, loss_d: 0.000939
0.4914 --- loss: 0.975092, loss_ss: 0.973244, loss_d: 0.001848
0.7371 --- loss: 1.026801, loss_ss: 1.018463, loss_d: 0.008338
0.9828 --- loss: 1.042790, loss_ss: 1.039890, loss_d: 0.002900
Epoch finished! Loss: 1.143733412027359
Starting epoch 7/10.
0.0000 --- loss: 1.104653, loss_ss: 1.101742, loss_d: 0.002911
0.2457 --- loss: 1.026176, loss_ss: 1.001337, loss_d: 0.024839
0.4914 --- loss: 1.068167, loss_ss: 1.065483, loss_d: 0.002684
0.7371 --- loss: 1.006467, loss_ss: 1.006274, loss_d: 0.000193
0.9828 --- loss: 1.070629, loss_ss: 1.070523, loss_d: 0.000106
Epoch finished! Loss: 1.089586079120636
Starting epoch 8/10.
0.0000 --- loss: 1.102432, loss_ss: 1.101053, loss_d: 0.001379
0.2457 --- loss: 0.890111, loss_ss: 0.886705, loss_d: 0.003406
0.4914 --- loss: 0.992439, loss_ss: 0.990303, loss_d: 0.002136
0.7371 --- loss: 0.991645, loss_ss: 0.984828, loss_d: 0.006817
0.9828 --- loss: 0.971076, loss_ss: 0.970881, loss_d: 0.000196
Epoch finished! Loss: 1.0425030007958411
Starting epoch 9/10.
0.0000 --- loss: 1.008191, loss_ss: 1.005249, loss_d: 0.002942
0.2457 --- loss: 1.029217, loss_ss: 1.023844, loss_d: 0.005372
0.4914 --- loss: 0.929207, loss_ss: 0.928919, loss_d: 0.000288
0.7371 --- loss: 1.037468, loss_ss: 1.037169, loss_d: 0.000298
0.9828 --- loss: 0.902373, loss_ss: 0.902069, loss_d: 0.000304
Epoch finished! Loss: 1.00638437718153
Starting epoch 10/10.
0.0000 --- loss: 0.845870, loss_ss: 0.843413, loss_d: 0.002456
0.2457 --- loss: 0.935132, loss_ss: 0.934503, loss_d: 0.000630
0.4914 --- loss: 0.945521, loss_ss: 0.925740, loss_d: 0.019780
0.7371 --- loss: 0.868096, loss_ss: 0.867722, loss_d: 0.000374
0.9828 --- loss: 0.892932, loss_ss: 0.892680, loss_d: 0.000252
Epoch finished! Loss: 0.9697744086384773
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7511111111111111
             precision    recall  f1-score   support

        0.0       0.63      0.94      0.75        63
        1.0       0.00      0.00      0.00        22
        2.0       0.74      1.00      0.85       541
        3.0       1.00      0.33      0.50       204
        4.0       0.90      0.13      0.23        70

avg / total       0.79      0.75      0.70       900
 


====== chc012-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  95.67  93.65   95.82   62.77     75.16
1  97.56   0.00  100.00    0.00      0.00
2  79.00  99.82   47.63   74.18     85.11
3  84.89  33.33  100.00  100.00     50.00
4  93.11  12.86   99.88   90.00     22.50
Total accuracy: 75.11%
Average sen: 47.93%
Average spec: 88.67%
Macro f1-score: 46.55%
Diagnosis acc on 90mins: 0.2
[0.984487   0.99978882 0.99927086 0.99250484 0.1316587 ]
pred: 0.8215420424938202, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc012-nsrr

=== Test on chc013-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.545698, loss_ss: 1.887059, loss_d: 0.658639
0.2457 --- loss: 2.338999, loss_ss: 1.678638, loss_d: 0.660361
0.4914 --- loss: 2.271076, loss_ss: 1.652456, loss_d: 0.618620
0.7371 --- loss: 2.340248, loss_ss: 1.666023, loss_d: 0.674225
0.9828 --- loss: 2.163400, loss_ss: 1.706018, loss_d: 0.457382
Epoch finished! Loss: 2.4054566085338593
Starting epoch 2/10.
0.0000 --- loss: 2.239874, loss_ss: 1.707923, loss_d: 0.531952
0.2457 --- loss: 2.157578, loss_ss: 1.595536, loss_d: 0.562041
0.4914 --- loss: 2.068157, loss_ss: 1.628699, loss_d: 0.439458
0.7371 --- loss: 1.762905, loss_ss: 1.507589, loss_d: 0.255315
0.9828 --- loss: 2.344676, loss_ss: 1.584378, loss_d: 0.760298
Epoch finished! Loss: 2.148279219865799
Starting epoch 3/10.
0.0000 --- loss: 1.867837, loss_ss: 1.562089, loss_d: 0.305748
0.2457 --- loss: 1.814903, loss_ss: 1.558851, loss_d: 0.256052
0.4914 --- loss: 1.864817, loss_ss: 1.577384, loss_d: 0.287433
0.7371 --- loss: 2.236911, loss_ss: 1.558246, loss_d: 0.678666
0.9828 --- loss: 1.747861, loss_ss: 1.579172, loss_d: 0.168690
Epoch finished! Loss: 1.919265478849411
Starting epoch 4/10.
0.0000 --- loss: 1.533159, loss_ss: 1.421027, loss_d: 0.112132
0.2457 --- loss: 1.535693, loss_ss: 1.473868, loss_d: 0.061824
0.4914 --- loss: 1.526704, loss_ss: 1.438057, loss_d: 0.088647
0.7371 --- loss: 1.438940, loss_ss: 1.379570, loss_d: 0.059370
0.9828 --- loss: 1.572497, loss_ss: 1.378609, loss_d: 0.193888
Epoch finished! Loss: 1.6063631057739258
Starting epoch 5/10.
0.0000 --- loss: 1.382894, loss_ss: 1.369864, loss_d: 0.013030
0.2457 --- loss: 1.382613, loss_ss: 1.309950, loss_d: 0.072663
0.4914 --- loss: 1.594302, loss_ss: 1.427240, loss_d: 0.167062
0.7371 --- loss: 1.369727, loss_ss: 1.353559, loss_d: 0.016168
0.9828 --- loss: 1.295205, loss_ss: 1.273272, loss_d: 0.021934
Epoch finished! Loss: 1.4930660039186479
Starting epoch 6/10.
0.0000 --- loss: 1.414303, loss_ss: 1.411636, loss_d: 0.002668
0.2457 --- loss: 1.342518, loss_ss: 1.339491, loss_d: 0.003027
0.4914 --- loss: 1.349601, loss_ss: 1.324226, loss_d: 0.025375
0.7371 --- loss: 1.259340, loss_ss: 1.216274, loss_d: 0.043066
0.9828 --- loss: 1.269951, loss_ss: 1.268531, loss_d: 0.001420
Epoch finished! Loss: 1.3603147000074387
Starting epoch 7/10.
0.0000 --- loss: 1.322454, loss_ss: 1.321922, loss_d: 0.000532
0.2457 --- loss: 1.121673, loss_ss: 1.114143, loss_d: 0.007530
0.4914 --- loss: 1.192629, loss_ss: 1.189722, loss_d: 0.002907
0.7371 --- loss: 1.083846, loss_ss: 1.082497, loss_d: 0.001349
0.9828 --- loss: 1.063522, loss_ss: 1.061076, loss_d: 0.002447
Epoch finished! Loss: 1.2346508473157882
Starting epoch 8/10.
0.0000 --- loss: 1.103253, loss_ss: 1.102814, loss_d: 0.000440
0.2457 --- loss: 1.165591, loss_ss: 1.163047, loss_d: 0.002545
0.4914 --- loss: 1.043254, loss_ss: 1.042435, loss_d: 0.000819
0.7371 --- loss: 1.028079, loss_ss: 1.022435, loss_d: 0.005644
0.9828 --- loss: 1.002259, loss_ss: 0.999935, loss_d: 0.002324
Epoch finished! Loss: 1.1341953545808792
Starting epoch 9/10.
0.0000 --- loss: 0.988439, loss_ss: 0.987661, loss_d: 0.000778
0.2457 --- loss: 0.982632, loss_ss: 0.980605, loss_d: 0.002027
0.4914 --- loss: 0.940498, loss_ss: 0.940383, loss_d: 0.000115
0.7371 --- loss: 0.980329, loss_ss: 0.979827, loss_d: 0.000502
0.9828 --- loss: 0.996419, loss_ss: 0.984323, loss_d: 0.012096
Epoch finished! Loss: 1.0597080767154694
Starting epoch 10/10.
0.0000 --- loss: 1.050822, loss_ss: 1.048129, loss_d: 0.002693
0.2457 --- loss: 1.017467, loss_ss: 1.016823, loss_d: 0.000644
0.4914 --- loss: 0.911477, loss_ss: 0.910407, loss_d: 0.001070
0.7371 --- loss: 0.983002, loss_ss: 0.981411, loss_d: 0.001590
0.9828 --- loss: 0.819390, loss_ss: 0.818990, loss_d: 0.000400
Epoch finished! Loss: 1.0118933632969855
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5722222222222222
             precision    recall  f1-score   support

        0.0       0.29      1.00      0.45        69
        1.0       0.24      0.13      0.17        38
        2.0       0.65      0.89      0.75       410
        3.0       1.00      0.27      0.42       228
        4.0       0.81      0.11      0.19       155

avg / total       0.72      0.57      0.52       900
 


====== chc013-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  81.56  100.00   80.02   29.36     45.39
1  94.56   13.16   98.14   23.81     16.95
2  72.67   88.54   59.39   64.59     74.69
3  81.44   26.75  100.00  100.00     42.21
4  84.22   10.97   99.46   80.95     19.32
Total accuracy: 57.22%
Average sen: 47.88%
Average spec: 87.40%
Macro f1-score: 39.71%
Diagnosis acc on 90mins: 0.4
[0.05008012 0.98115414 0.27286768 0.89105147 0.67941266]
pred: 0.574913214892149, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc013-nsrr

=== Test on chc014-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.382486, loss_ss: 1.656356, loss_d: 0.726129
0.2457 --- loss: 2.143239, loss_ss: 1.508846, loss_d: 0.634393
0.4914 --- loss: 1.919892, loss_ss: 1.480094, loss_d: 0.439798
0.7371 --- loss: 2.080150, loss_ss: 1.461626, loss_d: 0.618524
0.9828 --- loss: 1.916251, loss_ss: 1.391704, loss_d: 0.524547
Epoch finished! Loss: 2.1486050367355345
Starting epoch 2/10.
0.0000 --- loss: 1.955657, loss_ss: 1.405048, loss_d: 0.550609
0.2457 --- loss: 2.158592, loss_ss: 1.382552, loss_d: 0.776040
0.4914 --- loss: 1.966669, loss_ss: 1.337683, loss_d: 0.628986
0.7371 --- loss: 1.703663, loss_ss: 1.272477, loss_d: 0.431187
0.9828 --- loss: 1.588943, loss_ss: 1.416592, loss_d: 0.172351
Epoch finished! Loss: 1.8380397379398346
Starting epoch 3/10.
0.0000 --- loss: 1.562273, loss_ss: 1.225727, loss_d: 0.336546
0.2457 --- loss: 1.472701, loss_ss: 1.269066, loss_d: 0.203635
0.4914 --- loss: 1.581664, loss_ss: 1.340470, loss_d: 0.241194
0.7371 --- loss: 1.348893, loss_ss: 1.220119, loss_d: 0.128774
0.9828 --- loss: 1.333687, loss_ss: 1.190568, loss_d: 0.143119
Epoch finished! Loss: 1.492082065343857
Starting epoch 4/10.
0.0000 --- loss: 1.204308, loss_ss: 1.158935, loss_d: 0.045373
0.2457 --- loss: 1.150498, loss_ss: 1.133528, loss_d: 0.016970
0.4914 --- loss: 1.197672, loss_ss: 1.181971, loss_d: 0.015700
0.7371 --- loss: 1.205026, loss_ss: 1.161047, loss_d: 0.043979
0.9828 --- loss: 1.330668, loss_ss: 1.298285, loss_d: 0.032383
Epoch finished! Loss: 1.274810317158699
Starting epoch 5/10.
0.0000 --- loss: 1.239881, loss_ss: 1.128752, loss_d: 0.111129
0.2457 --- loss: 1.190184, loss_ss: 1.182544, loss_d: 0.007640
0.4914 --- loss: 1.094621, loss_ss: 1.064263, loss_d: 0.030358
0.7371 --- loss: 1.082895, loss_ss: 1.059617, loss_d: 0.023278
0.9828 --- loss: 1.021816, loss_ss: 1.020998, loss_d: 0.000818
Epoch finished! Loss: 1.1584987461566925
Starting epoch 6/10.
0.0000 --- loss: 1.063562, loss_ss: 1.061507, loss_d: 0.002055
0.2457 --- loss: 1.119179, loss_ss: 1.101485, loss_d: 0.017693
0.4914 --- loss: 1.016760, loss_ss: 1.014747, loss_d: 0.002013
0.7371 --- loss: 1.241450, loss_ss: 1.070682, loss_d: 0.170769
0.9828 --- loss: 1.073719, loss_ss: 1.072634, loss_d: 0.001085
Epoch finished! Loss: 1.0909851238131523
Starting epoch 7/10.
0.0000 --- loss: 0.958830, loss_ss: 0.948351, loss_d: 0.010479
0.2457 --- loss: 1.545038, loss_ss: 1.112171, loss_d: 0.432867
0.4914 --- loss: 1.236755, loss_ss: 0.922438, loss_d: 0.314317
0.7371 --- loss: 1.203513, loss_ss: 0.984197, loss_d: 0.219316
0.9828 --- loss: 0.912725, loss_ss: 0.872952, loss_d: 0.039773
Epoch finished! Loss: 1.1318173617124558
Starting epoch 8/10.
0.0000 --- loss: 0.930823, loss_ss: 0.907307, loss_d: 0.023516
0.2457 --- loss: 0.941118, loss_ss: 0.913158, loss_d: 0.027960
0.4914 --- loss: 0.910798, loss_ss: 0.905482, loss_d: 0.005316
0.7371 --- loss: 0.953956, loss_ss: 0.889624, loss_d: 0.064333
0.9828 --- loss: 1.068553, loss_ss: 1.068192, loss_d: 0.000361
Epoch finished! Loss: 0.9741831958293915
Starting epoch 9/10.
0.0000 --- loss: 0.904191, loss_ss: 0.893731, loss_d: 0.010460
0.2457 --- loss: 0.940181, loss_ss: 0.938931, loss_d: 0.001250
0.4914 --- loss: 0.982715, loss_ss: 0.982291, loss_d: 0.000424
0.7371 --- loss: 0.935231, loss_ss: 0.931370, loss_d: 0.003862
0.9828 --- loss: 0.868559, loss_ss: 0.866880, loss_d: 0.001679
Epoch finished! Loss: 0.9152342334389687
Starting epoch 10/10.
0.0000 --- loss: 0.796098, loss_ss: 0.792530, loss_d: 0.003569
0.2457 --- loss: 0.762338, loss_ss: 0.761589, loss_d: 0.000749
0.4914 --- loss: 0.905604, loss_ss: 0.904937, loss_d: 0.000667
0.7371 --- loss: 0.855564, loss_ss: 0.854989, loss_d: 0.000575
0.9828 --- loss: 0.920206, loss_ss: 0.919845, loss_d: 0.000361
Epoch finished! Loss: 0.8772428914904594
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8466666666666667
             precision    recall  f1-score   support

        0.0       0.97      0.88      0.92       240
        1.0       0.00      0.00      0.00         6
        2.0       0.88      0.88      0.88       436
        3.0       0.98      0.67      0.80       143
        4.0       0.48      0.96      0.64        75

avg / total       0.88      0.85      0.85       900
 


====== chc014-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  96.00  87.50   99.09  97.22     92.11
1  99.33   0.00  100.00   0.00      0.00
2  88.44  88.07   88.79  88.07     88.07
3  94.56  67.13   99.74  97.96     79.67
4  91.00  96.00   90.55  48.00     64.00
Total accuracy: 84.67%
Average sen: 67.74%
Average spec: 95.63%
Macro f1-score: 64.77%
Diagnosis acc on 90mins: 0.0
[0.99999762 0.73107052 0.94527453 0.97890043 0.99990273]
pred: 0.9310291647911072, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc014-nsrr

=== Test on chc015-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.407551, loss_ss: 1.694803, loss_d: 0.712748
0.2457 --- loss: 2.160111, loss_ss: 1.688450, loss_d: 0.471662
0.4914 --- loss: 2.284426, loss_ss: 1.490498, loss_d: 0.793928
0.7371 --- loss: 2.193492, loss_ss: 1.493795, loss_d: 0.699697
0.9828 --- loss: 1.837708, loss_ss: 1.468765, loss_d: 0.368943
Epoch finished! Loss: 2.208609753847122
Starting epoch 2/10.
0.0000 --- loss: 1.948063, loss_ss: 1.472154, loss_d: 0.475910
0.2457 --- loss: 1.911999, loss_ss: 1.400921, loss_d: 0.511077
0.4914 --- loss: 1.803486, loss_ss: 1.382157, loss_d: 0.421329
0.7371 --- loss: 1.620540, loss_ss: 1.454424, loss_d: 0.166116
0.9828 --- loss: 1.469784, loss_ss: 1.275804, loss_d: 0.193981
Epoch finished! Loss: 1.8707723677158357
Starting epoch 3/10.
0.0000 --- loss: 1.613354, loss_ss: 1.389304, loss_d: 0.224051
0.2457 --- loss: 1.443900, loss_ss: 1.286544, loss_d: 0.157356
0.4914 --- loss: 1.634130, loss_ss: 1.331482, loss_d: 0.302647
0.7371 --- loss: 1.361386, loss_ss: 1.229000, loss_d: 0.132386
0.9828 --- loss: 1.341016, loss_ss: 1.294475, loss_d: 0.046541
Epoch finished! Loss: 1.5708480298519134
Starting epoch 4/10.
0.0000 --- loss: 1.379469, loss_ss: 1.286245, loss_d: 0.093224
0.2457 --- loss: 1.308395, loss_ss: 1.188777, loss_d: 0.119618
0.4914 --- loss: 1.343383, loss_ss: 1.317049, loss_d: 0.026335
0.7371 --- loss: 1.304422, loss_ss: 1.094409, loss_d: 0.210013
0.9828 --- loss: 1.556351, loss_ss: 1.185670, loss_d: 0.370680
Epoch finished! Loss: 1.3243413090705871
Starting epoch 5/10.
0.0000 --- loss: 1.130300, loss_ss: 1.119670, loss_d: 0.010630
0.2457 --- loss: 1.206744, loss_ss: 1.144183, loss_d: 0.062561
0.4914 --- loss: 1.176691, loss_ss: 1.123417, loss_d: 0.053274
0.7371 --- loss: 1.097573, loss_ss: 1.093590, loss_d: 0.003983
0.9828 --- loss: 1.369018, loss_ss: 1.116565, loss_d: 0.252453
Epoch finished! Loss: 1.2181785821914672
Starting epoch 6/10.
0.0000 --- loss: 1.059070, loss_ss: 1.054712, loss_d: 0.004358
0.2457 --- loss: 1.078103, loss_ss: 1.031143, loss_d: 0.046960
0.4914 --- loss: 1.045420, loss_ss: 1.029763, loss_d: 0.015658
0.7371 --- loss: 1.151990, loss_ss: 1.130558, loss_d: 0.021432
0.9828 --- loss: 1.074400, loss_ss: 1.006030, loss_d: 0.068371
Epoch finished! Loss: 1.1155690833926202
Starting epoch 7/10.
0.0000 --- loss: 1.032102, loss_ss: 1.019333, loss_d: 0.012769
0.2457 --- loss: 1.063894, loss_ss: 1.051432, loss_d: 0.012462
0.4914 --- loss: 1.486669, loss_ss: 1.039474, loss_d: 0.447196
0.7371 --- loss: 0.970623, loss_ss: 0.954451, loss_d: 0.016172
0.9828 --- loss: 2.507357, loss_ss: 0.885269, loss_d: 1.622088
Epoch finished! Loss: 1.0900309264659882
Starting epoch 8/10.
0.0000 --- loss: 0.916988, loss_ss: 0.916312, loss_d: 0.000676
0.2457 --- loss: 0.991532, loss_ss: 0.978506, loss_d: 0.013026
0.4914 --- loss: 1.088145, loss_ss: 1.052065, loss_d: 0.036080
0.7371 --- loss: 1.006187, loss_ss: 1.004702, loss_d: 0.001485
0.9828 --- loss: 0.851917, loss_ss: 0.849882, loss_d: 0.002036
Epoch finished! Loss: 0.9908447995781898
Starting epoch 9/10.
0.0000 --- loss: 1.021483, loss_ss: 1.014758, loss_d: 0.006725
0.2457 --- loss: 0.941408, loss_ss: 0.938415, loss_d: 0.002992
0.4914 --- loss: 0.927681, loss_ss: 0.925944, loss_d: 0.001737
0.7371 --- loss: 0.881461, loss_ss: 0.880178, loss_d: 0.001283
0.9828 --- loss: 0.972330, loss_ss: 0.971666, loss_d: 0.000664
Epoch finished! Loss: 0.9310116469860077
Starting epoch 10/10.
0.0000 --- loss: 0.869865, loss_ss: 0.829380, loss_d: 0.040485
0.2457 --- loss: 0.867257, loss_ss: 0.865079, loss_d: 0.002179
0.4914 --- loss: 0.960244, loss_ss: 0.959585, loss_d: 0.000659
0.7371 --- loss: 0.859706, loss_ss: 0.858849, loss_d: 0.000856
0.9828 --- loss: 0.825715, loss_ss: 0.824974, loss_d: 0.000741
Epoch finished! Loss: 0.8789667099714279
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7822222222222223
             precision    recall  f1-score   support

        0.0       0.29      0.95      0.45        37
        1.0       0.00      0.00      0.00        82
        2.0       0.87      0.85      0.86       474
        3.0       0.99      0.86      0.92       166
        4.0       0.72      0.86      0.78       141

avg / total       0.77      0.78      0.76       900
 


====== chc015-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  90.44  94.59   90.27  29.41     44.87
1  90.67   0.00   99.76   0.00      0.00
2  85.56  85.44   85.68  86.91     86.17
3  97.33  86.14   99.86  99.31     92.26
4  92.44  85.82   93.68  71.60     78.06
Total accuracy: 78.22%
Average sen: 70.40%
Average spec: 93.85%
Macro f1-score: 60.27%
Diagnosis acc on 90mins: 0.0
[0.99976224 0.9999814  0.9999572  0.99985695 0.99999917]
pred: 0.9999113917350769, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc015-nsrr

=== Test on chc016-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.388408, loss_ss: 1.702393, loss_d: 0.686015
0.2457 --- loss: 2.113957, loss_ss: 1.588217, loss_d: 0.525740
0.4914 --- loss: 2.204099, loss_ss: 1.565566, loss_d: 0.638533
0.7371 --- loss: 1.854096, loss_ss: 1.537715, loss_d: 0.316381
0.9828 --- loss: 1.798847, loss_ss: 1.539756, loss_d: 0.259091
Epoch finished! Loss: 2.28383147418499
Starting epoch 2/10.
0.0000 --- loss: 2.005668, loss_ss: 1.495318, loss_d: 0.510349
0.2457 --- loss: 1.941513, loss_ss: 1.520779, loss_d: 0.420734
0.4914 --- loss: 1.952109, loss_ss: 1.563327, loss_d: 0.388782
0.7371 --- loss: 1.871312, loss_ss: 1.449409, loss_d: 0.421903
0.9828 --- loss: 1.538710, loss_ss: 1.314103, loss_d: 0.224607
Epoch finished! Loss: 1.9270988762378694
Starting epoch 3/10.
0.0000 --- loss: 1.504447, loss_ss: 1.386375, loss_d: 0.118072
0.2457 --- loss: 1.617097, loss_ss: 1.422427, loss_d: 0.194670
0.4914 --- loss: 1.847742, loss_ss: 1.412266, loss_d: 0.435477
0.7371 --- loss: 1.550874, loss_ss: 1.317455, loss_d: 0.233419
0.9828 --- loss: 1.290642, loss_ss: 1.277002, loss_d: 0.013641
Epoch finished! Loss: 1.5848163723945619
Starting epoch 4/10.
0.0000 --- loss: 1.325426, loss_ss: 1.288970, loss_d: 0.036456
0.2457 --- loss: 1.356062, loss_ss: 1.293721, loss_d: 0.062341
0.4914 --- loss: 1.327699, loss_ss: 1.238333, loss_d: 0.089366
0.7371 --- loss: 1.296382, loss_ss: 1.216383, loss_d: 0.079999
0.9828 --- loss: 1.693442, loss_ss: 1.170038, loss_d: 0.523404
Epoch finished! Loss: 1.3561561048030852
Starting epoch 5/10.
0.0000 --- loss: 1.158752, loss_ss: 1.144535, loss_d: 0.014216
0.2457 --- loss: 1.268387, loss_ss: 1.266819, loss_d: 0.001568
0.4914 --- loss: 1.098935, loss_ss: 1.091563, loss_d: 0.007372
0.7371 --- loss: 1.106402, loss_ss: 1.091173, loss_d: 0.015229
0.9828 --- loss: 1.057582, loss_ss: 1.056089, loss_d: 0.001493
Epoch finished! Loss: 1.192559278011322
Starting epoch 6/10.
0.0000 --- loss: 1.026477, loss_ss: 1.024515, loss_d: 0.001961
0.2457 --- loss: 1.202475, loss_ss: 1.201902, loss_d: 0.000573
0.4914 --- loss: 1.069214, loss_ss: 1.064773, loss_d: 0.004441
0.7371 --- loss: 0.984346, loss_ss: 0.981496, loss_d: 0.002849
0.9828 --- loss: 1.154509, loss_ss: 1.089390, loss_d: 0.065119
Epoch finished! Loss: 1.0909807294607163
Starting epoch 7/10.
0.0000 --- loss: 1.028949, loss_ss: 1.026318, loss_d: 0.002631
0.2457 --- loss: 1.075280, loss_ss: 1.074497, loss_d: 0.000782
0.4914 --- loss: 0.963655, loss_ss: 0.963444, loss_d: 0.000212
0.7371 --- loss: 0.963108, loss_ss: 0.962521, loss_d: 0.000588
0.9828 --- loss: 1.033281, loss_ss: 1.032722, loss_d: 0.000560
Epoch finished! Loss: 1.0267786905169487
Starting epoch 8/10.
0.0000 --- loss: 0.928627, loss_ss: 0.926376, loss_d: 0.002251
0.2457 --- loss: 0.910965, loss_ss: 0.910271, loss_d: 0.000695
0.4914 --- loss: 1.055385, loss_ss: 1.048543, loss_d: 0.006841
0.7371 --- loss: 0.855509, loss_ss: 0.855288, loss_d: 0.000221
0.9828 --- loss: 0.955190, loss_ss: 0.954299, loss_d: 0.000891
Epoch finished! Loss: 0.9728425875306129
Starting epoch 9/10.
0.0000 --- loss: 0.905091, loss_ss: 0.897693, loss_d: 0.007398
0.2457 --- loss: 0.932370, loss_ss: 0.931140, loss_d: 0.001231
0.4914 --- loss: 1.096784, loss_ss: 1.095800, loss_d: 0.000984
0.7371 --- loss: 0.844934, loss_ss: 0.844410, loss_d: 0.000524
0.9828 --- loss: 0.767850, loss_ss: 0.766000, loss_d: 0.001851
Epoch finished! Loss: 0.9181549042463303
Starting epoch 10/10.
0.0000 --- loss: 0.873231, loss_ss: 0.873174, loss_d: 0.000057
0.2457 --- loss: 0.803003, loss_ss: 0.799500, loss_d: 0.003503
0.4914 --- loss: 0.826970, loss_ss: 0.825497, loss_d: 0.001472
0.7371 --- loss: 0.858314, loss_ss: 0.858295, loss_d: 0.000020
0.9828 --- loss: 0.773228, loss_ss: 0.770699, loss_d: 0.002529
Epoch finished! Loss: 0.8772314250469208
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7411111111111112
             precision    recall  f1-score   support

        0.0       0.61      0.99      0.75       226
        1.0       0.00      0.00      0.00        55
        2.0       0.81      0.89      0.85       410
        3.0       1.00      0.46      0.63       108
        4.0       0.91      0.30      0.45       101

avg / total       0.74      0.74      0.70       900
 


====== chc016-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  83.78  99.12   78.64   60.87     75.42
1  93.89   0.00  100.00    0.00      0.00
2  85.22  88.54   82.45   80.85     84.52
3  93.56  46.30  100.00  100.00     63.29
4  91.78  29.70   99.62   90.91     44.78
Total accuracy: 74.11%
Average sen: 52.73%
Average spec: 92.14%
Macro f1-score: 53.60%
Diagnosis acc on 90mins: 0.2
[0.9970367  0.9998135  0.3105512  0.8790316  0.99940372]
pred: 0.8371673405170441, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc016-nsrr

=== Test on chc022-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.263063, loss_ss: 1.584856, loss_d: 0.678207
0.2451 --- loss: 2.686145, loss_ss: 1.484651, loss_d: 1.201494
0.4902 --- loss: 1.942502, loss_ss: 1.423465, loss_d: 0.519038
0.7353 --- loss: 1.940057, loss_ss: 1.387229, loss_d: 0.552828
0.9804 --- loss: 1.925607, loss_ss: 1.318716, loss_d: 0.606891
Epoch finished! Loss: 2.1386778324842455
Starting epoch 2/10.
0.0000 --- loss: 1.712241, loss_ss: 1.297976, loss_d: 0.414265
0.2451 --- loss: 1.569300, loss_ss: 1.379703, loss_d: 0.189597
0.4902 --- loss: 1.752611, loss_ss: 1.320564, loss_d: 0.432048
0.7353 --- loss: 2.046202, loss_ss: 1.297079, loss_d: 0.749123
0.9804 --- loss: 2.042345, loss_ss: 1.320517, loss_d: 0.721828
Epoch finished! Loss: 1.8081290483474732
Starting epoch 3/10.
0.0000 --- loss: 1.582292, loss_ss: 1.225615, loss_d: 0.356677
0.2451 --- loss: 1.392528, loss_ss: 1.256347, loss_d: 0.136181
0.4902 --- loss: 1.347099, loss_ss: 1.218205, loss_d: 0.128894
0.7353 --- loss: 1.255681, loss_ss: 1.219764, loss_d: 0.035917
0.9804 --- loss: 1.267151, loss_ss: 1.215665, loss_d: 0.051486
Epoch finished! Loss: 1.4592507988214494
Starting epoch 4/10.
0.0000 --- loss: 1.301215, loss_ss: 1.216438, loss_d: 0.084778
0.2451 --- loss: 1.170766, loss_ss: 1.107637, loss_d: 0.063129
0.4902 --- loss: 1.284317, loss_ss: 1.242737, loss_d: 0.041580
0.7353 --- loss: 1.354777, loss_ss: 1.060566, loss_d: 0.294211
0.9804 --- loss: 1.218470, loss_ss: 1.186820, loss_d: 0.031651
Epoch finished! Loss: 1.2874142974615097
Starting epoch 5/10.
0.0000 --- loss: 1.170396, loss_ss: 1.155405, loss_d: 0.014991
0.2451 --- loss: 1.297683, loss_ss: 1.033498, loss_d: 0.264185
0.4902 --- loss: 1.167324, loss_ss: 1.148513, loss_d: 0.018811
0.7353 --- loss: 1.203621, loss_ss: 1.195915, loss_d: 0.007706
0.9804 --- loss: 1.377554, loss_ss: 1.374029, loss_d: 0.003524
Epoch finished! Loss: 1.2136395961046218
Starting epoch 6/10.
0.0000 --- loss: 1.111975, loss_ss: 1.110155, loss_d: 0.001819
0.2451 --- loss: 0.999468, loss_ss: 0.998830, loss_d: 0.000639
0.4902 --- loss: 1.203358, loss_ss: 1.195069, loss_d: 0.008289
0.7353 --- loss: 1.044184, loss_ss: 1.033842, loss_d: 0.010341
0.9804 --- loss: 1.155046, loss_ss: 1.152063, loss_d: 0.002983
Epoch finished! Loss: 1.1090065777301787
Starting epoch 7/10.
0.0000 --- loss: 1.041436, loss_ss: 1.037097, loss_d: 0.004339
0.2451 --- loss: 0.938704, loss_ss: 0.932395, loss_d: 0.006310
0.4902 --- loss: 0.905417, loss_ss: 0.904324, loss_d: 0.001093
0.7353 --- loss: 1.092731, loss_ss: 1.092200, loss_d: 0.000531
0.9804 --- loss: 0.933298, loss_ss: 0.930345, loss_d: 0.002952
Epoch finished! Loss: 1.0355611085891723
Starting epoch 8/10.
0.0000 --- loss: 0.969250, loss_ss: 0.964450, loss_d: 0.004800
0.2451 --- loss: 0.896926, loss_ss: 0.892428, loss_d: 0.004497
0.4902 --- loss: 1.057642, loss_ss: 1.056969, loss_d: 0.000673
0.7353 --- loss: 0.819478, loss_ss: 0.818438, loss_d: 0.001041
0.9804 --- loss: 0.889673, loss_ss: 0.888983, loss_d: 0.000690
Epoch finished! Loss: 0.9893890485167504
Starting epoch 9/10.
0.0000 --- loss: 0.899130, loss_ss: 0.897449, loss_d: 0.001681
0.2451 --- loss: 0.990345, loss_ss: 0.989803, loss_d: 0.000543
0.4902 --- loss: 0.905798, loss_ss: 0.905283, loss_d: 0.000515
0.7353 --- loss: 0.895404, loss_ss: 0.894999, loss_d: 0.000405
0.9804 --- loss: 0.920199, loss_ss: 0.919945, loss_d: 0.000255
Epoch finished! Loss: 0.94444560110569
Starting epoch 10/10.
0.0000 --- loss: 0.892474, loss_ss: 0.892424, loss_d: 0.000050
0.2451 --- loss: 0.919907, loss_ss: 0.919350, loss_d: 0.000556
0.4902 --- loss: 0.817308, loss_ss: 0.816656, loss_d: 0.000652
0.7353 --- loss: 0.767609, loss_ss: 0.767268, loss_d: 0.000342
0.9804 --- loss: 0.952156, loss_ss: 0.951940, loss_d: 0.000216
Epoch finished! Loss: 0.910799452662468
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7694444444444445
             precision    recall  f1-score   support

        0.0       0.97      0.68      0.80        91
        1.0       0.00      0.00      0.00         5
        2.0       0.87      0.70      0.78       328
        3.0       0.70      0.93      0.80       187
        4.0       0.61      0.81      0.70       109

avg / total       0.79      0.77      0.77       720
 


====== chc022-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.69  68.13   99.68  96.88     80.00
1  99.31   0.00  100.00   0.00      0.00
2  81.67  70.12   91.33  87.12     77.70
3  87.92  93.05   86.12  70.16     80.00
4  89.31  80.73   90.83  61.11     69.57
Total accuracy: 76.94%
Average sen: 62.41%
Average spec: 93.59%
Macro f1-score: 61.45%
Diagnosis acc on 90mins: 0.5
[0.99885833 0.162496   0.85799247 0.43500096]
pred: 0.6135869398713112, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc022-nsrr

=== Test on chc025-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.290033, loss_ss: 1.599273, loss_d: 0.690760
0.2451 --- loss: 1.575009, loss_ss: 1.446059, loss_d: 0.128949
0.4902 --- loss: 2.237229, loss_ss: 1.425055, loss_d: 0.812174
0.7353 --- loss: 1.917122, loss_ss: 1.404555, loss_d: 0.512567
0.9804 --- loss: 2.021254, loss_ss: 1.393763, loss_d: 0.627491
Epoch finished! Loss: 2.078114923834801
Starting epoch 2/10.
0.0000 --- loss: 1.878134, loss_ss: 1.423137, loss_d: 0.454997
0.2451 --- loss: 1.544947, loss_ss: 1.319523, loss_d: 0.225424
0.4902 --- loss: 1.745889, loss_ss: 1.417737, loss_d: 0.328152
0.7353 --- loss: 1.564067, loss_ss: 1.278315, loss_d: 0.285752
0.9804 --- loss: 1.896240, loss_ss: 1.292428, loss_d: 0.603812
Epoch finished! Loss: 1.808730897307396
Starting epoch 3/10.
0.0000 --- loss: 1.619502, loss_ss: 1.338638, loss_d: 0.280865
0.2451 --- loss: 1.537437, loss_ss: 1.333281, loss_d: 0.204156
0.4902 --- loss: 1.338403, loss_ss: 1.237889, loss_d: 0.100514
0.7353 --- loss: 1.331915, loss_ss: 1.241718, loss_d: 0.090198
0.9804 --- loss: 1.360940, loss_ss: 1.185043, loss_d: 0.175898
Epoch finished! Loss: 1.4809687614440918
Starting epoch 4/10.
0.0000 --- loss: 1.298129, loss_ss: 1.289510, loss_d: 0.008619
0.2451 --- loss: 1.215925, loss_ss: 1.179005, loss_d: 0.036920
0.4902 --- loss: 1.203992, loss_ss: 1.183941, loss_d: 0.020051
0.7353 --- loss: 1.791548, loss_ss: 1.277519, loss_d: 0.514030
0.9804 --- loss: 1.370879, loss_ss: 1.354454, loss_d: 0.016426
Epoch finished! Loss: 1.2963716953992843
Starting epoch 5/10.
0.0000 --- loss: 1.124034, loss_ss: 1.121477, loss_d: 0.002557
0.2451 --- loss: 1.128101, loss_ss: 1.092236, loss_d: 0.035865
0.4902 --- loss: 1.170414, loss_ss: 1.146438, loss_d: 0.023976
0.7353 --- loss: 1.159008, loss_ss: 1.130470, loss_d: 0.028538
0.9804 --- loss: 1.242202, loss_ss: 1.103564, loss_d: 0.138638
Epoch finished! Loss: 1.258316621184349
Starting epoch 6/10.
0.0000 --- loss: 1.147481, loss_ss: 1.145677, loss_d: 0.001804
0.2451 --- loss: 1.194144, loss_ss: 1.161169, loss_d: 0.032975
0.4902 --- loss: 1.176709, loss_ss: 1.098961, loss_d: 0.077748
0.7353 --- loss: 1.050387, loss_ss: 1.026988, loss_d: 0.023399
0.9804 --- loss: 1.138448, loss_ss: 1.091070, loss_d: 0.047378
Epoch finished! Loss: 1.187928205728531
Starting epoch 7/10.
0.0000 --- loss: 1.175500, loss_ss: 1.172979, loss_d: 0.002521
0.2451 --- loss: 1.133250, loss_ss: 1.129252, loss_d: 0.003997
0.4902 --- loss: 1.002430, loss_ss: 0.998517, loss_d: 0.003913
0.7353 --- loss: 0.970695, loss_ss: 0.970221, loss_d: 0.000474
0.9804 --- loss: 1.004977, loss_ss: 0.995908, loss_d: 0.009069
Epoch finished! Loss: 1.0957317277789116
Starting epoch 8/10.
0.0000 --- loss: 0.996347, loss_ss: 0.992338, loss_d: 0.004009
0.2451 --- loss: 1.010802, loss_ss: 1.009827, loss_d: 0.000975
0.4902 --- loss: 1.059325, loss_ss: 1.057681, loss_d: 0.001644
0.7353 --- loss: 1.029174, loss_ss: 1.028793, loss_d: 0.000381
0.9804 --- loss: 0.893958, loss_ss: 0.893758, loss_d: 0.000199
Epoch finished! Loss: 1.0258743792772294
Starting epoch 9/10.
0.0000 --- loss: 1.030001, loss_ss: 1.029850, loss_d: 0.000150
0.2451 --- loss: 0.883740, loss_ss: 0.883393, loss_d: 0.000347
0.4902 --- loss: 0.914071, loss_ss: 0.913270, loss_d: 0.000801
0.7353 --- loss: 0.883941, loss_ss: 0.883394, loss_d: 0.000547
0.9804 --- loss: 1.000698, loss_ss: 1.000148, loss_d: 0.000550
Epoch finished! Loss: 0.9862362280488014
Starting epoch 10/10.
0.0000 --- loss: 0.987978, loss_ss: 0.986915, loss_d: 0.001063
0.2451 --- loss: 0.891414, loss_ss: 0.890597, loss_d: 0.000816
0.4902 --- loss: 0.867159, loss_ss: 0.846778, loss_d: 0.020381
0.7353 --- loss: 0.849158, loss_ss: 0.849061, loss_d: 0.000097
0.9804 --- loss: 0.903530, loss_ss: 0.865143, loss_d: 0.038386
Epoch finished! Loss: 0.9678491845726966
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.49166666666666664
             precision    recall  f1-score   support

        0.0       0.09      0.71      0.16        21
        1.0       0.22      0.51      0.31        39
        2.0       0.67      0.66      0.66       382
        3.0       1.00      0.06      0.12       114
        4.0       0.74      0.37      0.50       164

avg / total       0.70      0.49      0.50       720
 


====== chc025-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  78.19  71.43   78.40    9.04     16.04
1  87.64  51.28   89.72   22.22     31.01
2  64.58  65.71   63.31   66.93     66.31
3  85.14   6.14  100.00  100.00     11.57
4  82.78  37.20   96.22   74.39     49.59
Total accuracy: 49.17%
Average sen: 46.35%
Average spec: 85.53%
Macro f1-score: 34.91%
Diagnosis acc on 90mins: 0.0
[0.9999963  0.99864596 0.99628472 0.99339998]
pred: 0.9970817416906357, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc025-nsrr

=== Test on chc027-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.258988, loss_ss: 1.581505, loss_d: 0.677483
0.2457 --- loss: 1.964364, loss_ss: 1.435062, loss_d: 0.529302
0.4914 --- loss: 1.952131, loss_ss: 1.446009, loss_d: 0.506123
0.7371 --- loss: 2.276811, loss_ss: 1.543540, loss_d: 0.733272
0.9828 --- loss: 1.609889, loss_ss: 1.450577, loss_d: 0.159312
Epoch finished! Loss: 2.1084199219942095
Starting epoch 2/10.
0.0000 --- loss: 1.851801, loss_ss: 1.397106, loss_d: 0.454695
0.2457 --- loss: 1.629371, loss_ss: 1.283102, loss_d: 0.346269
0.4914 --- loss: 1.732188, loss_ss: 1.337462, loss_d: 0.394727
0.7371 --- loss: 1.693758, loss_ss: 1.362870, loss_d: 0.330888
0.9828 --- loss: 1.711329, loss_ss: 1.279139, loss_d: 0.432189
Epoch finished! Loss: 1.823443776369095
Starting epoch 3/10.
0.0000 --- loss: 1.473021, loss_ss: 1.335697, loss_d: 0.137324
0.2457 --- loss: 1.389802, loss_ss: 1.266069, loss_d: 0.123733
0.4914 --- loss: 1.327543, loss_ss: 1.259224, loss_d: 0.068319
0.7371 --- loss: 1.324184, loss_ss: 1.297643, loss_d: 0.026540
0.9828 --- loss: 1.333882, loss_ss: 1.095794, loss_d: 0.238088
Epoch finished! Loss: 1.479297024011612
Starting epoch 4/10.
0.0000 --- loss: 1.228444, loss_ss: 1.206604, loss_d: 0.021840
0.2457 --- loss: 1.232693, loss_ss: 1.138245, loss_d: 0.094447
0.4914 --- loss: 1.160631, loss_ss: 1.131666, loss_d: 0.028966
0.7371 --- loss: 1.172671, loss_ss: 1.138700, loss_d: 0.033970
0.9828 --- loss: 1.115587, loss_ss: 1.113875, loss_d: 0.001713
Epoch finished! Loss: 1.2666289418935777
Starting epoch 5/10.
0.0000 --- loss: 1.144779, loss_ss: 1.143231, loss_d: 0.001549
0.2457 --- loss: 1.152711, loss_ss: 1.150846, loss_d: 0.001865
0.4914 --- loss: 1.087252, loss_ss: 1.084844, loss_d: 0.002408
0.7371 --- loss: 1.779908, loss_ss: 1.179983, loss_d: 0.599924
0.9828 --- loss: 0.990768, loss_ss: 0.952597, loss_d: 0.038172
Epoch finished! Loss: 1.152493442595005
Starting epoch 6/10.
0.0000 --- loss: 1.009920, loss_ss: 1.003493, loss_d: 0.006427
0.2457 --- loss: 1.089040, loss_ss: 1.085104, loss_d: 0.003936
0.4914 --- loss: 1.019832, loss_ss: 0.999657, loss_d: 0.020174
0.7371 --- loss: 0.964711, loss_ss: 0.962993, loss_d: 0.001718
0.9828 --- loss: 1.285811, loss_ss: 1.124174, loss_d: 0.161636
Epoch finished! Loss: 1.059140819311142
Starting epoch 7/10.
0.0000 --- loss: 0.898341, loss_ss: 0.895453, loss_d: 0.002889
0.2457 --- loss: 0.920337, loss_ss: 0.913516, loss_d: 0.006821
0.4914 --- loss: 1.063492, loss_ss: 1.056761, loss_d: 0.006731
0.7371 --- loss: 0.988038, loss_ss: 0.985189, loss_d: 0.002849
0.9828 --- loss: 0.796364, loss_ss: 0.790869, loss_d: 0.005494
Epoch finished! Loss: 1.0313355222344398
Starting epoch 8/10.
0.0000 --- loss: 1.015802, loss_ss: 1.015482, loss_d: 0.000320
0.2457 --- loss: 0.987453, loss_ss: 0.985055, loss_d: 0.002398
0.4914 --- loss: 0.923432, loss_ss: 0.923168, loss_d: 0.000264
0.7371 --- loss: 0.888104, loss_ss: 0.887788, loss_d: 0.000316
0.9828 --- loss: 0.947271, loss_ss: 0.944927, loss_d: 0.002344
Epoch finished! Loss: 0.9432526275515556
Starting epoch 9/10.
0.0000 --- loss: 0.931453, loss_ss: 0.913757, loss_d: 0.017696
0.2457 --- loss: 0.983584, loss_ss: 0.983504, loss_d: 0.000080
0.4914 --- loss: 0.732867, loss_ss: 0.732470, loss_d: 0.000398
0.7371 --- loss: 0.954291, loss_ss: 0.952189, loss_d: 0.002102
0.9828 --- loss: 1.079424, loss_ss: 1.079222, loss_d: 0.000203
Epoch finished! Loss: 0.9089656949043274
Starting epoch 10/10.
0.0000 --- loss: 0.969505, loss_ss: 0.955634, loss_d: 0.013871
0.2457 --- loss: 0.861538, loss_ss: 0.861395, loss_d: 0.000143
0.4914 --- loss: 0.824565, loss_ss: 0.824320, loss_d: 0.000245
0.7371 --- loss: 0.783131, loss_ss: 0.782355, loss_d: 0.000776
0.9828 --- loss: 0.842338, loss_ss: 0.841991, loss_d: 0.000347
Epoch finished! Loss: 0.8697532564401627
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.59
             precision    recall  f1-score   support

        0.0       0.94      0.74      0.83       277
        1.0       0.00      0.00      0.00        66
        2.0       0.65      0.45      0.53       293
        3.0       1.00      0.63      0.77       189
        4.0       0.21      1.00      0.34        75

avg / total       0.73      0.59      0.62       900
 


====== chc027-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  90.44   74.01   97.75   93.61     82.66
1  92.67    0.00  100.00    0.00      0.00
2  74.33   45.05   88.47   65.35     53.33
3  92.22   62.96  100.00  100.00     77.27
4  68.33  100.00   65.45   20.83     34.48
Total accuracy: 59.00%
Average sen: 56.40%
Average spec: 90.34%
Macro f1-score: 49.55%
Diagnosis acc on 90mins: 0.0
[0.9999907  0.9998697  0.99995768 0.99988389 0.99996555]
pred: 0.9999335050582886, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc027-nsrr

=== Test on chc028-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.545820, loss_ss: 1.807694, loss_d: 0.738126
0.2451 --- loss: 2.326535, loss_ss: 1.711886, loss_d: 0.614649
0.4902 --- loss: 2.458842, loss_ss: 1.648032, loss_d: 0.810810
0.7353 --- loss: 2.152421, loss_ss: 1.599488, loss_d: 0.552933
0.9804 --- loss: 1.818550, loss_ss: 1.496006, loss_d: 0.322544
Epoch finished! Loss: 2.3264071881771087
Starting epoch 2/10.
0.0000 --- loss: 2.111362, loss_ss: 1.477195, loss_d: 0.634167
0.2451 --- loss: 1.851107, loss_ss: 1.417193, loss_d: 0.433914
0.4902 --- loss: 1.795141, loss_ss: 1.434653, loss_d: 0.360488
0.7353 --- loss: 2.027483, loss_ss: 1.379652, loss_d: 0.647831
0.9804 --- loss: 2.160250, loss_ss: 1.345544, loss_d: 0.814706
Epoch finished! Loss: 1.9553293347358705
Starting epoch 3/10.
0.0000 --- loss: 1.608400, loss_ss: 1.327313, loss_d: 0.281086
0.2451 --- loss: 1.643817, loss_ss: 1.344482, loss_d: 0.299335
0.4902 --- loss: 1.428903, loss_ss: 1.296588, loss_d: 0.132315
0.7353 --- loss: 1.368555, loss_ss: 1.305688, loss_d: 0.062868
0.9804 --- loss: 1.609433, loss_ss: 1.319902, loss_d: 0.289531
Epoch finished! Loss: 1.6317523747682572
Starting epoch 4/10.
0.0000 --- loss: 1.364427, loss_ss: 1.286576, loss_d: 0.077851
0.2451 --- loss: 1.379362, loss_ss: 1.309948, loss_d: 0.069415
0.4902 --- loss: 1.313348, loss_ss: 1.294382, loss_d: 0.018966
0.7353 --- loss: 1.590939, loss_ss: 1.264749, loss_d: 0.326190
0.9804 --- loss: 1.194592, loss_ss: 1.125757, loss_d: 0.068835
Epoch finished! Loss: 1.3953551083803177
Starting epoch 5/10.
0.0000 --- loss: 1.311408, loss_ss: 1.287280, loss_d: 0.024128
0.2451 --- loss: 1.242870, loss_ss: 1.204676, loss_d: 0.038193
0.4902 --- loss: 1.206917, loss_ss: 1.197985, loss_d: 0.008932
0.7353 --- loss: 1.300896, loss_ss: 1.242091, loss_d: 0.058804
0.9804 --- loss: 1.403235, loss_ss: 1.160922, loss_d: 0.242313
Epoch finished! Loss: 1.3133276253938675
Starting epoch 6/10.
0.0000 --- loss: 1.164696, loss_ss: 1.158274, loss_d: 0.006422
0.2451 --- loss: 1.436021, loss_ss: 1.129591, loss_d: 0.306431
0.4902 --- loss: 1.171112, loss_ss: 1.159455, loss_d: 0.011657
0.7353 --- loss: 1.244347, loss_ss: 1.204830, loss_d: 0.039517
0.9804 --- loss: 1.030056, loss_ss: 1.008404, loss_d: 0.021651
Epoch finished! Loss: 1.1850422322750092
Starting epoch 7/10.
0.0000 --- loss: 1.201338, loss_ss: 1.078236, loss_d: 0.123102
0.2451 --- loss: 1.124586, loss_ss: 1.117412, loss_d: 0.007174
0.4902 --- loss: 1.047421, loss_ss: 1.036663, loss_d: 0.010759
0.7353 --- loss: 1.044705, loss_ss: 1.042697, loss_d: 0.002008
0.9804 --- loss: 1.244140, loss_ss: 0.996885, loss_d: 0.247254
Epoch finished! Loss: 1.1489496633410454
Starting epoch 8/10.
0.0000 --- loss: 0.950501, loss_ss: 0.949099, loss_d: 0.001402
0.2451 --- loss: 1.098143, loss_ss: 1.087608, loss_d: 0.010534
0.4902 --- loss: 1.035149, loss_ss: 1.014565, loss_d: 0.020584
0.7353 --- loss: 0.959987, loss_ss: 0.959746, loss_d: 0.000241
0.9804 --- loss: 0.907381, loss_ss: 0.887078, loss_d: 0.020303
Epoch finished! Loss: 1.0298083439469337
Starting epoch 9/10.
0.0000 --- loss: 1.020385, loss_ss: 1.016791, loss_d: 0.003594
0.2451 --- loss: 0.986400, loss_ss: 0.985826, loss_d: 0.000573
0.4902 --- loss: 0.946071, loss_ss: 0.944424, loss_d: 0.001646
0.7353 --- loss: 0.932133, loss_ss: 0.923987, loss_d: 0.008147
0.9804 --- loss: 0.920802, loss_ss: 0.918355, loss_d: 0.002447
Epoch finished! Loss: 0.9497037783265114
Starting epoch 10/10.
0.0000 --- loss: 0.914081, loss_ss: 0.914022, loss_d: 0.000059
0.2451 --- loss: 0.830823, loss_ss: 0.822658, loss_d: 0.008165
0.4902 --- loss: 0.789859, loss_ss: 0.788068, loss_d: 0.001791
0.7353 --- loss: 0.855443, loss_ss: 0.854778, loss_d: 0.000666
0.9804 --- loss: 0.938400, loss_ss: 0.937751, loss_d: 0.000649
Epoch finished! Loss: 0.9079309478402138
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6722222222222223
             precision    recall  f1-score   support

        0.0       0.68      0.97      0.80        98
        1.0       0.50      0.07      0.12        44
        2.0       0.93      0.50      0.65       359
        3.0       0.98      0.94      0.96       145
        4.0       0.29      0.97      0.45        74

avg / total       0.82      0.67      0.68       720
 


====== chc028-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  93.47  96.94   92.93  68.35     80.17
1  93.89   6.82   99.56  50.00     12.00
2  73.06  49.58   96.40  93.19     64.73
3  98.33  93.79   99.48  97.84     95.77
4  75.69  97.30   73.22  29.39     45.14
Total accuracy: 67.22%
Average sen: 68.89%
Average spec: 92.32%
Macro f1-score: 59.56%
Diagnosis acc on 90mins: 0.0
[0.99999976 0.9998697  0.99516052 0.99980682]
pred: 0.9987092018127441, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc028-nsrr

=== Test on chc033-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.626741, loss_ss: 1.918945, loss_d: 0.707796
0.2451 --- loss: 2.775259, loss_ss: 1.642847, loss_d: 1.132413
0.4902 --- loss: 2.484030, loss_ss: 1.604435, loss_d: 0.879595
0.7353 --- loss: 2.232870, loss_ss: 1.671210, loss_d: 0.561659
0.9804 --- loss: 2.128111, loss_ss: 1.658257, loss_d: 0.469854
Epoch finished! Loss: 2.3138741493225097
Starting epoch 2/10.
0.0000 --- loss: 1.970145, loss_ss: 1.487635, loss_d: 0.482510
0.2451 --- loss: 1.720160, loss_ss: 1.476051, loss_d: 0.244109
0.4902 --- loss: 2.184206, loss_ss: 1.533977, loss_d: 0.650230
0.7353 --- loss: 1.758743, loss_ss: 1.457610, loss_d: 0.301133
0.9804 --- loss: 1.936394, loss_ss: 1.449906, loss_d: 0.486488
Epoch finished! Loss: 1.9406205773353578
Starting epoch 3/10.
0.0000 --- loss: 1.609237, loss_ss: 1.449165, loss_d: 0.160072
0.2451 --- loss: 1.498529, loss_ss: 1.353578, loss_d: 0.144951
0.4902 --- loss: 1.593352, loss_ss: 1.373030, loss_d: 0.220322
0.7353 --- loss: 1.602723, loss_ss: 1.324460, loss_d: 0.278264
0.9804 --- loss: 1.372484, loss_ss: 1.182800, loss_d: 0.189684
Epoch finished! Loss: 1.6040537536144257
Starting epoch 4/10.
0.0000 --- loss: 1.328918, loss_ss: 1.293008, loss_d: 0.035910
0.2451 --- loss: 1.344020, loss_ss: 1.326689, loss_d: 0.017331
0.4902 --- loss: 1.449190, loss_ss: 1.400360, loss_d: 0.048830
0.7353 --- loss: 1.456569, loss_ss: 1.210818, loss_d: 0.245751
0.9804 --- loss: 1.359182, loss_ss: 1.269511, loss_d: 0.089671
Epoch finished! Loss: 1.406997698545456
Starting epoch 5/10.
0.0000 --- loss: 1.252834, loss_ss: 1.240492, loss_d: 0.012342
0.2451 --- loss: 1.225255, loss_ss: 1.128909, loss_d: 0.096347
0.4902 --- loss: 1.288635, loss_ss: 1.249207, loss_d: 0.039427
0.7353 --- loss: 1.238734, loss_ss: 1.227057, loss_d: 0.011677
0.9804 --- loss: 1.515361, loss_ss: 1.122301, loss_d: 0.393060
Epoch finished! Loss: 1.2853412181138992
Starting epoch 6/10.
0.0000 --- loss: 1.477725, loss_ss: 1.148088, loss_d: 0.329636
0.2451 --- loss: 1.105217, loss_ss: 1.103853, loss_d: 0.001365
0.4902 --- loss: 1.081599, loss_ss: 1.078182, loss_d: 0.003416
0.7353 --- loss: 1.147790, loss_ss: 1.069350, loss_d: 0.078440
0.9804 --- loss: 1.316132, loss_ss: 1.063823, loss_d: 0.252309
Epoch finished! Loss: 1.1918453723192215
Starting epoch 7/10.
0.0000 --- loss: 1.071372, loss_ss: 1.066598, loss_d: 0.004774
0.2451 --- loss: 1.030470, loss_ss: 1.025049, loss_d: 0.005421
0.4902 --- loss: 1.026888, loss_ss: 1.021186, loss_d: 0.005701
0.7353 --- loss: 1.073886, loss_ss: 1.062848, loss_d: 0.011038
0.9804 --- loss: 1.036212, loss_ss: 1.032714, loss_d: 0.003498
Epoch finished! Loss: 1.1350424885749817
Starting epoch 8/10.
0.0000 --- loss: 0.934373, loss_ss: 0.929048, loss_d: 0.005325
0.2451 --- loss: 0.918096, loss_ss: 0.905888, loss_d: 0.012208
0.4902 --- loss: 1.001147, loss_ss: 0.998299, loss_d: 0.002848
0.7353 --- loss: 0.939703, loss_ss: 0.939153, loss_d: 0.000550
0.9804 --- loss: 0.880163, loss_ss: 0.816300, loss_d: 0.063862
Epoch finished! Loss: 1.0023483842611314
Starting epoch 9/10.
0.0000 --- loss: 0.846139, loss_ss: 0.845976, loss_d: 0.000163
0.2451 --- loss: 1.036340, loss_ss: 0.908377, loss_d: 0.127963
0.4902 --- loss: 0.862421, loss_ss: 0.860259, loss_d: 0.002162
0.7353 --- loss: 0.937246, loss_ss: 0.936122, loss_d: 0.001123
0.9804 --- loss: 0.872500, loss_ss: 0.867524, loss_d: 0.004976
Epoch finished! Loss: 0.9436410188674926
Starting epoch 10/10.
0.0000 --- loss: 0.798907, loss_ss: 0.798113, loss_d: 0.000793
0.2451 --- loss: 1.001892, loss_ss: 1.001770, loss_d: 0.000122
0.4902 --- loss: 0.839117, loss_ss: 0.838152, loss_d: 0.000965
0.7353 --- loss: 0.837522, loss_ss: 0.836176, loss_d: 0.001347
0.9804 --- loss: 0.855686, loss_ss: 0.855193, loss_d: 0.000494
Epoch finished! Loss: 0.8992544040083885
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7986111111111112
             precision    recall  f1-score   support

        0.0       0.60      1.00      0.75        59
        1.0       0.00      0.00      0.00        56
        2.0       0.84      0.95      0.89       358
        3.0       0.99      0.72      0.83       151
        4.0       0.63      0.72      0.67        96

avg / total       0.76      0.80      0.77       720
 


====== chc033-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  94.44  100.00   93.95  59.60     74.68
1  92.22    0.00  100.00   0.00      0.00
2  88.47   94.69   82.32  84.12     89.09
3  93.89   71.52   99.82  99.08     83.08
4  90.69   71.88   93.59  63.30     67.32
Total accuracy: 79.86%
Average sen: 67.62%
Average spec: 93.94%
Macro f1-score: 62.83%
Diagnosis acc on 90mins: 0.0
[0.96546    0.94863302 0.90287966 0.99954224]
pred: 0.9541287273168564, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc033-nsrr

=== Test on chc035-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.582139, loss_ss: 1.905168, loss_d: 0.676971
0.2457 --- loss: 2.143884, loss_ss: 1.579487, loss_d: 0.564397
0.4914 --- loss: 2.044611, loss_ss: 1.613488, loss_d: 0.431123
0.7371 --- loss: 2.147998, loss_ss: 1.591998, loss_d: 0.556000
0.9828 --- loss: 2.326471, loss_ss: 1.382290, loss_d: 0.944181
Epoch finished! Loss: 2.2484849810600283
Starting epoch 2/10.
0.0000 --- loss: 1.872418, loss_ss: 1.426785, loss_d: 0.445632
0.2457 --- loss: 1.947643, loss_ss: 1.409172, loss_d: 0.538470
0.4914 --- loss: 1.752020, loss_ss: 1.413501, loss_d: 0.338519
0.7371 --- loss: 1.801259, loss_ss: 1.357209, loss_d: 0.444049
0.9828 --- loss: 1.920527, loss_ss: 1.271233, loss_d: 0.649293
Epoch finished! Loss: 1.8966282099485396
Starting epoch 3/10.
0.0000 --- loss: 1.895989, loss_ss: 1.358951, loss_d: 0.537038
0.2457 --- loss: 1.481523, loss_ss: 1.230082, loss_d: 0.251441
0.4914 --- loss: 1.388380, loss_ss: 1.284285, loss_d: 0.104096
0.7371 --- loss: 1.473505, loss_ss: 1.309954, loss_d: 0.163550
0.9828 --- loss: 1.398976, loss_ss: 1.269701, loss_d: 0.129274
Epoch finished! Loss: 1.5530221611261368
Starting epoch 4/10.
0.0000 --- loss: 1.331511, loss_ss: 1.319520, loss_d: 0.011991
0.2457 --- loss: 1.174036, loss_ss: 1.162959, loss_d: 0.011077
0.4914 --- loss: 1.233489, loss_ss: 1.224600, loss_d: 0.008888
0.7371 --- loss: 1.458969, loss_ss: 1.190819, loss_d: 0.268150
0.9828 --- loss: 1.174428, loss_ss: 1.127327, loss_d: 0.047101
Epoch finished! Loss: 1.2533880382776261
Starting epoch 5/10.
0.0000 --- loss: 1.093039, loss_ss: 1.090670, loss_d: 0.002369
0.2457 --- loss: 1.074259, loss_ss: 1.059622, loss_d: 0.014638
0.4914 --- loss: 1.143558, loss_ss: 1.142904, loss_d: 0.000654
0.7371 --- loss: 1.076765, loss_ss: 1.073515, loss_d: 0.003250
0.9828 --- loss: 1.078911, loss_ss: 1.062831, loss_d: 0.016080
Epoch finished! Loss: 1.1677462726831436
Starting epoch 6/10.
0.0000 --- loss: 1.131768, loss_ss: 1.084134, loss_d: 0.047634
0.2457 --- loss: 1.038918, loss_ss: 1.036040, loss_d: 0.002877
0.4914 --- loss: 1.193721, loss_ss: 1.116290, loss_d: 0.077430
0.7371 --- loss: 0.983136, loss_ss: 0.928099, loss_d: 0.055036
0.9828 --- loss: 1.034081, loss_ss: 1.033636, loss_d: 0.000445
Epoch finished! Loss: 1.115632426738739
Starting epoch 7/10.
0.0000 --- loss: 0.999151, loss_ss: 0.990066, loss_d: 0.009084
0.2457 --- loss: 1.002894, loss_ss: 1.002602, loss_d: 0.000292
0.4914 --- loss: 1.110184, loss_ss: 1.027992, loss_d: 0.082192
0.7371 --- loss: 0.966031, loss_ss: 0.958910, loss_d: 0.007121
0.9828 --- loss: 1.303443, loss_ss: 1.110618, loss_d: 0.192825
Epoch finished! Loss: 1.082857221364975
Starting epoch 8/10.
0.0000 --- loss: 1.027572, loss_ss: 1.027282, loss_d: 0.000290
0.2457 --- loss: 1.014572, loss_ss: 1.011316, loss_d: 0.003256
0.4914 --- loss: 1.029720, loss_ss: 1.002602, loss_d: 0.027119
0.7371 --- loss: 1.276193, loss_ss: 0.898097, loss_d: 0.378097
0.9828 --- loss: 1.066691, loss_ss: 0.937580, loss_d: 0.129111
Epoch finished! Loss: 1.0812384560704231
Starting epoch 9/10.
0.0000 --- loss: 1.011136, loss_ss: 1.008173, loss_d: 0.002963
0.2457 --- loss: 1.041227, loss_ss: 0.889337, loss_d: 0.151890
0.4914 --- loss: 0.966836, loss_ss: 0.954446, loss_d: 0.012390
0.7371 --- loss: 0.853269, loss_ss: 0.852913, loss_d: 0.000356
0.9828 --- loss: 1.043562, loss_ss: 1.040944, loss_d: 0.002618
Epoch finished! Loss: 1.0000320687890052
Starting epoch 10/10.
0.0000 --- loss: 0.859950, loss_ss: 0.854686, loss_d: 0.005265
0.2457 --- loss: 0.999620, loss_ss: 0.992897, loss_d: 0.006722
0.4914 --- loss: 0.842515, loss_ss: 0.841132, loss_d: 0.001383
0.7371 --- loss: 0.799123, loss_ss: 0.797660, loss_d: 0.001463
0.9828 --- loss: 0.791963, loss_ss: 0.789191, loss_d: 0.002772
Epoch finished! Loss: 0.9297975018620491
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6888888888888889
             precision    recall  f1-score   support

        0.0       0.59      0.90      0.71        29
        1.0       0.67      0.11      0.18        57
        2.0       0.63      0.96      0.76       391
        3.0       1.00      0.53      0.69       250
        4.0       0.67      0.46      0.55       173

avg / total       0.74      0.69      0.66       900
 


====== chc035-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  97.67  89.66   97.93   59.09     71.23
1  94.00  10.53   99.64   66.67     18.18
2  73.89  95.91   56.97   63.13     76.14
3  87.00  53.20  100.00  100.00     69.45
4  85.22  46.24   94.50   66.67     54.61
Total accuracy: 68.89%
Average sen: 59.11%
Average spec: 89.81%
Macro f1-score: 57.92%
Diagnosis acc on 90mins: 0.2
[0.34321046 0.962448   0.97820103 0.99239069 0.67051321]
pred: 0.7893526792526245, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc035-nsrr

=== Test on chc037-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.325835, loss_ss: 1.645846, loss_d: 0.679989
0.2451 --- loss: 2.093185, loss_ss: 1.570186, loss_d: 0.522999
0.4902 --- loss: 2.002563, loss_ss: 1.488369, loss_d: 0.514194
0.7353 --- loss: 1.935626, loss_ss: 1.352757, loss_d: 0.582869
0.9804 --- loss: 1.764664, loss_ss: 1.356735, loss_d: 0.407928
Epoch finished! Loss: 2.1685853749513626
Starting epoch 2/10.
0.0000 --- loss: 1.939880, loss_ss: 1.456809, loss_d: 0.483072
0.2451 --- loss: 1.961053, loss_ss: 1.317431, loss_d: 0.643623
0.4902 --- loss: 1.712331, loss_ss: 1.357299, loss_d: 0.355033
0.7353 --- loss: 2.141662, loss_ss: 1.284796, loss_d: 0.856866
0.9804 --- loss: 1.613312, loss_ss: 1.198717, loss_d: 0.414596
Epoch finished! Loss: 1.8381324678659439
Starting epoch 3/10.
0.0000 --- loss: 1.540798, loss_ss: 1.328047, loss_d: 0.212751
0.2451 --- loss: 1.365594, loss_ss: 1.239670, loss_d: 0.125924
0.4902 --- loss: 1.598555, loss_ss: 1.306583, loss_d: 0.291972
0.7353 --- loss: 1.407315, loss_ss: 1.183560, loss_d: 0.223755
0.9804 --- loss: 1.812807, loss_ss: 1.195048, loss_d: 0.617758
Epoch finished! Loss: 1.4963326841592788
Starting epoch 4/10.
0.0000 --- loss: 1.291316, loss_ss: 1.275136, loss_d: 0.016180
0.2451 --- loss: 1.180051, loss_ss: 1.154248, loss_d: 0.025802
0.4902 --- loss: 1.306031, loss_ss: 1.274802, loss_d: 0.031229
0.7353 --- loss: 1.426321, loss_ss: 1.132854, loss_d: 0.293467
0.9804 --- loss: 1.185579, loss_ss: 1.182180, loss_d: 0.003399
Epoch finished! Loss: 1.3441253453493118
Starting epoch 5/10.
0.0000 --- loss: 1.110907, loss_ss: 1.101134, loss_d: 0.009774
0.2451 --- loss: 1.342779, loss_ss: 1.217049, loss_d: 0.125729
0.4902 --- loss: 1.202975, loss_ss: 1.155826, loss_d: 0.047148
0.7353 --- loss: 1.110080, loss_ss: 1.092078, loss_d: 0.018001
0.9804 --- loss: 1.471196, loss_ss: 1.019614, loss_d: 0.451581
Epoch finished! Loss: 1.2779644429683685
Starting epoch 6/10.
0.0000 --- loss: 1.338210, loss_ss: 1.119664, loss_d: 0.218545
0.2451 --- loss: 1.224234, loss_ss: 1.121357, loss_d: 0.102877
0.4902 --- loss: 1.250238, loss_ss: 1.246884, loss_d: 0.003353
0.7353 --- loss: 1.064401, loss_ss: 1.007605, loss_d: 0.056796
0.9804 --- loss: 1.200060, loss_ss: 1.185963, loss_d: 0.014097
Epoch finished! Loss: 1.2056963101029397
Starting epoch 7/10.
0.0000 --- loss: 1.099891, loss_ss: 1.099518, loss_d: 0.000372
0.2451 --- loss: 1.225487, loss_ss: 1.165582, loss_d: 0.059905
0.4902 --- loss: 1.263079, loss_ss: 1.069607, loss_d: 0.193472
0.7353 --- loss: 1.043864, loss_ss: 1.042481, loss_d: 0.001383
0.9804 --- loss: 1.094952, loss_ss: 1.093628, loss_d: 0.001324
Epoch finished! Loss: 1.1357386767864228
Starting epoch 8/10.
0.0000 --- loss: 0.989631, loss_ss: 0.983228, loss_d: 0.006403
0.2451 --- loss: 1.149008, loss_ss: 1.146162, loss_d: 0.002846
0.4902 --- loss: 1.068446, loss_ss: 1.067963, loss_d: 0.000483
0.7353 --- loss: 1.069673, loss_ss: 1.069209, loss_d: 0.000465
0.9804 --- loss: 1.082429, loss_ss: 1.081820, loss_d: 0.000609
Epoch finished! Loss: 1.0944037154316901
Starting epoch 9/10.
0.0000 --- loss: 0.985359, loss_ss: 0.983370, loss_d: 0.001989
0.2451 --- loss: 0.925187, loss_ss: 0.923684, loss_d: 0.001503
0.4902 --- loss: 1.164076, loss_ss: 1.163244, loss_d: 0.000832
0.7353 --- loss: 0.978389, loss_ss: 0.978249, loss_d: 0.000140
0.9804 --- loss: 0.931524, loss_ss: 0.931193, loss_d: 0.000331
Epoch finished! Loss: 1.0460980534553528
Starting epoch 10/10.
0.0000 --- loss: 1.134215, loss_ss: 1.134141, loss_d: 0.000074
0.2451 --- loss: 1.117897, loss_ss: 1.116932, loss_d: 0.000966
0.4902 --- loss: 0.902714, loss_ss: 0.902402, loss_d: 0.000312
0.7353 --- loss: 1.078937, loss_ss: 1.078891, loss_d: 0.000046
0.9804 --- loss: 0.887558, loss_ss: 0.887307, loss_d: 0.000251
Epoch finished! Loss: 1.0195274740457534
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5486111111111112
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       154
        1.0       0.12      0.87      0.21        30
        2.0       0.92      0.78      0.84       259
        3.0       0.97      0.89      0.93       168
        4.0       0.14      0.17      0.15       109

avg / total       0.58      0.55      0.55       720
 


====== chc037-nsrr ======

The ppr of  0  has ZeroDivisionError.

The f1-score of  0  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  78.61   0.00  100.00   0.00      0.00
1  72.64  86.67   72.03  11.87     20.88
2  89.44  77.61   96.10  91.78     84.10
3  96.81  89.29   99.09  96.77     92.88
4  72.22  16.51   82.16  14.17     15.25
Total accuracy: 54.86%
Average sen: 54.01%
Average spec: 89.88%
Macro f1-score: 42.62%
Diagnosis acc on 90mins: 0.0
[0.99998331 0.6998449  0.73505217 0.93417943]
pred: 0.8422649502754211, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc037-nsrr

=== Test on chc040-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.582351, loss_ss: 1.917826, loss_d: 0.664525
0.2463 --- loss: 2.284888, loss_ss: 1.708543, loss_d: 0.576345
0.4926 --- loss: 2.390786, loss_ss: 1.717285, loss_d: 0.673501
0.7389 --- loss: 1.967132, loss_ss: 1.601009, loss_d: 0.366123
0.9852 --- loss: 2.289195, loss_ss: 1.659016, loss_d: 0.630180
Epoch finished! Loss: 2.4184179335832594
Starting epoch 2/10.
0.0000 --- loss: 1.896222, loss_ss: 1.486470, loss_d: 0.409752
0.2463 --- loss: 2.074987, loss_ss: 1.640775, loss_d: 0.434212
0.4926 --- loss: 1.797453, loss_ss: 1.463320, loss_d: 0.334132
0.7389 --- loss: 1.951711, loss_ss: 1.463391, loss_d: 0.488321
0.9852 --- loss: 2.037171, loss_ss: 1.656334, loss_d: 0.380837
Epoch finished! Loss: 2.1050489276647566
Starting epoch 3/10.
0.0000 --- loss: 1.847648, loss_ss: 1.497449, loss_d: 0.350199
0.2463 --- loss: 1.755512, loss_ss: 1.470542, loss_d: 0.284970
0.4926 --- loss: 1.892244, loss_ss: 1.490531, loss_d: 0.401713
0.7389 --- loss: 1.728300, loss_ss: 1.386775, loss_d: 0.341524
0.9852 --- loss: 1.737537, loss_ss: 1.424365, loss_d: 0.313172
Epoch finished! Loss: 1.848211807012558
Starting epoch 4/10.
0.0000 --- loss: 1.660573, loss_ss: 1.596316, loss_d: 0.064256
0.2463 --- loss: 1.648583, loss_ss: 1.474508, loss_d: 0.174075
0.4926 --- loss: 1.477835, loss_ss: 1.376274, loss_d: 0.101562
0.7389 --- loss: 1.485636, loss_ss: 1.403690, loss_d: 0.081946
0.9852 --- loss: 1.835069, loss_ss: 1.450868, loss_d: 0.384201
Epoch finished! Loss: 1.578177374601364
Starting epoch 5/10.
0.0000 --- loss: 1.467816, loss_ss: 1.429510, loss_d: 0.038306
0.2463 --- loss: 1.376198, loss_ss: 1.368409, loss_d: 0.007789
0.4926 --- loss: 1.302893, loss_ss: 1.273044, loss_d: 0.029849
0.7389 --- loss: 1.400425, loss_ss: 1.390181, loss_d: 0.010244
0.9852 --- loss: 1.263167, loss_ss: 1.258241, loss_d: 0.004925
Epoch finished! Loss: 1.4327447205781936
Starting epoch 6/10.
0.0000 --- loss: 1.332017, loss_ss: 1.168110, loss_d: 0.163908
0.2463 --- loss: 1.360037, loss_ss: 1.345365, loss_d: 0.014673
0.4926 --- loss: 1.320573, loss_ss: 1.189101, loss_d: 0.131472
0.7389 --- loss: 1.228607, loss_ss: 1.205522, loss_d: 0.023085
0.9852 --- loss: 1.997837, loss_ss: 1.362816, loss_d: 0.635022
Epoch finished! Loss: 1.4297248661518096
Starting epoch 7/10.
0.0000 --- loss: 1.250472, loss_ss: 1.241134, loss_d: 0.009338
0.2463 --- loss: 1.305008, loss_ss: 1.205312, loss_d: 0.099696
0.4926 --- loss: 1.160074, loss_ss: 1.148695, loss_d: 0.011378
0.7389 --- loss: 1.278036, loss_ss: 1.185367, loss_d: 0.092669
0.9852 --- loss: 1.280427, loss_ss: 1.277963, loss_d: 0.002464
Epoch finished! Loss: 1.287775593996048
Starting epoch 8/10.
0.0000 --- loss: 1.259919, loss_ss: 1.257386, loss_d: 0.002533
0.2463 --- loss: 1.104690, loss_ss: 1.096734, loss_d: 0.007956
0.4926 --- loss: 1.245583, loss_ss: 1.242515, loss_d: 0.003068
0.7389 --- loss: 1.106415, loss_ss: 1.095569, loss_d: 0.010845
0.9852 --- loss: 1.040641, loss_ss: 0.997624, loss_d: 0.043018
Epoch finished! Loss: 1.2096988141536713
Starting epoch 9/10.
0.0000 --- loss: 1.114771, loss_ss: 1.113545, loss_d: 0.001226
0.2463 --- loss: 1.039082, loss_ss: 1.038831, loss_d: 0.000251
0.4926 --- loss: 1.065679, loss_ss: 1.061737, loss_d: 0.003942
0.7389 --- loss: 1.089399, loss_ss: 1.082954, loss_d: 0.006445
0.9852 --- loss: 1.010759, loss_ss: 1.009699, loss_d: 0.001060
Epoch finished! Loss: 1.126101902127266
Starting epoch 10/10.
0.0000 --- loss: 1.075945, loss_ss: 1.074743, loss_d: 0.001203
0.2463 --- loss: 1.032414, loss_ss: 1.032374, loss_d: 0.000040
0.4926 --- loss: 0.960825, loss_ss: 0.958847, loss_d: 0.001979
0.7389 --- loss: 0.947696, loss_ss: 0.946826, loss_d: 0.000869
0.9852 --- loss: 1.123206, loss_ss: 1.122087, loss_d: 0.001119
Epoch finished! Loss: 1.069836212694645
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6296296296296297
             precision    recall  f1-score   support

        0.0       0.81      0.78      0.80       185
        1.0       0.00      0.00      0.00        50
        2.0       0.57      0.99      0.72       483
        3.0       0.98      0.27      0.42       216
        4.0       0.00      0.00      0.00       146

avg / total       0.59      0.63      0.54      1080
 


====== chc040-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.

The ppr of  4  has ZeroDivisionError.

The f1-score of  4  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  93.15  78.38   96.20  81.01     79.67
1  95.37   0.00  100.00   0.00      0.00
2  65.65  98.76   38.86  56.65     72.00
3  85.28  26.85   99.88  98.31     42.18
4  86.48   0.00  100.00   0.00      0.00
Total accuracy: 62.96%
Average sen: 40.80%
Average spec: 86.99%
Macro f1-score: 38.77%
Diagnosis acc on 90mins: 0.0
[0.9981457  0.99977273 0.82243091 0.9954496  0.88933671 0.9984926 ]
pred: 0.9506047070026398, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc040-nsrr

=== Test on chc041-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.265590, loss_ss: 1.643288, loss_d: 0.622302
0.2451 --- loss: 2.096060, loss_ss: 1.452993, loss_d: 0.643066
0.4902 --- loss: 2.495919, loss_ss: 1.424407, loss_d: 1.071512
0.7353 --- loss: 1.889617, loss_ss: 1.390913, loss_d: 0.498704
0.9804 --- loss: 1.943854, loss_ss: 1.290298, loss_d: 0.653556
Epoch finished! Loss: 2.057910093665123
Starting epoch 2/10.
0.0000 --- loss: 1.765402, loss_ss: 1.350859, loss_d: 0.414543
0.2451 --- loss: 1.686002, loss_ss: 1.288832, loss_d: 0.397170
0.4902 --- loss: 1.507354, loss_ss: 1.171323, loss_d: 0.336031
0.7353 --- loss: 1.673872, loss_ss: 1.257076, loss_d: 0.416796
0.9804 --- loss: 1.510324, loss_ss: 1.270450, loss_d: 0.239874
Epoch finished! Loss: 1.710894849896431
Starting epoch 3/10.
0.0000 --- loss: 1.414649, loss_ss: 1.229489, loss_d: 0.185160
0.2451 --- loss: 1.280840, loss_ss: 1.215728, loss_d: 0.065111
0.4902 --- loss: 1.280901, loss_ss: 1.144575, loss_d: 0.136326
0.7353 --- loss: 1.390572, loss_ss: 1.143884, loss_d: 0.246688
0.9804 --- loss: 1.445268, loss_ss: 1.170243, loss_d: 0.275025
Epoch finished! Loss: 1.3726010292768478
Starting epoch 4/10.
0.0000 --- loss: 1.205276, loss_ss: 1.173988, loss_d: 0.031288
0.2451 --- loss: 1.350055, loss_ss: 1.117186, loss_d: 0.232869
0.4902 --- loss: 1.276390, loss_ss: 1.097309, loss_d: 0.179082
0.7353 --- loss: 1.196821, loss_ss: 1.077230, loss_d: 0.119591
0.9804 --- loss: 1.171153, loss_ss: 1.169590, loss_d: 0.001563
Epoch finished! Loss: 1.232418131828308
Starting epoch 5/10.
0.0000 --- loss: 1.122460, loss_ss: 1.017182, loss_d: 0.105278
0.2451 --- loss: 1.046280, loss_ss: 1.039425, loss_d: 0.006855
0.4902 --- loss: 1.491454, loss_ss: 1.053737, loss_d: 0.437718
0.7353 --- loss: 1.108346, loss_ss: 1.064705, loss_d: 0.043641
0.9804 --- loss: 0.959070, loss_ss: 0.952214, loss_d: 0.006856
Epoch finished! Loss: 1.145538517832756
Starting epoch 6/10.
0.0000 --- loss: 0.931925, loss_ss: 0.928457, loss_d: 0.003468
0.2451 --- loss: 1.003186, loss_ss: 0.988725, loss_d: 0.014460
0.4902 --- loss: 0.921667, loss_ss: 0.919081, loss_d: 0.002586
0.7353 --- loss: 0.902659, loss_ss: 0.890033, loss_d: 0.012626
0.9804 --- loss: 0.934029, loss_ss: 0.904452, loss_d: 0.029577
Epoch finished! Loss: 1.0571396738290786
Starting epoch 7/10.
0.0000 --- loss: 1.064458, loss_ss: 1.061255, loss_d: 0.003204
0.2451 --- loss: 0.863733, loss_ss: 0.862088, loss_d: 0.001645
0.4902 --- loss: 0.909270, loss_ss: 0.898858, loss_d: 0.010411
0.7353 --- loss: 0.982377, loss_ss: 0.981977, loss_d: 0.000400
0.9804 --- loss: 0.887887, loss_ss: 0.887043, loss_d: 0.000844
Epoch finished! Loss: 0.9802906304597855
Starting epoch 8/10.
0.0000 --- loss: 1.004192, loss_ss: 1.001857, loss_d: 0.002334
0.2451 --- loss: 0.908631, loss_ss: 0.908149, loss_d: 0.000482
0.4902 --- loss: 0.789401, loss_ss: 0.788681, loss_d: 0.000720
0.7353 --- loss: 1.019870, loss_ss: 0.957449, loss_d: 0.062421
0.9804 --- loss: 1.179153, loss_ss: 0.957645, loss_d: 0.221508
Epoch finished! Loss: 0.9557658985257149
Starting epoch 9/10.
0.0000 --- loss: 0.844887, loss_ss: 0.829073, loss_d: 0.015814
0.2451 --- loss: 0.888842, loss_ss: 0.888761, loss_d: 0.000081
0.4902 --- loss: 0.818701, loss_ss: 0.817820, loss_d: 0.000881
0.7353 --- loss: 0.867001, loss_ss: 0.864706, loss_d: 0.002295
0.9804 --- loss: 0.860752, loss_ss: 0.853414, loss_d: 0.007337
Epoch finished! Loss: 0.9079084977507591
Starting epoch 10/10.
0.0000 --- loss: 0.832945, loss_ss: 0.830991, loss_d: 0.001954
0.2451 --- loss: 0.893290, loss_ss: 0.877356, loss_d: 0.015934
0.4902 --- loss: 0.783326, loss_ss: 0.770943, loss_d: 0.012384
0.7353 --- loss: 0.830119, loss_ss: 0.829324, loss_d: 0.000795
0.9804 --- loss: 0.728569, loss_ss: 0.728234, loss_d: 0.000335
Epoch finished! Loss: 0.851125793159008
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6152777777777778
             precision    recall  f1-score   support

        0.0       0.66      0.64      0.65        55
        1.0       0.11      0.60      0.19        35
        2.0       0.75      0.69      0.72       336
        3.0       0.97      0.57      0.71       166
        4.0       0.90      0.47      0.62       128

avg / total       0.79      0.62      0.67       720
 


====== chc041-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  94.72  63.64   97.29  66.04     64.81
1  74.44  60.00   75.18  10.99     18.58
2  74.72  69.35   79.43  74.68     71.91
3  89.58  56.63   99.46  96.91     71.48
4  89.58  46.88   98.82  89.55     61.54
Total accuracy: 61.53%
Average sen: 59.30%
Average spec: 90.04%
Macro f1-score: 57.67%
Diagnosis acc on 90mins: 0.0
[0.90527892 0.99993646 0.99999142 1.        ]
pred: 0.9763016998767853, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc041-nsrr

=== Test on chc052-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.333175, loss_ss: 1.675627, loss_d: 0.657548
0.2457 --- loss: 2.156492, loss_ss: 1.507324, loss_d: 0.649167
0.4914 --- loss: 2.044261, loss_ss: 1.441797, loss_d: 0.602464
0.7371 --- loss: 2.217026, loss_ss: 1.507592, loss_d: 0.709434
0.9828 --- loss: 1.929879, loss_ss: 1.467016, loss_d: 0.462863
Epoch finished! Loss: 2.177813082933426
Starting epoch 2/10.
0.0000 --- loss: 1.976643, loss_ss: 1.361097, loss_d: 0.615546
0.2457 --- loss: 1.989564, loss_ss: 1.382652, loss_d: 0.606912
0.4914 --- loss: 1.730458, loss_ss: 1.433255, loss_d: 0.297203
0.7371 --- loss: 1.655840, loss_ss: 1.311020, loss_d: 0.344820
0.9828 --- loss: 1.629952, loss_ss: 1.295957, loss_d: 0.333995
Epoch finished! Loss: 1.8767944246530532
Starting epoch 3/10.
0.0000 --- loss: 1.817777, loss_ss: 1.269352, loss_d: 0.548425
0.2457 --- loss: 1.459600, loss_ss: 1.272382, loss_d: 0.187218
0.4914 --- loss: 1.976574, loss_ss: 1.351608, loss_d: 0.624967
0.7371 --- loss: 1.416926, loss_ss: 1.280786, loss_d: 0.136140
0.9828 --- loss: 1.544759, loss_ss: 1.370708, loss_d: 0.174052
Epoch finished! Loss: 1.5744761526584625
Starting epoch 4/10.
0.0000 --- loss: 1.288180, loss_ss: 1.259483, loss_d: 0.028697
0.2457 --- loss: 1.307593, loss_ss: 1.279149, loss_d: 0.028444
0.4914 --- loss: 1.220964, loss_ss: 1.206401, loss_d: 0.014563
0.7371 --- loss: 1.181406, loss_ss: 1.139889, loss_d: 0.041517
0.9828 --- loss: 1.792791, loss_ss: 1.168812, loss_d: 0.623979
Epoch finished! Loss: 1.3445971876382827
Starting epoch 5/10.
0.0000 --- loss: 1.245334, loss_ss: 1.217628, loss_d: 0.027706
0.2457 --- loss: 1.218183, loss_ss: 1.187777, loss_d: 0.030406
0.4914 --- loss: 1.328362, loss_ss: 1.182089, loss_d: 0.146272
0.7371 --- loss: 1.693958, loss_ss: 1.214974, loss_d: 0.478984
0.9828 --- loss: 1.291553, loss_ss: 1.083653, loss_d: 0.207899
Epoch finished! Loss: 1.2603213965892792
Starting epoch 6/10.
0.0000 --- loss: 1.273155, loss_ss: 1.249218, loss_d: 0.023937
0.2457 --- loss: 1.209606, loss_ss: 1.158132, loss_d: 0.051473
0.4914 --- loss: 1.098317, loss_ss: 1.093904, loss_d: 0.004413
0.7371 --- loss: 1.009147, loss_ss: 0.983166, loss_d: 0.025982
0.9828 --- loss: 1.026711, loss_ss: 1.020521, loss_d: 0.006191
Epoch finished! Loss: 1.176086989045143
Starting epoch 7/10.
0.0000 --- loss: 1.118437, loss_ss: 1.110298, loss_d: 0.008139
0.2457 --- loss: 1.252822, loss_ss: 0.960677, loss_d: 0.292145
0.4914 --- loss: 1.232579, loss_ss: 1.035851, loss_d: 0.196728
0.7371 --- loss: 1.510675, loss_ss: 0.968596, loss_d: 0.542079
0.9828 --- loss: 1.012551, loss_ss: 1.011830, loss_d: 0.000722
Epoch finished! Loss: 1.1595534458756447
Starting epoch 8/10.
0.0000 --- loss: 0.940242, loss_ss: 0.930444, loss_d: 0.009798
0.2457 --- loss: 1.008913, loss_ss: 1.000756, loss_d: 0.008157
0.4914 --- loss: 1.222227, loss_ss: 0.975612, loss_d: 0.246615
0.7371 --- loss: 1.017931, loss_ss: 1.017519, loss_d: 0.000413
0.9828 --- loss: 0.874633, loss_ss: 0.868191, loss_d: 0.006442
Epoch finished! Loss: 1.0794818997383118
Starting epoch 9/10.
0.0000 --- loss: 1.072268, loss_ss: 1.071682, loss_d: 0.000585
0.2457 --- loss: 0.971194, loss_ss: 0.970631, loss_d: 0.000562
0.4914 --- loss: 0.918215, loss_ss: 0.916960, loss_d: 0.001254
0.7371 --- loss: 0.881974, loss_ss: 0.881771, loss_d: 0.000203
0.9828 --- loss: 0.834927, loss_ss: 0.834605, loss_d: 0.000322
Epoch finished! Loss: 1.0015836954116821
Starting epoch 10/10.
0.0000 --- loss: 0.964693, loss_ss: 0.964215, loss_d: 0.000478
0.2457 --- loss: 0.863929, loss_ss: 0.853810, loss_d: 0.010119
0.4914 --- loss: 1.078410, loss_ss: 1.001984, loss_d: 0.076426
0.7371 --- loss: 0.762371, loss_ss: 0.760775, loss_d: 0.001596
0.9828 --- loss: 0.764874, loss_ss: 0.761674, loss_d: 0.003200
Epoch finished! Loss: 0.9752837285399437
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6522222222222223
             precision    recall  f1-score   support

        0.0       0.94      0.24      0.38       142
        1.0       0.50      0.22      0.30        23
        2.0       0.77      0.85      0.81       466
        3.0       0.95      0.32      0.48       167
        4.0       0.35      0.96      0.51       102

avg / total       0.77      0.65      0.63       900
 


====== chc052-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  87.78  23.94   99.74  94.44     38.20
1  97.44  21.74   99.43  50.00     30.30
2  78.78  84.98   72.12  76.60     80.57
3  87.11  32.34   99.59  94.74     48.21
4  79.33  96.08   77.19  35.00     51.31
Total accuracy: 65.22%
Average sen: 51.82%
Average spec: 89.61%
Macro f1-score: 49.72%
Diagnosis acc on 90mins: 0.2
[0.9876287  0.56917369 0.98420608 0.33300579 0.99097955]
pred: 0.7729987621307373, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc052-nsrr

=== Test on chc056-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.440156, loss_ss: 1.761086, loss_d: 0.679071
0.2457 --- loss: 2.092068, loss_ss: 1.505215, loss_d: 0.586853
0.4914 --- loss: 1.882854, loss_ss: 1.471973, loss_d: 0.410881
0.7371 --- loss: 1.748758, loss_ss: 1.318096, loss_d: 0.430662
0.9828 --- loss: 1.715468, loss_ss: 1.319357, loss_d: 0.396111
Epoch finished! Loss: 2.1515922129154204
Starting epoch 2/10.
0.0000 --- loss: 1.774998, loss_ss: 1.226063, loss_d: 0.548935
0.2457 --- loss: 1.783388, loss_ss: 1.444034, loss_d: 0.339354
0.4914 --- loss: 1.750854, loss_ss: 1.249300, loss_d: 0.501554
0.7371 --- loss: 1.639801, loss_ss: 1.288262, loss_d: 0.351539
0.9828 --- loss: 2.277317, loss_ss: 1.086837, loss_d: 1.190480
Epoch finished! Loss: 1.7692442178726195
Starting epoch 3/10.
0.0000 --- loss: 1.394738, loss_ss: 1.255111, loss_d: 0.139627
0.2457 --- loss: 1.683295, loss_ss: 1.164093, loss_d: 0.519202
0.4914 --- loss: 1.470291, loss_ss: 1.214398, loss_d: 0.255893
0.7371 --- loss: 1.465387, loss_ss: 1.295457, loss_d: 0.169930
0.9828 --- loss: 1.514598, loss_ss: 1.366028, loss_d: 0.148570
Epoch finished! Loss: 1.5005381762981416
Starting epoch 4/10.
0.0000 --- loss: 1.281570, loss_ss: 1.161141, loss_d: 0.120429
0.2457 --- loss: 1.101166, loss_ss: 1.055487, loss_d: 0.045679
0.4914 --- loss: 1.178656, loss_ss: 1.151025, loss_d: 0.027631
0.7371 --- loss: 1.182591, loss_ss: 1.017215, loss_d: 0.165376
0.9828 --- loss: 1.120617, loss_ss: 1.085351, loss_d: 0.035266
Epoch finished! Loss: 1.2197606176137925
Starting epoch 5/10.
0.0000 --- loss: 1.030029, loss_ss: 1.024982, loss_d: 0.005047
0.2457 --- loss: 1.070400, loss_ss: 1.052781, loss_d: 0.017619
0.4914 --- loss: 1.050353, loss_ss: 1.043311, loss_d: 0.007042
0.7371 --- loss: 0.997012, loss_ss: 0.986449, loss_d: 0.010563
0.9828 --- loss: 1.072379, loss_ss: 1.003835, loss_d: 0.068544
Epoch finished! Loss: 1.1191980794072152
Starting epoch 6/10.
0.0000 --- loss: 1.178649, loss_ss: 1.128637, loss_d: 0.050012
0.2457 --- loss: 0.936544, loss_ss: 0.911239, loss_d: 0.025305
0.4914 --- loss: 0.970935, loss_ss: 0.949560, loss_d: 0.021375
0.7371 --- loss: 0.976075, loss_ss: 0.965387, loss_d: 0.010688
0.9828 --- loss: 0.878065, loss_ss: 0.862448, loss_d: 0.015617
Epoch finished! Loss: 1.0396068766713142
Starting epoch 7/10.
0.0000 --- loss: 0.996327, loss_ss: 0.993230, loss_d: 0.003097
0.2457 --- loss: 1.014776, loss_ss: 0.999376, loss_d: 0.015400
0.4914 --- loss: 1.068174, loss_ss: 1.042589, loss_d: 0.025586
0.7371 --- loss: 0.948970, loss_ss: 0.943338, loss_d: 0.005632
0.9828 --- loss: 0.867812, loss_ss: 0.855124, loss_d: 0.012688
Epoch finished! Loss: 0.9739583700895309
Starting epoch 8/10.
0.0000 --- loss: 0.971669, loss_ss: 0.968441, loss_d: 0.003228
0.2457 --- loss: 0.754588, loss_ss: 0.753985, loss_d: 0.000603
0.4914 --- loss: 0.999670, loss_ss: 0.998526, loss_d: 0.001144
0.7371 --- loss: 0.830664, loss_ss: 0.826654, loss_d: 0.004010
0.9828 --- loss: 0.783176, loss_ss: 0.782310, loss_d: 0.000866
Epoch finished! Loss: 0.9240942448377609
Starting epoch 9/10.
0.0000 --- loss: 0.897041, loss_ss: 0.896693, loss_d: 0.000348
0.2457 --- loss: 0.823288, loss_ss: 0.823167, loss_d: 0.000121
0.4914 --- loss: 0.823986, loss_ss: 0.823037, loss_d: 0.000949
0.7371 --- loss: 0.775481, loss_ss: 0.772801, loss_d: 0.002680
0.9828 --- loss: 0.877495, loss_ss: 0.877313, loss_d: 0.000181
Epoch finished! Loss: 0.8795093148946762
Starting epoch 10/10.
0.0000 --- loss: 0.840767, loss_ss: 0.840445, loss_d: 0.000322
0.2457 --- loss: 0.892550, loss_ss: 0.892336, loss_d: 0.000213
0.4914 --- loss: 0.888541, loss_ss: 0.881080, loss_d: 0.007460
0.7371 --- loss: 0.722975, loss_ss: 0.713372, loss_d: 0.009603
0.9828 --- loss: 0.778126, loss_ss: 0.778055, loss_d: 0.000070
Epoch finished! Loss: 0.8481289550662041
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.66
             precision    recall  f1-score   support

        0.0       0.68      1.00      0.81       175
        1.0       0.38      0.06      0.10        86
        2.0       0.79      0.59      0.67       396
        3.0       1.00      0.62      0.77       153
        4.0       0.36      0.94      0.52        90

avg / total       0.72      0.66      0.65       900
 


====== chc056-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  90.78  100.00   88.55   67.83     80.83
1  90.11    5.81   99.02   38.46     10.10
2  74.89   59.09   87.30   78.52     67.44
3  93.56   62.09  100.00  100.00     76.61
4  82.67   94.44   81.36   36.02     52.15
Total accuracy: 66.00%
Average sen: 64.29%
Average spec: 91.25%
Macro f1-score: 57.43%
Diagnosis acc on 90mins: 0.0
[0.99981099 0.94530761 0.99992394 0.99989879 0.99997532]
pred: 0.9889833331108093, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc056-nsrr

=== Test on chp001-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.461598, loss_ss: 1.665188, loss_d: 0.796410
0.2463 --- loss: 1.716539, loss_ss: 1.372418, loss_d: 0.344122
0.4926 --- loss: 2.213885, loss_ss: 1.347039, loss_d: 0.866846
0.7389 --- loss: 1.875366, loss_ss: 1.289654, loss_d: 0.585711
0.9852 --- loss: 1.773064, loss_ss: 1.352784, loss_d: 0.420280
Epoch finished! Loss: 2.064755344390869
Starting epoch 2/10.
0.0000 --- loss: 1.672317, loss_ss: 1.297336, loss_d: 0.374981
0.2463 --- loss: 1.732682, loss_ss: 1.223003, loss_d: 0.509680
0.4926 --- loss: 1.540325, loss_ss: 1.236103, loss_d: 0.304223
0.7389 --- loss: 1.792087, loss_ss: 1.227356, loss_d: 0.564731
0.9852 --- loss: 1.932227, loss_ss: 1.269726, loss_d: 0.662501
Epoch finished! Loss: 1.7175949841737748
Starting epoch 3/10.
0.0000 --- loss: 1.922617, loss_ss: 1.165918, loss_d: 0.756699
0.2463 --- loss: 1.356785, loss_ss: 1.236911, loss_d: 0.119875
0.4926 --- loss: 1.209954, loss_ss: 1.170387, loss_d: 0.039568
0.7389 --- loss: 1.209762, loss_ss: 1.143195, loss_d: 0.066567
0.9852 --- loss: 2.012923, loss_ss: 1.157231, loss_d: 0.855692
Epoch finished! Loss: 1.4626574695110321
Starting epoch 4/10.
0.0000 --- loss: 1.329219, loss_ss: 1.180018, loss_d: 0.149200
0.2463 --- loss: 1.209890, loss_ss: 1.108392, loss_d: 0.101498
0.4926 --- loss: 1.183024, loss_ss: 1.150256, loss_d: 0.032769
0.7389 --- loss: 1.190831, loss_ss: 1.098769, loss_d: 0.092062
0.9852 --- loss: 1.147402, loss_ss: 1.125784, loss_d: 0.021618
Epoch finished! Loss: 1.2667650699615478
Starting epoch 5/10.
0.0000 --- loss: 1.327236, loss_ss: 1.084753, loss_d: 0.242482
0.2463 --- loss: 1.318185, loss_ss: 1.086765, loss_d: 0.231421
0.4926 --- loss: 1.147046, loss_ss: 1.140234, loss_d: 0.006812
0.7389 --- loss: 1.093490, loss_ss: 1.086990, loss_d: 0.006501
0.9852 --- loss: 1.155617, loss_ss: 1.149463, loss_d: 0.006154
Epoch finished! Loss: 1.160110080242157
Starting epoch 6/10.
0.0000 --- loss: 1.173663, loss_ss: 1.171600, loss_d: 0.002063
0.2463 --- loss: 0.950487, loss_ss: 0.941489, loss_d: 0.008998
0.4926 --- loss: 0.982166, loss_ss: 0.979267, loss_d: 0.002899
0.7389 --- loss: 1.007172, loss_ss: 1.004742, loss_d: 0.002429
0.9852 --- loss: 1.084702, loss_ss: 1.084365, loss_d: 0.000337
Epoch finished! Loss: 1.0504573807120323
Starting epoch 7/10.
0.0000 --- loss: 0.887420, loss_ss: 0.886504, loss_d: 0.000916
0.2463 --- loss: 1.057535, loss_ss: 1.048471, loss_d: 0.009064
0.4926 --- loss: 0.957392, loss_ss: 0.955564, loss_d: 0.001828
0.7389 --- loss: 0.968366, loss_ss: 0.968157, loss_d: 0.000209
0.9852 --- loss: 1.005439, loss_ss: 1.002893, loss_d: 0.002546
Epoch finished! Loss: 0.9930054500699044
Starting epoch 8/10.
0.0000 --- loss: 0.955651, loss_ss: 0.954699, loss_d: 0.000951
0.2463 --- loss: 0.937566, loss_ss: 0.936776, loss_d: 0.000790
0.4926 --- loss: 0.822280, loss_ss: 0.820624, loss_d: 0.001656
0.7389 --- loss: 0.818988, loss_ss: 0.818406, loss_d: 0.000582
0.9852 --- loss: 0.879614, loss_ss: 0.879357, loss_d: 0.000258
Epoch finished! Loss: 0.9265317797660828
Starting epoch 9/10.
0.0000 --- loss: 0.859172, loss_ss: 0.858569, loss_d: 0.000603
0.2463 --- loss: 0.783604, loss_ss: 0.783271, loss_d: 0.000333
0.4926 --- loss: 0.916029, loss_ss: 0.915360, loss_d: 0.000669
0.7389 --- loss: 0.824271, loss_ss: 0.824158, loss_d: 0.000112
0.9852 --- loss: 0.962464, loss_ss: 0.962177, loss_d: 0.000287
Epoch finished! Loss: 0.8936062261462212
Starting epoch 10/10.
0.0000 --- loss: 0.813814, loss_ss: 0.813064, loss_d: 0.000750
0.2463 --- loss: 0.933296, loss_ss: 0.932988, loss_d: 0.000308
0.4926 --- loss: 0.924672, loss_ss: 0.924249, loss_d: 0.000423
0.7389 --- loss: 0.978395, loss_ss: 0.978284, loss_d: 0.000111
0.9852 --- loss: 0.771743, loss_ss: 0.771512, loss_d: 0.000231
Epoch finished! Loss: 0.8473694011569023
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.32314814814814813
             precision    recall  f1-score   support

        0.0       0.18      0.68      0.28        25
        1.0       0.11      0.99      0.20        77
        2.0       0.82      0.44      0.57       553
        3.0       1.00      0.16      0.27        69
        4.0       0.00      0.00      0.00       356

avg / total       0.49      0.32      0.33      1080
 


====== chp001-nsrr ======

The ppr of  4  has ZeroDivisionError.

The f1-score of  4  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  91.85  68.00   92.42   17.53     27.87
1  44.72  98.70   40.58   11.31     20.29
2  66.39  44.30   89.56   81.67     57.44
3  94.63  15.94  100.00  100.00     27.50
4  67.04   0.00  100.00    0.00      0.00
Total accuracy: 32.31%
Average sen: 45.39%
Average spec: 84.51%
Macro f1-score: 26.62%
Diagnosis acc on 90mins: 1.0
[0.9997279  0.99976307 0.99999809 0.99827278 0.99999809 0.99887127]
pred: 0.9994385341803232, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp001-nsrr

=== Test on chp002-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.362578, loss_ss: 1.708904, loss_d: 0.653675
0.2463 --- loss: 2.238577, loss_ss: 1.554462, loss_d: 0.684115
0.4926 --- loss: 2.038415, loss_ss: 1.432356, loss_d: 0.606059
0.7389 --- loss: 2.160743, loss_ss: 1.433613, loss_d: 0.727130
0.9852 --- loss: 2.001770, loss_ss: 1.449377, loss_d: 0.552392
Epoch finished! Loss: 2.1910145074129104
Starting epoch 2/10.
0.0000 --- loss: 1.969045, loss_ss: 1.440857, loss_d: 0.528189
0.2463 --- loss: 1.907946, loss_ss: 1.400612, loss_d: 0.507333
0.4926 --- loss: 1.808749, loss_ss: 1.335882, loss_d: 0.472867
0.7389 --- loss: 1.508632, loss_ss: 1.315813, loss_d: 0.192819
0.9852 --- loss: 1.839595, loss_ss: 1.327740, loss_d: 0.511854
Epoch finished! Loss: 1.8337169200181962
Starting epoch 3/10.
0.0000 --- loss: 1.459940, loss_ss: 1.256761, loss_d: 0.203179
0.2463 --- loss: 1.534933, loss_ss: 1.435088, loss_d: 0.099845
0.4926 --- loss: 1.353906, loss_ss: 1.241293, loss_d: 0.112612
0.7389 --- loss: 1.300860, loss_ss: 1.223248, loss_d: 0.077612
0.9852 --- loss: 1.279552, loss_ss: 1.250391, loss_d: 0.029162
Epoch finished! Loss: 1.4918368697166442
Starting epoch 4/10.
0.0000 --- loss: 1.477366, loss_ss: 1.242286, loss_d: 0.235080
0.2463 --- loss: 1.324796, loss_ss: 1.282966, loss_d: 0.041830
0.4926 --- loss: 1.321064, loss_ss: 1.173855, loss_d: 0.147209
0.7389 --- loss: 1.306988, loss_ss: 1.179692, loss_d: 0.127295
0.9852 --- loss: 1.127708, loss_ss: 1.087760, loss_d: 0.039948
Epoch finished! Loss: 1.3422184407711029
Starting epoch 5/10.
0.0000 --- loss: 1.211477, loss_ss: 1.078254, loss_d: 0.133223
0.2463 --- loss: 1.108718, loss_ss: 1.089687, loss_d: 0.019031
0.4926 --- loss: 1.113937, loss_ss: 1.109003, loss_d: 0.004934
0.7389 --- loss: 1.141299, loss_ss: 1.134120, loss_d: 0.007179
0.9852 --- loss: 1.123177, loss_ss: 1.093840, loss_d: 0.029337
Epoch finished! Loss: 1.1544223368167876
Starting epoch 6/10.
0.0000 --- loss: 1.085600, loss_ss: 1.071710, loss_d: 0.013890
0.2463 --- loss: 1.086524, loss_ss: 1.066036, loss_d: 0.020488
0.4926 --- loss: 0.890007, loss_ss: 0.880135, loss_d: 0.009872
0.7389 --- loss: 0.956352, loss_ss: 0.947042, loss_d: 0.009310
0.9852 --- loss: 1.005031, loss_ss: 1.003326, loss_d: 0.001705
Epoch finished! Loss: 1.0519107699394226
Starting epoch 7/10.
0.0000 --- loss: 1.040056, loss_ss: 1.039041, loss_d: 0.001015
0.2463 --- loss: 1.060003, loss_ss: 1.051842, loss_d: 0.008161
0.4926 --- loss: 1.019418, loss_ss: 1.018020, loss_d: 0.001398
0.7389 --- loss: 0.936994, loss_ss: 0.934075, loss_d: 0.002919
0.9852 --- loss: 1.007424, loss_ss: 1.006423, loss_d: 0.001002
Epoch finished! Loss: 0.9906322702765464
Starting epoch 8/10.
0.0000 --- loss: 0.986683, loss_ss: 0.984639, loss_d: 0.002044
0.2463 --- loss: 0.904773, loss_ss: 0.903798, loss_d: 0.000975
0.4926 --- loss: 0.919056, loss_ss: 0.918764, loss_d: 0.000292
0.7389 --- loss: 0.862106, loss_ss: 0.861168, loss_d: 0.000938
0.9852 --- loss: 0.911057, loss_ss: 0.910151, loss_d: 0.000906
Epoch finished! Loss: 0.9178700923919678
Starting epoch 9/10.
0.0000 --- loss: 0.855405, loss_ss: 0.855133, loss_d: 0.000273
0.2463 --- loss: 0.852108, loss_ss: 0.851870, loss_d: 0.000238
0.4926 --- loss: 0.838998, loss_ss: 0.838534, loss_d: 0.000464
0.7389 --- loss: 1.027467, loss_ss: 1.027328, loss_d: 0.000139
0.9852 --- loss: 0.985690, loss_ss: 0.984709, loss_d: 0.000981
Epoch finished! Loss: 0.8866271644830703
Starting epoch 10/10.
0.0000 --- loss: 0.718432, loss_ss: 0.717643, loss_d: 0.000790
0.2463 --- loss: 0.776608, loss_ss: 0.776473, loss_d: 0.000135
0.4926 --- loss: 0.918411, loss_ss: 0.917965, loss_d: 0.000446
0.7389 --- loss: 0.904168, loss_ss: 0.893621, loss_d: 0.010546
0.9852 --- loss: 0.834313, loss_ss: 0.834082, loss_d: 0.000231
Epoch finished! Loss: 0.8497356876730919
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7111111111111111
             precision    recall  f1-score   support

        0.0       0.85      0.45      0.59       260
        1.0       0.61      0.58      0.60       248
        2.0       0.91      0.93      0.92       375
        3.0       1.00      0.83      0.91       169
        4.0       0.10      0.64      0.17        28

avg / total       0.82      0.71      0.74      1080
 


====== chp002-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  84.81  45.00   97.44   84.78     58.79
1  81.94  58.47   88.94   61.18     59.79
2  94.26  92.80   95.04   90.86     91.82
3  97.31  82.84  100.00  100.00     90.61
4  83.89  64.29   84.41    9.89     17.14
Total accuracy: 71.11%
Average sen: 68.68%
Average spec: 93.17%
Macro f1-score: 63.63%
Diagnosis acc on 90mins: 1.0
[0.99896204 0.99987578 0.99902034 0.99999857 0.99870634 0.99866843]
pred: 0.9992052515347799, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp002-nsrr

=== Test on chp003-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.409415, loss_ss: 1.768020, loss_d: 0.641395
0.2457 --- loss: 2.403078, loss_ss: 1.538794, loss_d: 0.864284
0.4914 --- loss: 2.043966, loss_ss: 1.544667, loss_d: 0.499298
0.7371 --- loss: 2.109642, loss_ss: 1.564017, loss_d: 0.545625
0.9828 --- loss: 2.167766, loss_ss: 1.529998, loss_d: 0.637768
Epoch finished! Loss: 2.2580279797315597
Starting epoch 2/10.
0.0000 --- loss: 2.098470, loss_ss: 1.593268, loss_d: 0.505202
0.2457 --- loss: 2.006066, loss_ss: 1.535786, loss_d: 0.470280
0.4914 --- loss: 1.662824, loss_ss: 1.417724, loss_d: 0.245100
0.7371 --- loss: 2.088042, loss_ss: 1.411194, loss_d: 0.676849
0.9828 --- loss: 1.899271, loss_ss: 1.358397, loss_d: 0.540874
Epoch finished! Loss: 1.918336495757103
Starting epoch 3/10.
0.0000 --- loss: 1.753423, loss_ss: 1.403156, loss_d: 0.350267
0.2457 --- loss: 1.540762, loss_ss: 1.287842, loss_d: 0.252920
0.4914 --- loss: 1.427396, loss_ss: 1.339798, loss_d: 0.087598
0.7371 --- loss: 1.591182, loss_ss: 1.344225, loss_d: 0.246957
0.9828 --- loss: 1.606185, loss_ss: 1.336973, loss_d: 0.269212
Epoch finished! Loss: 1.5635082185268403
Starting epoch 4/10.
0.0000 --- loss: 1.521426, loss_ss: 1.400294, loss_d: 0.121132
0.2457 --- loss: 1.438989, loss_ss: 1.390805, loss_d: 0.048184
0.4914 --- loss: 1.476106, loss_ss: 1.463920, loss_d: 0.012186
0.7371 --- loss: 1.347328, loss_ss: 1.335615, loss_d: 0.011713
0.9828 --- loss: 1.243553, loss_ss: 1.191397, loss_d: 0.052156
Epoch finished! Loss: 1.3949942469596863
Starting epoch 5/10.
0.0000 --- loss: 1.268266, loss_ss: 1.265073, loss_d: 0.003194
0.2457 --- loss: 1.415182, loss_ss: 1.399236, loss_d: 0.015945
0.4914 --- loss: 1.206752, loss_ss: 1.204119, loss_d: 0.002633
0.7371 --- loss: 1.290806, loss_ss: 1.249363, loss_d: 0.041443
0.9828 --- loss: 1.197267, loss_ss: 1.197238, loss_d: 0.000029
Epoch finished! Loss: 1.3011113435029984
Starting epoch 6/10.
0.0000 --- loss: 1.246300, loss_ss: 1.219985, loss_d: 0.026315
0.2457 --- loss: 1.107249, loss_ss: 1.104610, loss_d: 0.002639
0.4914 --- loss: 1.449263, loss_ss: 1.103940, loss_d: 0.345323
0.7371 --- loss: 1.142788, loss_ss: 1.128372, loss_d: 0.014416
0.9828 --- loss: 1.202868, loss_ss: 1.146860, loss_d: 0.056009
Epoch finished! Loss: 1.2607337325811385
Starting epoch 7/10.
0.0000 --- loss: 1.066518, loss_ss: 1.064690, loss_d: 0.001828
0.2457 --- loss: 1.202732, loss_ss: 1.117390, loss_d: 0.085342
0.4914 --- loss: 1.125848, loss_ss: 1.117835, loss_d: 0.008013
0.7371 --- loss: 1.110539, loss_ss: 1.092973, loss_d: 0.017567
0.9828 --- loss: 1.005125, loss_ss: 0.998555, loss_d: 0.006570
Epoch finished! Loss: 1.1371562257409096
Starting epoch 8/10.
0.0000 --- loss: 1.083731, loss_ss: 1.082363, loss_d: 0.001368
0.2457 --- loss: 1.107843, loss_ss: 1.028074, loss_d: 0.079769
0.4914 --- loss: 1.044776, loss_ss: 0.984639, loss_d: 0.060137
0.7371 --- loss: 1.214560, loss_ss: 0.934227, loss_d: 0.280334
0.9828 --- loss: 0.966272, loss_ss: 0.964717, loss_d: 0.001555
Epoch finished! Loss: 1.0832669958472252
Starting epoch 9/10.
0.0000 --- loss: 0.980647, loss_ss: 0.966364, loss_d: 0.014284
0.2457 --- loss: 0.913292, loss_ss: 0.907756, loss_d: 0.005536
0.4914 --- loss: 1.179377, loss_ss: 1.087161, loss_d: 0.092216
0.7371 --- loss: 1.105347, loss_ss: 1.100270, loss_d: 0.005077
0.9828 --- loss: 0.920474, loss_ss: 0.915753, loss_d: 0.004721
Epoch finished! Loss: 1.0226004704833032
Starting epoch 10/10.
0.0000 --- loss: 1.007683, loss_ss: 0.868455, loss_d: 0.139228
0.2457 --- loss: 0.907954, loss_ss: 0.902277, loss_d: 0.005678
0.4914 --- loss: 0.909723, loss_ss: 0.891657, loss_d: 0.018067
0.7371 --- loss: 0.955202, loss_ss: 0.877268, loss_d: 0.077933
0.9828 --- loss: 1.031785, loss_ss: 1.030218, loss_d: 0.001567
Epoch finished! Loss: 0.9526521056890488
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7255555555555555
             precision    recall  f1-score   support

        0.0       0.36      0.80      0.50        59
        1.0       0.00      0.00      0.00        27
        2.0       0.77      0.86      0.81       468
        3.0       0.99      0.68      0.80       196
        4.0       0.63      0.47      0.54       150

avg / total       0.74      0.73      0.72       900
 


====== chp003-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  89.44  79.66   90.13  36.15     49.74
1  97.00   0.00  100.00   0.00      0.00
2  79.33  86.11   71.99  76.91     81.25
3  92.78  67.86   99.72  98.52     80.36
4  86.56  46.67   94.53  63.06     53.64
Total accuracy: 72.56%
Average sen: 56.06%
Average spec: 91.27%
Macro f1-score: 53.00%
Diagnosis acc on 90mins: 0.4
[0.94593787 0.43607345 0.13432865 0.95976555 0.21654883]
pred: 0.5385308712720871, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp003-nsrr

=== Test on chp004-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.428895, loss_ss: 1.696788, loss_d: 0.732107
0.2457 --- loss: 2.240950, loss_ss: 1.562738, loss_d: 0.678213
0.4914 --- loss: 2.243345, loss_ss: 1.578712, loss_d: 0.664634
0.7371 --- loss: 1.871362, loss_ss: 1.474926, loss_d: 0.396436
0.9828 --- loss: 1.841154, loss_ss: 1.378784, loss_d: 0.462370
Epoch finished! Loss: 2.1494266599416734
Starting epoch 2/10.
0.0000 --- loss: 1.682108, loss_ss: 1.380328, loss_d: 0.301780
0.2457 --- loss: 1.962390, loss_ss: 1.312487, loss_d: 0.649903
0.4914 --- loss: 1.666226, loss_ss: 1.367186, loss_d: 0.299040
0.7371 --- loss: 1.881495, loss_ss: 1.318654, loss_d: 0.562842
0.9828 --- loss: 1.384001, loss_ss: 1.295704, loss_d: 0.088297
Epoch finished! Loss: 1.7582263618707656
Starting epoch 3/10.
0.0000 --- loss: 1.403487, loss_ss: 1.307471, loss_d: 0.096016
0.2457 --- loss: 1.337062, loss_ss: 1.228623, loss_d: 0.108439
0.4914 --- loss: 1.327172, loss_ss: 1.261786, loss_d: 0.065386
0.7371 --- loss: 1.217450, loss_ss: 1.188976, loss_d: 0.028474
0.9828 --- loss: 1.231964, loss_ss: 1.193750, loss_d: 0.038215
Epoch finished! Loss: 1.4087842613458634
Starting epoch 4/10.
0.0000 --- loss: 1.212769, loss_ss: 1.197903, loss_d: 0.014866
0.2457 --- loss: 1.150989, loss_ss: 1.141835, loss_d: 0.009155
0.4914 --- loss: 1.135671, loss_ss: 1.104265, loss_d: 0.031406
0.7371 --- loss: 1.290761, loss_ss: 1.173568, loss_d: 0.117193
0.9828 --- loss: 1.184872, loss_ss: 1.153847, loss_d: 0.031025
Epoch finished! Loss: 1.276011648774147
Starting epoch 5/10.
0.0000 --- loss: 1.305280, loss_ss: 1.198528, loss_d: 0.106751
0.2457 --- loss: 1.100748, loss_ss: 1.094923, loss_d: 0.005825
0.4914 --- loss: 1.113460, loss_ss: 1.103269, loss_d: 0.010191
0.7371 --- loss: 1.394681, loss_ss: 1.099136, loss_d: 0.295544
0.9828 --- loss: 1.223065, loss_ss: 1.220333, loss_d: 0.002732
Epoch finished! Loss: 1.177120567858219
Starting epoch 6/10.
0.0000 --- loss: 1.102968, loss_ss: 1.000111, loss_d: 0.102857
0.2457 --- loss: 0.982383, loss_ss: 0.976067, loss_d: 0.006315
0.4914 --- loss: 0.989872, loss_ss: 0.979174, loss_d: 0.010698
0.7371 --- loss: 1.039715, loss_ss: 1.034699, loss_d: 0.005017
0.9828 --- loss: 0.979435, loss_ss: 0.978034, loss_d: 0.001401
Epoch finished! Loss: 1.0624733969569207
Starting epoch 7/10.
0.0000 --- loss: 0.972661, loss_ss: 0.972100, loss_d: 0.000561
0.2457 --- loss: 0.971542, loss_ss: 0.970702, loss_d: 0.000840
0.4914 --- loss: 0.926370, loss_ss: 0.909907, loss_d: 0.016463
0.7371 --- loss: 1.037876, loss_ss: 1.036086, loss_d: 0.001790
0.9828 --- loss: 0.990772, loss_ss: 0.990194, loss_d: 0.000577
Epoch finished! Loss: 0.9902250424027443
Starting epoch 8/10.
0.0000 --- loss: 0.894691, loss_ss: 0.893918, loss_d: 0.000773
0.2457 --- loss: 0.898634, loss_ss: 0.898146, loss_d: 0.000488
0.4914 --- loss: 0.957680, loss_ss: 0.957580, loss_d: 0.000100
0.7371 --- loss: 0.817147, loss_ss: 0.816909, loss_d: 0.000238
0.9828 --- loss: 0.992089, loss_ss: 0.991348, loss_d: 0.000741
Epoch finished! Loss: 0.9327758774161339
Starting epoch 9/10.
0.0000 --- loss: 0.852000, loss_ss: 0.851124, loss_d: 0.000876
0.2457 --- loss: 0.807211, loss_ss: 0.806755, loss_d: 0.000455
0.4914 --- loss: 0.858311, loss_ss: 0.858151, loss_d: 0.000161
0.7371 --- loss: 0.889055, loss_ss: 0.873276, loss_d: 0.015779
0.9828 --- loss: 0.982260, loss_ss: 0.981826, loss_d: 0.000433
Epoch finished! Loss: 0.889896672964096
Starting epoch 10/10.
0.0000 --- loss: 0.780850, loss_ss: 0.776308, loss_d: 0.004542
0.2457 --- loss: 0.821896, loss_ss: 0.821717, loss_d: 0.000179
0.4914 --- loss: 0.870733, loss_ss: 0.870435, loss_d: 0.000297
0.7371 --- loss: 0.890030, loss_ss: 0.889866, loss_d: 0.000164
0.9828 --- loss: 0.922175, loss_ss: 0.921549, loss_d: 0.000626
Epoch finished! Loss: 0.8682820305228234
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6155555555555555
             precision    recall  f1-score   support

        0.0       0.79      0.21      0.33       105
        1.0       0.34      0.32      0.33       123
        2.0       0.67      0.85      0.75       354
        3.0       1.00      0.44      0.61       197
        4.0       0.48      0.88      0.62       121

avg / total       0.68      0.62      0.59       900
 


====== chp004-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  90.11  20.95   99.25   78.57     33.08
1  82.11  31.71   90.09   33.62     32.64
2  77.44  85.03   72.53   66.74     74.78
3  87.67  43.65  100.00  100.00     60.78
4  85.78  87.60   85.49   48.40     62.35
Total accuracy: 61.56%
Average sen: 53.79%
Average spec: 89.47%
Macro f1-score: 52.73%
Diagnosis acc on 90mins: 1.0
[0.99998426 0.99996507 0.99999917 0.99976808 0.99791473]
pred: 0.9995262622833252, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp004-nsrr

=== Test on chp005-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.439254, loss_ss: 1.813871, loss_d: 0.625383
0.2469 --- loss: 2.170583, loss_ss: 1.572821, loss_d: 0.597763
0.4938 --- loss: 2.037180, loss_ss: 1.594575, loss_d: 0.442605
0.7407 --- loss: 1.931847, loss_ss: 1.449645, loss_d: 0.482202
0.9877 --- loss: 2.254327, loss_ss: 1.412897, loss_d: 0.841429
Epoch finished! Loss: 2.2299057871103285
Starting epoch 2/10.
0.0000 --- loss: 1.824672, loss_ss: 1.358628, loss_d: 0.466044
0.2469 --- loss: 1.877151, loss_ss: 1.454190, loss_d: 0.422961
0.4938 --- loss: 1.884238, loss_ss: 1.291292, loss_d: 0.592946
0.7407 --- loss: 1.554144, loss_ss: 1.354900, loss_d: 0.199245
0.9877 --- loss: 1.749348, loss_ss: 1.380449, loss_d: 0.368899
Epoch finished! Loss: 1.8761103302240372
Starting epoch 3/10.
0.0000 --- loss: 1.627932, loss_ss: 1.274352, loss_d: 0.353579
0.2469 --- loss: 1.640136, loss_ss: 1.327692, loss_d: 0.312444
0.4938 --- loss: 1.389697, loss_ss: 1.307243, loss_d: 0.082454
0.7407 --- loss: 1.317058, loss_ss: 1.260124, loss_d: 0.056934
0.9877 --- loss: 2.249748, loss_ss: 1.397405, loss_d: 0.852343
Epoch finished! Loss: 1.5540104031562805
Starting epoch 4/10.
0.0000 --- loss: 1.343799, loss_ss: 1.208761, loss_d: 0.135038
0.2469 --- loss: 1.371525, loss_ss: 1.216917, loss_d: 0.154608
0.4938 --- loss: 1.444170, loss_ss: 1.166690, loss_d: 0.277480
0.7407 --- loss: 1.379422, loss_ss: 1.161578, loss_d: 0.217844
0.9877 --- loss: 1.226069, loss_ss: 1.222021, loss_d: 0.004049
Epoch finished! Loss: 1.3892219066619873
Starting epoch 5/10.
0.0000 --- loss: 1.235159, loss_ss: 1.172583, loss_d: 0.062577
0.2469 --- loss: 1.201713, loss_ss: 1.189213, loss_d: 0.012500
0.4938 --- loss: 1.188408, loss_ss: 1.172335, loss_d: 0.016073
0.7407 --- loss: 1.256030, loss_ss: 1.244616, loss_d: 0.011413
0.9877 --- loss: 1.060412, loss_ss: 1.052878, loss_d: 0.007534
Epoch finished! Loss: 1.1750604271888734
Starting epoch 6/10.
0.0000 --- loss: 1.075128, loss_ss: 1.070510, loss_d: 0.004618
0.2469 --- loss: 1.077236, loss_ss: 1.074532, loss_d: 0.002704
0.4938 --- loss: 1.052328, loss_ss: 1.048689, loss_d: 0.003639
0.7407 --- loss: 0.957695, loss_ss: 0.955743, loss_d: 0.001951
0.9877 --- loss: 0.990530, loss_ss: 0.989825, loss_d: 0.000704
Epoch finished! Loss: 1.0875733941793442
Starting epoch 7/10.
0.0000 --- loss: 1.009802, loss_ss: 1.008571, loss_d: 0.001230
0.2469 --- loss: 0.998599, loss_ss: 0.995872, loss_d: 0.002727
0.4938 --- loss: 1.018633, loss_ss: 1.017851, loss_d: 0.000783
0.7407 --- loss: 0.886729, loss_ss: 0.886267, loss_d: 0.000462
0.9877 --- loss: 0.930045, loss_ss: 0.928178, loss_d: 0.001867
Epoch finished! Loss: 1.000102812051773
Starting epoch 8/10.
0.0000 --- loss: 0.935407, loss_ss: 0.933427, loss_d: 0.001980
0.2469 --- loss: 0.894830, loss_ss: 0.894497, loss_d: 0.000332
0.4938 --- loss: 0.914731, loss_ss: 0.914351, loss_d: 0.000380
0.7407 --- loss: 1.025215, loss_ss: 1.024343, loss_d: 0.000872
0.9877 --- loss: 1.039787, loss_ss: 1.036679, loss_d: 0.003108
Epoch finished! Loss: 0.9471060141921044
Starting epoch 9/10.
0.0000 --- loss: 0.827848, loss_ss: 0.823834, loss_d: 0.004014
0.2469 --- loss: 0.882015, loss_ss: 0.881133, loss_d: 0.000882
0.4938 --- loss: 0.743833, loss_ss: 0.742458, loss_d: 0.001376
0.7407 --- loss: 0.753359, loss_ss: 0.752389, loss_d: 0.000971
0.9877 --- loss: 0.908235, loss_ss: 0.907869, loss_d: 0.000366
Epoch finished! Loss: 0.8979308500885963
Starting epoch 10/10.
0.0000 --- loss: 0.815470, loss_ss: 0.814978, loss_d: 0.000492
0.2469 --- loss: 0.878952, loss_ss: 0.878008, loss_d: 0.000943
0.4938 --- loss: 0.890961, loss_ss: 0.890681, loss_d: 0.000279
0.7407 --- loss: 0.799392, loss_ss: 0.784528, loss_d: 0.014864
0.9877 --- loss: 0.742859, loss_ss: 0.742565, loss_d: 0.000294
Epoch finished! Loss: 0.8479901224374771
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6436507936507937
             precision    recall  f1-score   support

        0.0       0.25      0.79      0.38        63
        1.0       0.59      0.35      0.44       235
        2.0       0.70      0.96      0.81       565
        3.0       1.00      0.01      0.01       136
        4.0       0.93      0.52      0.67       261

avg / total       0.74      0.64      0.60      1260
 


====== chp005-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  87.30  79.37   87.72   25.38     38.46
1  83.33  35.32   94.34   58.87     44.15
2  79.60  95.75   66.47   69.90     80.81
3  89.29   0.74  100.00  100.00      1.46
4  89.21  52.11   98.90   92.52     66.67
Total accuracy: 64.37%
Average sen: 52.66%
Average spec: 89.49%
Macro f1-score: 46.31%
Diagnosis acc on 90mins: 1.0
[0.99994421 0.98765999 0.99995971 0.9999994  0.99968219 0.99999988
 0.99999869]
pred: 0.9981777242251805, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp005-nsrr

=== Test on chp006-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.391719, loss_ss: 1.762695, loss_d: 0.629024
0.2463 --- loss: 2.363657, loss_ss: 1.701220, loss_d: 0.662438
0.4926 --- loss: 2.000452, loss_ss: 1.663196, loss_d: 0.337256
0.7389 --- loss: 1.977203, loss_ss: 1.550907, loss_d: 0.426296
0.9852 --- loss: 2.285649, loss_ss: 1.344640, loss_d: 0.941008
Epoch finished! Loss: 2.2477208882570268
Starting epoch 2/10.
0.0000 --- loss: 1.977102, loss_ss: 1.538090, loss_d: 0.439012
0.2463 --- loss: 1.947276, loss_ss: 1.451637, loss_d: 0.495638
0.4926 --- loss: 2.070863, loss_ss: 1.511050, loss_d: 0.559814
0.7389 --- loss: 2.230170, loss_ss: 1.416222, loss_d: 0.813949
0.9852 --- loss: 1.518898, loss_ss: 1.314527, loss_d: 0.204371
Epoch finished! Loss: 1.9557166129350663
Starting epoch 3/10.
0.0000 --- loss: 1.579932, loss_ss: 1.448167, loss_d: 0.131765
0.2463 --- loss: 1.718897, loss_ss: 1.454193, loss_d: 0.264704
0.4926 --- loss: 1.643802, loss_ss: 1.462410, loss_d: 0.181392
0.7389 --- loss: 1.763785, loss_ss: 1.416498, loss_d: 0.347287
0.9852 --- loss: 1.611152, loss_ss: 1.247125, loss_d: 0.364027
Epoch finished! Loss: 1.658966839313507
Starting epoch 4/10.
0.0000 --- loss: 1.639769, loss_ss: 1.374368, loss_d: 0.265401
0.2463 --- loss: 1.389652, loss_ss: 1.348375, loss_d: 0.041278
0.4926 --- loss: 1.396833, loss_ss: 1.280224, loss_d: 0.116610
0.7389 --- loss: 1.256258, loss_ss: 1.179089, loss_d: 0.077168
0.9852 --- loss: 1.326625, loss_ss: 1.207697, loss_d: 0.118928
Epoch finished! Loss: 1.412950986623764
Starting epoch 5/10.
0.0000 --- loss: 1.258198, loss_ss: 1.252593, loss_d: 0.005605
0.2463 --- loss: 1.206588, loss_ss: 1.164888, loss_d: 0.041700
0.4926 --- loss: 1.209645, loss_ss: 1.195605, loss_d: 0.014040
0.7389 --- loss: 1.149556, loss_ss: 1.141595, loss_d: 0.007962
0.9852 --- loss: 1.206182, loss_ss: 1.199932, loss_d: 0.006249
Epoch finished! Loss: 1.2673492789268495
Starting epoch 6/10.
0.0000 --- loss: 1.270750, loss_ss: 1.268610, loss_d: 0.002140
0.2463 --- loss: 1.217512, loss_ss: 1.040331, loss_d: 0.177181
0.4926 --- loss: 1.201453, loss_ss: 1.199521, loss_d: 0.001932
0.7389 --- loss: 1.194233, loss_ss: 1.162343, loss_d: 0.031890
0.9852 --- loss: 1.058043, loss_ss: 1.052575, loss_d: 0.005468
Epoch finished! Loss: 1.1876323014497756
Starting epoch 7/10.
0.0000 --- loss: 1.084754, loss_ss: 1.079839, loss_d: 0.004915
0.2463 --- loss: 1.048101, loss_ss: 0.983057, loss_d: 0.065044
0.4926 --- loss: 1.088252, loss_ss: 1.085264, loss_d: 0.002988
0.7389 --- loss: 1.051908, loss_ss: 1.047359, loss_d: 0.004550
0.9852 --- loss: 0.983111, loss_ss: 0.982573, loss_d: 0.000538
Epoch finished! Loss: 1.076379917562008
Starting epoch 8/10.
0.0000 --- loss: 0.984339, loss_ss: 0.978706, loss_d: 0.005633
0.2463 --- loss: 1.082162, loss_ss: 1.081296, loss_d: 0.000866
0.4926 --- loss: 0.871818, loss_ss: 0.871349, loss_d: 0.000468
0.7389 --- loss: 0.906864, loss_ss: 0.906387, loss_d: 0.000477
0.9852 --- loss: 0.912460, loss_ss: 0.912370, loss_d: 0.000090
Epoch finished! Loss: 0.9968106031417847
Starting epoch 9/10.
0.0000 --- loss: 0.905497, loss_ss: 0.905477, loss_d: 0.000020
0.2463 --- loss: 0.889286, loss_ss: 0.888659, loss_d: 0.000627
0.4926 --- loss: 0.945998, loss_ss: 0.945621, loss_d: 0.000378
0.7389 --- loss: 1.021508, loss_ss: 1.017559, loss_d: 0.003949
0.9852 --- loss: 0.969701, loss_ss: 0.969472, loss_d: 0.000230
Epoch finished! Loss: 0.9568190753459931
Starting epoch 10/10.
0.0000 --- loss: 0.892231, loss_ss: 0.891744, loss_d: 0.000487
0.2463 --- loss: 1.015666, loss_ss: 1.009713, loss_d: 0.005953
0.4926 --- loss: 0.842022, loss_ss: 0.834704, loss_d: 0.007318
0.7389 --- loss: 0.908337, loss_ss: 0.907875, loss_d: 0.000462
0.9852 --- loss: 1.049421, loss_ss: 1.048569, loss_d: 0.000852
Epoch finished! Loss: 0.9249559089541435
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5388888888888889
             precision    recall  f1-score   support

        0.0       0.28      0.78      0.41       120
        1.0       0.00      0.00      0.00       322
        2.0       0.65      0.75      0.70       274
        3.0       0.99      0.83      0.90       224
        4.0       0.41      0.71      0.52       140

avg / total       0.46      0.54      0.48      1080
 


====== chp006-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  74.81  77.50   74.48  27.51     40.61
1  70.19   0.00  100.00   0.00      0.00
2  83.52  74.82   86.48  65.29     69.73
3  96.30  82.59   99.88  99.46     90.24
4  82.96  70.71   84.79  40.91     51.83
Total accuracy: 53.89%
Average sen: 61.12%
Average spec: 89.13%
Macro f1-score: 50.48%
Diagnosis acc on 90mins: 1.0
[0.98954505 0.99998283 0.99993277 0.99998593 0.99908054 0.99999917]
pred: 0.9980877141157786, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp006-nsrr

=== Test on chp007-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.285892, loss_ss: 1.607599, loss_d: 0.678294
0.2463 --- loss: 2.236252, loss_ss: 1.526036, loss_d: 0.710216
0.4926 --- loss: 2.273905, loss_ss: 1.498516, loss_d: 0.775390
0.7389 --- loss: 1.866153, loss_ss: 1.485191, loss_d: 0.380961
0.9852 --- loss: 2.330548, loss_ss: 1.478190, loss_d: 0.852358
Epoch finished! Loss: 2.2243817687034606
Starting epoch 2/10.
0.0000 --- loss: 2.010791, loss_ss: 1.434492, loss_d: 0.576299
0.2463 --- loss: 1.972997, loss_ss: 1.371988, loss_d: 0.601009
0.4926 --- loss: 1.927097, loss_ss: 1.413959, loss_d: 0.513138
0.7389 --- loss: 1.634252, loss_ss: 1.367477, loss_d: 0.266774
0.9852 --- loss: 1.773122, loss_ss: 1.373328, loss_d: 0.399794
Epoch finished! Loss: 1.9208251982927322
Starting epoch 3/10.
0.0000 --- loss: 1.713259, loss_ss: 1.413315, loss_d: 0.299944
0.2463 --- loss: 1.652793, loss_ss: 1.370087, loss_d: 0.282706
0.4926 --- loss: 1.435698, loss_ss: 1.361549, loss_d: 0.074148
0.7389 --- loss: 1.430789, loss_ss: 1.277523, loss_d: 0.153266
0.9852 --- loss: 1.568715, loss_ss: 1.324777, loss_d: 0.243938
Epoch finished! Loss: 1.594342377781868
Starting epoch 4/10.
0.0000 --- loss: 1.460494, loss_ss: 1.380749, loss_d: 0.079745
0.2463 --- loss: 1.401569, loss_ss: 1.352566, loss_d: 0.049003
0.4926 --- loss: 1.246813, loss_ss: 1.238953, loss_d: 0.007860
0.7389 --- loss: 1.263035, loss_ss: 1.243708, loss_d: 0.019326
0.9852 --- loss: 1.430272, loss_ss: 1.286659, loss_d: 0.143613
Epoch finished! Loss: 1.4150285065174102
Starting epoch 5/10.
0.0000 --- loss: 1.483507, loss_ss: 1.268338, loss_d: 0.215168
0.2463 --- loss: 1.369456, loss_ss: 1.251589, loss_d: 0.117867
0.4926 --- loss: 1.441566, loss_ss: 1.223174, loss_d: 0.218392
0.7389 --- loss: 1.392373, loss_ss: 1.270507, loss_d: 0.121866
0.9852 --- loss: 1.293147, loss_ss: 1.276971, loss_d: 0.016176
Epoch finished! Loss: 1.3352359384298325
Starting epoch 6/10.
0.0000 --- loss: 1.221729, loss_ss: 1.219437, loss_d: 0.002291
0.2463 --- loss: 1.142699, loss_ss: 1.139167, loss_d: 0.003532
0.4926 --- loss: 1.093894, loss_ss: 1.067848, loss_d: 0.026045
0.7389 --- loss: 1.202437, loss_ss: 1.189197, loss_d: 0.013240
0.9852 --- loss: 1.138318, loss_ss: 1.073998, loss_d: 0.064320
Epoch finished! Loss: 1.175422117114067
Starting epoch 7/10.
0.0000 --- loss: 1.074052, loss_ss: 1.072263, loss_d: 0.001789
0.2463 --- loss: 1.084009, loss_ss: 1.078398, loss_d: 0.005611
0.4926 --- loss: 1.061493, loss_ss: 1.057659, loss_d: 0.003834
0.7389 --- loss: 1.080458, loss_ss: 1.077361, loss_d: 0.003097
0.9852 --- loss: 0.971405, loss_ss: 0.969221, loss_d: 0.002184
Epoch finished! Loss: 1.1027652308344842
Starting epoch 8/10.
0.0000 --- loss: 0.911020, loss_ss: 0.903115, loss_d: 0.007905
0.2463 --- loss: 1.178157, loss_ss: 1.176755, loss_d: 0.001402
0.4926 --- loss: 0.888872, loss_ss: 0.886708, loss_d: 0.002164
0.7389 --- loss: 1.152680, loss_ss: 1.129180, loss_d: 0.023500
0.9852 --- loss: 1.167688, loss_ss: 1.152730, loss_d: 0.014958
Epoch finished! Loss: 1.0451779082417487
Starting epoch 9/10.
0.0000 --- loss: 0.902261, loss_ss: 0.901283, loss_d: 0.000978
0.2463 --- loss: 0.950099, loss_ss: 0.949475, loss_d: 0.000624
0.4926 --- loss: 0.948399, loss_ss: 0.947455, loss_d: 0.000945
0.7389 --- loss: 0.898712, loss_ss: 0.896979, loss_d: 0.001733
0.9852 --- loss: 1.017666, loss_ss: 1.017522, loss_d: 0.000144
Epoch finished! Loss: 0.9793945342302323
Starting epoch 10/10.
0.0000 --- loss: 0.779063, loss_ss: 0.775504, loss_d: 0.003559
0.2463 --- loss: 0.872099, loss_ss: 0.871902, loss_d: 0.000197
0.4926 --- loss: 0.895823, loss_ss: 0.895743, loss_d: 0.000081
0.7389 --- loss: 0.925805, loss_ss: 0.925348, loss_d: 0.000457
0.9852 --- loss: 0.881492, loss_ss: 0.881384, loss_d: 0.000108
Epoch finished! Loss: 0.9373102068901062
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5518518518518518
             precision    recall  f1-score   support

        0.0       0.71      0.75      0.73       166
        1.0       0.18      0.59      0.27        58
        2.0       0.50      0.75      0.60       369
        3.0       0.99      0.81      0.89       135
        4.0       0.98      0.14      0.25       352

avg / total       0.73      0.55      0.53      1080
 


====== chp007-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  91.57  75.30   94.53  71.43     73.31
1  82.96  58.62   84.34  17.53     26.98
2  66.30  75.07   61.74  50.46     60.35
3  97.59  81.48   99.89  99.10     89.43
4  71.94  14.20   99.86  98.04     24.81
Total accuracy: 55.19%
Average sen: 60.94%
Average spec: 88.07%
Macro f1-score: 54.98%
Diagnosis acc on 90mins: 1.0
[0.99995446 0.99996209 0.99998486 0.99979907 0.99998772 0.99982673]
pred: 0.9999191562334696, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp007-nsrr

=== Test on chp008-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.415279, loss_ss: 1.739119, loss_d: 0.676160
0.2457 --- loss: 2.506703, loss_ss: 1.656271, loss_d: 0.850433
0.4914 --- loss: 2.439858, loss_ss: 1.547401, loss_d: 0.892457
0.7371 --- loss: 1.868322, loss_ss: 1.501004, loss_d: 0.367318
0.9828 --- loss: 2.087100, loss_ss: 1.451073, loss_d: 0.636027
Epoch finished! Loss: 2.2603816121816633
Starting epoch 2/10.
0.0000 --- loss: 1.823346, loss_ss: 1.459623, loss_d: 0.363723
0.2457 --- loss: 1.924282, loss_ss: 1.426196, loss_d: 0.498086
0.4914 --- loss: 1.864843, loss_ss: 1.462660, loss_d: 0.402182
0.7371 --- loss: 1.650604, loss_ss: 1.413141, loss_d: 0.237463
0.9828 --- loss: 1.748725, loss_ss: 1.422300, loss_d: 0.326425
Epoch finished! Loss: 1.87750386595726
Starting epoch 3/10.
0.0000 --- loss: 1.485302, loss_ss: 1.300091, loss_d: 0.185211
0.2457 --- loss: 1.647505, loss_ss: 1.384016, loss_d: 0.263489
0.4914 --- loss: 1.369134, loss_ss: 1.279245, loss_d: 0.089889
0.7371 --- loss: 1.740381, loss_ss: 1.322065, loss_d: 0.418316
0.9828 --- loss: 1.390776, loss_ss: 1.321681, loss_d: 0.069095
Epoch finished! Loss: 1.607982099056244
Starting epoch 4/10.
0.0000 --- loss: 1.438893, loss_ss: 1.319301, loss_d: 0.119592
0.2457 --- loss: 1.499371, loss_ss: 1.361004, loss_d: 0.138367
0.4914 --- loss: 1.281787, loss_ss: 1.269392, loss_d: 0.012396
0.7371 --- loss: 1.293409, loss_ss: 1.243384, loss_d: 0.050025
0.9828 --- loss: 1.219786, loss_ss: 1.197992, loss_d: 0.021794
Epoch finished! Loss: 1.3583501040935517
Starting epoch 5/10.
0.0000 --- loss: 1.235649, loss_ss: 1.228053, loss_d: 0.007596
0.2457 --- loss: 1.204087, loss_ss: 1.191937, loss_d: 0.012151
0.4914 --- loss: 1.188775, loss_ss: 1.187937, loss_d: 0.000838
0.7371 --- loss: 1.311744, loss_ss: 1.297173, loss_d: 0.014571
0.9828 --- loss: 1.171071, loss_ss: 1.160764, loss_d: 0.010306
Epoch finished! Loss: 1.2116063326597213
Starting epoch 6/10.
0.0000 --- loss: 1.243280, loss_ss: 1.242229, loss_d: 0.001051
0.2457 --- loss: 1.168200, loss_ss: 1.166872, loss_d: 0.001328
0.4914 --- loss: 1.079601, loss_ss: 1.079011, loss_d: 0.000590
0.7371 --- loss: 1.063845, loss_ss: 1.062127, loss_d: 0.001718
0.9828 --- loss: 1.152578, loss_ss: 1.152105, loss_d: 0.000473
Epoch finished! Loss: 1.1406515955924987
Starting epoch 7/10.
0.0000 --- loss: 1.131519, loss_ss: 1.131078, loss_d: 0.000441
0.2457 --- loss: 1.113960, loss_ss: 1.113851, loss_d: 0.000109
0.4914 --- loss: 1.083798, loss_ss: 1.046123, loss_d: 0.037675
0.7371 --- loss: 1.092528, loss_ss: 1.049714, loss_d: 0.042814
0.9828 --- loss: 1.264602, loss_ss: 1.263909, loss_d: 0.000693
Epoch finished! Loss: 1.0616008907556533
Starting epoch 8/10.
0.0000 --- loss: 0.977008, loss_ss: 0.976806, loss_d: 0.000203
0.2457 --- loss: 1.038070, loss_ss: 1.037918, loss_d: 0.000152
0.4914 --- loss: 0.874292, loss_ss: 0.874193, loss_d: 0.000099
0.7371 --- loss: 1.024768, loss_ss: 1.024675, loss_d: 0.000092
0.9828 --- loss: 1.640269, loss_ss: 0.958574, loss_d: 0.681695
Epoch finished! Loss: 0.9993512719869614
Starting epoch 9/10.
0.0000 --- loss: 0.893697, loss_ss: 0.893029, loss_d: 0.000668
0.2457 --- loss: 0.894347, loss_ss: 0.894189, loss_d: 0.000157
0.4914 --- loss: 0.934046, loss_ss: 0.833790, loss_d: 0.100257
0.7371 --- loss: 0.979329, loss_ss: 0.852559, loss_d: 0.126770
0.9828 --- loss: 1.049458, loss_ss: 0.891478, loss_d: 0.157981
Epoch finished! Loss: 0.9978835865855217
Starting epoch 10/10.
0.0000 --- loss: 0.800563, loss_ss: 0.797314, loss_d: 0.003249
0.2457 --- loss: 1.116245, loss_ss: 1.021160, loss_d: 0.095086
0.4914 --- loss: 0.935077, loss_ss: 0.879941, loss_d: 0.055135
0.7371 --- loss: 0.966465, loss_ss: 0.949874, loss_d: 0.016591
0.9828 --- loss: 0.841233, loss_ss: 0.837393, loss_d: 0.003841
Epoch finished! Loss: 0.965991596877575
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6488888888888888
             precision    recall  f1-score   support

        0.0       0.53      0.53      0.53        89
        1.0       0.12      0.27      0.16        37
        2.0       0.72      0.58      0.64       387
        3.0       0.96      0.70      0.81       263
        4.0       0.53      0.94      0.68       124

avg / total       0.72      0.65      0.67       900
 


====== chp008-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  90.78  52.81   94.94  53.41     53.11
1  88.67  27.03   91.31  11.76     16.39
2  72.11  58.40   82.46  71.52     64.30
3  90.56  70.34   98.90  96.35     81.32
4  87.67  93.55   86.73  52.97     67.64
Total accuracy: 64.89%
Average sen: 60.42%
Average spec: 90.87%
Macro f1-score: 56.55%
Diagnosis acc on 90mins: 1.0
[0.99809557 0.99999988 0.99988091 0.98932463 0.91683447]
pred: 0.9808270931243896, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp008-nsrr

=== Test on chp009-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.401314, loss_ss: 1.711939, loss_d: 0.689375
0.2457 --- loss: 1.926989, loss_ss: 1.562154, loss_d: 0.364835
0.4914 --- loss: 2.168738, loss_ss: 1.523605, loss_d: 0.645133
0.7371 --- loss: 1.849027, loss_ss: 1.375857, loss_d: 0.473170
0.9828 --- loss: 1.981438, loss_ss: 1.503566, loss_d: 0.477871
Epoch finished! Loss: 2.2101940363645554
Starting epoch 2/10.
0.0000 --- loss: 2.082208, loss_ss: 1.435854, loss_d: 0.646354
0.2457 --- loss: 2.078810, loss_ss: 1.405001, loss_d: 0.673809
0.4914 --- loss: 1.761225, loss_ss: 1.330389, loss_d: 0.430836
0.7371 --- loss: 1.641170, loss_ss: 1.386456, loss_d: 0.254714
0.9828 --- loss: 1.683268, loss_ss: 1.287699, loss_d: 0.395569
Epoch finished! Loss: 1.895445328950882
Starting epoch 3/10.
0.0000 --- loss: 1.733872, loss_ss: 1.327631, loss_d: 0.406242
0.2457 --- loss: 1.572943, loss_ss: 1.278756, loss_d: 0.294187
0.4914 --- loss: 1.360842, loss_ss: 1.173347, loss_d: 0.187495
0.7371 --- loss: 1.454603, loss_ss: 1.282008, loss_d: 0.172594
0.9828 --- loss: 1.289695, loss_ss: 1.204308, loss_d: 0.085388
Epoch finished! Loss: 1.5145766347646714
Starting epoch 4/10.
0.0000 --- loss: 1.269361, loss_ss: 1.166376, loss_d: 0.102985
0.2457 --- loss: 1.586002, loss_ss: 1.281931, loss_d: 0.304071
0.4914 --- loss: 1.380589, loss_ss: 1.130079, loss_d: 0.250511
0.7371 --- loss: 1.463520, loss_ss: 1.186812, loss_d: 0.276709
0.9828 --- loss: 1.204488, loss_ss: 1.168010, loss_d: 0.036478
Epoch finished! Loss: 1.3332061648368836
Starting epoch 5/10.
0.0000 --- loss: 1.125183, loss_ss: 1.110931, loss_d: 0.014253
0.2457 --- loss: 1.193105, loss_ss: 1.139082, loss_d: 0.054024
0.4914 --- loss: 1.531988, loss_ss: 1.038012, loss_d: 0.493976
0.7371 --- loss: 1.293211, loss_ss: 1.199219, loss_d: 0.093992
0.9828 --- loss: 1.042832, loss_ss: 1.035192, loss_d: 0.007640
Epoch finished! Loss: 1.227484068274498
Starting epoch 6/10.
0.0000 --- loss: 1.075799, loss_ss: 1.058799, loss_d: 0.017000
0.2457 --- loss: 0.986937, loss_ss: 0.982441, loss_d: 0.004496
0.4914 --- loss: 1.024563, loss_ss: 1.017665, loss_d: 0.006897
0.7371 --- loss: 1.102008, loss_ss: 1.082913, loss_d: 0.019095
0.9828 --- loss: 1.151015, loss_ss: 1.144949, loss_d: 0.006066
Epoch finished! Loss: 1.1185865551233292
Starting epoch 7/10.
0.0000 --- loss: 1.030035, loss_ss: 1.026437, loss_d: 0.003598
0.2457 --- loss: 1.015928, loss_ss: 0.953497, loss_d: 0.062431
0.4914 --- loss: 0.965291, loss_ss: 0.950848, loss_d: 0.014443
0.7371 --- loss: 0.946974, loss_ss: 0.935318, loss_d: 0.011656
0.9828 --- loss: 1.166735, loss_ss: 1.162852, loss_d: 0.003884
Epoch finished! Loss: 1.0846210792660713
Starting epoch 8/10.
0.0000 --- loss: 0.989961, loss_ss: 0.988902, loss_d: 0.001059
0.2457 --- loss: 0.960493, loss_ss: 0.956365, loss_d: 0.004128
0.4914 --- loss: 0.922086, loss_ss: 0.917555, loss_d: 0.004531
0.7371 --- loss: 0.939127, loss_ss: 0.922678, loss_d: 0.016449
0.9828 --- loss: 1.040580, loss_ss: 1.032288, loss_d: 0.008292
Epoch finished! Loss: 1.0506563290953637
Starting epoch 9/10.
0.0000 --- loss: 1.036609, loss_ss: 1.030352, loss_d: 0.006257
0.2457 --- loss: 0.986462, loss_ss: 0.982753, loss_d: 0.003710
0.4914 --- loss: 1.254936, loss_ss: 1.253598, loss_d: 0.001337
0.7371 --- loss: 0.946052, loss_ss: 0.944660, loss_d: 0.001392
0.9828 --- loss: 0.933820, loss_ss: 0.932843, loss_d: 0.000976
Epoch finished! Loss: 0.9936237901449203
Starting epoch 10/10.
0.0000 --- loss: 0.876126, loss_ss: 0.872447, loss_d: 0.003679
0.2457 --- loss: 0.988573, loss_ss: 0.988397, loss_d: 0.000177
0.4914 --- loss: 0.866357, loss_ss: 0.865935, loss_d: 0.000421
0.7371 --- loss: 0.971295, loss_ss: 0.968275, loss_d: 0.003020
0.9828 --- loss: 0.872380, loss_ss: 0.871906, loss_d: 0.000474
Epoch finished! Loss: 0.9482145592570305
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.73
             precision    recall  f1-score   support

        0.0       0.45      0.92      0.61        96
        1.0       0.00      0.00      0.00        98
        2.0       0.75      0.87      0.80       340
        3.0       1.00      0.87      0.93       192
        4.0       0.74      0.61      0.67       174

avg / total       0.69      0.73      0.70       900
 


====== chp009-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  87.33  91.67   86.82   45.36     60.69
1  89.11   0.00  100.00    0.00      0.00
2  84.00  86.76   82.32   74.87     80.38
3  97.22  86.98  100.00  100.00     93.04
4  88.33  61.49   94.77   73.79     67.08
Total accuracy: 73.00%
Average sen: 65.38%
Average spec: 92.78%
Macro f1-score: 60.24%
Diagnosis acc on 90mins: 1.0
[0.9960919  0.9999944  0.99624628 0.99991012 0.99981385]
pred: 0.9984113097190856, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp009-nsrr

=== Test on chp010-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.257453, loss_ss: 1.574856, loss_d: 0.682597
0.2457 --- loss: 2.097157, loss_ss: 1.506836, loss_d: 0.590322
0.4914 --- loss: 1.868037, loss_ss: 1.435322, loss_d: 0.432715
0.7371 --- loss: 2.126124, loss_ss: 1.457921, loss_d: 0.668204
0.9828 --- loss: 1.822408, loss_ss: 1.340437, loss_d: 0.481971
Epoch finished! Loss: 2.1620364665985106
Starting epoch 2/10.
0.0000 --- loss: 1.678047, loss_ss: 1.394679, loss_d: 0.283368
0.2457 --- loss: 1.824816, loss_ss: 1.294048, loss_d: 0.530769
0.4914 --- loss: 1.687765, loss_ss: 1.292809, loss_d: 0.394956
0.7371 --- loss: 1.586554, loss_ss: 1.391681, loss_d: 0.194873
0.9828 --- loss: 1.529290, loss_ss: 1.286118, loss_d: 0.243172
Epoch finished! Loss: 1.8127057939767837
Starting epoch 3/10.
0.0000 --- loss: 1.412763, loss_ss: 1.289641, loss_d: 0.123123
0.2457 --- loss: 1.595884, loss_ss: 1.334653, loss_d: 0.261231
0.4914 --- loss: 1.333952, loss_ss: 1.313393, loss_d: 0.020559
0.7371 --- loss: 1.331669, loss_ss: 1.211340, loss_d: 0.120329
0.9828 --- loss: 1.318262, loss_ss: 1.266348, loss_d: 0.051913
Epoch finished! Loss: 1.4368692308664321
Starting epoch 4/10.
0.0000 --- loss: 1.240369, loss_ss: 1.220216, loss_d: 0.020153
0.2457 --- loss: 1.244613, loss_ss: 1.230297, loss_d: 0.014316
0.4914 --- loss: 1.228647, loss_ss: 1.198938, loss_d: 0.029709
0.7371 --- loss: 1.178242, loss_ss: 1.170252, loss_d: 0.007990
0.9828 --- loss: 1.188840, loss_ss: 1.078900, loss_d: 0.109940
Epoch finished! Loss: 1.2685422986745833
Starting epoch 5/10.
0.0000 --- loss: 1.145450, loss_ss: 1.136495, loss_d: 0.008955
0.2457 --- loss: 1.119265, loss_ss: 1.056364, loss_d: 0.062901
0.4914 --- loss: 1.037705, loss_ss: 1.037385, loss_d: 0.000319
0.7371 --- loss: 1.163060, loss_ss: 1.069767, loss_d: 0.093293
0.9828 --- loss: 1.428123, loss_ss: 1.425584, loss_d: 0.002538
Epoch finished! Loss: 1.1508331567049026
Starting epoch 6/10.
0.0000 --- loss: 1.008068, loss_ss: 0.999237, loss_d: 0.008831
0.2457 --- loss: 1.058645, loss_ss: 1.052491, loss_d: 0.006154
0.4914 --- loss: 1.045455, loss_ss: 1.042821, loss_d: 0.002635
0.7371 --- loss: 0.938111, loss_ss: 0.932316, loss_d: 0.005795
0.9828 --- loss: 1.266381, loss_ss: 1.266217, loss_d: 0.000164
Epoch finished! Loss: 1.0880402252078056
Starting epoch 7/10.
0.0000 --- loss: 1.055773, loss_ss: 1.052484, loss_d: 0.003289
0.2457 --- loss: 1.593857, loss_ss: 1.051461, loss_d: 0.542396
0.4914 --- loss: 1.020826, loss_ss: 0.932672, loss_d: 0.088153
0.7371 --- loss: 0.957164, loss_ss: 0.951435, loss_d: 0.005730
0.9828 --- loss: 0.980489, loss_ss: 0.974917, loss_d: 0.005572
Epoch finished! Loss: 1.0702990025281907
Starting epoch 8/10.
0.0000 --- loss: 0.989620, loss_ss: 0.984569, loss_d: 0.005051
0.2457 --- loss: 1.390724, loss_ss: 0.994544, loss_d: 0.396180
0.4914 --- loss: 0.965594, loss_ss: 0.953718, loss_d: 0.011876
0.7371 --- loss: 1.051002, loss_ss: 1.049491, loss_d: 0.001511
0.9828 --- loss: 1.153556, loss_ss: 1.059304, loss_d: 0.094252
Epoch finished! Loss: 1.0396240413188935
Starting epoch 9/10.
0.0000 --- loss: 0.956820, loss_ss: 0.955238, loss_d: 0.001582
0.2457 --- loss: 0.980573, loss_ss: 0.977818, loss_d: 0.002756
0.4914 --- loss: 0.908242, loss_ss: 0.907136, loss_d: 0.001106
0.7371 --- loss: 1.621102, loss_ss: 0.992365, loss_d: 0.628737
0.9828 --- loss: 1.060915, loss_ss: 1.054097, loss_d: 0.006819
Epoch finished! Loss: 1.031117855012417
Starting epoch 10/10.
0.0000 --- loss: 0.858908, loss_ss: 0.857755, loss_d: 0.001153
0.2457 --- loss: 0.906617, loss_ss: 0.884282, loss_d: 0.022334
0.4914 --- loss: 0.905656, loss_ss: 0.898957, loss_d: 0.006699
0.7371 --- loss: 0.960326, loss_ss: 0.956526, loss_d: 0.003800
0.9828 --- loss: 0.918124, loss_ss: 0.907707, loss_d: 0.010417
Epoch finished! Loss: 0.974758991599083
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5522222222222222
             precision    recall  f1-score   support

        0.0       0.15      0.94      0.26        54
        1.0       0.00      0.00      0.00        45
        2.0       0.82      0.81      0.81       493
        3.0       1.00      0.18      0.30        90
        4.0       0.49      0.15      0.23       218

avg / total       0.68      0.55      0.55       900
 


====== chp010-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  68.11  94.44   66.43   15.22     26.22
1  95.00   0.00  100.00    0.00      0.00
2  79.89  80.73   78.87   82.23     81.47
3  91.78  17.78  100.00  100.00     30.19
4  75.67  14.68   95.16   49.23     22.61
Total accuracy: 55.22%
Average sen: 41.53%
Average spec: 88.09%
Macro f1-score: 32.10%
Diagnosis acc on 90mins: 1.0
[0.9990502  0.9999603  0.99833542 0.9999994  0.99961168]
pred: 0.9993914008140564, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp010-nsrr

=== Test on chp011-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.495077, loss_ss: 1.808334, loss_d: 0.686744
0.2457 --- loss: 2.150230, loss_ss: 1.564459, loss_d: 0.585772
0.4914 --- loss: 2.354551, loss_ss: 1.587128, loss_d: 0.767423
0.7371 --- loss: 1.820181, loss_ss: 1.509005, loss_d: 0.311177
0.9828 --- loss: 2.244274, loss_ss: 1.468586, loss_d: 0.775688
Epoch finished! Loss: 2.2803819239139558
Starting epoch 2/10.
0.0000 --- loss: 1.902124, loss_ss: 1.513375, loss_d: 0.388749
0.2457 --- loss: 1.952469, loss_ss: 1.542020, loss_d: 0.410449
0.4914 --- loss: 1.896183, loss_ss: 1.482629, loss_d: 0.413553
0.7371 --- loss: 1.848006, loss_ss: 1.470072, loss_d: 0.377934
0.9828 --- loss: 1.759131, loss_ss: 1.502685, loss_d: 0.256446
Epoch finished! Loss: 2.01351193189621
Starting epoch 3/10.
0.0000 --- loss: 1.693971, loss_ss: 1.457649, loss_d: 0.236322
0.2457 --- loss: 1.689047, loss_ss: 1.409706, loss_d: 0.279340
0.4914 --- loss: 1.586091, loss_ss: 1.389808, loss_d: 0.196283
0.7371 --- loss: 1.689060, loss_ss: 1.460924, loss_d: 0.228135
0.9828 --- loss: 2.243806, loss_ss: 1.293814, loss_d: 0.949992
Epoch finished! Loss: 1.649340432882309
Starting epoch 4/10.
0.0000 --- loss: 1.311062, loss_ss: 1.274924, loss_d: 0.036138
0.2457 --- loss: 1.567023, loss_ss: 1.264319, loss_d: 0.302704
0.4914 --- loss: 1.774069, loss_ss: 1.334867, loss_d: 0.439202
0.7371 --- loss: 1.357230, loss_ss: 1.270787, loss_d: 0.086443
0.9828 --- loss: 2.055480, loss_ss: 1.206700, loss_d: 0.848780
Epoch finished! Loss: 1.4609374523162841
Starting epoch 5/10.
0.0000 --- loss: 1.339941, loss_ss: 1.328850, loss_d: 0.011091
0.2457 --- loss: 1.326276, loss_ss: 1.195255, loss_d: 0.131021
0.4914 --- loss: 1.335949, loss_ss: 1.118538, loss_d: 0.217411
0.7371 --- loss: 1.225140, loss_ss: 1.206417, loss_d: 0.018724
0.9828 --- loss: 1.248867, loss_ss: 1.246404, loss_d: 0.002463
Epoch finished! Loss: 1.2847964614629745
Starting epoch 6/10.
0.0000 --- loss: 1.191338, loss_ss: 1.188535, loss_d: 0.002803
0.2457 --- loss: 1.102396, loss_ss: 1.097320, loss_d: 0.005076
0.4914 --- loss: 1.097060, loss_ss: 1.095351, loss_d: 0.001709
0.7371 --- loss: 1.120333, loss_ss: 1.116795, loss_d: 0.003538
0.9828 --- loss: 1.099350, loss_ss: 1.089599, loss_d: 0.009751
Epoch finished! Loss: 1.1757546544075013
Starting epoch 7/10.
0.0000 --- loss: 1.070067, loss_ss: 1.069320, loss_d: 0.000747
0.2457 --- loss: 1.115412, loss_ss: 1.105998, loss_d: 0.009414
0.4914 --- loss: 1.125723, loss_ss: 1.068484, loss_d: 0.057239
0.7371 --- loss: 1.009130, loss_ss: 0.996789, loss_d: 0.012340
0.9828 --- loss: 0.985964, loss_ss: 0.983762, loss_d: 0.002202
Epoch finished! Loss: 1.0943746790289879
Starting epoch 8/10.
0.0000 --- loss: 1.002977, loss_ss: 0.995012, loss_d: 0.007965
0.2457 --- loss: 1.010273, loss_ss: 0.984846, loss_d: 0.025427
0.4914 --- loss: 0.963040, loss_ss: 0.962618, loss_d: 0.000422
0.7371 --- loss: 0.946802, loss_ss: 0.946214, loss_d: 0.000588
0.9828 --- loss: 0.958363, loss_ss: 0.945733, loss_d: 0.012629
Epoch finished! Loss: 1.0276810586452485
Starting epoch 9/10.
0.0000 --- loss: 0.900296, loss_ss: 0.898230, loss_d: 0.002065
0.2457 --- loss: 0.877740, loss_ss: 0.877293, loss_d: 0.000447
0.4914 --- loss: 0.902885, loss_ss: 0.902495, loss_d: 0.000390
0.7371 --- loss: 0.862156, loss_ss: 0.860649, loss_d: 0.001507
0.9828 --- loss: 0.988999, loss_ss: 0.988779, loss_d: 0.000220
Epoch finished! Loss: 0.9613746091723442
Starting epoch 10/10.
0.0000 --- loss: 1.028239, loss_ss: 1.027680, loss_d: 0.000559
0.2457 --- loss: 0.917502, loss_ss: 0.917444, loss_d: 0.000058
0.4914 --- loss: 0.893166, loss_ss: 0.892726, loss_d: 0.000440
0.7371 --- loss: 0.815213, loss_ss: 0.812653, loss_d: 0.002560
0.9828 --- loss: 0.853606, loss_ss: 0.853510, loss_d: 0.000096
Epoch finished! Loss: 0.9211726546287536
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6144444444444445
             precision    recall  f1-score   support

        0.0       0.79      0.12      0.20       129
        1.0       0.00      0.00      0.00       143
        2.0       0.46      0.92      0.61       221
        3.0       0.98      0.76      0.86       271
        4.0       0.56      0.94      0.70       136

avg / total       0.61      0.61      0.54       900
 


====== chp011-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  86.89  11.63   99.48  78.95     20.27
1  84.11   0.00  100.00   0.00      0.00
2  71.44  91.86   64.80  45.93     61.24
3  92.44  76.38   99.36  98.10     85.89
4  88.00  94.12   86.91  56.14     70.33
Total accuracy: 61.44%
Average sen: 54.80%
Average spec: 90.11%
Macro f1-score: 47.55%
Diagnosis acc on 90mins: 1.0
[0.99992466 0.99835902 0.99941516 0.82507664 0.99999762]
pred: 0.9645546197891235, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp011-nsrr

=== Test on chp012-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.442501, loss_ss: 1.695135, loss_d: 0.747365
0.2463 --- loss: 2.455598, loss_ss: 1.563228, loss_d: 0.892370
0.4926 --- loss: 2.128661, loss_ss: 1.560650, loss_d: 0.568011
0.7389 --- loss: 2.495459, loss_ss: 1.511483, loss_d: 0.983976
0.9852 --- loss: 1.937521, loss_ss: 1.447824, loss_d: 0.489697
Epoch finished! Loss: 2.251028171181679
Starting epoch 2/10.
0.0000 --- loss: 1.814387, loss_ss: 1.413901, loss_d: 0.400486
0.2463 --- loss: 1.968745, loss_ss: 1.418220, loss_d: 0.550526
0.4926 --- loss: 1.735659, loss_ss: 1.346072, loss_d: 0.389587
0.7389 --- loss: 1.895173, loss_ss: 1.377916, loss_d: 0.517257
0.9852 --- loss: 1.588838, loss_ss: 1.356571, loss_d: 0.232267
Epoch finished! Loss: 1.905942639708519
Starting epoch 3/10.
0.0000 --- loss: 1.615849, loss_ss: 1.332407, loss_d: 0.283442
0.2463 --- loss: 1.431818, loss_ss: 1.330955, loss_d: 0.100863
0.4926 --- loss: 1.822771, loss_ss: 1.451628, loss_d: 0.371144
0.7389 --- loss: 1.371202, loss_ss: 1.248596, loss_d: 0.122606
0.9852 --- loss: 1.390865, loss_ss: 1.248387, loss_d: 0.142479
Epoch finished! Loss: 1.6370398283004761
Starting epoch 4/10.
0.0000 --- loss: 1.313636, loss_ss: 1.239219, loss_d: 0.074418
0.2463 --- loss: 1.347914, loss_ss: 1.243276, loss_d: 0.104639
0.4926 --- loss: 1.245450, loss_ss: 1.230374, loss_d: 0.015076
0.7389 --- loss: 1.873068, loss_ss: 1.165061, loss_d: 0.708007
0.9852 --- loss: 1.297361, loss_ss: 1.216843, loss_d: 0.080518
Epoch finished! Loss: 1.4032285630702972
Starting epoch 5/10.
0.0000 --- loss: 1.130253, loss_ss: 1.106838, loss_d: 0.023414
0.2463 --- loss: 1.177091, loss_ss: 1.135271, loss_d: 0.041820
0.4926 --- loss: 1.193263, loss_ss: 1.131157, loss_d: 0.062106
0.7389 --- loss: 1.095444, loss_ss: 1.074561, loss_d: 0.020883
0.9852 --- loss: 1.124947, loss_ss: 1.122636, loss_d: 0.002311
Epoch finished! Loss: 1.2499481469392777
Starting epoch 6/10.
0.0000 --- loss: 1.091189, loss_ss: 1.081361, loss_d: 0.009828
0.2463 --- loss: 1.067591, loss_ss: 1.059588, loss_d: 0.008004
0.4926 --- loss: 1.059819, loss_ss: 1.034356, loss_d: 0.025464
0.7389 --- loss: 0.996539, loss_ss: 0.980476, loss_d: 0.016063
0.9852 --- loss: 1.386426, loss_ss: 1.131220, loss_d: 0.255206
Epoch finished! Loss: 1.108621734380722
Starting epoch 7/10.
0.0000 --- loss: 1.059695, loss_ss: 1.058224, loss_d: 0.001470
0.2463 --- loss: 1.093634, loss_ss: 0.995867, loss_d: 0.097767
0.4926 --- loss: 0.962870, loss_ss: 0.947514, loss_d: 0.015356
0.7389 --- loss: 1.089289, loss_ss: 1.070452, loss_d: 0.018836
0.9852 --- loss: 1.221843, loss_ss: 1.068828, loss_d: 0.153016
Epoch finished! Loss: 1.052344200015068
Starting epoch 8/10.
0.0000 --- loss: 0.988894, loss_ss: 0.986171, loss_d: 0.002723
0.2463 --- loss: 0.983657, loss_ss: 0.964293, loss_d: 0.019364
0.4926 --- loss: 0.974332, loss_ss: 0.963374, loss_d: 0.010958
0.7389 --- loss: 0.877501, loss_ss: 0.876842, loss_d: 0.000659
0.9852 --- loss: 0.973775, loss_ss: 0.921152, loss_d: 0.052623
Epoch finished! Loss: 0.9779598042368889
Starting epoch 9/10.
0.0000 --- loss: 0.889201, loss_ss: 0.889112, loss_d: 0.000088
0.2463 --- loss: 0.830915, loss_ss: 0.830676, loss_d: 0.000239
0.4926 --- loss: 0.929142, loss_ss: 0.928486, loss_d: 0.000657
0.7389 --- loss: 0.918622, loss_ss: 0.915185, loss_d: 0.003437
0.9852 --- loss: 0.961285, loss_ss: 0.961243, loss_d: 0.000042
Epoch finished! Loss: 0.9289077058434486
Starting epoch 10/10.
0.0000 --- loss: 0.976636, loss_ss: 0.973248, loss_d: 0.003388
0.2463 --- loss: 0.816755, loss_ss: 0.816465, loss_d: 0.000290
0.4926 --- loss: 0.866274, loss_ss: 0.863952, loss_d: 0.002322
0.7389 --- loss: 0.803883, loss_ss: 0.800769, loss_d: 0.003114
0.9852 --- loss: 0.813515, loss_ss: 0.811495, loss_d: 0.002020
Epoch finished! Loss: 0.900803430378437
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6981481481481482
             precision    recall  f1-score   support

        0.0       0.57      0.52      0.55        23
        1.0       0.36      0.44      0.39       178
        2.0       0.78      0.77      0.77       379
        3.0       1.00      0.70      0.82       203
        4.0       0.71      0.77      0.74       297

avg / total       0.73      0.70      0.71      1080
 


====== chp012-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  98.15  52.17   99.15   57.14     54.55
1  77.78  43.82   84.48   35.78     39.39
2  84.17  77.04   88.02   77.66     77.35
3  94.35  69.95  100.00  100.00     82.32
4  85.19  77.44   88.12   71.21     74.19
Total accuracy: 69.81%
Average sen: 64.09%
Average spec: 91.95%
Macro f1-score: 65.56%
Diagnosis acc on 90mins: 1.0
[0.99369335 0.9996928  0.99991965 0.9994635  0.99969625 0.99999988]
pred: 0.9987442394097646, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp012-nsrr

=== Test on chp013-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.555190, loss_ss: 1.909113, loss_d: 0.646077
0.2457 --- loss: 2.009498, loss_ss: 1.563750, loss_d: 0.445748
0.4914 --- loss: 2.641762, loss_ss: 1.738837, loss_d: 0.902925
0.7371 --- loss: 2.196944, loss_ss: 1.658633, loss_d: 0.538311
0.9828 --- loss: 2.134112, loss_ss: 1.683904, loss_d: 0.450208
Epoch finished! Loss: 2.3527236551046373
Starting epoch 2/10.
0.0000 --- loss: 2.198186, loss_ss: 1.642768, loss_d: 0.555418
0.2457 --- loss: 1.950923, loss_ss: 1.478459, loss_d: 0.472464
0.4914 --- loss: 1.930338, loss_ss: 1.529154, loss_d: 0.401184
0.7371 --- loss: 2.000552, loss_ss: 1.525903, loss_d: 0.474650
0.9828 --- loss: 2.015436, loss_ss: 1.564060, loss_d: 0.451376
Epoch finished! Loss: 2.0407873660326006
Starting epoch 3/10.
0.0000 --- loss: 1.738693, loss_ss: 1.491420, loss_d: 0.247273
0.2457 --- loss: 1.656172, loss_ss: 1.493886, loss_d: 0.162285
0.4914 --- loss: 1.561991, loss_ss: 1.427359, loss_d: 0.134632
0.7371 --- loss: 1.703801, loss_ss: 1.536260, loss_d: 0.167541
0.9828 --- loss: 1.896719, loss_ss: 1.354218, loss_d: 0.542502
Epoch finished! Loss: 1.7451226174831391
Starting epoch 4/10.
0.0000 --- loss: 1.486741, loss_ss: 1.459376, loss_d: 0.027365
0.2457 --- loss: 1.367450, loss_ss: 1.350274, loss_d: 0.017177
0.4914 --- loss: 1.402632, loss_ss: 1.376871, loss_d: 0.025760
0.7371 --- loss: 1.316047, loss_ss: 1.295382, loss_d: 0.020665
0.9828 --- loss: 1.320060, loss_ss: 1.317501, loss_d: 0.002560
Epoch finished! Loss: 1.4629189044237136
Starting epoch 5/10.
0.0000 --- loss: 2.119587, loss_ss: 1.319752, loss_d: 0.799834
0.2457 --- loss: 1.301728, loss_ss: 1.298576, loss_d: 0.003152
0.4914 --- loss: 1.260218, loss_ss: 1.254492, loss_d: 0.005726
0.7371 --- loss: 1.303120, loss_ss: 1.296390, loss_d: 0.006730
0.9828 --- loss: 1.214334, loss_ss: 1.212042, loss_d: 0.002292
Epoch finished! Loss: 1.3285615861415863
Starting epoch 6/10.
0.0000 --- loss: 1.174719, loss_ss: 1.163501, loss_d: 0.011218
0.2457 --- loss: 1.177732, loss_ss: 1.173243, loss_d: 0.004489
0.4914 --- loss: 1.154418, loss_ss: 1.153490, loss_d: 0.000928
0.7371 --- loss: 1.081521, loss_ss: 1.076062, loss_d: 0.005459
0.9828 --- loss: 1.130461, loss_ss: 1.129890, loss_d: 0.000571
Epoch finished! Loss: 1.197089621424675
Starting epoch 7/10.
0.0000 --- loss: 1.074499, loss_ss: 1.072257, loss_d: 0.002242
0.2457 --- loss: 1.265486, loss_ss: 1.264954, loss_d: 0.000531
0.4914 --- loss: 1.041900, loss_ss: 1.041194, loss_d: 0.000706
0.7371 --- loss: 1.115576, loss_ss: 1.115020, loss_d: 0.000556
0.9828 --- loss: 1.072606, loss_ss: 1.071790, loss_d: 0.000816
Epoch finished! Loss: 1.1192092180252076
Starting epoch 8/10.
0.0000 --- loss: 1.029373, loss_ss: 1.028905, loss_d: 0.000468
0.2457 --- loss: 1.033711, loss_ss: 1.032159, loss_d: 0.001552
0.4914 --- loss: 0.954754, loss_ss: 0.954351, loss_d: 0.000403
0.7371 --- loss: 0.967729, loss_ss: 0.966211, loss_d: 0.001517
0.9828 --- loss: 1.082294, loss_ss: 1.081416, loss_d: 0.000878
Epoch finished! Loss: 1.0391413912177085
Starting epoch 9/10.
0.0000 --- loss: 1.016704, loss_ss: 1.013493, loss_d: 0.003211
0.2457 --- loss: 1.058831, loss_ss: 1.058619, loss_d: 0.000212
0.4914 --- loss: 1.002002, loss_ss: 1.001830, loss_d: 0.000172
0.7371 --- loss: 1.190889, loss_ss: 1.190759, loss_d: 0.000130
0.9828 --- loss: 0.897941, loss_ss: 0.897811, loss_d: 0.000130
Epoch finished! Loss: 0.9912346065044403
Starting epoch 10/10.
0.0000 --- loss: 0.937024, loss_ss: 0.936593, loss_d: 0.000431
0.2457 --- loss: 1.007656, loss_ss: 1.007398, loss_d: 0.000258
0.4914 --- loss: 1.207283, loss_ss: 1.207104, loss_d: 0.000179
0.7371 --- loss: 0.834983, loss_ss: 0.834264, loss_d: 0.000718
0.9828 --- loss: 0.985827, loss_ss: 0.985797, loss_d: 0.000031
Epoch finished! Loss: 0.9519964039325715
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7022222222222222
             precision    recall  f1-score   support

        0.0       0.53      0.89      0.67        27
        1.0       0.00      0.00      0.00       107
        2.0       0.76      0.86      0.81       425
        3.0       0.92      0.52      0.66       189
        4.0       0.54      0.95      0.69       152

avg / total       0.66      0.70      0.66       900
 


====== chp013-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  97.33  88.89   97.59  53.33     66.67
1  88.11   0.00  100.00   0.00      0.00
2  80.78  86.12   76.00  76.25     80.88
3  88.89  51.85   98.73  91.59     66.22
4  85.33  94.74   83.42  53.73     68.57
Total accuracy: 70.22%
Average sen: 64.32%
Average spec: 91.15%
Macro f1-score: 56.47%
Diagnosis acc on 90mins: 1.0
[0.90520042 0.99777168 0.95537966 0.99803132 0.99794024]
pred: 0.9708646655082702, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp013-nsrr

=== Test on chp014-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.583796, loss_ss: 1.888532, loss_d: 0.695264
0.2457 --- loss: 2.598653, loss_ss: 1.556203, loss_d: 1.042450
0.4914 --- loss: 2.208439, loss_ss: 1.583914, loss_d: 0.624526
0.7371 --- loss: 2.009646, loss_ss: 1.547807, loss_d: 0.461839
0.9828 --- loss: 2.491806, loss_ss: 1.510884, loss_d: 0.980922
Epoch finished! Loss: 2.2761491149663926
Starting epoch 2/10.
0.0000 --- loss: 1.976102, loss_ss: 1.593139, loss_d: 0.382962
0.2457 --- loss: 1.861842, loss_ss: 1.427302, loss_d: 0.434540
0.4914 --- loss: 1.738862, loss_ss: 1.476084, loss_d: 0.262778
0.7371 --- loss: 1.630105, loss_ss: 1.362318, loss_d: 0.267787
0.9828 --- loss: 1.700443, loss_ss: 1.388084, loss_d: 0.312359
Epoch finished! Loss: 1.988944661617279
Starting epoch 3/10.
0.0000 --- loss: 1.685968, loss_ss: 1.390354, loss_d: 0.295614
0.2457 --- loss: 1.509683, loss_ss: 1.377381, loss_d: 0.132302
0.4914 --- loss: 1.500117, loss_ss: 1.336136, loss_d: 0.163980
0.7371 --- loss: 1.490457, loss_ss: 1.311707, loss_d: 0.178749
0.9828 --- loss: 1.589566, loss_ss: 1.341514, loss_d: 0.248052
Epoch finished! Loss: 1.5737206667661667
Starting epoch 4/10.
0.0000 --- loss: 1.395556, loss_ss: 1.294513, loss_d: 0.101043
0.2457 --- loss: 1.371268, loss_ss: 1.264638, loss_d: 0.106630
0.4914 --- loss: 1.340139, loss_ss: 1.182516, loss_d: 0.157623
0.7371 --- loss: 1.237086, loss_ss: 1.218946, loss_d: 0.018140
0.9828 --- loss: 1.266225, loss_ss: 1.263478, loss_d: 0.002747
Epoch finished! Loss: 1.317563334107399
Starting epoch 5/10.
0.0000 --- loss: 1.857695, loss_ss: 1.207524, loss_d: 0.650171
0.2457 --- loss: 1.108010, loss_ss: 1.093049, loss_d: 0.014961
0.4914 --- loss: 1.188090, loss_ss: 1.182610, loss_d: 0.005481
0.7371 --- loss: 1.175855, loss_ss: 1.139886, loss_d: 0.035969
0.9828 --- loss: 1.087796, loss_ss: 1.030991, loss_d: 0.056805
Epoch finished! Loss: 1.2106778979301454
Starting epoch 6/10.
0.0000 --- loss: 1.053356, loss_ss: 1.049359, loss_d: 0.003996
0.2457 --- loss: 1.171513, loss_ss: 1.169529, loss_d: 0.001984
0.4914 --- loss: 1.192545, loss_ss: 1.039890, loss_d: 0.152655
0.7371 --- loss: 1.007388, loss_ss: 0.993429, loss_d: 0.013959
0.9828 --- loss: 1.142553, loss_ss: 1.131974, loss_d: 0.010579
Epoch finished! Loss: 1.098394076526165
Starting epoch 7/10.
0.0000 --- loss: 1.042912, loss_ss: 1.042119, loss_d: 0.000794
0.2457 --- loss: 1.028109, loss_ss: 1.022926, loss_d: 0.005183
0.4914 --- loss: 0.898538, loss_ss: 0.896899, loss_d: 0.001639
0.7371 --- loss: 0.973513, loss_ss: 0.955868, loss_d: 0.017645
0.9828 --- loss: 0.964392, loss_ss: 0.964325, loss_d: 0.000067
Epoch finished! Loss: 1.0390086457133294
Starting epoch 8/10.
0.0000 --- loss: 0.978870, loss_ss: 0.975627, loss_d: 0.003243
0.2457 --- loss: 0.906755, loss_ss: 0.904449, loss_d: 0.002306
0.4914 --- loss: 1.075894, loss_ss: 1.074473, loss_d: 0.001421
0.7371 --- loss: 0.851895, loss_ss: 0.850875, loss_d: 0.001020
0.9828 --- loss: 0.886845, loss_ss: 0.866635, loss_d: 0.020210
Epoch finished! Loss: 0.9739813327789306
Starting epoch 9/10.
0.0000 --- loss: 0.991165, loss_ss: 0.988843, loss_d: 0.002322
0.2457 --- loss: 0.857362, loss_ss: 0.857260, loss_d: 0.000102
0.4914 --- loss: 0.868861, loss_ss: 0.858704, loss_d: 0.010157
0.7371 --- loss: 0.906191, loss_ss: 0.903751, loss_d: 0.002441
0.9828 --- loss: 0.765988, loss_ss: 0.758431, loss_d: 0.007557
Epoch finished! Loss: 0.982881385087967
Starting epoch 10/10.
0.0000 --- loss: 0.917447, loss_ss: 0.806304, loss_d: 0.111142
0.2457 --- loss: 0.927581, loss_ss: 0.904283, loss_d: 0.023298
0.4914 --- loss: 0.884280, loss_ss: 0.876107, loss_d: 0.008173
0.7371 --- loss: 0.942475, loss_ss: 0.934060, loss_d: 0.008415
0.9828 --- loss: 0.899234, loss_ss: 0.881321, loss_d: 0.017914
Epoch finished! Loss: 0.9293097138404847
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6244444444444445
             precision    recall  f1-score   support

        0.0       0.60      0.95      0.74       170
        1.0       0.27      0.05      0.09        55
        2.0       0.62      0.88      0.73       363
        3.0       0.00      0.00      0.00       146
        4.0       0.72      0.48      0.57       166

avg / total       0.51      0.62      0.54       900
 


====== chp014-nsrr ======

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  87.11  94.71   85.34  60.07     73.52
1  93.33   5.45   99.05  27.27      9.09
2  73.78  87.88   64.25  62.43     73.00
3  83.78   0.00  100.00   0.00      0.00
4  86.89  47.59   95.78  71.82     57.25
Total accuracy: 62.44%
Average sen: 47.13%
Average spec: 88.88%
Macro f1-score: 42.57%
Diagnosis acc on 90mins: 1.0
[0.99997973 0.99998891 0.99999964 1.         0.99999952]
pred: 0.9999935626983643, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp014-nsrr

=== Test on chp015-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.291733, loss_ss: 1.570089, loss_d: 0.721644
0.2463 --- loss: 1.921854, loss_ss: 1.563434, loss_d: 0.358420
0.4926 --- loss: 1.886278, loss_ss: 1.469573, loss_d: 0.416705
0.7389 --- loss: 2.305378, loss_ss: 1.487247, loss_d: 0.818131
0.9852 --- loss: 2.140646, loss_ss: 1.436552, loss_d: 0.704093
Epoch finished! Loss: 2.208553099632263
Starting epoch 2/10.
0.0000 --- loss: 1.910350, loss_ss: 1.390828, loss_d: 0.519522
0.2463 --- loss: 2.001318, loss_ss: 1.381403, loss_d: 0.619915
0.4926 --- loss: 1.645961, loss_ss: 1.347960, loss_d: 0.298001
0.7389 --- loss: 1.954829, loss_ss: 1.487845, loss_d: 0.466984
0.9852 --- loss: 1.523169, loss_ss: 1.347754, loss_d: 0.175415
Epoch finished! Loss: 1.8584368914365768
Starting epoch 3/10.
0.0000 --- loss: 1.635151, loss_ss: 1.483618, loss_d: 0.151533
0.2463 --- loss: 1.481290, loss_ss: 1.303244, loss_d: 0.178046
0.4926 --- loss: 1.432925, loss_ss: 1.231628, loss_d: 0.201297
0.7389 --- loss: 1.407896, loss_ss: 1.294970, loss_d: 0.112925
0.9852 --- loss: 1.770738, loss_ss: 1.331694, loss_d: 0.439044
Epoch finished! Loss: 1.5327963054180145
Starting epoch 4/10.
0.0000 --- loss: 1.319237, loss_ss: 1.304337, loss_d: 0.014900
0.2463 --- loss: 1.242086, loss_ss: 1.199833, loss_d: 0.042253
0.4926 --- loss: 1.667904, loss_ss: 1.262455, loss_d: 0.405449
0.7389 --- loss: 1.236870, loss_ss: 1.223711, loss_d: 0.013160
0.9852 --- loss: 1.099670, loss_ss: 1.079920, loss_d: 0.019751
Epoch finished! Loss: 1.3382232278585433
Starting epoch 5/10.
0.0000 --- loss: 1.290052, loss_ss: 1.284933, loss_d: 0.005119
0.2463 --- loss: 1.135639, loss_ss: 1.130551, loss_d: 0.005088
0.4926 --- loss: 1.231824, loss_ss: 1.225217, loss_d: 0.006607
0.7389 --- loss: 1.100518, loss_ss: 1.098247, loss_d: 0.002270
0.9852 --- loss: 0.958431, loss_ss: 0.949755, loss_d: 0.008676
Epoch finished! Loss: 1.1739908173680305
Starting epoch 6/10.
0.0000 --- loss: 1.103782, loss_ss: 1.102348, loss_d: 0.001434
0.2463 --- loss: 1.068273, loss_ss: 1.068029, loss_d: 0.000243
0.4926 --- loss: 0.953157, loss_ss: 0.952351, loss_d: 0.000806
0.7389 --- loss: 1.078020, loss_ss: 1.076862, loss_d: 0.001158
0.9852 --- loss: 1.118888, loss_ss: 1.117824, loss_d: 0.001064
Epoch finished! Loss: 1.0912624835968017
Starting epoch 7/10.
0.0000 --- loss: 0.927268, loss_ss: 0.920280, loss_d: 0.006988
0.2463 --- loss: 1.244149, loss_ss: 1.241707, loss_d: 0.002442
0.4926 --- loss: 1.027189, loss_ss: 1.026710, loss_d: 0.000479
0.7389 --- loss: 1.195453, loss_ss: 1.194992, loss_d: 0.000461
0.9852 --- loss: 1.133236, loss_ss: 1.133069, loss_d: 0.000167
Epoch finished! Loss: 1.0459373727440835
Starting epoch 8/10.
0.0000 --- loss: 0.951044, loss_ss: 0.950575, loss_d: 0.000469
0.2463 --- loss: 0.998102, loss_ss: 0.997678, loss_d: 0.000424
0.4926 --- loss: 1.065370, loss_ss: 1.063498, loss_d: 0.001872
0.7389 --- loss: 0.956698, loss_ss: 0.956491, loss_d: 0.000206
0.9852 --- loss: 0.790025, loss_ss: 0.788705, loss_d: 0.001319
Epoch finished! Loss: 0.9931498229503631
Starting epoch 9/10.
0.0000 --- loss: 0.995974, loss_ss: 0.995852, loss_d: 0.000122
0.2463 --- loss: 0.896494, loss_ss: 0.891222, loss_d: 0.005272
0.4926 --- loss: 0.941966, loss_ss: 0.941421, loss_d: 0.000546
0.7389 --- loss: 0.984173, loss_ss: 0.983003, loss_d: 0.001170
0.9852 --- loss: 0.811190, loss_ss: 0.808283, loss_d: 0.002907
Epoch finished! Loss: 0.9615970969200134
Starting epoch 10/10.
0.0000 --- loss: 0.895274, loss_ss: 0.894514, loss_d: 0.000760
0.2463 --- loss: 1.133380, loss_ss: 1.133287, loss_d: 0.000093
0.4926 --- loss: 0.933499, loss_ss: 0.933170, loss_d: 0.000330
0.7389 --- loss: 0.840059, loss_ss: 0.839815, loss_d: 0.000244
0.9852 --- loss: 0.971951, loss_ss: 0.971929, loss_d: 0.000022
Epoch finished! Loss: 0.9451917856931686
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5351851851851852
             precision    recall  f1-score   support

        0.0       0.22      0.79      0.35        67
        1.0       0.00      0.00      0.00       257
        2.0       0.55      0.92      0.69       304
        3.0       1.00      0.66      0.80       259
        4.0       0.44      0.38      0.41       193

avg / total       0.49      0.54      0.48      1080
 


====== chp015-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  81.76  79.10   81.93   22.46     34.98
1  76.20   0.00  100.00    0.00      0.00
2  76.85  92.43   70.75   55.31     69.21
3  91.85  66.02  100.00  100.00     79.53
4  80.37  37.82   89.63   44.24     40.78
Total accuracy: 53.52%
Average sen: 55.08%
Average spec: 88.46%
Macro f1-score: 44.90%
Diagnosis acc on 90mins: 1.0
[0.9999994  0.9999969  0.99999905 0.99909413 0.99878794 0.99218142]
pred: 0.9983431398868561, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp015-nsrr

=== Test on chp016-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.329325, loss_ss: 1.685891, loss_d: 0.643434
0.2469 --- loss: 2.480291, loss_ss: 1.571722, loss_d: 0.908569
0.4938 --- loss: 1.869307, loss_ss: 1.421842, loss_d: 0.447465
0.7407 --- loss: 2.128391, loss_ss: 1.368895, loss_d: 0.759496
0.9877 --- loss: 1.774393, loss_ss: 1.308790, loss_d: 0.465602
Epoch finished! Loss: 2.1178200364112856
Starting epoch 2/10.
0.0000 --- loss: 1.905761, loss_ss: 1.354341, loss_d: 0.551420
0.2469 --- loss: 1.514685, loss_ss: 1.301373, loss_d: 0.213313
0.4938 --- loss: 1.708024, loss_ss: 1.225712, loss_d: 0.482312
0.7407 --- loss: 1.483022, loss_ss: 1.257675, loss_d: 0.225347
0.9877 --- loss: 1.415145, loss_ss: 1.231652, loss_d: 0.183494
Epoch finished! Loss: 1.7833381831645965
Starting epoch 3/10.
0.0000 --- loss: 1.485802, loss_ss: 1.212715, loss_d: 0.273088
0.2469 --- loss: 1.355490, loss_ss: 1.248504, loss_d: 0.106986
0.4938 --- loss: 1.387698, loss_ss: 1.222996, loss_d: 0.164702
0.7407 --- loss: 1.462184, loss_ss: 1.268257, loss_d: 0.193927
0.9877 --- loss: 1.807632, loss_ss: 1.093148, loss_d: 0.714485
Epoch finished! Loss: 1.5485297471284867
Starting epoch 4/10.
0.0000 --- loss: 1.238333, loss_ss: 1.173297, loss_d: 0.065036
0.2469 --- loss: 1.423921, loss_ss: 1.125840, loss_d: 0.298081
0.4938 --- loss: 1.227783, loss_ss: 1.190732, loss_d: 0.037052
0.7407 --- loss: 1.168288, loss_ss: 1.093840, loss_d: 0.074448
0.9877 --- loss: 1.149683, loss_ss: 1.015067, loss_d: 0.134615
Epoch finished! Loss: 1.3010893940925599
Starting epoch 5/10.
0.0000 --- loss: 1.200201, loss_ss: 1.146990, loss_d: 0.053211
0.2469 --- loss: 1.027546, loss_ss: 1.019391, loss_d: 0.008155
0.4938 --- loss: 1.088444, loss_ss: 1.075575, loss_d: 0.012869
0.7407 --- loss: 1.049178, loss_ss: 1.009328, loss_d: 0.039850
0.9877 --- loss: 1.087721, loss_ss: 1.061506, loss_d: 0.026215
Epoch finished! Loss: 1.1325963005423545
Starting epoch 6/10.
0.0000 --- loss: 1.094737, loss_ss: 1.085472, loss_d: 0.009265
0.2469 --- loss: 0.985538, loss_ss: 0.973829, loss_d: 0.011709
0.4938 --- loss: 1.005263, loss_ss: 0.992477, loss_d: 0.012785
0.7407 --- loss: 1.015200, loss_ss: 1.005430, loss_d: 0.009770
0.9877 --- loss: 1.038211, loss_ss: 1.037821, loss_d: 0.000389
Epoch finished! Loss: 1.0515485480427742
Starting epoch 7/10.
0.0000 --- loss: 0.957816, loss_ss: 0.956315, loss_d: 0.001502
0.2469 --- loss: 0.896222, loss_ss: 0.889035, loss_d: 0.007188
0.4938 --- loss: 0.986918, loss_ss: 0.985726, loss_d: 0.001193
0.7407 --- loss: 1.009609, loss_ss: 1.008186, loss_d: 0.001422
0.9877 --- loss: 1.172120, loss_ss: 1.047199, loss_d: 0.124922
Epoch finished! Loss: 1.0005331829190254
Starting epoch 8/10.
0.0000 --- loss: 0.880764, loss_ss: 0.878430, loss_d: 0.002335
0.2469 --- loss: 0.917854, loss_ss: 0.914082, loss_d: 0.003771
0.4938 --- loss: 0.827207, loss_ss: 0.766744, loss_d: 0.060462
0.7407 --- loss: 0.852724, loss_ss: 0.852321, loss_d: 0.000403
0.9877 --- loss: 0.878847, loss_ss: 0.878781, loss_d: 0.000066
Epoch finished! Loss: 0.9286435395479202
Starting epoch 9/10.
0.0000 --- loss: 0.865256, loss_ss: 0.864624, loss_d: 0.000631
0.2469 --- loss: 0.819350, loss_ss: 0.817283, loss_d: 0.002066
0.4938 --- loss: 0.911472, loss_ss: 0.908353, loss_d: 0.003119
0.7407 --- loss: 1.092777, loss_ss: 0.794305, loss_d: 0.298471
0.9877 --- loss: 1.356810, loss_ss: 0.867362, loss_d: 0.489447
Epoch finished! Loss: 0.9510532602667808
Starting epoch 10/10.
0.0000 --- loss: 1.346328, loss_ss: 0.899643, loss_d: 0.446685
0.2469 --- loss: 1.009780, loss_ss: 0.973558, loss_d: 0.036222
0.4938 --- loss: 1.653244, loss_ss: 0.750459, loss_d: 0.902785
0.7407 --- loss: 0.900636, loss_ss: 0.837563, loss_d: 0.063073
0.9877 --- loss: 0.872732, loss_ss: 0.770602, loss_d: 0.102130
Epoch finished! Loss: 0.9934813603758812
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6126984126984127
             precision    recall  f1-score   support

        0.0       0.86      0.96      0.91       297
        1.0       0.00      0.00      0.00       289
        2.0       0.43      0.99      0.60       330
        3.0       0.98      0.65      0.78       133
        4.0       0.86      0.35      0.50       211

avg / total       0.56      0.61      0.54      1260
 


====== chp016-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.40  95.62   95.33  86.32     90.73
1  77.06   0.00  100.00   0.00      0.00
2  65.79  99.39   53.87  43.33     60.35
3  96.11  64.66   99.82  97.73     77.83
4  88.17  35.07   98.86  86.05     49.83
Total accuracy: 61.27%
Average sen: 58.95%
Average spec: 89.58%
Macro f1-score: 55.75%
Diagnosis acc on 90mins: 1.0
[0.99962687 0.9798106  0.93741643 0.99999976 0.99986005 0.94389564
 0.99936157]
pred: 0.979995846748352, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp016-nsrr

=== Test on chp017-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.411992, loss_ss: 1.729801, loss_d: 0.682190
0.2457 --- loss: 2.174534, loss_ss: 1.703841, loss_d: 0.470693
0.4914 --- loss: 2.354399, loss_ss: 1.570863, loss_d: 0.783537
0.7371 --- loss: 2.251729, loss_ss: 1.648190, loss_d: 0.603539
0.9828 --- loss: 2.092891, loss_ss: 1.577117, loss_d: 0.515774
Epoch finished! Loss: 2.303759416937828
Starting epoch 2/10.
0.0000 --- loss: 2.070913, loss_ss: 1.559552, loss_d: 0.511362
0.2457 --- loss: 1.923195, loss_ss: 1.617106, loss_d: 0.306088
0.4914 --- loss: 1.901345, loss_ss: 1.574196, loss_d: 0.327149
0.7371 --- loss: 1.857292, loss_ss: 1.487250, loss_d: 0.370042
0.9828 --- loss: 2.135878, loss_ss: 1.488374, loss_d: 0.647504
Epoch finished! Loss: 2.0547452002763746
Starting epoch 3/10.
0.0000 --- loss: 1.831831, loss_ss: 1.501359, loss_d: 0.330472
0.2457 --- loss: 1.553993, loss_ss: 1.418841, loss_d: 0.135152
0.4914 --- loss: 1.463919, loss_ss: 1.401750, loss_d: 0.062169
0.7371 --- loss: 1.652704, loss_ss: 1.396673, loss_d: 0.256031
0.9828 --- loss: 1.684467, loss_ss: 1.414712, loss_d: 0.269755
Epoch finished! Loss: 1.7165948003530502
Starting epoch 4/10.
0.0000 --- loss: 1.628921, loss_ss: 1.449926, loss_d: 0.178995
0.2457 --- loss: 1.498947, loss_ss: 1.323516, loss_d: 0.175431
0.4914 --- loss: 1.503423, loss_ss: 1.403927, loss_d: 0.099496
0.7371 --- loss: 1.346248, loss_ss: 1.298173, loss_d: 0.048075
0.9828 --- loss: 1.388195, loss_ss: 1.330842, loss_d: 0.057352
Epoch finished! Loss: 1.5316711574792863
Starting epoch 5/10.
0.0000 --- loss: 1.401052, loss_ss: 1.312626, loss_d: 0.088426
0.2457 --- loss: 1.293266, loss_ss: 1.243770, loss_d: 0.049496
0.4914 --- loss: 1.274805, loss_ss: 1.260906, loss_d: 0.013899
0.7371 --- loss: 1.258031, loss_ss: 1.241723, loss_d: 0.016307
0.9828 --- loss: 1.191925, loss_ss: 1.190815, loss_d: 0.001111
Epoch finished! Loss: 1.344226360321045
Starting epoch 6/10.
0.0000 --- loss: 1.259105, loss_ss: 1.203615, loss_d: 0.055490
0.2457 --- loss: 1.221140, loss_ss: 1.206883, loss_d: 0.014257
0.4914 --- loss: 1.378809, loss_ss: 1.259139, loss_d: 0.119670
0.7371 --- loss: 1.201915, loss_ss: 1.199710, loss_d: 0.002205
0.9828 --- loss: 1.101770, loss_ss: 1.097522, loss_d: 0.004248
Epoch finished! Loss: 1.2458719849586486
Starting epoch 7/10.
0.0000 --- loss: 1.095226, loss_ss: 1.085104, loss_d: 0.010122
0.2457 --- loss: 1.104840, loss_ss: 1.102465, loss_d: 0.002376
0.4914 --- loss: 1.114037, loss_ss: 1.111300, loss_d: 0.002738
0.7371 --- loss: 1.070874, loss_ss: 1.069073, loss_d: 0.001801
0.9828 --- loss: 1.056971, loss_ss: 1.050508, loss_d: 0.006462
Epoch finished! Loss: 1.1387067720294
Starting epoch 8/10.
0.0000 --- loss: 1.020961, loss_ss: 1.019368, loss_d: 0.001593
0.2457 --- loss: 1.034849, loss_ss: 1.030979, loss_d: 0.003870
0.4914 --- loss: 1.137306, loss_ss: 1.136312, loss_d: 0.000994
0.7371 --- loss: 1.046097, loss_ss: 1.044773, loss_d: 0.001324
0.9828 --- loss: 0.944326, loss_ss: 0.943980, loss_d: 0.000346
Epoch finished! Loss: 1.0519454076886177
Starting epoch 9/10.
0.0000 --- loss: 1.004435, loss_ss: 1.003578, loss_d: 0.000856
0.2457 --- loss: 0.909548, loss_ss: 0.909459, loss_d: 0.000089
0.4914 --- loss: 0.995220, loss_ss: 0.993831, loss_d: 0.001389
0.7371 --- loss: 1.043174, loss_ss: 1.042566, loss_d: 0.000608
0.9828 --- loss: 0.816787, loss_ss: 0.814767, loss_d: 0.002020
Epoch finished! Loss: 0.9706018969416619
Starting epoch 10/10.
0.0000 --- loss: 1.033644, loss_ss: 1.033094, loss_d: 0.000550
0.2457 --- loss: 0.935145, loss_ss: 0.934616, loss_d: 0.000530
0.4914 --- loss: 0.760053, loss_ss: 0.759633, loss_d: 0.000421
0.7371 --- loss: 0.789872, loss_ss: 0.789203, loss_d: 0.000669
0.9828 --- loss: 1.046158, loss_ss: 1.045894, loss_d: 0.000264
Epoch finished! Loss: 0.9293579116463662
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.21555555555555556
             precision    recall  f1-score   support

        0.0       0.71      0.13      0.22       232
        1.0       0.00      0.00      0.00       237
        2.0       0.32      0.30      0.31       181
        3.0       1.00      0.30      0.46       201
        4.0       0.08      1.00      0.15        49

avg / total       0.48      0.22      0.23       900
 


====== chp017-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  76.22   12.93   98.20   71.43     21.90
1  73.67    0.00  100.00    0.00      0.00
2  72.89   30.39   83.59   31.79     31.07
3  84.33   29.85  100.00  100.00     45.98
4  36.00  100.00   32.31    7.84     14.54
Total accuracy: 21.56%
Average sen: 34.63%
Average spec: 82.82%
Macro f1-score: 22.70%
Diagnosis acc on 90mins: 1.0
[0.99998868 0.9735232  0.99813914 0.9956584  0.9989202 ]
pred: 0.9932459235191345, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp017-nsrr

=== Test on chp018-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.362935, loss_ss: 1.617687, loss_d: 0.745248
0.2463 --- loss: 2.137853, loss_ss: 1.515690, loss_d: 0.622162
0.4926 --- loss: 1.888943, loss_ss: 1.420878, loss_d: 0.468065
0.7389 --- loss: 2.292501, loss_ss: 1.515424, loss_d: 0.777077
0.9852 --- loss: 1.773808, loss_ss: 1.376362, loss_d: 0.397445
Epoch finished! Loss: 2.1525927126407622
Starting epoch 2/10.
0.0000 --- loss: 2.102955, loss_ss: 1.338150, loss_d: 0.764806
0.2463 --- loss: 1.945831, loss_ss: 1.404486, loss_d: 0.541345
0.4926 --- loss: 1.864213, loss_ss: 1.284156, loss_d: 0.580057
0.7389 --- loss: 1.621420, loss_ss: 1.280780, loss_d: 0.340640
0.9852 --- loss: 1.591540, loss_ss: 1.250769, loss_d: 0.340771
Epoch finished! Loss: 1.8536917328834535
Starting epoch 3/10.
0.0000 --- loss: 1.719839, loss_ss: 1.242605, loss_d: 0.477235
0.2463 --- loss: 1.478187, loss_ss: 1.277414, loss_d: 0.200773
0.4926 --- loss: 1.433783, loss_ss: 1.121312, loss_d: 0.312471
0.7389 --- loss: 1.361083, loss_ss: 1.120402, loss_d: 0.240681
0.9852 --- loss: 1.442800, loss_ss: 1.173133, loss_d: 0.269666
Epoch finished! Loss: 1.5393700927495957
Starting epoch 4/10.
0.0000 --- loss: 1.461765, loss_ss: 1.172935, loss_d: 0.288830
0.2463 --- loss: 1.216736, loss_ss: 1.095572, loss_d: 0.121164
0.4926 --- loss: 1.503940, loss_ss: 1.200870, loss_d: 0.303070
0.7389 --- loss: 1.173257, loss_ss: 1.084901, loss_d: 0.088356
0.9852 --- loss: 1.133134, loss_ss: 1.124394, loss_d: 0.008740
Epoch finished! Loss: 1.3069606304168702
Starting epoch 5/10.
0.0000 --- loss: 1.115729, loss_ss: 1.104919, loss_d: 0.010809
0.2463 --- loss: 1.280994, loss_ss: 1.265280, loss_d: 0.015715
0.4926 --- loss: 1.060288, loss_ss: 1.036328, loss_d: 0.023960
0.7389 --- loss: 1.059543, loss_ss: 1.056006, loss_d: 0.003537
0.9852 --- loss: 1.083307, loss_ss: 1.060709, loss_d: 0.022599
Epoch finished! Loss: 1.1373971343040465
Starting epoch 6/10.
0.0000 --- loss: 1.009557, loss_ss: 1.004701, loss_d: 0.004855
0.2463 --- loss: 1.264892, loss_ss: 0.973218, loss_d: 0.291674
0.4926 --- loss: 1.015878, loss_ss: 1.012528, loss_d: 0.003349
0.7389 --- loss: 1.027779, loss_ss: 0.963429, loss_d: 0.064350
0.9852 --- loss: 1.102271, loss_ss: 1.101664, loss_d: 0.000607
Epoch finished! Loss: 1.118302008509636
Starting epoch 7/10.
0.0000 --- loss: 1.137457, loss_ss: 1.098750, loss_d: 0.038707
0.2463 --- loss: 1.005777, loss_ss: 0.998086, loss_d: 0.007691
0.4926 --- loss: 0.906334, loss_ss: 0.894180, loss_d: 0.012154
0.7389 --- loss: 1.090344, loss_ss: 1.088430, loss_d: 0.001913
0.9852 --- loss: 0.999252, loss_ss: 0.996970, loss_d: 0.002283
Epoch finished! Loss: 1.028290618956089
Starting epoch 8/10.
0.0000 --- loss: 0.918487, loss_ss: 0.913066, loss_d: 0.005421
0.2463 --- loss: 0.849886, loss_ss: 0.848774, loss_d: 0.001112
0.4926 --- loss: 0.972442, loss_ss: 0.970561, loss_d: 0.001881
0.7389 --- loss: 0.802554, loss_ss: 0.800089, loss_d: 0.002465
0.9852 --- loss: 0.846661, loss_ss: 0.845937, loss_d: 0.000724
Epoch finished! Loss: 0.958011056482792
Starting epoch 9/10.
0.0000 --- loss: 0.813075, loss_ss: 0.812830, loss_d: 0.000245
0.2463 --- loss: 0.884782, loss_ss: 0.883911, loss_d: 0.000871
0.4926 --- loss: 0.828611, loss_ss: 0.828392, loss_d: 0.000220
0.7389 --- loss: 0.986315, loss_ss: 0.984706, loss_d: 0.001608
0.9852 --- loss: 0.920393, loss_ss: 0.920246, loss_d: 0.000147
Epoch finished! Loss: 0.9352744951844215
Starting epoch 10/10.
0.0000 --- loss: 0.826260, loss_ss: 0.825654, loss_d: 0.000606
0.2463 --- loss: 0.994222, loss_ss: 0.992302, loss_d: 0.001920
0.4926 --- loss: 0.786129, loss_ss: 0.782820, loss_d: 0.003309
0.7389 --- loss: 0.829645, loss_ss: 0.818902, loss_d: 0.010743
0.9852 --- loss: 0.856077, loss_ss: 0.855782, loss_d: 0.000295
Epoch finished! Loss: 0.9263125479221344
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.45555555555555555
             precision    recall  f1-score   support

        0.0       0.75      0.78      0.76       138
        1.0       0.27      0.03      0.06       117
        2.0       0.17      0.95      0.30       119
        3.0       0.98      0.68      0.81       363
        4.0       0.83      0.06      0.11       343

avg / total       0.74      0.46      0.44      1080
 


====== chp018-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  93.80  77.54   96.18  74.83     76.16
1  88.52   3.42   98.86  26.67      6.06
2  50.09  94.96   44.54  17.49     29.54
3  88.98  68.32   99.44  98.41     80.65
4  69.72   5.83   99.46  83.33     10.90
Total accuracy: 45.56%
Average sen: 50.01%
Average spec: 87.69%
Macro f1-score: 40.66%
Diagnosis acc on 90mins: 1.0
[0.99827743 0.99977487 0.99999988 0.93926769 0.99998605 1.        ]
pred: 0.9895509878794352, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp018-nsrr

=== Test on chp019-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.350550, loss_ss: 1.673104, loss_d: 0.677445
0.2457 --- loss: 1.972544, loss_ss: 1.455216, loss_d: 0.517328
0.4914 --- loss: 2.120543, loss_ss: 1.528567, loss_d: 0.591975
0.7371 --- loss: 1.774140, loss_ss: 1.381978, loss_d: 0.392161
0.9828 --- loss: 1.665548, loss_ss: 1.292118, loss_d: 0.373430
Epoch finished! Loss: 2.1258827596902847
Starting epoch 2/10.
0.0000 --- loss: 1.819194, loss_ss: 1.264293, loss_d: 0.554901
0.2457 --- loss: 1.653935, loss_ss: 1.264729, loss_d: 0.389206
0.4914 --- loss: 1.591044, loss_ss: 1.188607, loss_d: 0.402436
0.7371 --- loss: 1.870477, loss_ss: 1.257101, loss_d: 0.613376
0.9828 --- loss: 1.645711, loss_ss: 1.302831, loss_d: 0.342880
Epoch finished! Loss: 1.766106939315796
Starting epoch 3/10.
0.0000 --- loss: 1.439655, loss_ss: 1.200073, loss_d: 0.239582
0.2457 --- loss: 1.471571, loss_ss: 1.151579, loss_d: 0.319991
0.4914 --- loss: 1.231398, loss_ss: 1.199981, loss_d: 0.031417
0.7371 --- loss: 1.562743, loss_ss: 1.133869, loss_d: 0.428874
0.9828 --- loss: 1.649864, loss_ss: 1.220670, loss_d: 0.429194
Epoch finished! Loss: 1.4532844334840775
Starting epoch 4/10.
0.0000 --- loss: 1.381403, loss_ss: 1.206691, loss_d: 0.174712
0.2457 --- loss: 1.197828, loss_ss: 1.096565, loss_d: 0.101263
0.4914 --- loss: 1.084628, loss_ss: 1.033741, loss_d: 0.050888
0.7371 --- loss: 1.207497, loss_ss: 1.157831, loss_d: 0.049666
0.9828 --- loss: 1.173361, loss_ss: 1.124645, loss_d: 0.048716
Epoch finished! Loss: 1.2884830743074418
Starting epoch 5/10.
0.0000 --- loss: 1.075612, loss_ss: 1.072105, loss_d: 0.003507
0.2457 --- loss: 1.139475, loss_ss: 1.117930, loss_d: 0.021545
0.4914 --- loss: 1.205594, loss_ss: 1.178859, loss_d: 0.026735
0.7371 --- loss: 1.210540, loss_ss: 0.931668, loss_d: 0.278872
0.9828 --- loss: 0.990307, loss_ss: 0.986759, loss_d: 0.003549
Epoch finished! Loss: 1.124558539688587
Starting epoch 6/10.
0.0000 --- loss: 1.202405, loss_ss: 1.072052, loss_d: 0.130353
0.2457 --- loss: 1.035370, loss_ss: 1.031434, loss_d: 0.003937
0.4914 --- loss: 0.981878, loss_ss: 0.979310, loss_d: 0.002568
0.7371 --- loss: 1.008166, loss_ss: 1.003084, loss_d: 0.005082
0.9828 --- loss: 0.987326, loss_ss: 0.984193, loss_d: 0.003133
Epoch finished! Loss: 1.0316550090909005
Starting epoch 7/10.
0.0000 --- loss: 0.914490, loss_ss: 0.913130, loss_d: 0.001361
0.2457 --- loss: 0.907769, loss_ss: 0.904587, loss_d: 0.003182
0.4914 --- loss: 1.028070, loss_ss: 1.025161, loss_d: 0.002908
0.7371 --- loss: 0.902228, loss_ss: 0.901554, loss_d: 0.000675
0.9828 --- loss: 0.905093, loss_ss: 0.903050, loss_d: 0.002043
Epoch finished! Loss: 0.9613809645175934
Starting epoch 8/10.
0.0000 --- loss: 1.035554, loss_ss: 1.023388, loss_d: 0.012167
0.2457 --- loss: 0.902139, loss_ss: 0.901951, loss_d: 0.000188
0.4914 --- loss: 0.978740, loss_ss: 0.976863, loss_d: 0.001877
0.7371 --- loss: 0.891625, loss_ss: 0.891207, loss_d: 0.000419
0.9828 --- loss: 0.895192, loss_ss: 0.878624, loss_d: 0.016567
Epoch finished! Loss: 0.9191431239247322
Starting epoch 9/10.
0.0000 --- loss: 0.810884, loss_ss: 0.810390, loss_d: 0.000495
0.2457 --- loss: 0.828926, loss_ss: 0.828017, loss_d: 0.000909
0.4914 --- loss: 0.756188, loss_ss: 0.754899, loss_d: 0.001289
0.7371 --- loss: 0.809128, loss_ss: 0.795613, loss_d: 0.013516
0.9828 --- loss: 0.991983, loss_ss: 0.989321, loss_d: 0.002662
Epoch finished! Loss: 0.8941899910569191
Starting epoch 10/10.
0.0000 --- loss: 0.822522, loss_ss: 0.821239, loss_d: 0.001284
0.2457 --- loss: 1.081147, loss_ss: 0.934800, loss_d: 0.146347
0.4914 --- loss: 1.033828, loss_ss: 0.764413, loss_d: 0.269414
0.7371 --- loss: 0.926460, loss_ss: 0.925474, loss_d: 0.000987
0.9828 --- loss: 1.149753, loss_ss: 1.149383, loss_d: 0.000370
Epoch finished! Loss: 0.8935383513569832
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6322222222222222
             precision    recall  f1-score   support

        0.0       0.17      0.83      0.28        36
        1.0       0.00      0.00      0.00       108
        2.0       0.65      0.75      0.70       215
        3.0       0.98      0.84      0.91       223
        4.0       0.68      0.60      0.64       318

avg / total       0.65      0.63      0.63       900
 


====== chp019-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  83.22  83.33   83.22  17.14     28.44
1  87.22   0.00   99.12   0.00      0.00
2  84.44  75.35   87.30  65.06     69.83
3  95.67  83.86   99.56  98.42     90.56
4  75.89  59.75   84.71  68.10     63.65
Total accuracy: 63.22%
Average sen: 60.46%
Average spec: 90.78%
Macro f1-score: 50.49%
Diagnosis acc on 90mins: 1.0
[0.9995141  0.99963188 0.99913895 0.99999571 0.99999905]
pred: 0.9996559381484985, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp019-nsrr

=== Test on chp020-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.460049, loss_ss: 1.669290, loss_d: 0.790759
0.2463 --- loss: 1.994573, loss_ss: 1.495202, loss_d: 0.499370
0.4926 --- loss: 2.096773, loss_ss: 1.459133, loss_d: 0.637640
0.7389 --- loss: 2.113837, loss_ss: 1.325466, loss_d: 0.788371
0.9852 --- loss: 1.818260, loss_ss: 1.306453, loss_d: 0.511807
Epoch finished! Loss: 2.180973491072655
Starting epoch 2/10.
0.0000 --- loss: 1.776252, loss_ss: 1.310224, loss_d: 0.466028
0.2463 --- loss: 1.664629, loss_ss: 1.314139, loss_d: 0.350490
0.4926 --- loss: 1.769711, loss_ss: 1.217153, loss_d: 0.552557
0.7389 --- loss: 2.099268, loss_ss: 1.297211, loss_d: 0.802057
0.9852 --- loss: 1.551297, loss_ss: 1.246837, loss_d: 0.304460
Epoch finished! Loss: 1.8103256404399872
Starting epoch 3/10.
0.0000 --- loss: 1.491534, loss_ss: 1.160435, loss_d: 0.331099
0.2463 --- loss: 1.498717, loss_ss: 1.178675, loss_d: 0.320042
0.4926 --- loss: 1.456139, loss_ss: 1.209332, loss_d: 0.246807
0.7389 --- loss: 1.542829, loss_ss: 1.241956, loss_d: 0.300873
0.9852 --- loss: 1.222676, loss_ss: 1.171318, loss_d: 0.051358
Epoch finished! Loss: 1.508649343252182
Starting epoch 4/10.
0.0000 --- loss: 1.291873, loss_ss: 1.181762, loss_d: 0.110111
0.2463 --- loss: 1.267877, loss_ss: 1.170193, loss_d: 0.097684
0.4926 --- loss: 1.156906, loss_ss: 1.056739, loss_d: 0.100168
0.7389 --- loss: 1.281561, loss_ss: 1.177678, loss_d: 0.103883
0.9852 --- loss: 1.788094, loss_ss: 1.079457, loss_d: 0.708637
Epoch finished! Loss: 1.296055093407631
Starting epoch 5/10.
0.0000 --- loss: 1.087531, loss_ss: 1.068855, loss_d: 0.018677
0.2463 --- loss: 1.135086, loss_ss: 1.108587, loss_d: 0.026499
0.4926 --- loss: 1.128941, loss_ss: 1.110656, loss_d: 0.018285
0.7389 --- loss: 1.205832, loss_ss: 1.189018, loss_d: 0.016814
0.9852 --- loss: 1.078939, loss_ss: 1.071352, loss_d: 0.007587
Epoch finished! Loss: 1.1860669255256653
Starting epoch 6/10.
0.0000 --- loss: 0.983454, loss_ss: 0.948502, loss_d: 0.034952
0.2463 --- loss: 1.098126, loss_ss: 0.949207, loss_d: 0.148919
0.4926 --- loss: 0.956965, loss_ss: 0.946913, loss_d: 0.010052
0.7389 --- loss: 1.139725, loss_ss: 0.997662, loss_d: 0.142063
0.9852 --- loss: 1.059580, loss_ss: 1.046902, loss_d: 0.012677
Epoch finished! Loss: 1.1019151851534843
Starting epoch 7/10.
0.0000 --- loss: 1.100168, loss_ss: 1.038623, loss_d: 0.061545
0.2463 --- loss: 0.977990, loss_ss: 0.976996, loss_d: 0.000994
0.4926 --- loss: 0.917629, loss_ss: 0.916674, loss_d: 0.000955
0.7389 --- loss: 0.928400, loss_ss: 0.920726, loss_d: 0.007674
0.9852 --- loss: 0.909265, loss_ss: 0.896392, loss_d: 0.012874
Epoch finished! Loss: 1.0121636480093001
Starting epoch 8/10.
0.0000 --- loss: 0.877695, loss_ss: 0.866475, loss_d: 0.011220
0.2463 --- loss: 0.967682, loss_ss: 0.918935, loss_d: 0.048748
0.4926 --- loss: 1.041579, loss_ss: 0.991124, loss_d: 0.050455
0.7389 --- loss: 0.886731, loss_ss: 0.886108, loss_d: 0.000623
0.9852 --- loss: 0.776890, loss_ss: 0.774866, loss_d: 0.002023
Epoch finished! Loss: 0.9623452097177505
Starting epoch 9/10.
0.0000 --- loss: 0.809231, loss_ss: 0.803447, loss_d: 0.005783
0.2463 --- loss: 0.832701, loss_ss: 0.829409, loss_d: 0.003292
0.4926 --- loss: 0.908399, loss_ss: 0.908087, loss_d: 0.000312
0.7389 --- loss: 0.743507, loss_ss: 0.741911, loss_d: 0.001596
0.9852 --- loss: 1.019700, loss_ss: 1.019399, loss_d: 0.000301
Epoch finished! Loss: 0.9188482999801636
Starting epoch 10/10.
0.0000 --- loss: 0.790122, loss_ss: 0.787857, loss_d: 0.002265
0.2463 --- loss: 0.931588, loss_ss: 0.931377, loss_d: 0.000211
0.4926 --- loss: 0.794313, loss_ss: 0.793541, loss_d: 0.000772
0.7389 --- loss: 0.839443, loss_ss: 0.838704, loss_d: 0.000739
0.9852 --- loss: 0.828546, loss_ss: 0.826928, loss_d: 0.001618
Epoch finished! Loss: 0.8828303188085556
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5916666666666667
             precision    recall  f1-score   support

        0.0       0.80      0.69      0.74       237
        1.0       0.63      0.13      0.22       200
        2.0       0.62      0.97      0.75       354
        3.0       0.00      0.00      0.00       159
        4.0       0.38      0.82      0.52       130

avg / total       0.54      0.59      0.51      1080
 


====== chp020-nsrr ======

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  89.35  69.20   95.02  79.61     74.04
1  82.50  13.00   98.30  63.41     21.58
2  79.35  96.89   70.80  61.80     75.47
3  85.28   0.00  100.00   0.00      0.00
4  81.85  81.54   81.89  38.13     51.96
Total accuracy: 59.17%
Average sen: 52.13%
Average spec: 89.20%
Macro f1-score: 44.61%
Diagnosis acc on 90mins: 1.0
[0.99135935 0.99857867 1.         1.         0.99999976 0.99999976]
pred: 0.9983229239781698, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp020-nsrr

=== Test on chp022-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.529669, loss_ss: 1.855269, loss_d: 0.674400
0.2469 --- loss: 2.096427, loss_ss: 1.684052, loss_d: 0.412375
0.4938 --- loss: 2.143575, loss_ss: 1.467618, loss_d: 0.675956
0.7407 --- loss: 2.113129, loss_ss: 1.497429, loss_d: 0.615700
0.9877 --- loss: 1.837643, loss_ss: 1.507913, loss_d: 0.329731
Epoch finished! Loss: 2.28372009396553
Starting epoch 2/10.
0.0000 --- loss: 1.885568, loss_ss: 1.533117, loss_d: 0.352451
0.2469 --- loss: 2.237198, loss_ss: 1.463783, loss_d: 0.773415
0.4938 --- loss: 1.953087, loss_ss: 1.437916, loss_d: 0.515171
0.7407 --- loss: 1.794129, loss_ss: 1.466028, loss_d: 0.328101
0.9877 --- loss: 1.701919, loss_ss: 1.457952, loss_d: 0.243968
Epoch finished! Loss: 1.9407175421714782
Starting epoch 3/10.
0.0000 --- loss: 1.600355, loss_ss: 1.338678, loss_d: 0.261677
0.2469 --- loss: 1.383900, loss_ss: 1.347684, loss_d: 0.036216
0.4938 --- loss: 1.584502, loss_ss: 1.371767, loss_d: 0.212735
0.7407 --- loss: 1.539304, loss_ss: 1.316263, loss_d: 0.223041
0.9877 --- loss: 1.882285, loss_ss: 1.222232, loss_d: 0.660053
Epoch finished! Loss: 1.5595152258872986
Starting epoch 4/10.
0.0000 --- loss: 1.334423, loss_ss: 1.260988, loss_d: 0.073435
0.2469 --- loss: 1.415285, loss_ss: 1.317408, loss_d: 0.097877
0.4938 --- loss: 1.486833, loss_ss: 1.237232, loss_d: 0.249601
0.7407 --- loss: 1.513721, loss_ss: 1.207437, loss_d: 0.306284
0.9877 --- loss: 1.331908, loss_ss: 1.256653, loss_d: 0.075255
Epoch finished! Loss: 1.3993234485387802
Starting epoch 5/10.
0.0000 --- loss: 1.165325, loss_ss: 1.150198, loss_d: 0.015127
0.2469 --- loss: 1.262707, loss_ss: 1.241680, loss_d: 0.021027
0.4938 --- loss: 1.159183, loss_ss: 1.117812, loss_d: 0.041371
0.7407 --- loss: 1.185025, loss_ss: 1.178264, loss_d: 0.006762
0.9877 --- loss: 1.226245, loss_ss: 1.213047, loss_d: 0.013198
Epoch finished! Loss: 1.2359737932682038
Starting epoch 6/10.
0.0000 --- loss: 1.123469, loss_ss: 1.120907, loss_d: 0.002562
0.2469 --- loss: 1.157185, loss_ss: 1.155416, loss_d: 0.001770
0.4938 --- loss: 1.020226, loss_ss: 1.010800, loss_d: 0.009427
0.7407 --- loss: 1.066828, loss_ss: 1.066620, loss_d: 0.000208
0.9877 --- loss: 1.056933, loss_ss: 1.056612, loss_d: 0.000321
Epoch finished! Loss: 1.12173023968935
Starting epoch 7/10.
0.0000 --- loss: 1.003507, loss_ss: 1.003334, loss_d: 0.000173
0.2469 --- loss: 0.973059, loss_ss: 0.972785, loss_d: 0.000274
0.4938 --- loss: 1.007237, loss_ss: 1.006366, loss_d: 0.000871
0.7407 --- loss: 1.072809, loss_ss: 0.971983, loss_d: 0.100826
0.9877 --- loss: 0.870139, loss_ss: 0.868345, loss_d: 0.001794
Epoch finished! Loss: 1.0512930169701575
Starting epoch 8/10.
0.0000 --- loss: 1.028078, loss_ss: 1.027483, loss_d: 0.000595
0.2469 --- loss: 0.979988, loss_ss: 0.977075, loss_d: 0.002913
0.4938 --- loss: 0.896004, loss_ss: 0.895535, loss_d: 0.000469
0.7407 --- loss: 0.873103, loss_ss: 0.872736, loss_d: 0.000368
0.9877 --- loss: 1.067287, loss_ss: 1.065810, loss_d: 0.001477
Epoch finished! Loss: 1.0020843222737312
Starting epoch 9/10.
0.0000 --- loss: 0.892870, loss_ss: 0.892636, loss_d: 0.000234
0.2469 --- loss: 0.850792, loss_ss: 0.838242, loss_d: 0.012550
0.4938 --- loss: 0.965662, loss_ss: 0.965513, loss_d: 0.000149
0.7407 --- loss: 0.943367, loss_ss: 0.926574, loss_d: 0.016793
0.9877 --- loss: 0.918580, loss_ss: 0.916204, loss_d: 0.002376
Epoch finished! Loss: 0.988723537325859
Starting epoch 10/10.
0.0000 --- loss: 0.918252, loss_ss: 0.917541, loss_d: 0.000711
0.2469 --- loss: 1.151805, loss_ss: 1.100965, loss_d: 0.050840
0.4938 --- loss: 0.954808, loss_ss: 0.952707, loss_d: 0.002100
0.7407 --- loss: 0.968379, loss_ss: 0.965126, loss_d: 0.003254
0.9877 --- loss: 0.827869, loss_ss: 0.827488, loss_d: 0.000381
Epoch finished! Loss: 0.9743870377540589
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5746031746031746
             precision    recall  f1-score   support

        0.0       0.43      0.97      0.60       253
        1.0       0.68      0.05      0.10       293
        2.0       0.73      0.92      0.82       468
        3.0       0.83      0.09      0.17       107
        4.0       0.30      0.16      0.21       139

avg / total       0.62      0.57      0.48      1260
 


====== chp022-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  74.05  97.23   68.22  43.46     60.07
1  77.38   5.12   99.28  68.18      9.52
2  84.68  92.09   80.30  73.42     81.71
3  92.14   9.35   99.83  83.33     16.81
4  86.67  15.83   95.45  30.14     20.75
Total accuracy: 57.46%
Average sen: 43.92%
Average spec: 88.62%
Macro f1-score: 37.77%
Diagnosis acc on 90mins: 1.0
[0.99987805 0.9989906  0.99998498 0.99999726 0.99999905 0.99941742
 0.99996543]
pred: 0.9997475402695792, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp022-nsrr

=== Test on chp024-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.407180, loss_ss: 1.701466, loss_d: 0.705714
0.2463 --- loss: 2.315960, loss_ss: 1.634436, loss_d: 0.681524
0.4926 --- loss: 2.274939, loss_ss: 1.567913, loss_d: 0.707027
0.7389 --- loss: 1.983557, loss_ss: 1.452348, loss_d: 0.531208
0.9852 --- loss: 2.195600, loss_ss: 1.403432, loss_d: 0.792168
Epoch finished! Loss: 2.206320568919182
Starting epoch 2/10.
0.0000 --- loss: 1.597421, loss_ss: 1.388620, loss_d: 0.208801
0.2463 --- loss: 1.979508, loss_ss: 1.337685, loss_d: 0.641823
0.4926 --- loss: 1.782414, loss_ss: 1.290213, loss_d: 0.492201
0.7389 --- loss: 1.879719, loss_ss: 1.326712, loss_d: 0.553007
0.9852 --- loss: 1.630143, loss_ss: 1.305185, loss_d: 0.324959
Epoch finished! Loss: 1.787198033928871
Starting epoch 3/10.
0.0000 --- loss: 1.465025, loss_ss: 1.360646, loss_d: 0.104379
0.2463 --- loss: 1.333038, loss_ss: 1.269257, loss_d: 0.063782
0.4926 --- loss: 1.339330, loss_ss: 1.252878, loss_d: 0.086452
0.7389 --- loss: 1.477471, loss_ss: 1.217640, loss_d: 0.259831
0.9852 --- loss: 1.431254, loss_ss: 1.236316, loss_d: 0.194938
Epoch finished! Loss: 1.519789308309555
Starting epoch 4/10.
0.0000 --- loss: 1.292190, loss_ss: 1.178819, loss_d: 0.113370
0.2463 --- loss: 1.335401, loss_ss: 1.187770, loss_d: 0.147632
0.4926 --- loss: 1.239455, loss_ss: 1.200190, loss_d: 0.039265
0.7389 --- loss: 1.862359, loss_ss: 1.144962, loss_d: 0.717397
0.9852 --- loss: 1.103763, loss_ss: 1.095827, loss_d: 0.007936
Epoch finished! Loss: 1.3062485873699188
Starting epoch 5/10.
0.0000 --- loss: 1.126900, loss_ss: 1.089431, loss_d: 0.037468
0.2463 --- loss: 1.074494, loss_ss: 1.070186, loss_d: 0.004308
0.4926 --- loss: 1.133297, loss_ss: 1.130418, loss_d: 0.002879
0.7389 --- loss: 1.084513, loss_ss: 1.078783, loss_d: 0.005729
0.9852 --- loss: 1.107053, loss_ss: 1.096129, loss_d: 0.010923
Epoch finished! Loss: 1.1547428607940673
Starting epoch 6/10.
0.0000 --- loss: 1.051974, loss_ss: 1.048849, loss_d: 0.003124
0.2463 --- loss: 1.063483, loss_ss: 1.051242, loss_d: 0.012241
0.4926 --- loss: 0.994648, loss_ss: 0.990294, loss_d: 0.004354
0.7389 --- loss: 0.995435, loss_ss: 0.994550, loss_d: 0.000885
0.9852 --- loss: 0.958070, loss_ss: 0.956086, loss_d: 0.001984
Epoch finished! Loss: 1.0742081835865975
Starting epoch 7/10.
0.0000 --- loss: 0.977756, loss_ss: 0.976252, loss_d: 0.001504
0.2463 --- loss: 0.982752, loss_ss: 0.982054, loss_d: 0.000699
0.4926 --- loss: 1.022802, loss_ss: 1.022056, loss_d: 0.000746
0.7389 --- loss: 1.026210, loss_ss: 1.026108, loss_d: 0.000103
0.9852 --- loss: 1.089566, loss_ss: 1.089136, loss_d: 0.000430
Epoch finished! Loss: 1.011743177473545
Starting epoch 8/10.
0.0000 --- loss: 0.947843, loss_ss: 0.947614, loss_d: 0.000229
0.2463 --- loss: 0.953480, loss_ss: 0.953081, loss_d: 0.000399
0.4926 --- loss: 0.868689, loss_ss: 0.867947, loss_d: 0.000742
0.7389 --- loss: 0.958420, loss_ss: 0.958099, loss_d: 0.000320
0.9852 --- loss: 0.996241, loss_ss: 0.995494, loss_d: 0.000747
Epoch finished! Loss: 0.9582748726010323
Starting epoch 9/10.
0.0000 --- loss: 0.911013, loss_ss: 0.910719, loss_d: 0.000294
0.2463 --- loss: 0.939179, loss_ss: 0.938957, loss_d: 0.000222
0.4926 --- loss: 0.830506, loss_ss: 0.828044, loss_d: 0.002463
0.7389 --- loss: 0.912273, loss_ss: 0.911884, loss_d: 0.000389
0.9852 --- loss: 0.886927, loss_ss: 0.886222, loss_d: 0.000706
Epoch finished! Loss: 0.9271309792995452
Starting epoch 10/10.
0.0000 --- loss: 0.896834, loss_ss: 0.896591, loss_d: 0.000243
0.2463 --- loss: 0.856255, loss_ss: 0.856098, loss_d: 0.000157
0.4926 --- loss: 0.869524, loss_ss: 0.869287, loss_d: 0.000237
0.7389 --- loss: 0.973995, loss_ss: 0.973491, loss_d: 0.000504
0.9852 --- loss: 0.938137, loss_ss: 0.938057, loss_d: 0.000080
Epoch finished! Loss: 0.9057590216398239
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5657407407407408
             precision    recall  f1-score   support

        0.0       0.62      0.78      0.69       232
        1.0       0.26      0.08      0.13       179
        2.0       0.51      0.69      0.58       216
        3.0       1.00      0.62      0.76       339
        4.0       0.25      0.50      0.34       114

avg / total       0.62      0.57      0.56      1080
 


====== chp024-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  84.81  78.02   86.67   61.56     68.82
1  80.93   8.38   95.34   26.32     12.71
2  80.28  68.98   83.10   50.51     58.32
3  87.96  61.65  100.00  100.00     76.28
4  79.17  50.00   82.61   25.33     33.63
Total accuracy: 56.57%
Average sen: 53.41%
Average spec: 89.54%
Macro f1-score: 49.95%
Diagnosis acc on 90mins: 1.0
[0.99107111 0.95480955 0.99897265 0.99429059 0.9999553  0.9812727 ]
pred: 0.9867286483446757, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp024-nsrr

=== Test on chp025-nsrr. train_data(410), test_data(2) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.647702, loss_ss: 1.863292, loss_d: 0.784410
0.2439 --- loss: 2.094918, loss_ss: 1.567994, loss_d: 0.526924
0.4878 --- loss: 1.983376, loss_ss: 1.485725, loss_d: 0.497651
0.7317 --- loss: 2.037317, loss_ss: 1.395885, loss_d: 0.641432
0.9756 --- loss: 2.220143, loss_ss: 1.477591, loss_d: 0.742552
Epoch finished! Loss: 2.2444512844085693
Starting epoch 2/10.
0.0000 --- loss: 1.952182, loss_ss: 1.419552, loss_d: 0.532630
0.2439 --- loss: 1.922331, loss_ss: 1.366838, loss_d: 0.555493
0.4878 --- loss: 1.728049, loss_ss: 1.435831, loss_d: 0.292217
0.7317 --- loss: 1.777869, loss_ss: 1.359869, loss_d: 0.417999
0.9756 --- loss: 1.616938, loss_ss: 1.263106, loss_d: 0.353832
Epoch finished! Loss: 1.8599440932273865
Starting epoch 3/10.
0.0000 --- loss: 1.649314, loss_ss: 1.409333, loss_d: 0.239981
0.2439 --- loss: 1.622077, loss_ss: 1.339938, loss_d: 0.282139
0.4878 --- loss: 1.428376, loss_ss: 1.362914, loss_d: 0.065462
0.7317 --- loss: 1.413403, loss_ss: 1.227165, loss_d: 0.186238
0.9756 --- loss: 1.380677, loss_ss: 1.322314, loss_d: 0.058363
Epoch finished! Loss: 1.4688784390687943
Starting epoch 4/10.
0.0000 --- loss: 1.298658, loss_ss: 1.275334, loss_d: 0.023324
0.2439 --- loss: 1.311571, loss_ss: 1.302200, loss_d: 0.009370
0.4878 --- loss: 1.203071, loss_ss: 1.168958, loss_d: 0.034113
0.7317 --- loss: 1.394515, loss_ss: 1.224804, loss_d: 0.169712
0.9756 --- loss: 1.168114, loss_ss: 1.166182, loss_d: 0.001932
Epoch finished! Loss: 1.2777640789747238
Starting epoch 5/10.
0.0000 --- loss: 1.117944, loss_ss: 1.101880, loss_d: 0.016064
0.2439 --- loss: 1.186942, loss_ss: 1.182961, loss_d: 0.003981
0.4878 --- loss: 1.107439, loss_ss: 1.103292, loss_d: 0.004147
0.7317 --- loss: 1.149874, loss_ss: 1.146811, loss_d: 0.003063
0.9756 --- loss: 1.164923, loss_ss: 1.159588, loss_d: 0.005334
Epoch finished! Loss: 1.2033697664737701
Starting epoch 6/10.
0.0000 --- loss: 0.997721, loss_ss: 0.997219, loss_d: 0.000502
0.2439 --- loss: 1.041248, loss_ss: 1.034107, loss_d: 0.007141
0.4878 --- loss: 1.109741, loss_ss: 1.067295, loss_d: 0.042446
0.7317 --- loss: 1.014967, loss_ss: 1.002241, loss_d: 0.012726
0.9756 --- loss: 1.008057, loss_ss: 0.903355, loss_d: 0.104702
Epoch finished! Loss: 1.1040585592389107
Starting epoch 7/10.
0.0000 --- loss: 1.038137, loss_ss: 0.990991, loss_d: 0.047146
0.2439 --- loss: 1.012980, loss_ss: 0.964068, loss_d: 0.048912
0.4878 --- loss: 0.992359, loss_ss: 0.992064, loss_d: 0.000294
0.7317 --- loss: 1.068199, loss_ss: 1.019665, loss_d: 0.048534
0.9756 --- loss: 1.123405, loss_ss: 1.005441, loss_d: 0.117964
Epoch finished! Loss: 1.086103293299675
Starting epoch 8/10.
0.0000 --- loss: 1.011602, loss_ss: 1.008163, loss_d: 0.003439
0.2439 --- loss: 0.938925, loss_ss: 0.834697, loss_d: 0.104228
0.4878 --- loss: 1.021364, loss_ss: 1.020271, loss_d: 0.001093
0.7317 --- loss: 0.946545, loss_ss: 0.941794, loss_d: 0.004751
0.9756 --- loss: 0.984717, loss_ss: 0.860952, loss_d: 0.123765
Epoch finished! Loss: 1.0623894602060318
Starting epoch 9/10.
0.0000 --- loss: 1.523962, loss_ss: 1.181859, loss_d: 0.342103
0.2439 --- loss: 1.076303, loss_ss: 0.988840, loss_d: 0.087463
0.4878 --- loss: 1.034596, loss_ss: 0.997340, loss_d: 0.037256
0.7317 --- loss: 1.011059, loss_ss: 1.011019, loss_d: 0.000040
0.9756 --- loss: 0.978160, loss_ss: 0.969022, loss_d: 0.009138
Epoch finished! Loss: 1.0277531072497368
Starting epoch 10/10.
0.0000 --- loss: 0.913564, loss_ss: 0.912135, loss_d: 0.001428
0.2439 --- loss: 0.898408, loss_ss: 0.898212, loss_d: 0.000196
0.4878 --- loss: 0.887367, loss_ss: 0.886238, loss_d: 0.001129
0.7317 --- loss: 0.864037, loss_ss: 0.855498, loss_d: 0.008539
0.9756 --- loss: 0.927328, loss_ss: 0.926044, loss_d: 0.001284
Epoch finished! Loss: 0.967198196053505
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7916666666666666
             precision    recall  f1-score   support

        0.0       0.99      0.79      0.88       249
        1.0       0.40      0.10      0.16        20
        2.0       0.54      0.93      0.68        29
        3.0       1.00      0.95      0.98        62
        4.0       0.00      0.00      0.00         0

avg / total       0.93      0.79      0.84       360
 


====== chp025-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  85.28  79.12   99.10   99.49     88.14
1  94.17  10.00   99.12   40.00     16.00
2  93.06  93.10   93.05   54.00     68.35
3  99.17  95.16  100.00  100.00     97.52
4  86.67    NaN   86.67    0.00       NaN
Total accuracy: 79.17%
Average sen: 69.35%
Average spec: 95.59%
Macro f1-score: 67.50%
Diagnosis acc on 90mins: 1.0
[0.99993038 0.99866867]
pred: 0.9992995262145996, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp025-nsrr

=== Test on chp026-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.339315, loss_ss: 1.631340, loss_d: 0.707975
0.2457 --- loss: 2.164116, loss_ss: 1.478430, loss_d: 0.685686
0.4914 --- loss: 1.819621, loss_ss: 1.438220, loss_d: 0.381401
0.7371 --- loss: 1.903119, loss_ss: 1.304681, loss_d: 0.598438
0.9828 --- loss: 2.297540, loss_ss: 1.283304, loss_d: 1.014236
Epoch finished! Loss: 2.107274267077446
Starting epoch 2/10.
0.0000 --- loss: 2.070741, loss_ss: 1.293981, loss_d: 0.776760
0.2457 --- loss: 1.913430, loss_ss: 1.234480, loss_d: 0.678950
0.4914 --- loss: 1.712849, loss_ss: 1.202416, loss_d: 0.510433
0.7371 --- loss: 1.607408, loss_ss: 1.298488, loss_d: 0.308919
0.9828 --- loss: 1.435241, loss_ss: 1.154742, loss_d: 0.280500
Epoch finished! Loss: 1.7567206144332885
Starting epoch 3/10.
0.0000 --- loss: 1.386542, loss_ss: 1.231916, loss_d: 0.154626
0.2457 --- loss: 1.552663, loss_ss: 1.231136, loss_d: 0.321527
0.4914 --- loss: 1.509100, loss_ss: 1.281996, loss_d: 0.227104
0.7371 --- loss: 1.435791, loss_ss: 1.095101, loss_d: 0.340690
0.9828 --- loss: 1.403842, loss_ss: 1.163018, loss_d: 0.240825
Epoch finished! Loss: 1.484515431523323
Starting epoch 4/10.
0.0000 --- loss: 1.178784, loss_ss: 1.147210, loss_d: 0.031574
0.2457 --- loss: 1.168670, loss_ss: 1.094862, loss_d: 0.073808
0.4914 --- loss: 1.103793, loss_ss: 1.050991, loss_d: 0.052802
0.7371 --- loss: 1.246031, loss_ss: 1.038306, loss_d: 0.207726
0.9828 --- loss: 1.716542, loss_ss: 1.247429, loss_d: 0.469113
Epoch finished! Loss: 1.2411212921142578
Starting epoch 5/10.
0.0000 --- loss: 1.029539, loss_ss: 1.019467, loss_d: 0.010072
0.2457 --- loss: 1.147505, loss_ss: 1.107983, loss_d: 0.039522
0.4914 --- loss: 1.175852, loss_ss: 1.052811, loss_d: 0.123041
0.7371 --- loss: 1.112707, loss_ss: 1.103037, loss_d: 0.009670
0.9828 --- loss: 1.176815, loss_ss: 1.175802, loss_d: 0.001012
Epoch finished! Loss: 1.2101786255836486
Starting epoch 6/10.
0.0000 --- loss: 1.042423, loss_ss: 1.037560, loss_d: 0.004864
0.2457 --- loss: 1.017592, loss_ss: 1.013809, loss_d: 0.003784
0.4914 --- loss: 0.946944, loss_ss: 0.914864, loss_d: 0.032080
0.7371 --- loss: 0.952129, loss_ss: 0.936461, loss_d: 0.015669
0.9828 --- loss: 1.010034, loss_ss: 0.978201, loss_d: 0.031833
Epoch finished! Loss: 1.0673203274607659
Starting epoch 7/10.
0.0000 --- loss: 0.947492, loss_ss: 0.942228, loss_d: 0.005263
0.2457 --- loss: 0.899190, loss_ss: 0.896058, loss_d: 0.003132
0.4914 --- loss: 0.990468, loss_ss: 0.989784, loss_d: 0.000684
0.7371 --- loss: 0.860292, loss_ss: 0.855783, loss_d: 0.004509
0.9828 --- loss: 0.820354, loss_ss: 0.820180, loss_d: 0.000174
Epoch finished! Loss: 0.9851602286100387
Starting epoch 8/10.
0.0000 --- loss: 0.884107, loss_ss: 0.883437, loss_d: 0.000670
0.2457 --- loss: 0.851634, loss_ss: 0.849144, loss_d: 0.002490
0.4914 --- loss: 0.869340, loss_ss: 0.869136, loss_d: 0.000203
0.7371 --- loss: 0.782324, loss_ss: 0.780219, loss_d: 0.002105
0.9828 --- loss: 0.868236, loss_ss: 0.868191, loss_d: 0.000045
Epoch finished! Loss: 0.9252705320715904
Starting epoch 9/10.
0.0000 --- loss: 0.816173, loss_ss: 0.815968, loss_d: 0.000205
0.2457 --- loss: 0.971134, loss_ss: 0.970854, loss_d: 0.000280
0.4914 --- loss: 0.800658, loss_ss: 0.800309, loss_d: 0.000349
0.7371 --- loss: 0.760500, loss_ss: 0.760248, loss_d: 0.000252
0.9828 --- loss: 0.795594, loss_ss: 0.795366, loss_d: 0.000228
Epoch finished! Loss: 0.8895377784967422
Starting epoch 10/10.
0.0000 --- loss: 0.860002, loss_ss: 0.857802, loss_d: 0.002200
0.2457 --- loss: 0.780826, loss_ss: 0.780744, loss_d: 0.000083
0.4914 --- loss: 0.789116, loss_ss: 0.788948, loss_d: 0.000168
0.7371 --- loss: 0.941687, loss_ss: 0.941379, loss_d: 0.000307
0.9828 --- loss: 0.904060, loss_ss: 0.903847, loss_d: 0.000213
Epoch finished! Loss: 0.8620225623250007
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7744444444444445
             precision    recall  f1-score   support

        0.0       0.40      0.95      0.56        58
        1.0       0.00      0.00      0.00        55
        2.0       0.81      0.87      0.84       386
        3.0       0.93      0.82      0.87       182
        4.0       0.84      0.72      0.77       219

avg / total       0.77      0.77      0.76       900
 


====== chp026-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  90.33  94.83   90.02  39.57     55.84
1  93.89   0.00  100.00   0.00      0.00
2  85.78  86.79   85.02  81.31     83.96
3  95.11  82.42   98.33  92.59     87.21
4  89.78  71.69   95.59  83.96     77.34
Total accuracy: 77.44%
Average sen: 67.14%
Average spec: 93.79%
Macro f1-score: 60.87%
Diagnosis acc on 90mins: 1.0
[0.99865204 0.99928373 0.99988437 0.9989171  0.985843  ]
pred: 0.9965160489082336, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp026-nsrr

=== Test on chp028-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.401861, loss_ss: 1.670834, loss_d: 0.731027
0.2457 --- loss: 2.141119, loss_ss: 1.541767, loss_d: 0.599352
0.4914 --- loss: 2.164380, loss_ss: 1.435799, loss_d: 0.728581
0.7371 --- loss: 2.000826, loss_ss: 1.401688, loss_d: 0.599138
0.9828 --- loss: 2.002441, loss_ss: 1.330146, loss_d: 0.672295
Epoch finished! Loss: 2.1595057219266893
Starting epoch 2/10.
0.0000 --- loss: 1.768831, loss_ss: 1.385687, loss_d: 0.383144
0.2457 --- loss: 1.768125, loss_ss: 1.327463, loss_d: 0.440662
0.4914 --- loss: 1.757595, loss_ss: 1.405326, loss_d: 0.352269
0.7371 --- loss: 1.667473, loss_ss: 1.219169, loss_d: 0.448304
0.9828 --- loss: 1.653886, loss_ss: 1.239114, loss_d: 0.414772
Epoch finished! Loss: 1.7971085250377654
Starting epoch 3/10.
0.0000 --- loss: 1.793337, loss_ss: 1.385610, loss_d: 0.407727
0.2457 --- loss: 1.529261, loss_ss: 1.222095, loss_d: 0.307166
0.4914 --- loss: 1.499750, loss_ss: 1.194817, loss_d: 0.304932
0.7371 --- loss: 1.403121, loss_ss: 1.344014, loss_d: 0.059107
0.9828 --- loss: 1.592116, loss_ss: 1.219016, loss_d: 0.373101
Epoch finished! Loss: 1.5498274236917495
Starting epoch 4/10.
0.0000 --- loss: 1.312955, loss_ss: 1.224993, loss_d: 0.087962
0.2457 --- loss: 1.630781, loss_ss: 1.355798, loss_d: 0.274983
0.4914 --- loss: 1.344690, loss_ss: 1.270069, loss_d: 0.074621
0.7371 --- loss: 1.229088, loss_ss: 1.096780, loss_d: 0.132308
0.9828 --- loss: 1.154452, loss_ss: 1.138444, loss_d: 0.016008
Epoch finished! Loss: 1.380718794465065
Starting epoch 5/10.
0.0000 --- loss: 1.106847, loss_ss: 1.096539, loss_d: 0.010308
0.2457 --- loss: 1.267935, loss_ss: 1.238375, loss_d: 0.029560
0.4914 --- loss: 1.326540, loss_ss: 1.299227, loss_d: 0.027313
0.7371 --- loss: 1.205371, loss_ss: 1.046779, loss_d: 0.158592
0.9828 --- loss: 1.090960, loss_ss: 1.087235, loss_d: 0.003724
Epoch finished! Loss: 1.2265439301729202
Starting epoch 6/10.
0.0000 --- loss: 1.048118, loss_ss: 1.038881, loss_d: 0.009237
0.2457 --- loss: 1.063714, loss_ss: 1.061844, loss_d: 0.001870
0.4914 --- loss: 1.096070, loss_ss: 1.093671, loss_d: 0.002399
0.7371 --- loss: 1.187884, loss_ss: 1.172463, loss_d: 0.015421
0.9828 --- loss: 1.000708, loss_ss: 0.976351, loss_d: 0.024357
Epoch finished! Loss: 1.1101723864674569
Starting epoch 7/10.
0.0000 --- loss: 1.117886, loss_ss: 1.117502, loss_d: 0.000384
0.2457 --- loss: 1.044032, loss_ss: 1.042385, loss_d: 0.001646
0.4914 --- loss: 1.024684, loss_ss: 1.023662, loss_d: 0.001021
0.7371 --- loss: 1.119701, loss_ss: 1.076706, loss_d: 0.042995
0.9828 --- loss: 1.421667, loss_ss: 1.013174, loss_d: 0.408493
Epoch finished! Loss: 1.0674233213067055
Starting epoch 8/10.
0.0000 --- loss: 1.269895, loss_ss: 1.266440, loss_d: 0.003455
0.2457 --- loss: 1.104137, loss_ss: 1.077902, loss_d: 0.026235
0.4914 --- loss: 1.227686, loss_ss: 0.912359, loss_d: 0.315327
0.7371 --- loss: 0.987288, loss_ss: 0.948301, loss_d: 0.038987
0.9828 --- loss: 1.242637, loss_ss: 1.226801, loss_d: 0.015836
Epoch finished! Loss: 1.0834307968616486
Starting epoch 9/10.
0.0000 --- loss: 0.958768, loss_ss: 0.953789, loss_d: 0.004980
0.2457 --- loss: 0.963886, loss_ss: 0.956555, loss_d: 0.007331
0.4914 --- loss: 0.971911, loss_ss: 0.971239, loss_d: 0.000673
0.7371 --- loss: 0.833862, loss_ss: 0.830882, loss_d: 0.002980
0.9828 --- loss: 1.181259, loss_ss: 1.180867, loss_d: 0.000393
Epoch finished! Loss: 1.0191516399383544
Starting epoch 10/10.
0.0000 --- loss: 0.883852, loss_ss: 0.883098, loss_d: 0.000754
0.2457 --- loss: 1.058871, loss_ss: 1.046682, loss_d: 0.012189
0.4914 --- loss: 0.838914, loss_ss: 0.838465, loss_d: 0.000449
0.7371 --- loss: 0.800720, loss_ss: 0.798734, loss_d: 0.001987
0.9828 --- loss: 0.921570, loss_ss: 0.918414, loss_d: 0.003155
Epoch finished! Loss: 0.939593905210495
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6407119021134594
             precision    recall  f1-score   support

        0.0       0.93      0.57      0.71        89
        1.0       0.14      0.23      0.18        53
        2.0       0.61      0.96      0.74       382
        3.0       0.95      0.19      0.31       191
        4.0       0.94      0.59      0.73       184

avg / total       0.75      0.64      0.61       899
 


====== chp028-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  95.33  57.30   99.51  92.73     70.83
1  87.54  22.64   91.61  14.46     17.65
2  71.86  96.34   53.77  60.63     74.42
3  82.54  18.85   99.72  94.74     31.44
4  90.88  59.24   99.02  93.97     72.67
Total accuracy: 64.07%
Average sen: 50.87%
Average spec: 88.72%
Macro f1-score: 53.40%
Diagnosis acc on 90mins: 1.0
[0.99993086 0.98431903 0.99793351 0.9999975  0.99999833]
pred: 0.9964358448982239, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp028-nsrr

=== Test on chp029-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.530017, loss_ss: 1.900931, loss_d: 0.629086
0.2457 --- loss: 2.274747, loss_ss: 1.724369, loss_d: 0.550378
0.4914 --- loss: 1.983869, loss_ss: 1.591772, loss_d: 0.392097
0.7371 --- loss: 2.162268, loss_ss: 1.600465, loss_d: 0.561803
0.9828 --- loss: 2.056747, loss_ss: 1.434956, loss_d: 0.621791
Epoch finished! Loss: 2.300285053253174
Starting epoch 2/10.
0.0000 --- loss: 2.215733, loss_ss: 1.496632, loss_d: 0.719101
0.2457 --- loss: 1.867504, loss_ss: 1.497833, loss_d: 0.369671
0.4914 --- loss: 1.694578, loss_ss: 1.456098, loss_d: 0.238479
0.7371 --- loss: 2.036602, loss_ss: 1.453503, loss_d: 0.583098
0.9828 --- loss: 2.072193, loss_ss: 1.390796, loss_d: 0.681397
Epoch finished! Loss: 2.0142197966575623
Starting epoch 3/10.
0.0000 --- loss: 1.571581, loss_ss: 1.401427, loss_d: 0.170155
0.2457 --- loss: 1.615287, loss_ss: 1.419634, loss_d: 0.195653
0.4914 --- loss: 1.894763, loss_ss: 1.389552, loss_d: 0.505211
0.7371 --- loss: 1.641367, loss_ss: 1.432329, loss_d: 0.209038
0.9828 --- loss: 1.543518, loss_ss: 1.340523, loss_d: 0.202995
Epoch finished! Loss: 1.7462215214967727
Starting epoch 4/10.
0.0000 --- loss: 1.415601, loss_ss: 1.342615, loss_d: 0.072986
0.2457 --- loss: 1.336001, loss_ss: 1.284384, loss_d: 0.051617
0.4914 --- loss: 1.399812, loss_ss: 1.272790, loss_d: 0.127022
0.7371 --- loss: 1.360997, loss_ss: 1.330011, loss_d: 0.030986
0.9828 --- loss: 1.305005, loss_ss: 1.252373, loss_d: 0.052633
Epoch finished! Loss: 1.4679787009954453
Starting epoch 5/10.
0.0000 --- loss: 1.337953, loss_ss: 1.283826, loss_d: 0.054127
0.2457 --- loss: 1.385433, loss_ss: 1.331991, loss_d: 0.053442
0.4914 --- loss: 1.205206, loss_ss: 1.200000, loss_d: 0.005206
0.7371 --- loss: 1.442683, loss_ss: 1.239181, loss_d: 0.203502
0.9828 --- loss: 1.117227, loss_ss: 1.115212, loss_d: 0.002015
Epoch finished! Loss: 1.3321955025196075
Starting epoch 6/10.
0.0000 --- loss: 1.171827, loss_ss: 1.166450, loss_d: 0.005378
0.2457 --- loss: 1.116113, loss_ss: 1.103606, loss_d: 0.012507
0.4914 --- loss: 1.151461, loss_ss: 1.092017, loss_d: 0.059444
0.7371 --- loss: 1.152743, loss_ss: 1.118971, loss_d: 0.033772
0.9828 --- loss: 1.050527, loss_ss: 1.050010, loss_d: 0.000518
Epoch finished! Loss: 1.182526084780693
Starting epoch 7/10.
0.0000 --- loss: 1.090728, loss_ss: 1.089121, loss_d: 0.001607
0.2457 --- loss: 1.018478, loss_ss: 1.017864, loss_d: 0.000614
0.4914 --- loss: 1.002056, loss_ss: 1.001484, loss_d: 0.000572
0.7371 --- loss: 1.095389, loss_ss: 1.094822, loss_d: 0.000567
0.9828 --- loss: 0.990359, loss_ss: 0.988246, loss_d: 0.002113
Epoch finished! Loss: 1.094094155728817
Starting epoch 8/10.
0.0000 --- loss: 1.140348, loss_ss: 1.117624, loss_d: 0.022725
0.2457 --- loss: 0.974740, loss_ss: 0.974028, loss_d: 0.000712
0.4914 --- loss: 1.023865, loss_ss: 1.023571, loss_d: 0.000294
0.7371 --- loss: 1.003593, loss_ss: 0.989429, loss_d: 0.014164
0.9828 --- loss: 1.049498, loss_ss: 1.031682, loss_d: 0.017816
Epoch finished! Loss: 1.0357861176133156
Starting epoch 9/10.
0.0000 --- loss: 0.980875, loss_ss: 0.977084, loss_d: 0.003790
0.2457 --- loss: 0.981754, loss_ss: 0.981412, loss_d: 0.000343
0.4914 --- loss: 0.979303, loss_ss: 0.958281, loss_d: 0.021022
0.7371 --- loss: 0.884345, loss_ss: 0.883236, loss_d: 0.001109
0.9828 --- loss: 0.880593, loss_ss: 0.871351, loss_d: 0.009242
Epoch finished! Loss: 0.9721767038106919
Starting epoch 10/10.
0.0000 --- loss: 1.015938, loss_ss: 0.970413, loss_d: 0.045525
0.2457 --- loss: 0.917870, loss_ss: 0.896181, loss_d: 0.021688
0.4914 --- loss: 0.875650, loss_ss: 0.875464, loss_d: 0.000186
0.7371 --- loss: 0.938527, loss_ss: 0.937645, loss_d: 0.000883
0.9828 --- loss: 0.905895, loss_ss: 0.904999, loss_d: 0.000896
Epoch finished! Loss: 0.9212438315153122
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5111111111111111
             precision    recall  f1-score   support

        0.0       0.52      0.67      0.58        66
        1.0       0.13      0.75      0.23        44
        2.0       0.57      0.59      0.58       374
        3.0       1.00      0.38      0.55       311
        4.0       0.71      0.40      0.51       105

avg / total       0.71      0.51      0.55       900
 


====== chp029-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  93.00  66.67   95.08   51.76     58.28
1  75.11  75.00   75.12   13.41     22.76
2  64.33  59.36   67.87   56.78     58.04
3  78.67  38.26  100.00  100.00     55.35
4  91.11  40.00   97.86   71.19     51.22
Total accuracy: 51.11%
Average sen: 55.86%
Average spec: 87.19%
Macro f1-score: 49.13%
Diagnosis acc on 90mins: 1.0
[0.99999535 0.99999428 0.99980932 0.99948251 0.99998784]
pred: 0.9998538613319397, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp029-nsrr

=== Test on chp030-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.446158, loss_ss: 1.705983, loss_d: 0.740176
0.2463 --- loss: 1.895864, loss_ss: 1.488303, loss_d: 0.407561
0.4926 --- loss: 1.929773, loss_ss: 1.483933, loss_d: 0.445840
0.7389 --- loss: 2.015079, loss_ss: 1.428997, loss_d: 0.586083
0.9852 --- loss: 1.702873, loss_ss: 1.456757, loss_d: 0.246116
Epoch finished! Loss: 2.114693948626518
Starting epoch 2/10.
0.0000 --- loss: 1.900112, loss_ss: 1.348413, loss_d: 0.551699
0.2463 --- loss: 1.939769, loss_ss: 1.331721, loss_d: 0.608048
0.4926 --- loss: 1.810932, loss_ss: 1.260603, loss_d: 0.550328
0.7389 --- loss: 1.501145, loss_ss: 1.237542, loss_d: 0.263603
0.9852 --- loss: 1.365189, loss_ss: 1.217820, loss_d: 0.147369
Epoch finished! Loss: 1.7243014246225357
Starting epoch 3/10.
0.0000 --- loss: 1.255419, loss_ss: 1.212189, loss_d: 0.043230
0.2463 --- loss: 1.352958, loss_ss: 1.290609, loss_d: 0.062348
0.4926 --- loss: 1.296004, loss_ss: 1.162997, loss_d: 0.133007
0.7389 --- loss: 1.374698, loss_ss: 1.272637, loss_d: 0.102060
0.9852 --- loss: 1.547887, loss_ss: 1.197813, loss_d: 0.350074
Epoch finished! Loss: 1.3755405575037003
Starting epoch 4/10.
0.0000 --- loss: 1.221934, loss_ss: 1.218273, loss_d: 0.003660
0.2463 --- loss: 1.125860, loss_ss: 1.091028, loss_d: 0.034832
0.4926 --- loss: 1.195646, loss_ss: 1.153412, loss_d: 0.042234
0.7389 --- loss: 1.498382, loss_ss: 1.298449, loss_d: 0.199933
0.9852 --- loss: 1.041390, loss_ss: 1.025809, loss_d: 0.015581
Epoch finished! Loss: 1.2151073575019837
Starting epoch 5/10.
0.0000 --- loss: 1.132989, loss_ss: 1.127989, loss_d: 0.005000
0.2463 --- loss: 1.058544, loss_ss: 1.054020, loss_d: 0.004525
0.4926 --- loss: 1.146980, loss_ss: 1.098349, loss_d: 0.048631
0.7389 --- loss: 1.151950, loss_ss: 1.150770, loss_d: 0.001180
0.9852 --- loss: 1.026272, loss_ss: 1.023648, loss_d: 0.002624
Epoch finished! Loss: 1.1282351285219192
Starting epoch 6/10.
0.0000 --- loss: 1.155311, loss_ss: 1.153591, loss_d: 0.001720
0.2463 --- loss: 1.105721, loss_ss: 1.105429, loss_d: 0.000292
0.4926 --- loss: 1.071717, loss_ss: 1.019490, loss_d: 0.052227
0.7389 --- loss: 0.936054, loss_ss: 0.933782, loss_d: 0.002272
0.9852 --- loss: 1.311515, loss_ss: 1.311481, loss_d: 0.000034
Epoch finished! Loss: 1.0598182082176208
Starting epoch 7/10.
0.0000 --- loss: 1.064949, loss_ss: 1.059810, loss_d: 0.005140
0.2463 --- loss: 0.979416, loss_ss: 0.978140, loss_d: 0.001276
0.4926 --- loss: 1.299972, loss_ss: 1.299881, loss_d: 0.000091
0.7389 --- loss: 0.989080, loss_ss: 0.988133, loss_d: 0.000947
0.9852 --- loss: 1.023840, loss_ss: 1.022946, loss_d: 0.000894
Epoch finished! Loss: 1.014228230714798
Starting epoch 8/10.
0.0000 --- loss: 1.001965, loss_ss: 0.998367, loss_d: 0.003598
0.2463 --- loss: 0.939878, loss_ss: 0.939518, loss_d: 0.000360
0.4926 --- loss: 0.856639, loss_ss: 0.856444, loss_d: 0.000195
0.7389 --- loss: 1.052994, loss_ss: 1.052586, loss_d: 0.000408
0.9852 --- loss: 0.799075, loss_ss: 0.796205, loss_d: 0.002870
Epoch finished! Loss: 0.9699382051825524
Starting epoch 9/10.
0.0000 --- loss: 0.913160, loss_ss: 0.912338, loss_d: 0.000822
0.2463 --- loss: 0.852985, loss_ss: 0.850676, loss_d: 0.002310
0.4926 --- loss: 0.922159, loss_ss: 0.918766, loss_d: 0.003393
0.7389 --- loss: 0.784856, loss_ss: 0.784552, loss_d: 0.000305
0.9852 --- loss: 0.954934, loss_ss: 0.954406, loss_d: 0.000528
Epoch finished! Loss: 0.9285932391881943
Starting epoch 10/10.
0.0000 --- loss: 0.827215, loss_ss: 0.826695, loss_d: 0.000520
0.2463 --- loss: 0.810873, loss_ss: 0.810649, loss_d: 0.000224
0.4926 --- loss: 0.894650, loss_ss: 0.894617, loss_d: 0.000033
0.7389 --- loss: 0.777223, loss_ss: 0.777101, loss_d: 0.000122
0.9852 --- loss: 0.978333, loss_ss: 0.978281, loss_d: 0.000052
Epoch finished! Loss: 0.88797297924757
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.376274328081557
             precision    recall  f1-score   support

        0.0       0.89      0.41      0.56       335
        1.0       0.00      0.00      0.00       200
        2.0       0.45      0.57      0.50       270
        3.0       0.00      0.00      0.00       154
        4.0       0.21      0.97      0.34       120

avg / total       0.41      0.38      0.34      1079
 


====== chp030-nsrr ======

The f1-score of  1  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  79.98  40.60   97.72  88.89     55.74
1  79.98   0.00   98.18   0.00      0.00
2  71.55  56.67   76.51  44.61     49.92
3  85.54   0.00   99.78   0.00      0.00
4  58.20  97.50   53.28  20.71     34.16
Total accuracy: 37.63%
Average sen: 38.95%
Average spec: 85.10%
Macro f1-score: 27.96%
Diagnosis acc on 90mins: 1.0
[0.99999964 0.99855107 1.         0.99999988 0.99999988 0.99999785]
pred: 0.9997580548127493, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp030-nsrr

=== Test on chp031-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.343288, loss_ss: 1.662589, loss_d: 0.680699
0.2463 --- loss: 2.159789, loss_ss: 1.514958, loss_d: 0.644831
0.4926 --- loss: 1.934200, loss_ss: 1.472616, loss_d: 0.461584
0.7389 --- loss: 2.055853, loss_ss: 1.425323, loss_d: 0.630530
0.9852 --- loss: 1.988203, loss_ss: 1.516953, loss_d: 0.471249
Epoch finished! Loss: 2.1961302548646926
Starting epoch 2/10.
0.0000 --- loss: 1.807870, loss_ss: 1.396788, loss_d: 0.411082
0.2463 --- loss: 1.789549, loss_ss: 1.352345, loss_d: 0.437205
0.4926 --- loss: 1.595897, loss_ss: 1.367821, loss_d: 0.228077
0.7389 --- loss: 1.737500, loss_ss: 1.349604, loss_d: 0.387896
0.9852 --- loss: 1.854738, loss_ss: 1.265140, loss_d: 0.589598
Epoch finished! Loss: 1.8622094243764877
Starting epoch 3/10.
0.0000 --- loss: 1.707925, loss_ss: 1.233938, loss_d: 0.473987
0.2463 --- loss: 1.610919, loss_ss: 1.301754, loss_d: 0.309165
0.4926 --- loss: 1.501762, loss_ss: 1.233345, loss_d: 0.268418
0.7389 --- loss: 1.426797, loss_ss: 1.214129, loss_d: 0.212667
0.9852 --- loss: 1.325557, loss_ss: 1.276163, loss_d: 0.049394
Epoch finished! Loss: 1.5599943310022355
Starting epoch 4/10.
0.0000 --- loss: 1.146609, loss_ss: 1.111340, loss_d: 0.035269
0.2463 --- loss: 1.198205, loss_ss: 1.133441, loss_d: 0.064764
0.4926 --- loss: 1.112510, loss_ss: 1.052040, loss_d: 0.060470
0.7389 --- loss: 1.239086, loss_ss: 1.112793, loss_d: 0.126293
0.9852 --- loss: 1.223895, loss_ss: 1.079332, loss_d: 0.144563
Epoch finished! Loss: 1.2674788296222688
Starting epoch 5/10.
0.0000 --- loss: 1.114151, loss_ss: 1.099865, loss_d: 0.014286
0.2463 --- loss: 1.176690, loss_ss: 1.150166, loss_d: 0.026524
0.4926 --- loss: 1.119633, loss_ss: 1.117691, loss_d: 0.001942
0.7389 --- loss: 1.053222, loss_ss: 1.022202, loss_d: 0.031020
0.9852 --- loss: 1.176624, loss_ss: 1.138258, loss_d: 0.038366
Epoch finished! Loss: 1.1916467308998109
Starting epoch 6/10.
0.0000 --- loss: 1.076097, loss_ss: 1.059772, loss_d: 0.016325
0.2463 --- loss: 1.104056, loss_ss: 1.022901, loss_d: 0.081154
0.4926 --- loss: 0.990586, loss_ss: 0.978313, loss_d: 0.012274
0.7389 --- loss: 1.030868, loss_ss: 1.024428, loss_d: 0.006440
0.9852 --- loss: 1.136007, loss_ss: 1.115489, loss_d: 0.020518
Epoch finished! Loss: 1.134078250825405
Starting epoch 7/10.
0.0000 --- loss: 1.040939, loss_ss: 1.022077, loss_d: 0.018862
0.2463 --- loss: 1.285382, loss_ss: 0.915539, loss_d: 0.369843
0.4926 --- loss: 1.017136, loss_ss: 1.006168, loss_d: 0.010968
0.7389 --- loss: 0.907734, loss_ss: 0.902666, loss_d: 0.005068
0.9852 --- loss: 0.924922, loss_ss: 0.919453, loss_d: 0.005468
Epoch finished! Loss: 1.052201361954212
Starting epoch 8/10.
0.0000 --- loss: 0.958317, loss_ss: 0.957935, loss_d: 0.000381
0.2463 --- loss: 0.995924, loss_ss: 0.995139, loss_d: 0.000785
0.4926 --- loss: 1.140202, loss_ss: 1.139987, loss_d: 0.000215
0.7389 --- loss: 0.849873, loss_ss: 0.831097, loss_d: 0.018776
0.9852 --- loss: 0.852164, loss_ss: 0.848460, loss_d: 0.003704
Epoch finished! Loss: 0.9926125124096871
Starting epoch 9/10.
0.0000 --- loss: 0.803839, loss_ss: 0.803262, loss_d: 0.000577
0.2463 --- loss: 1.090774, loss_ss: 1.082548, loss_d: 0.008225
0.4926 --- loss: 0.952036, loss_ss: 0.950925, loss_d: 0.001111
0.7389 --- loss: 0.793815, loss_ss: 0.790089, loss_d: 0.003727
0.9852 --- loss: 0.898713, loss_ss: 0.897318, loss_d: 0.001395
Epoch finished! Loss: 0.9494442462921142
Starting epoch 10/10.
0.0000 --- loss: 0.855245, loss_ss: 0.852913, loss_d: 0.002332
0.2463 --- loss: 0.886411, loss_ss: 0.881245, loss_d: 0.005167
0.4926 --- loss: 0.923916, loss_ss: 0.903000, loss_d: 0.020915
0.7389 --- loss: 0.749945, loss_ss: 0.749764, loss_d: 0.000181
0.9852 --- loss: 0.872835, loss_ss: 0.872813, loss_d: 0.000022
Epoch finished! Loss: 0.901788504421711
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6703703703703704
             precision    recall  f1-score   support

        0.0       0.22      0.59      0.32        51
        1.0       0.00      0.00      0.00        48
        2.0       0.61      0.85      0.71       309
        3.0       1.00      0.59      0.74       229
        4.0       0.79      0.67      0.73       443

avg / total       0.72      0.67      0.67      1080
 


====== chp031-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  88.24  58.82   89.70   22.06     32.09
1  95.09   0.00   99.52    0.00      0.00
2  80.09  84.79   78.21   60.93     70.91
3  91.20  58.52  100.00  100.00     73.83
4  79.44  67.27   87.91   79.47     72.86
Total accuracy: 67.04%
Average sen: 53.88%
Average spec: 91.07%
Macro f1-score: 49.94%
Diagnosis acc on 90mins: 1.0
[0.99999034 0.99952567 0.97240978 0.99961287 0.99996412 0.99965739]
pred: 0.995193362236023, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp031-nsrr

=== Test on chp032-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.429629, loss_ss: 1.690110, loss_d: 0.739519
0.2457 --- loss: 1.960625, loss_ss: 1.541501, loss_d: 0.419124
0.4914 --- loss: 2.103254, loss_ss: 1.447058, loss_d: 0.656196
0.7371 --- loss: 2.106638, loss_ss: 1.427200, loss_d: 0.679439
0.9828 --- loss: 1.801308, loss_ss: 1.373173, loss_d: 0.428136
Epoch finished! Loss: 2.1563622087240217
Starting epoch 2/10.
0.0000 --- loss: 1.731588, loss_ss: 1.394221, loss_d: 0.337367
0.2457 --- loss: 1.868662, loss_ss: 1.370894, loss_d: 0.497768
0.4914 --- loss: 1.770742, loss_ss: 1.385804, loss_d: 0.384937
0.7371 --- loss: 1.759811, loss_ss: 1.318869, loss_d: 0.440941
0.9828 --- loss: 1.802072, loss_ss: 1.367569, loss_d: 0.434502
Epoch finished! Loss: 1.8461998581886292
Starting epoch 3/10.
0.0000 --- loss: 1.444455, loss_ss: 1.268191, loss_d: 0.176264
0.2457 --- loss: 1.482090, loss_ss: 1.346675, loss_d: 0.135415
0.4914 --- loss: 1.469665, loss_ss: 1.230983, loss_d: 0.238683
0.7371 --- loss: 1.272731, loss_ss: 1.139249, loss_d: 0.133482
0.9828 --- loss: 1.608063, loss_ss: 1.269941, loss_d: 0.338123
Epoch finished! Loss: 1.4356835961341858
Starting epoch 4/10.
0.0000 --- loss: 1.174124, loss_ss: 1.146256, loss_d: 0.027868
0.2457 --- loss: 1.173693, loss_ss: 1.159460, loss_d: 0.014232
0.4914 --- loss: 1.182440, loss_ss: 1.173735, loss_d: 0.008705
0.7371 --- loss: 1.259146, loss_ss: 1.201095, loss_d: 0.058051
0.9828 --- loss: 1.191540, loss_ss: 1.187391, loss_d: 0.004150
Epoch finished! Loss: 1.2546803444623946
Starting epoch 5/10.
0.0000 --- loss: 1.089666, loss_ss: 1.062451, loss_d: 0.027214
0.2457 --- loss: 1.217005, loss_ss: 1.116922, loss_d: 0.100083
0.4914 --- loss: 1.848040, loss_ss: 1.054164, loss_d: 0.793876
0.7371 --- loss: 1.740848, loss_ss: 1.153788, loss_d: 0.587060
0.9828 --- loss: 1.290208, loss_ss: 1.193024, loss_d: 0.097184
Epoch finished! Loss: 1.2345396399497985
Starting epoch 6/10.
0.0000 --- loss: 1.097134, loss_ss: 1.077769, loss_d: 0.019365
0.2457 --- loss: 1.202330, loss_ss: 1.197559, loss_d: 0.004770
0.4914 --- loss: 1.369527, loss_ss: 0.919164, loss_d: 0.450363
0.7371 --- loss: 1.138564, loss_ss: 1.128492, loss_d: 0.010071
0.9828 --- loss: 0.998716, loss_ss: 0.993207, loss_d: 0.005508
Epoch finished! Loss: 1.1296353101730348
Starting epoch 7/10.
0.0000 --- loss: 0.953464, loss_ss: 0.951954, loss_d: 0.001510
0.2457 --- loss: 0.930678, loss_ss: 0.928155, loss_d: 0.002522
0.4914 --- loss: 0.931382, loss_ss: 0.876112, loss_d: 0.055271
0.7371 --- loss: 1.308343, loss_ss: 1.150370, loss_d: 0.157973
0.9828 --- loss: 1.089719, loss_ss: 1.009146, loss_d: 0.080573
Epoch finished! Loss: 1.025647558271885
Starting epoch 8/10.
0.0000 --- loss: 1.096044, loss_ss: 1.093449, loss_d: 0.002595
0.2457 --- loss: 0.921518, loss_ss: 0.920528, loss_d: 0.000990
0.4914 --- loss: 0.810529, loss_ss: 0.806596, loss_d: 0.003933
0.7371 --- loss: 0.861723, loss_ss: 0.860609, loss_d: 0.001114
0.9828 --- loss: 1.168060, loss_ss: 1.166404, loss_d: 0.001656
Epoch finished! Loss: 0.9755486771464348
Starting epoch 9/10.
0.0000 --- loss: 0.873958, loss_ss: 0.869658, loss_d: 0.004300
0.2457 --- loss: 0.960532, loss_ss: 0.959947, loss_d: 0.000585
0.4914 --- loss: 0.866480, loss_ss: 0.864734, loss_d: 0.001746
0.7371 --- loss: 0.913468, loss_ss: 0.900145, loss_d: 0.013323
0.9828 --- loss: 0.959901, loss_ss: 0.949854, loss_d: 0.010047
Epoch finished! Loss: 0.9484978497028351
Starting epoch 10/10.
0.0000 --- loss: 0.893963, loss_ss: 0.892612, loss_d: 0.001352
0.2457 --- loss: 0.906039, loss_ss: 0.901147, loss_d: 0.004892
0.4914 --- loss: 0.811453, loss_ss: 0.809741, loss_d: 0.001712
0.7371 --- loss: 0.966560, loss_ss: 0.917836, loss_d: 0.048724
0.9828 --- loss: 0.822791, loss_ss: 0.822660, loss_d: 0.000130
Epoch finished! Loss: 0.9296825289726257
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7488888888888889
             precision    recall  f1-score   support

        0.0       0.52      0.86      0.65        14
        1.0       0.00      0.00      0.00        92
        2.0       0.89      0.82      0.86       486
        3.0       1.00      0.73      0.85       150
        4.0       0.48      0.97      0.64       158

avg / total       0.74      0.75      0.73       900
 


====== chp032-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  98.56  85.71   98.76   52.17     64.86
1  89.78   0.00  100.00    0.00      0.00
2  85.11  82.10   88.65   89.46     85.62
3  95.56  73.33  100.00  100.00     84.62
4  80.78  96.84   77.36   47.66     63.88
Total accuracy: 74.89%
Average sen: 67.60%
Average spec: 92.95%
Macro f1-score: 59.80%
Diagnosis acc on 90mins: 0.8
[0.99999154 0.98829985 0.14226811 0.99999535 0.9997713 ]
pred: 0.8260652273893356, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp032-nsrr

=== Test on chp033-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.344205, loss_ss: 1.628880, loss_d: 0.715325
0.2457 --- loss: 2.154248, loss_ss: 1.492975, loss_d: 0.661272
0.4914 --- loss: 2.165407, loss_ss: 1.586496, loss_d: 0.578911
0.7371 --- loss: 2.101117, loss_ss: 1.504687, loss_d: 0.596430
0.9828 --- loss: 1.918700, loss_ss: 1.486462, loss_d: 0.432238
Epoch finished! Loss: 2.192186227440834
Starting epoch 2/10.
0.0000 --- loss: 1.749445, loss_ss: 1.447363, loss_d: 0.302082
0.2457 --- loss: 1.733253, loss_ss: 1.413158, loss_d: 0.320095
0.4914 --- loss: 1.580439, loss_ss: 1.365980, loss_d: 0.214458
0.7371 --- loss: 1.630343, loss_ss: 1.371079, loss_d: 0.259264
0.9828 --- loss: 1.622467, loss_ss: 1.431672, loss_d: 0.190794
Epoch finished! Loss: 1.8412817656993865
Starting epoch 3/10.
0.0000 --- loss: 1.447546, loss_ss: 1.320515, loss_d: 0.127031
0.2457 --- loss: 1.605101, loss_ss: 1.390723, loss_d: 0.214378
0.4914 --- loss: 1.585376, loss_ss: 1.259572, loss_d: 0.325804
0.7371 --- loss: 1.370521, loss_ss: 1.270757, loss_d: 0.099764
0.9828 --- loss: 1.301580, loss_ss: 1.282246, loss_d: 0.019335
Epoch finished! Loss: 1.5077718436717986
Starting epoch 4/10.
0.0000 --- loss: 1.308029, loss_ss: 1.286031, loss_d: 0.021998
0.2457 --- loss: 1.248116, loss_ss: 1.182316, loss_d: 0.065800
0.4914 --- loss: 1.288302, loss_ss: 1.239438, loss_d: 0.048865
0.7371 --- loss: 1.176978, loss_ss: 1.153770, loss_d: 0.023208
0.9828 --- loss: 1.179821, loss_ss: 1.178181, loss_d: 0.001640
Epoch finished! Loss: 1.315343087911606
Starting epoch 5/10.
0.0000 --- loss: 1.299842, loss_ss: 1.291150, loss_d: 0.008692
0.2457 --- loss: 1.134536, loss_ss: 1.115104, loss_d: 0.019432
0.4914 --- loss: 1.040667, loss_ss: 1.039414, loss_d: 0.001253
0.7371 --- loss: 1.152144, loss_ss: 1.150963, loss_d: 0.001182
0.9828 --- loss: 1.057294, loss_ss: 1.027833, loss_d: 0.029461
Epoch finished! Loss: 1.1996804803609848
Starting epoch 6/10.
0.0000 --- loss: 1.104370, loss_ss: 1.098741, loss_d: 0.005629
0.2457 --- loss: 1.106620, loss_ss: 1.102844, loss_d: 0.003776
0.4914 --- loss: 1.215475, loss_ss: 1.041064, loss_d: 0.174411
0.7371 --- loss: 1.123094, loss_ss: 0.974080, loss_d: 0.149014
0.9828 --- loss: 1.111052, loss_ss: 1.107199, loss_d: 0.003853
Epoch finished! Loss: 1.1435123935341835
Starting epoch 7/10.
0.0000 --- loss: 0.977451, loss_ss: 0.957570, loss_d: 0.019881
0.2457 --- loss: 0.982754, loss_ss: 0.972906, loss_d: 0.009848
0.4914 --- loss: 1.064498, loss_ss: 1.058655, loss_d: 0.005843
0.7371 --- loss: 0.907806, loss_ss: 0.904773, loss_d: 0.003032
0.9828 --- loss: 1.280005, loss_ss: 1.279180, loss_d: 0.000825
Epoch finished! Loss: 1.067012368142605
Starting epoch 8/10.
0.0000 --- loss: 0.982194, loss_ss: 0.979322, loss_d: 0.002872
0.2457 --- loss: 0.978619, loss_ss: 0.975490, loss_d: 0.003129
0.4914 --- loss: 1.082519, loss_ss: 1.080513, loss_d: 0.002006
0.7371 --- loss: 1.265168, loss_ss: 1.109519, loss_d: 0.155649
0.9828 --- loss: 1.037392, loss_ss: 1.006503, loss_d: 0.030889
Epoch finished! Loss: 1.0737438812851905
Starting epoch 9/10.
0.0000 --- loss: 1.014963, loss_ss: 1.013805, loss_d: 0.001158
0.2457 --- loss: 1.019753, loss_ss: 1.015533, loss_d: 0.004220
0.4914 --- loss: 1.083222, loss_ss: 1.077218, loss_d: 0.006004
0.7371 --- loss: 0.929332, loss_ss: 0.927951, loss_d: 0.001381
0.9828 --- loss: 1.036989, loss_ss: 1.036870, loss_d: 0.000119
Epoch finished! Loss: 1.0142147108912467
Starting epoch 10/10.
0.0000 --- loss: 0.925025, loss_ss: 0.924187, loss_d: 0.000838
0.2457 --- loss: 1.449345, loss_ss: 0.926369, loss_d: 0.522976
0.4914 --- loss: 0.993620, loss_ss: 0.977660, loss_d: 0.015960
0.7371 --- loss: 0.986391, loss_ss: 0.985554, loss_d: 0.000838
0.9828 --- loss: 0.979962, loss_ss: 0.979755, loss_d: 0.000206
Epoch finished! Loss: 1.0012600317597389
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5977777777777777
             precision    recall  f1-score   support

        0.0       0.18      0.56      0.27        32
        1.0       0.53      0.73      0.61       248
        2.0       0.53      0.64      0.58       208
        3.0       1.00      0.80      0.89       254
        4.0       1.00      0.01      0.02       158

avg / total       0.73      0.60      0.57       900
 


====== chp033-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  89.44  56.25   90.67   18.18     27.48
1  74.56  72.58   75.31   52.79     61.12
2  78.56  64.42   82.80   52.96     58.13
3  94.33  80.31   99.85   99.51     88.89
4  82.67   1.27  100.00  100.00      2.50
Total accuracy: 59.78%
Average sen: 54.97%
Average spec: 89.72%
Macro f1-score: 47.62%
Diagnosis acc on 90mins: 1.0
[0.99999392 1.         0.99999976 1.         0.99999928]
pred: 0.9999985933303833, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp033-nsrr

=== Test on chp034-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.427425, loss_ss: 1.652649, loss_d: 0.774777
0.2457 --- loss: 2.299696, loss_ss: 1.476286, loss_d: 0.823410
0.4914 --- loss: 2.104618, loss_ss: 1.426566, loss_d: 0.678052
0.7371 --- loss: 2.140611, loss_ss: 1.474062, loss_d: 0.666549
0.9828 --- loss: 1.993739, loss_ss: 1.372937, loss_d: 0.620802
Epoch finished! Loss: 2.132606992125511
Starting epoch 2/10.
0.0000 --- loss: 1.865175, loss_ss: 1.384220, loss_d: 0.480954
0.2457 --- loss: 1.742104, loss_ss: 1.393339, loss_d: 0.348765
0.4914 --- loss: 2.040892, loss_ss: 1.343102, loss_d: 0.697790
0.7371 --- loss: 1.798209, loss_ss: 1.313287, loss_d: 0.484923
0.9828 --- loss: 1.569882, loss_ss: 1.279221, loss_d: 0.290661
Epoch finished! Loss: 1.8420980125665665
Starting epoch 3/10.
0.0000 --- loss: 1.633653, loss_ss: 1.297803, loss_d: 0.335851
0.2457 --- loss: 1.541875, loss_ss: 1.271473, loss_d: 0.270401
0.4914 --- loss: 1.422360, loss_ss: 1.229363, loss_d: 0.192997
0.7371 --- loss: 1.556495, loss_ss: 1.244602, loss_d: 0.311893
0.9828 --- loss: 1.852871, loss_ss: 1.298580, loss_d: 0.554291
Epoch finished! Loss: 1.5491988211870193
Starting epoch 4/10.
0.0000 --- loss: 1.248678, loss_ss: 1.175010, loss_d: 0.073668
0.2457 --- loss: 1.897704, loss_ss: 1.203716, loss_d: 0.693988
0.4914 --- loss: 1.296687, loss_ss: 1.261563, loss_d: 0.035124
0.7371 --- loss: 1.199164, loss_ss: 1.165218, loss_d: 0.033946
0.9828 --- loss: 1.138092, loss_ss: 1.127098, loss_d: 0.010994
Epoch finished! Loss: 1.333634614944458
Starting epoch 5/10.
0.0000 --- loss: 1.321831, loss_ss: 1.245757, loss_d: 0.076074
0.2457 --- loss: 1.208284, loss_ss: 1.201085, loss_d: 0.007199
0.4914 --- loss: 1.171351, loss_ss: 1.163672, loss_d: 0.007679
0.7371 --- loss: 1.055496, loss_ss: 1.048881, loss_d: 0.006615
0.9828 --- loss: 1.304726, loss_ss: 1.095113, loss_d: 0.209613
Epoch finished! Loss: 1.2325463205575944
Starting epoch 6/10.
0.0000 --- loss: 1.230528, loss_ss: 1.227715, loss_d: 0.002813
0.2457 --- loss: 1.152291, loss_ss: 1.148023, loss_d: 0.004268
0.4914 --- loss: 1.082188, loss_ss: 1.081541, loss_d: 0.000647
0.7371 --- loss: 1.024844, loss_ss: 1.023190, loss_d: 0.001654
0.9828 --- loss: 1.039325, loss_ss: 1.030230, loss_d: 0.009095
Epoch finished! Loss: 1.1102735862135886
Starting epoch 7/10.
0.0000 --- loss: 0.973871, loss_ss: 0.972433, loss_d: 0.001438
0.2457 --- loss: 1.456166, loss_ss: 1.001311, loss_d: 0.454855
0.4914 --- loss: 1.059723, loss_ss: 1.034045, loss_d: 0.025678
0.7371 --- loss: 1.129081, loss_ss: 0.949573, loss_d: 0.179509
0.9828 --- loss: 1.017872, loss_ss: 1.015473, loss_d: 0.002398
Epoch finished! Loss: 1.1027957633137704
Starting epoch 8/10.
0.0000 --- loss: 1.006985, loss_ss: 0.992505, loss_d: 0.014480
0.2457 --- loss: 1.123128, loss_ss: 1.118260, loss_d: 0.004867
0.4914 --- loss: 1.116463, loss_ss: 1.115669, loss_d: 0.000794
0.7371 --- loss: 0.970220, loss_ss: 0.966098, loss_d: 0.004122
0.9828 --- loss: 0.950989, loss_ss: 0.948999, loss_d: 0.001991
Epoch finished! Loss: 1.0092500627040863
Starting epoch 9/10.
0.0000 --- loss: 0.852880, loss_ss: 0.847128, loss_d: 0.005752
0.2457 --- loss: 0.938931, loss_ss: 0.926709, loss_d: 0.012222
0.4914 --- loss: 0.898402, loss_ss: 0.898002, loss_d: 0.000400
0.7371 --- loss: 0.900521, loss_ss: 0.889789, loss_d: 0.010732
0.9828 --- loss: 0.881242, loss_ss: 0.863459, loss_d: 0.017783
Epoch finished! Loss: 0.941898199915886
Starting epoch 10/10.
0.0000 --- loss: 0.904659, loss_ss: 0.903891, loss_d: 0.000768
0.2457 --- loss: 0.858374, loss_ss: 0.857601, loss_d: 0.000773
0.4914 --- loss: 0.992891, loss_ss: 0.992647, loss_d: 0.000244
0.7371 --- loss: 1.056157, loss_ss: 1.047045, loss_d: 0.009111
0.9828 --- loss: 0.978602, loss_ss: 0.960585, loss_d: 0.018016
Epoch finished! Loss: 0.8933311983942985
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6911111111111111
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00        17
        1.0       0.00      0.00      0.00        62
        2.0       0.66      0.74      0.70       325
        3.0       0.96      0.68      0.80       316
        4.0       0.58      0.91      0.71       180

avg / total       0.69      0.69      0.67       900
 


====== chp034-nsrr ======

The f1-score of  0  has ZeroDivisionError.

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.56   0.00   97.40   0.00      0.00
1  93.11   0.00  100.00   0.00      0.00
2  76.78  74.46   78.09  65.76     69.84
3  87.89  68.35   98.46  96.00     79.85
4  84.89  91.11   83.33  57.75     70.69
Total accuracy: 69.11%
Average sen: 46.79%
Average spec: 91.45%
Macro f1-score: 44.08%
Diagnosis acc on 90mins: 1.0
[0.99938035 1.         0.54877752 0.99514991 0.99523008]
pred: 0.9077075719833374, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp034-nsrr

=== Test on chp036-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.241520, loss_ss: 1.547186, loss_d: 0.694334
0.2469 --- loss: 2.068882, loss_ss: 1.397125, loss_d: 0.671757
0.4938 --- loss: 2.024063, loss_ss: 1.443373, loss_d: 0.580689
0.7407 --- loss: 1.891553, loss_ss: 1.327822, loss_d: 0.563731
0.9877 --- loss: 2.136798, loss_ss: 1.305365, loss_d: 0.831433
Epoch finished! Loss: 2.1387776523828506
Starting epoch 2/10.
0.0000 --- loss: 1.854496, loss_ss: 1.420920, loss_d: 0.433575
0.2469 --- loss: 1.808553, loss_ss: 1.270769, loss_d: 0.537784
0.4938 --- loss: 1.682418, loss_ss: 1.363935, loss_d: 0.318483
0.7407 --- loss: 1.550117, loss_ss: 1.216621, loss_d: 0.333496
0.9877 --- loss: 1.366630, loss_ss: 1.093263, loss_d: 0.273367
Epoch finished! Loss: 1.7630656063556671
Starting epoch 3/10.
0.0000 --- loss: 1.459735, loss_ss: 1.285955, loss_d: 0.173781
0.2469 --- loss: 1.341333, loss_ss: 1.211187, loss_d: 0.130146
0.4938 --- loss: 1.379984, loss_ss: 1.208962, loss_d: 0.171023
0.7407 --- loss: 1.199227, loss_ss: 1.144631, loss_d: 0.054596
0.9877 --- loss: 1.315344, loss_ss: 1.145635, loss_d: 0.169709
Epoch finished! Loss: 1.4382625222206116
Starting epoch 4/10.
0.0000 --- loss: 1.135056, loss_ss: 1.094254, loss_d: 0.040803
0.2469 --- loss: 1.276062, loss_ss: 1.229104, loss_d: 0.046959
0.4938 --- loss: 1.220251, loss_ss: 1.214120, loss_d: 0.006131
0.7407 --- loss: 1.575146, loss_ss: 1.062933, loss_d: 0.512214
0.9877 --- loss: 1.254838, loss_ss: 1.151361, loss_d: 0.103478
Epoch finished! Loss: 1.2466819763183594
Starting epoch 5/10.
0.0000 --- loss: 1.160657, loss_ss: 1.123038, loss_d: 0.037619
0.2469 --- loss: 1.079618, loss_ss: 1.066454, loss_d: 0.013164
0.4938 --- loss: 1.160929, loss_ss: 1.042018, loss_d: 0.118912
0.7407 --- loss: 1.100110, loss_ss: 1.081137, loss_d: 0.018973
0.9877 --- loss: 1.004010, loss_ss: 0.997006, loss_d: 0.007003
Epoch finished! Loss: 1.1115140274167061
Starting epoch 6/10.
0.0000 --- loss: 0.981912, loss_ss: 0.946716, loss_d: 0.035195
0.2469 --- loss: 1.001182, loss_ss: 0.981235, loss_d: 0.019948
0.4938 --- loss: 1.258496, loss_ss: 1.235029, loss_d: 0.023467
0.7407 --- loss: 0.973801, loss_ss: 0.953655, loss_d: 0.020146
0.9877 --- loss: 0.881578, loss_ss: 0.867866, loss_d: 0.013712
Epoch finished! Loss: 1.0455758720636368
Starting epoch 7/10.
0.0000 --- loss: 1.105977, loss_ss: 1.100277, loss_d: 0.005700
0.2469 --- loss: 1.264087, loss_ss: 0.993539, loss_d: 0.270548
0.4938 --- loss: 0.956138, loss_ss: 0.951681, loss_d: 0.004457
0.7407 --- loss: 0.873902, loss_ss: 0.870782, loss_d: 0.003120
0.9877 --- loss: 1.085243, loss_ss: 1.031843, loss_d: 0.053400
Epoch finished! Loss: 1.012439414858818
Starting epoch 8/10.
0.0000 --- loss: 0.842555, loss_ss: 0.839796, loss_d: 0.002759
0.2469 --- loss: 0.879011, loss_ss: 0.875034, loss_d: 0.003978
0.4938 --- loss: 0.934941, loss_ss: 0.934715, loss_d: 0.000226
0.7407 --- loss: 0.841209, loss_ss: 0.838425, loss_d: 0.002784
0.9877 --- loss: 1.091990, loss_ss: 1.089773, loss_d: 0.002217
Epoch finished! Loss: 0.9941417902708054
Starting epoch 9/10.
0.0000 --- loss: 0.882990, loss_ss: 0.876083, loss_d: 0.006907
0.2469 --- loss: 0.952976, loss_ss: 0.952264, loss_d: 0.000712
0.4938 --- loss: 0.880523, loss_ss: 0.879714, loss_d: 0.000810
0.7407 --- loss: 0.792446, loss_ss: 0.765147, loss_d: 0.027299
0.9877 --- loss: 0.940601, loss_ss: 0.937317, loss_d: 0.003284
Epoch finished! Loss: 0.9113137498497963
Starting epoch 10/10.
0.0000 --- loss: 1.047592, loss_ss: 1.046508, loss_d: 0.001084
0.2469 --- loss: 0.757532, loss_ss: 0.756048, loss_d: 0.001484
0.4938 --- loss: 0.989309, loss_ss: 0.989139, loss_d: 0.000170
0.7407 --- loss: 1.013124, loss_ss: 1.006666, loss_d: 0.006458
0.9877 --- loss: 0.737758, loss_ss: 0.727441, loss_d: 0.010318
Epoch finished! Loss: 0.8694067597389221
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8
             precision    recall  f1-score   support

        0.0       0.78      0.92      0.85       237
        1.0       0.00      0.00      0.00       167
        2.0       0.91      0.91      0.91       563
        3.0       0.00      0.00      0.00         8
        4.0       0.66      0.98      0.79       285

avg / total       0.71      0.80      0.74      1260
 


====== chp036-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  93.73  91.98   94.13  78.42     84.66
1  86.75   0.00  100.00   0.00      0.00
2  92.14  90.94   93.11  91.43     91.18
3  99.37   0.00  100.00   0.00      0.00
4  88.02  97.54   85.23  65.88     78.64
Total accuracy: 80.00%
Average sen: 56.09%
Average spec: 94.50%
Macro f1-score: 50.90%
Diagnosis acc on 90mins: 1.0
[0.98918545 0.99827349 0.9999001  0.98647213 0.99999952 0.99572504
 0.99827731]
pred: 0.9954047203063965, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp036-nsrr

=== Test on chp037-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.301799, loss_ss: 1.619431, loss_d: 0.682369
0.2457 --- loss: 2.117218, loss_ss: 1.552760, loss_d: 0.564458
0.4914 --- loss: 1.837166, loss_ss: 1.393502, loss_d: 0.443665
0.7371 --- loss: 1.607901, loss_ss: 1.344748, loss_d: 0.263154
0.9828 --- loss: 1.630799, loss_ss: 1.293486, loss_d: 0.337313
Epoch finished! Loss: 2.0669434756040572
Starting epoch 2/10.
0.0000 --- loss: 1.969221, loss_ss: 1.351632, loss_d: 0.617589
0.2457 --- loss: 1.776134, loss_ss: 1.294925, loss_d: 0.481209
0.4914 --- loss: 1.583977, loss_ss: 1.301936, loss_d: 0.282040
0.7371 --- loss: 1.728338, loss_ss: 1.207144, loss_d: 0.521194
0.9828 --- loss: 1.640494, loss_ss: 1.251027, loss_d: 0.389467
Epoch finished! Loss: 1.7629427313804626
Starting epoch 3/10.
0.0000 --- loss: 1.422908, loss_ss: 1.239177, loss_d: 0.183731
0.2457 --- loss: 1.389033, loss_ss: 1.133436, loss_d: 0.255598
0.4914 --- loss: 1.442412, loss_ss: 1.180110, loss_d: 0.262302
0.7371 --- loss: 1.275635, loss_ss: 1.110869, loss_d: 0.164766
0.9828 --- loss: 1.289011, loss_ss: 1.171116, loss_d: 0.117895
Epoch finished! Loss: 1.4680158615112304
Starting epoch 4/10.
0.0000 --- loss: 1.177816, loss_ss: 1.157689, loss_d: 0.020128
0.2457 --- loss: 1.208502, loss_ss: 1.135494, loss_d: 0.073008
0.4914 --- loss: 1.317519, loss_ss: 1.082732, loss_d: 0.234787
0.7371 --- loss: 1.118137, loss_ss: 1.097656, loss_d: 0.020481
0.9828 --- loss: 1.084267, loss_ss: 1.072545, loss_d: 0.011722
Epoch finished! Loss: 1.2793883949518203
Starting epoch 5/10.
0.0000 --- loss: 1.123541, loss_ss: 1.090223, loss_d: 0.033318
0.2457 --- loss: 1.114002, loss_ss: 1.083354, loss_d: 0.030649
0.4914 --- loss: 1.108380, loss_ss: 1.100342, loss_d: 0.008038
0.7371 --- loss: 1.138504, loss_ss: 1.130929, loss_d: 0.007575
0.9828 --- loss: 1.030458, loss_ss: 1.016972, loss_d: 0.013486
Epoch finished! Loss: 1.1389304175972939
Starting epoch 6/10.
0.0000 --- loss: 1.017753, loss_ss: 1.016896, loss_d: 0.000857
0.2457 --- loss: 1.073462, loss_ss: 1.072361, loss_d: 0.001101
0.4914 --- loss: 1.078405, loss_ss: 1.077573, loss_d: 0.000832
0.7371 --- loss: 1.041219, loss_ss: 1.040711, loss_d: 0.000509
0.9828 --- loss: 0.927405, loss_ss: 0.925751, loss_d: 0.001654
Epoch finished! Loss: 1.0758519902825356
Starting epoch 7/10.
0.0000 --- loss: 0.955823, loss_ss: 0.944404, loss_d: 0.011419
0.2457 --- loss: 1.013499, loss_ss: 1.009611, loss_d: 0.003888
0.4914 --- loss: 0.982851, loss_ss: 0.982694, loss_d: 0.000157
0.7371 --- loss: 1.016507, loss_ss: 1.015677, loss_d: 0.000830
0.9828 --- loss: 1.116054, loss_ss: 1.115530, loss_d: 0.000524
Epoch finished! Loss: 1.0294576555490493
Starting epoch 8/10.
0.0000 --- loss: 0.913612, loss_ss: 0.909692, loss_d: 0.003920
0.2457 --- loss: 0.973444, loss_ss: 0.968374, loss_d: 0.005070
0.4914 --- loss: 0.955898, loss_ss: 0.947998, loss_d: 0.007900
0.7371 --- loss: 0.956815, loss_ss: 0.956608, loss_d: 0.000207
0.9828 --- loss: 0.945436, loss_ss: 0.924584, loss_d: 0.020852
Epoch finished! Loss: 0.9861072838306427
Starting epoch 9/10.
0.0000 --- loss: 1.021016, loss_ss: 1.020821, loss_d: 0.000195
0.2457 --- loss: 0.959554, loss_ss: 0.959047, loss_d: 0.000507
0.4914 --- loss: 0.866935, loss_ss: 0.866696, loss_d: 0.000238
0.7371 --- loss: 0.750047, loss_ss: 0.749592, loss_d: 0.000455
0.9828 --- loss: 1.110918, loss_ss: 1.110594, loss_d: 0.000324
Epoch finished! Loss: 0.9586790263652801
Starting epoch 10/10.
0.0000 --- loss: 0.925271, loss_ss: 0.883346, loss_d: 0.041925
0.2457 --- loss: 0.847601, loss_ss: 0.847262, loss_d: 0.000339
0.4914 --- loss: 0.990506, loss_ss: 0.980606, loss_d: 0.009900
0.7371 --- loss: 0.895992, loss_ss: 0.895762, loss_d: 0.000231
0.9828 --- loss: 0.873500, loss_ss: 0.868492, loss_d: 0.005007
Epoch finished! Loss: 0.9237588614225387
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5411111111111111
             precision    recall  f1-score   support

        0.0       0.80      0.65      0.72       191
        1.0       0.00      0.00      0.00       143
        2.0       0.72      0.52      0.60       274
        3.0       1.00      0.72      0.83       208
        4.0       0.18      0.85      0.30        84

avg / total       0.64      0.54      0.56       900
 


====== chp037-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  89.11  65.45   95.49   79.62     71.84
1  84.11   0.00  100.00    0.00      0.00
2  79.22  51.82   91.21   72.08     60.30
3  93.44  71.63  100.00  100.00     83.47
4  62.33  84.52   60.05   17.88     29.52
Total accuracy: 54.11%
Average sen: 54.69%
Average spec: 89.35%
Macro f1-score: 49.03%
Diagnosis acc on 90mins: 1.0
[0.99999964 1.         1.         0.99999976 1.        ]
pred: 0.9999998807907104, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp037-nsrr

=== Test on chp038-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.434913, loss_ss: 1.795588, loss_d: 0.639325
0.2457 --- loss: 2.379019, loss_ss: 1.649069, loss_d: 0.729950
0.4914 --- loss: 2.082917, loss_ss: 1.592877, loss_d: 0.490040
0.7371 --- loss: 2.515382, loss_ss: 1.608925, loss_d: 0.906457
0.9828 --- loss: 2.115397, loss_ss: 1.536875, loss_d: 0.578522
Epoch finished! Loss: 2.320400148630142
Starting epoch 2/10.
0.0000 --- loss: 1.951429, loss_ss: 1.534392, loss_d: 0.417037
0.2457 --- loss: 1.965980, loss_ss: 1.487823, loss_d: 0.478157
0.4914 --- loss: 1.771247, loss_ss: 1.479801, loss_d: 0.291446
0.7371 --- loss: 2.013488, loss_ss: 1.411798, loss_d: 0.601690
0.9828 --- loss: 1.782166, loss_ss: 1.382109, loss_d: 0.400057
Epoch finished! Loss: 1.957716104388237
Starting epoch 3/10.
0.0000 --- loss: 1.751196, loss_ss: 1.409424, loss_d: 0.341772
0.2457 --- loss: 1.550497, loss_ss: 1.370914, loss_d: 0.179583
0.4914 --- loss: 1.456790, loss_ss: 1.300006, loss_d: 0.156784
0.7371 --- loss: 1.410764, loss_ss: 1.317090, loss_d: 0.093674
0.9828 --- loss: 1.384803, loss_ss: 1.267205, loss_d: 0.117598
Epoch finished! Loss: 1.5985480278730393
Starting epoch 4/10.
0.0000 --- loss: 1.368995, loss_ss: 1.339865, loss_d: 0.029130
0.2457 --- loss: 1.482482, loss_ss: 1.283818, loss_d: 0.198664
0.4914 --- loss: 1.342737, loss_ss: 1.225797, loss_d: 0.116940
0.7371 --- loss: 1.180658, loss_ss: 1.133273, loss_d: 0.047386
0.9828 --- loss: 1.272237, loss_ss: 1.254908, loss_d: 0.017329
Epoch finished! Loss: 1.3715414613485337
Starting epoch 5/10.
0.0000 --- loss: 1.201303, loss_ss: 1.184364, loss_d: 0.016938
0.2457 --- loss: 1.116981, loss_ss: 1.092002, loss_d: 0.024978
0.4914 --- loss: 1.088800, loss_ss: 1.068805, loss_d: 0.019995
0.7371 --- loss: 1.050784, loss_ss: 1.041012, loss_d: 0.009771
0.9828 --- loss: 1.261775, loss_ss: 1.209170, loss_d: 0.052605
Epoch finished! Loss: 1.1986850813031196
Starting epoch 6/10.
0.0000 --- loss: 1.126153, loss_ss: 1.120144, loss_d: 0.006009
0.2457 --- loss: 1.125856, loss_ss: 1.117540, loss_d: 0.008316
0.4914 --- loss: 1.252900, loss_ss: 1.252492, loss_d: 0.000408
0.7371 --- loss: 1.099927, loss_ss: 1.089355, loss_d: 0.010572
0.9828 --- loss: 1.079789, loss_ss: 1.078505, loss_d: 0.001284
Epoch finished! Loss: 1.146615742146969
Starting epoch 7/10.
0.0000 --- loss: 1.027902, loss_ss: 1.023429, loss_d: 0.004473
0.2457 --- loss: 1.076266, loss_ss: 1.038782, loss_d: 0.037483
0.4914 --- loss: 1.029871, loss_ss: 0.961295, loss_d: 0.068575
0.7371 --- loss: 0.913979, loss_ss: 0.912696, loss_d: 0.001284
0.9828 --- loss: 1.034309, loss_ss: 1.029534, loss_d: 0.004775
Epoch finished! Loss: 1.068269680440426
Starting epoch 8/10.
0.0000 --- loss: 0.902583, loss_ss: 0.901948, loss_d: 0.000635
0.2457 --- loss: 0.919152, loss_ss: 0.915751, loss_d: 0.003402
0.4914 --- loss: 1.112335, loss_ss: 1.068879, loss_d: 0.043456
0.7371 --- loss: 1.181856, loss_ss: 1.177071, loss_d: 0.004785
0.9828 --- loss: 1.082231, loss_ss: 1.033002, loss_d: 0.049229
Epoch finished! Loss: 1.0783663466572762
Starting epoch 9/10.
0.0000 --- loss: 1.144746, loss_ss: 1.102991, loss_d: 0.041755
0.2457 --- loss: 0.928812, loss_ss: 0.927884, loss_d: 0.000928
0.4914 --- loss: 0.868805, loss_ss: 0.842244, loss_d: 0.026561
0.7371 --- loss: 0.874533, loss_ss: 0.871218, loss_d: 0.003314
0.9828 --- loss: 0.987212, loss_ss: 0.986159, loss_d: 0.001053
Epoch finished! Loss: 0.9935893848538399
Starting epoch 10/10.
0.0000 --- loss: 1.015103, loss_ss: 1.014572, loss_d: 0.000531
0.2457 --- loss: 0.888587, loss_ss: 0.875391, loss_d: 0.013196
0.4914 --- loss: 1.022697, loss_ss: 1.021968, loss_d: 0.000729
0.7371 --- loss: 0.991547, loss_ss: 0.990938, loss_d: 0.000609
0.9828 --- loss: 0.940281, loss_ss: 0.925283, loss_d: 0.014999
Epoch finished! Loss: 0.9860873997211457
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5622222222222222
             precision    recall  f1-score   support

        0.0       0.19      0.98      0.32        61
        1.0       0.00      0.00      0.00       153
        2.0       0.86      0.81      0.83       373
        3.0       0.98      0.82      0.89       102
        4.0       0.40      0.28      0.33       211

avg / total       0.57      0.56      0.55       900
 


====== chp038-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  71.56  98.36   69.61  19.05     31.91
1  83.00   0.00  100.00   0.00      0.00
2  86.67  81.23   90.51  85.84     83.47
3  97.78  82.35   99.75  97.67     89.36
4  73.44  27.96   87.37  40.41     33.05
Total accuracy: 56.22%
Average sen: 57.98%
Average spec: 89.45%
Macro f1-score: 47.56%
Diagnosis acc on 90mins: 1.0
[0.99037969 0.99789029 0.54730272 0.9992913  0.99997473]
pred: 0.9069677472114563, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp038-nsrr

=== Test on chp039-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.480428, loss_ss: 1.681865, loss_d: 0.798563
0.2463 --- loss: 2.095279, loss_ss: 1.557138, loss_d: 0.538141
0.4926 --- loss: 2.055165, loss_ss: 1.400051, loss_d: 0.655114
0.7389 --- loss: 2.040855, loss_ss: 1.488954, loss_d: 0.551901
0.9852 --- loss: 2.349393, loss_ss: 1.377978, loss_d: 0.971415
Epoch finished! Loss: 2.13845012485981
Starting epoch 2/10.
0.0000 --- loss: 1.930152, loss_ss: 1.348738, loss_d: 0.581414
0.2463 --- loss: 1.982639, loss_ss: 1.334880, loss_d: 0.647759
0.4926 --- loss: 1.642064, loss_ss: 1.379557, loss_d: 0.262507
0.7389 --- loss: 1.655501, loss_ss: 1.246092, loss_d: 0.409409
0.9852 --- loss: 1.640746, loss_ss: 1.267483, loss_d: 0.373263
Epoch finished! Loss: 1.7838825225830077
Starting epoch 3/10.
0.0000 --- loss: 1.412111, loss_ss: 1.251834, loss_d: 0.160277
0.2463 --- loss: 1.335534, loss_ss: 1.269516, loss_d: 0.066018
0.4926 --- loss: 1.336888, loss_ss: 1.200111, loss_d: 0.136777
0.7389 --- loss: 1.372307, loss_ss: 1.246032, loss_d: 0.126275
0.9852 --- loss: 1.131759, loss_ss: 1.087113, loss_d: 0.044646
Epoch finished! Loss: 1.432032573223114
Starting epoch 4/10.
0.0000 --- loss: 1.151432, loss_ss: 1.111344, loss_d: 0.040088
0.2463 --- loss: 1.105799, loss_ss: 1.086699, loss_d: 0.019100
0.4926 --- loss: 1.147673, loss_ss: 1.141790, loss_d: 0.005882
0.7389 --- loss: 1.243810, loss_ss: 1.136564, loss_d: 0.107245
0.9852 --- loss: 1.146401, loss_ss: 1.048932, loss_d: 0.097470
Epoch finished! Loss: 1.2449765086174012
Starting epoch 5/10.
0.0000 --- loss: 1.104158, loss_ss: 1.088547, loss_d: 0.015612
0.2463 --- loss: 1.073605, loss_ss: 1.063920, loss_d: 0.009685
0.4926 --- loss: 1.135170, loss_ss: 1.107231, loss_d: 0.027939
0.7389 --- loss: 1.068387, loss_ss: 1.063798, loss_d: 0.004589
0.9852 --- loss: 1.353655, loss_ss: 1.206361, loss_d: 0.147294
Epoch finished! Loss: 1.182932797074318
Starting epoch 6/10.
0.0000 --- loss: 1.000696, loss_ss: 0.985409, loss_d: 0.015287
0.2463 --- loss: 1.140841, loss_ss: 1.113281, loss_d: 0.027561
0.4926 --- loss: 1.134137, loss_ss: 1.021197, loss_d: 0.112939
0.7389 --- loss: 0.964711, loss_ss: 0.906774, loss_d: 0.057937
0.9852 --- loss: 1.213504, loss_ss: 1.212959, loss_d: 0.000545
Epoch finished! Loss: 1.113811433315277
Starting epoch 7/10.
0.0000 --- loss: 1.040630, loss_ss: 0.996253, loss_d: 0.044377
0.2463 --- loss: 1.117218, loss_ss: 1.039035, loss_d: 0.078183
0.4926 --- loss: 1.055265, loss_ss: 1.049588, loss_d: 0.005677
0.7389 --- loss: 1.042574, loss_ss: 1.039985, loss_d: 0.002588
0.9852 --- loss: 0.865696, loss_ss: 0.862085, loss_d: 0.003611
Epoch finished! Loss: 1.017485348880291
Starting epoch 8/10.
0.0000 --- loss: 0.909020, loss_ss: 0.900339, loss_d: 0.008682
0.2463 --- loss: 1.018036, loss_ss: 1.013772, loss_d: 0.004264
0.4926 --- loss: 0.984041, loss_ss: 0.983390, loss_d: 0.000650
0.7389 --- loss: 0.964146, loss_ss: 0.961554, loss_d: 0.002592
0.9852 --- loss: 0.831737, loss_ss: 0.831109, loss_d: 0.000629
Epoch finished! Loss: 0.9559346690773964
Starting epoch 9/10.
0.0000 --- loss: 1.037158, loss_ss: 1.013776, loss_d: 0.023382
0.2463 --- loss: 0.889499, loss_ss: 0.864509, loss_d: 0.024991
0.4926 --- loss: 0.917289, loss_ss: 0.916436, loss_d: 0.000854
0.7389 --- loss: 0.829530, loss_ss: 0.826777, loss_d: 0.002753
0.9852 --- loss: 0.997009, loss_ss: 0.996803, loss_d: 0.000206
Epoch finished! Loss: 0.913583853840828
Starting epoch 10/10.
0.0000 --- loss: 0.960118, loss_ss: 0.959779, loss_d: 0.000338
0.2463 --- loss: 0.867784, loss_ss: 0.866664, loss_d: 0.001120
0.4926 --- loss: 0.852950, loss_ss: 0.851007, loss_d: 0.001943
0.7389 --- loss: 0.770394, loss_ss: 0.769939, loss_d: 0.000454
0.9852 --- loss: 0.807642, loss_ss: 0.807261, loss_d: 0.000380
Epoch finished! Loss: 0.874027305841446
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.44722222222222224
             precision    recall  f1-score   support

        0.0       0.08      0.79      0.15        19
        1.0       0.00      0.00      0.00       325
        2.0       0.48      0.81      0.60       376
        3.0       1.00      0.50      0.67       199
        4.0       0.40      0.40      0.40       161

avg / total       0.41      0.45      0.39      1080
 


====== chp039-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  84.17  78.95   84.26    8.24     14.93
1  69.91   0.00  100.00    0.00      0.00
2  62.59  80.85   52.84   47.80     60.08
3  90.83  50.25  100.00  100.00     66.89
4  81.94  39.75   89.34   39.51     39.63
Total accuracy: 44.72%
Average sen: 49.96%
Average spec: 85.29%
Macro f1-score: 36.30%
Diagnosis acc on 90mins: 1.0
[0.99980205 0.99995911 0.99986124 0.99998403 0.99967062 0.99950671]
pred: 0.9997972945372263, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp039-nsrr

=== Test on chp040-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.301759, loss_ss: 1.614074, loss_d: 0.687685
0.2457 --- loss: 2.185099, loss_ss: 1.528324, loss_d: 0.656774
0.4914 --- loss: 2.169197, loss_ss: 1.506551, loss_d: 0.662647
0.7371 --- loss: 1.803897, loss_ss: 1.479215, loss_d: 0.324682
0.9828 --- loss: 2.092101, loss_ss: 1.462952, loss_d: 0.629149
Epoch finished! Loss: 2.200214168429375
Starting epoch 2/10.
0.0000 --- loss: 2.338753, loss_ss: 1.506788, loss_d: 0.831965
0.2457 --- loss: 1.745559, loss_ss: 1.397336, loss_d: 0.348223
0.4914 --- loss: 1.915533, loss_ss: 1.414479, loss_d: 0.501054
0.7371 --- loss: 1.899465, loss_ss: 1.391676, loss_d: 0.507789
0.9828 --- loss: 1.802658, loss_ss: 1.288896, loss_d: 0.513762
Epoch finished! Loss: 1.8747077584266663
Starting epoch 3/10.
0.0000 --- loss: 1.517559, loss_ss: 1.352964, loss_d: 0.164595
0.2457 --- loss: 1.656107, loss_ss: 1.344410, loss_d: 0.311698
0.4914 --- loss: 1.416696, loss_ss: 1.319737, loss_d: 0.096959
0.7371 --- loss: 1.470064, loss_ss: 1.308921, loss_d: 0.161143
0.9828 --- loss: 1.495480, loss_ss: 1.238795, loss_d: 0.256685
Epoch finished! Loss: 1.4967741906642913
Starting epoch 4/10.
0.0000 --- loss: 1.448374, loss_ss: 1.248304, loss_d: 0.200069
0.2457 --- loss: 1.359668, loss_ss: 1.301057, loss_d: 0.058611
0.4914 --- loss: 1.267075, loss_ss: 1.232126, loss_d: 0.034950
0.7371 --- loss: 1.292723, loss_ss: 1.138912, loss_d: 0.153811
0.9828 --- loss: 1.167927, loss_ss: 1.161769, loss_d: 0.006158
Epoch finished! Loss: 1.3452018737792968
Starting epoch 5/10.
0.0000 --- loss: 1.190770, loss_ss: 1.183781, loss_d: 0.006989
0.2457 --- loss: 1.145241, loss_ss: 1.139584, loss_d: 0.005656
0.4914 --- loss: 1.086688, loss_ss: 1.083895, loss_d: 0.002793
0.7371 --- loss: 1.122614, loss_ss: 1.101458, loss_d: 0.021156
0.9828 --- loss: 1.259710, loss_ss: 1.252551, loss_d: 0.007159
Epoch finished! Loss: 1.1991355389356613
Starting epoch 6/10.
0.0000 --- loss: 1.226095, loss_ss: 1.195291, loss_d: 0.030804
0.2457 --- loss: 1.015242, loss_ss: 1.012288, loss_d: 0.002953
0.4914 --- loss: 1.000086, loss_ss: 0.998108, loss_d: 0.001978
0.7371 --- loss: 1.405904, loss_ss: 0.944969, loss_d: 0.460935
0.9828 --- loss: 1.022078, loss_ss: 1.021837, loss_d: 0.000241
Epoch finished! Loss: 1.1181142777204514
Starting epoch 7/10.
0.0000 --- loss: 1.116961, loss_ss: 1.115834, loss_d: 0.001127
0.2457 --- loss: 1.011724, loss_ss: 1.010516, loss_d: 0.001207
0.4914 --- loss: 0.975440, loss_ss: 0.974683, loss_d: 0.000757
0.7371 --- loss: 0.981490, loss_ss: 0.979060, loss_d: 0.002430
0.9828 --- loss: 1.006954, loss_ss: 1.006590, loss_d: 0.000364
Epoch finished! Loss: 1.0398671478033066
Starting epoch 8/10.
0.0000 --- loss: 1.111450, loss_ss: 1.107597, loss_d: 0.003854
0.2457 --- loss: 0.868168, loss_ss: 0.866196, loss_d: 0.001972
0.4914 --- loss: 1.010570, loss_ss: 1.009731, loss_d: 0.000839
0.7371 --- loss: 0.930473, loss_ss: 0.919641, loss_d: 0.010832
0.9828 --- loss: 0.808390, loss_ss: 0.807981, loss_d: 0.000409
Epoch finished! Loss: 0.9580934941768646
Starting epoch 9/10.
0.0000 --- loss: 0.833406, loss_ss: 0.828157, loss_d: 0.005249
0.2457 --- loss: 0.907739, loss_ss: 0.905813, loss_d: 0.001926
0.4914 --- loss: 0.781380, loss_ss: 0.780669, loss_d: 0.000711
0.7371 --- loss: 0.838979, loss_ss: 0.838679, loss_d: 0.000300
0.9828 --- loss: 0.979316, loss_ss: 0.976570, loss_d: 0.002745
Epoch finished! Loss: 0.9052855610847473
Starting epoch 10/10.
0.0000 --- loss: 0.898568, loss_ss: 0.898492, loss_d: 0.000077
0.2457 --- loss: 0.892908, loss_ss: 0.892856, loss_d: 0.000052
0.4914 --- loss: 0.831518, loss_ss: 0.831493, loss_d: 0.000025
0.7371 --- loss: 0.725580, loss_ss: 0.723164, loss_d: 0.002416
0.9828 --- loss: 0.839186, loss_ss: 0.838942, loss_d: 0.000245
Epoch finished! Loss: 0.8658303558826447
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5988888888888889
             precision    recall  f1-score   support

        0.0       0.70      0.78      0.74       157
        1.0       0.00      0.00      0.00       124
        2.0       0.50      0.97      0.66       264
        3.0       0.98      0.25      0.40       192
        4.0       0.67      0.68      0.68       163

avg / total       0.60      0.60      0.53       900
 


====== chp040-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  90.44  78.34   93.00  70.29     74.10
1  86.22   0.00  100.00   0.00      0.00
2  71.00  97.35   60.06  50.29     66.32
3  83.89  25.00   99.86  97.96     39.83
4  88.22  68.10   92.67  67.27     67.68
Total accuracy: 59.89%
Average sen: 53.76%
Average spec: 89.12%
Macro f1-score: 49.59%
Diagnosis acc on 90mins: 1.0
[0.988765   0.98005325 0.99996245 0.98607963 0.96772981]
pred: 0.984518027305603, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp040-nsrr

=== Test on chp041-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.465080, loss_ss: 1.674999, loss_d: 0.790080
0.2463 --- loss: 2.065512, loss_ss: 1.517603, loss_d: 0.547910
0.4926 --- loss: 1.879823, loss_ss: 1.440405, loss_d: 0.439418
0.7389 --- loss: 2.163725, loss_ss: 1.496229, loss_d: 0.667496
0.9852 --- loss: 2.191594, loss_ss: 1.422152, loss_d: 0.769442
Epoch finished! Loss: 2.1636573523283005
Starting epoch 2/10.
0.0000 --- loss: 1.642703, loss_ss: 1.307794, loss_d: 0.334909
0.2463 --- loss: 1.752521, loss_ss: 1.314281, loss_d: 0.438240
0.4926 --- loss: 1.457673, loss_ss: 1.252482, loss_d: 0.205191
0.7389 --- loss: 1.724492, loss_ss: 1.257172, loss_d: 0.467320
0.9852 --- loss: 1.566853, loss_ss: 1.153723, loss_d: 0.413130
Epoch finished! Loss: 1.8273768931627274
Starting epoch 3/10.
0.0000 --- loss: 1.518363, loss_ss: 1.232852, loss_d: 0.285511
0.2463 --- loss: 1.335261, loss_ss: 1.234998, loss_d: 0.100263
0.4926 --- loss: 1.296530, loss_ss: 1.232704, loss_d: 0.063826
0.7389 --- loss: 1.707018, loss_ss: 1.190767, loss_d: 0.516250
0.9852 --- loss: 1.335692, loss_ss: 1.207907, loss_d: 0.127785
Epoch finished! Loss: 1.4722212821245193
Starting epoch 4/10.
0.0000 --- loss: 1.284856, loss_ss: 1.185763, loss_d: 0.099093
0.2463 --- loss: 1.156080, loss_ss: 1.115471, loss_d: 0.040609
0.4926 --- loss: 2.078116, loss_ss: 1.133066, loss_d: 0.945050
0.7389 --- loss: 1.113421, loss_ss: 1.014583, loss_d: 0.098838
0.9852 --- loss: 1.114387, loss_ss: 1.100378, loss_d: 0.014009
Epoch finished! Loss: 1.2943259239196778
Starting epoch 5/10.
0.0000 --- loss: 1.295430, loss_ss: 1.230653, loss_d: 0.064777
0.2463 --- loss: 1.286717, loss_ss: 1.170017, loss_d: 0.116700
0.4926 --- loss: 1.349852, loss_ss: 1.341565, loss_d: 0.008286
0.7389 --- loss: 1.198398, loss_ss: 1.105760, loss_d: 0.092639
0.9852 --- loss: 1.413391, loss_ss: 0.922561, loss_d: 0.490829
Epoch finished! Loss: 1.2194245517253877
Starting epoch 6/10.
0.0000 --- loss: 1.001032, loss_ss: 0.990408, loss_d: 0.010625
0.2463 --- loss: 1.122276, loss_ss: 1.055884, loss_d: 0.066392
0.4926 --- loss: 1.032712, loss_ss: 1.028272, loss_d: 0.004439
0.7389 --- loss: 1.025472, loss_ss: 1.020582, loss_d: 0.004890
0.9852 --- loss: 1.006958, loss_ss: 1.002974, loss_d: 0.003984
Epoch finished! Loss: 1.0786583334207536
Starting epoch 7/10.
0.0000 --- loss: 1.047861, loss_ss: 1.035409, loss_d: 0.012452
0.2463 --- loss: 0.992098, loss_ss: 0.983682, loss_d: 0.008416
0.4926 --- loss: 1.200685, loss_ss: 1.018909, loss_d: 0.181775
0.7389 --- loss: 1.002249, loss_ss: 0.967942, loss_d: 0.034307
0.9852 --- loss: 1.042734, loss_ss: 1.035497, loss_d: 0.007237
Epoch finished! Loss: 1.0419891074299812
Starting epoch 8/10.
0.0000 --- loss: 0.928198, loss_ss: 0.919948, loss_d: 0.008251
0.2463 --- loss: 0.882981, loss_ss: 0.868808, loss_d: 0.014173
0.4926 --- loss: 0.983992, loss_ss: 0.931330, loss_d: 0.052662
0.7389 --- loss: 0.937023, loss_ss: 0.934991, loss_d: 0.002032
0.9852 --- loss: 0.792762, loss_ss: 0.788798, loss_d: 0.003964
Epoch finished! Loss: 0.9760474249720573
Starting epoch 9/10.
0.0000 --- loss: 0.852010, loss_ss: 0.850048, loss_d: 0.001961
0.2463 --- loss: 1.081811, loss_ss: 1.080919, loss_d: 0.000892
0.4926 --- loss: 0.916313, loss_ss: 0.915424, loss_d: 0.000889
0.7389 --- loss: 0.913245, loss_ss: 0.912357, loss_d: 0.000887
0.9852 --- loss: 1.049832, loss_ss: 1.049277, loss_d: 0.000555
Epoch finished! Loss: 0.9143761843442917
Starting epoch 10/10.
0.0000 --- loss: 0.795495, loss_ss: 0.790586, loss_d: 0.004908
0.2463 --- loss: 0.855936, loss_ss: 0.854987, loss_d: 0.000949
0.4926 --- loss: 1.004136, loss_ss: 1.003856, loss_d: 0.000280
0.7389 --- loss: 0.891992, loss_ss: 0.891629, loss_d: 0.000363
0.9852 --- loss: 0.877800, loss_ss: 0.877067, loss_d: 0.000732
Epoch finished! Loss: 0.8848096266388893
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7111111111111111
             precision    recall  f1-score   support

        0.0       0.60      0.81      0.69       196
        1.0       0.00      0.00      0.00        58
        2.0       0.88      0.77      0.82       527
        3.0       0.88      0.21      0.34        33
        4.0       0.56      0.73      0.64       266

avg / total       0.70      0.71      0.69      1080
 


====== chp041-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  86.76  80.61   88.12  60.08     68.85
1  94.63   0.00  100.00   0.00      0.00
2  83.89  77.42   90.05  88.12     82.42
3  97.50  21.21   99.90  87.50     34.15
4  79.44  73.31   81.45  56.36     63.73
Total accuracy: 71.11%
Average sen: 50.51%
Average spec: 91.91%
Macro f1-score: 49.83%
Diagnosis acc on 90mins: 1.0
[0.51057601 0.99999499 0.99909878 0.77130336 0.99997318 0.97042346]
pred: 0.8752282957235972, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp041-nsrr

=== Test on chp042-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.317090, loss_ss: 1.641329, loss_d: 0.675761
0.2463 --- loss: 2.030711, loss_ss: 1.437914, loss_d: 0.592797
0.4926 --- loss: 2.001836, loss_ss: 1.434388, loss_d: 0.567447
0.7389 --- loss: 1.846938, loss_ss: 1.275418, loss_d: 0.571520
0.9852 --- loss: 1.709787, loss_ss: 1.259547, loss_d: 0.450241
Epoch finished! Loss: 2.0412459284067155
Starting epoch 2/10.
0.0000 --- loss: 1.778573, loss_ss: 1.214676, loss_d: 0.563897
0.2463 --- loss: 1.505140, loss_ss: 1.272707, loss_d: 0.232433
0.4926 --- loss: 1.597123, loss_ss: 1.201826, loss_d: 0.395297
0.7389 --- loss: 1.798609, loss_ss: 1.132647, loss_d: 0.665962
0.9852 --- loss: 1.560231, loss_ss: 1.305730, loss_d: 0.254501
Epoch finished! Loss: 1.6761085897684098
Starting epoch 3/10.
0.0000 --- loss: 1.246332, loss_ss: 1.122305, loss_d: 0.124026
0.2463 --- loss: 1.521982, loss_ss: 1.201006, loss_d: 0.320976
0.4926 --- loss: 1.484638, loss_ss: 1.118406, loss_d: 0.366232
0.7389 --- loss: 1.183205, loss_ss: 1.095803, loss_d: 0.087401
0.9852 --- loss: 1.771840, loss_ss: 1.037330, loss_d: 0.734509
Epoch finished! Loss: 1.357186210155487
Starting epoch 4/10.
0.0000 --- loss: 1.158085, loss_ss: 1.122512, loss_d: 0.035574
0.2463 --- loss: 1.144382, loss_ss: 1.110963, loss_d: 0.033419
0.4926 --- loss: 1.030969, loss_ss: 1.025078, loss_d: 0.005892
0.7389 --- loss: 1.135606, loss_ss: 1.098633, loss_d: 0.036973
0.9852 --- loss: 1.190940, loss_ss: 1.139451, loss_d: 0.051489
Epoch finished! Loss: 1.1376373797655106
Starting epoch 5/10.
0.0000 --- loss: 1.098466, loss_ss: 1.035285, loss_d: 0.063181
0.2463 --- loss: 1.034767, loss_ss: 1.030006, loss_d: 0.004761
0.4926 --- loss: 0.876332, loss_ss: 0.874649, loss_d: 0.001683
0.7389 --- loss: 0.919768, loss_ss: 0.913132, loss_d: 0.006636
0.9852 --- loss: 1.024592, loss_ss: 1.022514, loss_d: 0.002078
Epoch finished! Loss: 1.066043621301651
Starting epoch 6/10.
0.0000 --- loss: 1.025507, loss_ss: 1.025389, loss_d: 0.000118
0.2463 --- loss: 0.949229, loss_ss: 0.947036, loss_d: 0.002193
0.4926 --- loss: 1.227314, loss_ss: 1.025326, loss_d: 0.201988
0.7389 --- loss: 0.961329, loss_ss: 0.941565, loss_d: 0.019764
0.9852 --- loss: 0.923617, loss_ss: 0.883878, loss_d: 0.039739
Epoch finished! Loss: 1.1084742188453673
Starting epoch 7/10.
0.0000 --- loss: 1.042696, loss_ss: 1.031758, loss_d: 0.010938
0.2463 --- loss: 0.912463, loss_ss: 0.879520, loss_d: 0.032943
0.4926 --- loss: 1.076166, loss_ss: 0.899919, loss_d: 0.176247
0.7389 --- loss: 1.113669, loss_ss: 0.895805, loss_d: 0.217864
0.9852 --- loss: 1.167346, loss_ss: 1.070373, loss_d: 0.096973
Epoch finished! Loss: 1.07652178555727
Starting epoch 8/10.
0.0000 --- loss: 0.852382, loss_ss: 0.847206, loss_d: 0.005176
0.2463 --- loss: 0.896195, loss_ss: 0.889389, loss_d: 0.006806
0.4926 --- loss: 0.932708, loss_ss: 0.927748, loss_d: 0.004960
0.7389 --- loss: 0.889938, loss_ss: 0.885454, loss_d: 0.004484
0.9852 --- loss: 1.179410, loss_ss: 1.170679, loss_d: 0.008731
Epoch finished! Loss: 0.9605883806943893
Starting epoch 9/10.
0.0000 --- loss: 0.947474, loss_ss: 0.945072, loss_d: 0.002402
0.2463 --- loss: 0.840671, loss_ss: 0.839767, loss_d: 0.000904
0.4926 --- loss: 0.861591, loss_ss: 0.859327, loss_d: 0.002264
0.7389 --- loss: 0.774068, loss_ss: 0.772320, loss_d: 0.001749
0.9852 --- loss: 0.963106, loss_ss: 0.962303, loss_d: 0.000803
Epoch finished! Loss: 0.9049390003085136
Starting epoch 10/10.
0.0000 --- loss: 0.801533, loss_ss: 0.799337, loss_d: 0.002196
0.2463 --- loss: 0.960194, loss_ss: 0.928178, loss_d: 0.032016
0.4926 --- loss: 0.831081, loss_ss: 0.828398, loss_d: 0.002683
0.7389 --- loss: 0.863250, loss_ss: 0.861948, loss_d: 0.001302
0.9852 --- loss: 0.785351, loss_ss: 0.785317, loss_d: 0.000034
Epoch finished! Loss: 0.8628886491060257
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.37962962962962965
             precision    recall  f1-score   support

        0.0       1.00      0.41      0.58       152
        1.0       0.14      0.22      0.17       230
        2.0       0.52      0.17      0.26       414
        3.0       1.00      0.47      0.64        93
        4.0       0.39      0.96      0.55       191

avg / total       0.53      0.38      0.37      1080
 


====== chp042-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  91.67  40.79  100.00  100.00     57.94
1  53.89  22.17   62.47   13.78     17.00
2  62.22  16.91   90.39   52.24     25.55
3  95.46  47.31  100.00  100.00     64.23
4  72.69  95.81   67.72   38.94     55.37
Total accuracy: 37.96%
Average sen: 44.60%
Average spec: 84.12%
Macro f1-score: 44.02%
Diagnosis acc on 90mins: 1.0
[0.92964369 0.99998009 0.99976212 0.99992871 0.99998546 0.99998903]
pred: 0.9882148504257202, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp042-nsrr

=== Test on chp043-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.287924, loss_ss: 1.566235, loss_d: 0.721689
0.2463 --- loss: 2.089751, loss_ss: 1.449568, loss_d: 0.640183
0.4926 --- loss: 2.110699, loss_ss: 1.333623, loss_d: 0.777076
0.7389 --- loss: 1.845675, loss_ss: 1.291766, loss_d: 0.553909
0.9852 --- loss: 1.806063, loss_ss: 1.300335, loss_d: 0.505728
Epoch finished! Loss: 2.0576944619417192
Starting epoch 2/10.
0.0000 --- loss: 2.012123, loss_ss: 1.329138, loss_d: 0.682985
0.2463 --- loss: 1.671740, loss_ss: 1.270559, loss_d: 0.401181
0.4926 --- loss: 1.609394, loss_ss: 1.187743, loss_d: 0.421650
0.7389 --- loss: 1.695137, loss_ss: 1.161645, loss_d: 0.533491
0.9852 --- loss: 1.414930, loss_ss: 1.219691, loss_d: 0.195239
Epoch finished! Loss: 1.6764114797115326
Starting epoch 3/10.
0.0000 --- loss: 1.838844, loss_ss: 1.131834, loss_d: 0.707010
0.2463 --- loss: 1.322762, loss_ss: 1.150996, loss_d: 0.171766
0.4926 --- loss: 1.314153, loss_ss: 1.180866, loss_d: 0.133287
0.7389 --- loss: 1.155639, loss_ss: 1.122318, loss_d: 0.033321
0.9852 --- loss: 1.426560, loss_ss: 1.208458, loss_d: 0.218102
Epoch finished! Loss: 1.3744682222604752
Starting epoch 4/10.
0.0000 --- loss: 1.136934, loss_ss: 1.123899, loss_d: 0.013035
0.2463 --- loss: 1.163169, loss_ss: 1.154231, loss_d: 0.008939
0.4926 --- loss: 1.246036, loss_ss: 1.117968, loss_d: 0.128067
0.7389 --- loss: 1.211808, loss_ss: 1.200815, loss_d: 0.010993
0.9852 --- loss: 1.172148, loss_ss: 1.115082, loss_d: 0.057066
Epoch finished! Loss: 1.2107406854629517
Starting epoch 5/10.
0.0000 --- loss: 1.027446, loss_ss: 1.023965, loss_d: 0.003482
0.2463 --- loss: 1.183925, loss_ss: 1.175582, loss_d: 0.008343
0.4926 --- loss: 1.215147, loss_ss: 1.142636, loss_d: 0.072511
0.7389 --- loss: 1.027512, loss_ss: 1.018641, loss_d: 0.008871
0.9852 --- loss: 1.246433, loss_ss: 1.110660, loss_d: 0.135773
Epoch finished! Loss: 1.1562224552035332
Starting epoch 6/10.
0.0000 --- loss: 1.051699, loss_ss: 1.013386, loss_d: 0.038313
0.2463 --- loss: 1.018687, loss_ss: 1.016804, loss_d: 0.001882
0.4926 --- loss: 0.997964, loss_ss: 0.982135, loss_d: 0.015829
0.7389 --- loss: 0.867958, loss_ss: 0.861955, loss_d: 0.006002
0.9852 --- loss: 1.054943, loss_ss: 1.029420, loss_d: 0.025523
Epoch finished! Loss: 1.0819177523255348
Starting epoch 7/10.
0.0000 --- loss: 1.166521, loss_ss: 0.971327, loss_d: 0.195194
0.2463 --- loss: 1.049346, loss_ss: 1.037931, loss_d: 0.011415
0.4926 --- loss: 0.978837, loss_ss: 0.976919, loss_d: 0.001918
0.7389 --- loss: 0.968801, loss_ss: 0.966491, loss_d: 0.002310
0.9852 --- loss: 1.010245, loss_ss: 1.009049, loss_d: 0.001196
Epoch finished! Loss: 1.0353400573134421
Starting epoch 8/10.
0.0000 --- loss: 0.989647, loss_ss: 0.988575, loss_d: 0.001073
0.2463 --- loss: 1.116209, loss_ss: 0.968144, loss_d: 0.148065
0.4926 --- loss: 0.919282, loss_ss: 0.918223, loss_d: 0.001060
0.7389 --- loss: 0.966280, loss_ss: 0.962768, loss_d: 0.003512
0.9852 --- loss: 1.108474, loss_ss: 1.106602, loss_d: 0.001872
Epoch finished! Loss: 1.036791369318962
Starting epoch 9/10.
0.0000 --- loss: 0.916010, loss_ss: 0.912705, loss_d: 0.003305
0.2463 --- loss: 0.913919, loss_ss: 0.904946, loss_d: 0.008973
0.4926 --- loss: 1.060412, loss_ss: 1.057945, loss_d: 0.002466
0.7389 --- loss: 0.869906, loss_ss: 0.852133, loss_d: 0.017772
0.9852 --- loss: 0.864950, loss_ss: 0.860870, loss_d: 0.004080
Epoch finished! Loss: 0.9775839403271676
Starting epoch 10/10.
0.0000 --- loss: 0.985727, loss_ss: 0.984965, loss_d: 0.000762
0.2463 --- loss: 0.893373, loss_ss: 0.893242, loss_d: 0.000131
0.4926 --- loss: 0.916373, loss_ss: 0.912468, loss_d: 0.003905
0.7389 --- loss: 1.162168, loss_ss: 1.161890, loss_d: 0.000278
0.9852 --- loss: 0.929191, loss_ss: 0.928144, loss_d: 0.001047
Epoch finished! Loss: 0.9193922638893127
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5675925925925925
             precision    recall  f1-score   support

        0.0       0.78      0.56      0.65       136
        1.0       0.00      0.00      0.00       184
        2.0       0.56      1.00      0.72       489
        3.0       1.00      0.08      0.14        39
        4.0       0.40      0.19      0.26       232

avg / total       0.48      0.57      0.47      1080
 


====== chp043-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %   ppr %  f1-score
0  92.41   55.88   97.67   77.55     64.96
1  82.96    0.00  100.00    0.00      0.00
2  65.00  100.00   36.04   56.40     72.12
3  96.67    7.69  100.00  100.00     14.29
4  76.48   19.40   92.10   40.18     26.16
Total accuracy: 56.76%
Average sen: 36.59%
Average spec: 85.16%
Macro f1-score: 35.51%
Diagnosis acc on 90mins: 1.0
[0.99983108 0.83780009 0.98205274 0.99902654 0.99928027 0.98929477]
pred: 0.9678809146086375, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp043-nsrr

=== Test on chp044-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.339412, loss_ss: 1.656482, loss_d: 0.682930
0.2457 --- loss: 2.100158, loss_ss: 1.510941, loss_d: 0.589216
0.4914 --- loss: 1.680124, loss_ss: 1.437209, loss_d: 0.242915
0.7371 --- loss: 2.063345, loss_ss: 1.290339, loss_d: 0.773006
0.9828 --- loss: 2.566457, loss_ss: 1.286009, loss_d: 1.280448
Epoch finished! Loss: 2.109079873561859
Starting epoch 2/10.
0.0000 --- loss: 1.560065, loss_ss: 1.326742, loss_d: 0.233324
0.2457 --- loss: 1.927295, loss_ss: 1.256005, loss_d: 0.671290
0.4914 --- loss: 1.653969, loss_ss: 1.361111, loss_d: 0.292858
0.7371 --- loss: 1.648257, loss_ss: 1.220816, loss_d: 0.427442
0.9828 --- loss: 1.709673, loss_ss: 1.395781, loss_d: 0.313892
Epoch finished! Loss: 1.7470945686101913
Starting epoch 3/10.
0.0000 --- loss: 1.481114, loss_ss: 1.169983, loss_d: 0.311131
0.2457 --- loss: 1.451238, loss_ss: 1.183368, loss_d: 0.267870
0.4914 --- loss: 1.271898, loss_ss: 1.203149, loss_d: 0.068749
0.7371 --- loss: 1.318491, loss_ss: 1.177449, loss_d: 0.141042
0.9828 --- loss: 1.262067, loss_ss: 1.250236, loss_d: 0.011832
Epoch finished! Loss: 1.4488616406917572
Starting epoch 4/10.
0.0000 --- loss: 1.216542, loss_ss: 1.090351, loss_d: 0.126191
0.2457 --- loss: 1.243451, loss_ss: 1.113004, loss_d: 0.130446
0.4914 --- loss: 1.173649, loss_ss: 1.159508, loss_d: 0.014141
0.7371 --- loss: 1.337794, loss_ss: 1.087589, loss_d: 0.250205
0.9828 --- loss: 1.098168, loss_ss: 1.071879, loss_d: 0.026290
Epoch finished! Loss: 1.2468436449766158
Starting epoch 5/10.
0.0000 --- loss: 1.224030, loss_ss: 1.216236, loss_d: 0.007793
0.2457 --- loss: 1.088063, loss_ss: 1.077224, loss_d: 0.010839
0.4914 --- loss: 1.134630, loss_ss: 1.118626, loss_d: 0.016004
0.7371 --- loss: 1.022828, loss_ss: 0.976387, loss_d: 0.046441
0.9828 --- loss: 1.019952, loss_ss: 1.004255, loss_d: 0.015697
Epoch finished! Loss: 1.1689947128295899
Starting epoch 6/10.
0.0000 --- loss: 1.046849, loss_ss: 1.034847, loss_d: 0.012002
0.2457 --- loss: 1.035811, loss_ss: 0.984527, loss_d: 0.051283
0.4914 --- loss: 1.196285, loss_ss: 1.106892, loss_d: 0.089393
0.7371 --- loss: 1.060339, loss_ss: 1.059092, loss_d: 0.001247
0.9828 --- loss: 1.221019, loss_ss: 0.932477, loss_d: 0.288542
Epoch finished! Loss: 1.0714619278907775
Starting epoch 7/10.
0.0000 --- loss: 0.957477, loss_ss: 0.956716, loss_d: 0.000761
0.2457 --- loss: 0.924316, loss_ss: 0.923990, loss_d: 0.000326
0.4914 --- loss: 1.037150, loss_ss: 1.027103, loss_d: 0.010047
0.7371 --- loss: 1.071548, loss_ss: 1.070910, loss_d: 0.000638
0.9828 --- loss: 1.036121, loss_ss: 1.024817, loss_d: 0.011304
Epoch finished! Loss: 1.0097545504570007
Starting epoch 8/10.
0.0000 --- loss: 0.965630, loss_ss: 0.964258, loss_d: 0.001372
0.2457 --- loss: 0.902083, loss_ss: 0.892641, loss_d: 0.009443
0.4914 --- loss: 1.058962, loss_ss: 1.058676, loss_d: 0.000286
0.7371 --- loss: 0.890856, loss_ss: 0.890279, loss_d: 0.000577
0.9828 --- loss: 0.881114, loss_ss: 0.880808, loss_d: 0.000306
Epoch finished! Loss: 0.9328951343894005
Starting epoch 9/10.
0.0000 --- loss: 0.802719, loss_ss: 0.802340, loss_d: 0.000379
0.2457 --- loss: 0.888104, loss_ss: 0.888043, loss_d: 0.000060
0.4914 --- loss: 0.855745, loss_ss: 0.854705, loss_d: 0.001040
0.7371 --- loss: 0.886407, loss_ss: 0.885194, loss_d: 0.001213
0.9828 --- loss: 0.726234, loss_ss: 0.722183, loss_d: 0.004051
Epoch finished! Loss: 0.8953611999750137
Starting epoch 10/10.
0.0000 --- loss: 0.823941, loss_ss: 0.823818, loss_d: 0.000124
0.2457 --- loss: 0.825489, loss_ss: 0.825175, loss_d: 0.000315
0.4914 --- loss: 0.773375, loss_ss: 0.772699, loss_d: 0.000676
0.7371 --- loss: 0.668511, loss_ss: 0.668388, loss_d: 0.000122
0.9828 --- loss: 0.756907, loss_ss: 0.756693, loss_d: 0.000213
Epoch finished! Loss: 0.8479591235518456
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5188888888888888
             precision    recall  f1-score   support

        0.0       0.16      0.93      0.27        15
        1.0       0.00      0.00      0.00        80
        2.0       0.43      0.62      0.51       286
        3.0       1.00      0.46      0.63       417
        4.0       0.40      0.81      0.54       102

avg / total       0.65      0.52      0.52       900
 


====== chp044-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  91.78  93.33   91.75   16.09     27.45
1  91.11   0.00  100.00    0.00      0.00
2  61.78  61.89   61.73   42.96     50.72
3  75.11  46.28  100.00  100.00     63.28
4  84.00  81.37   84.34   39.90     53.55
Total accuracy: 51.89%
Average sen: 56.58%
Average spec: 87.56%
Macro f1-score: 39.00%
Diagnosis acc on 90mins: 1.0
[0.99759007 0.99999821 0.99457139 0.99985051 0.99969888]
pred: 0.9983418107032775, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp044-nsrr

=== Test on chp045-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.334572, loss_ss: 1.630101, loss_d: 0.704470
0.2463 --- loss: 2.441413, loss_ss: 1.551153, loss_d: 0.890260
0.4926 --- loss: 2.052489, loss_ss: 1.507291, loss_d: 0.545198
0.7389 --- loss: 1.989082, loss_ss: 1.419011, loss_d: 0.570071
0.9852 --- loss: 2.099769, loss_ss: 1.376152, loss_d: 0.723617
Epoch finished! Loss: 2.1954958736896515
Starting epoch 2/10.
0.0000 --- loss: 1.862287, loss_ss: 1.365631, loss_d: 0.496657
0.2463 --- loss: 1.982558, loss_ss: 1.484100, loss_d: 0.498458
0.4926 --- loss: 1.707287, loss_ss: 1.391453, loss_d: 0.315833
0.7389 --- loss: 2.208527, loss_ss: 1.393733, loss_d: 0.814794
0.9852 --- loss: 1.609307, loss_ss: 1.381417, loss_d: 0.227890
Epoch finished! Loss: 1.9029769808053971
Starting epoch 3/10.
0.0000 --- loss: 1.654644, loss_ss: 1.389844, loss_d: 0.264800
0.2463 --- loss: 1.378630, loss_ss: 1.305106, loss_d: 0.073523
0.4926 --- loss: 1.497464, loss_ss: 1.403381, loss_d: 0.094083
0.7389 --- loss: 1.972648, loss_ss: 1.286150, loss_d: 0.686498
0.9852 --- loss: 1.620312, loss_ss: 1.248693, loss_d: 0.371620
Epoch finished! Loss: 1.6640781581401825
Starting epoch 4/10.
0.0000 --- loss: 1.432587, loss_ss: 1.280426, loss_d: 0.152161
0.2463 --- loss: 1.388100, loss_ss: 1.304117, loss_d: 0.083983
0.4926 --- loss: 1.439646, loss_ss: 1.324479, loss_d: 0.115167
0.7389 --- loss: 1.314557, loss_ss: 1.278185, loss_d: 0.036372
0.9852 --- loss: 1.356308, loss_ss: 1.310000, loss_d: 0.046308
Epoch finished! Loss: 1.4489335626363755
Starting epoch 5/10.
0.0000 --- loss: 1.494437, loss_ss: 1.245097, loss_d: 0.249341
0.2463 --- loss: 1.280527, loss_ss: 1.253297, loss_d: 0.027229
0.4926 --- loss: 1.447762, loss_ss: 1.341340, loss_d: 0.106422
0.7389 --- loss: 1.393673, loss_ss: 1.316006, loss_d: 0.077666
0.9852 --- loss: 1.285100, loss_ss: 1.191496, loss_d: 0.093604
Epoch finished! Loss: 1.4146681308746338
Starting epoch 6/10.
0.0000 --- loss: 1.251946, loss_ss: 1.218498, loss_d: 0.033448
0.2463 --- loss: 1.309023, loss_ss: 1.231364, loss_d: 0.077658
0.4926 --- loss: 1.178311, loss_ss: 1.169915, loss_d: 0.008396
0.7389 --- loss: 1.196485, loss_ss: 1.187258, loss_d: 0.009226
0.9852 --- loss: 2.245783, loss_ss: 1.055713, loss_d: 1.190071
Epoch finished! Loss: 1.2843609988689422
Starting epoch 7/10.
0.0000 --- loss: 1.177170, loss_ss: 1.175598, loss_d: 0.001572
0.2463 --- loss: 1.135361, loss_ss: 1.108230, loss_d: 0.027130
0.4926 --- loss: 1.070955, loss_ss: 1.063019, loss_d: 0.007936
0.7389 --- loss: 1.252368, loss_ss: 1.130988, loss_d: 0.121379
0.9852 --- loss: 1.241627, loss_ss: 1.240324, loss_d: 0.001303
Epoch finished! Loss: 1.205022966861725
Starting epoch 8/10.
0.0000 --- loss: 1.114629, loss_ss: 1.107043, loss_d: 0.007586
0.2463 --- loss: 1.132735, loss_ss: 1.131189, loss_d: 0.001546
0.4926 --- loss: 1.101153, loss_ss: 1.100494, loss_d: 0.000658
0.7389 --- loss: 1.108261, loss_ss: 1.105872, loss_d: 0.002389
0.9852 --- loss: 1.213138, loss_ss: 1.210738, loss_d: 0.002401
Epoch finished! Loss: 1.1405664786696434
Starting epoch 9/10.
0.0000 --- loss: 1.062851, loss_ss: 1.062778, loss_d: 0.000073
0.2463 --- loss: 1.275462, loss_ss: 1.273531, loss_d: 0.001930
0.4926 --- loss: 1.168366, loss_ss: 1.163847, loss_d: 0.004519
0.7389 --- loss: 1.128573, loss_ss: 1.124036, loss_d: 0.004537
0.9852 --- loss: 1.198975, loss_ss: 1.198811, loss_d: 0.000164
Epoch finished! Loss: 1.138621097803116
Starting epoch 10/10.
0.0000 --- loss: 1.063436, loss_ss: 1.062839, loss_d: 0.000598
0.2463 --- loss: 0.975433, loss_ss: 0.974611, loss_d: 0.000823
0.4926 --- loss: 1.056301, loss_ss: 1.023194, loss_d: 0.033107
0.7389 --- loss: 0.941715, loss_ss: 0.932925, loss_d: 0.008790
0.9852 --- loss: 1.005470, loss_ss: 1.004740, loss_d: 0.000730
Epoch finished! Loss: 1.0370159551501275
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.3697868396663577
             precision    recall  f1-score   support

        0.0       0.92      0.26      0.41       138
        1.0       0.40      0.03      0.06       120
        2.0       0.44      0.39      0.41       410
        3.0       0.33      0.00      0.01       212
        4.0       0.30      0.99      0.46       199

avg / total       0.45      0.37      0.30      1079
 


====== chp045-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  90.27  26.09   99.68  92.31     40.68
1  88.69   3.33   99.37  40.00      6.15
2  57.83  39.27   69.21  43.87     41.44
3  80.26   0.47   99.77  33.33      0.93
4  56.90  98.99   47.39  29.85     45.87
Total accuracy: 36.98%
Average sen: 33.63%
Average spec: 83.08%
Macro f1-score: 27.01%
Diagnosis acc on 90mins: 1.0
[0.99755067 0.99990988 0.99033195 0.99505615 0.99983501 0.99973923]
pred: 0.9970704813798269, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp045-nsrr

=== Test on chp046-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.319080, loss_ss: 1.653107, loss_d: 0.665972
0.2463 --- loss: 2.237165, loss_ss: 1.483035, loss_d: 0.754130
0.4926 --- loss: 2.073410, loss_ss: 1.477186, loss_d: 0.596224
0.7389 --- loss: 2.076340, loss_ss: 1.348057, loss_d: 0.728284
0.9852 --- loss: 1.876448, loss_ss: 1.175684, loss_d: 0.700765
Epoch finished! Loss: 2.0898347824811934
Starting epoch 2/10.
0.0000 --- loss: 1.591263, loss_ss: 1.237539, loss_d: 0.353724
0.2463 --- loss: 1.854849, loss_ss: 1.350012, loss_d: 0.504837
0.4926 --- loss: 1.554402, loss_ss: 1.256984, loss_d: 0.297418
0.7389 --- loss: 1.480816, loss_ss: 1.167873, loss_d: 0.312943
0.9852 --- loss: 1.782733, loss_ss: 1.115548, loss_d: 0.667185
Epoch finished! Loss: 1.768809050321579
Starting epoch 3/10.
0.0000 --- loss: 1.654610, loss_ss: 1.248027, loss_d: 0.406583
0.2463 --- loss: 1.495045, loss_ss: 1.332032, loss_d: 0.163013
0.4926 --- loss: 1.424296, loss_ss: 1.229190, loss_d: 0.195106
0.7389 --- loss: 1.610703, loss_ss: 1.255685, loss_d: 0.355018
0.9852 --- loss: 1.296504, loss_ss: 1.102035, loss_d: 0.194469
Epoch finished! Loss: 1.5065808326005936
Starting epoch 4/10.
0.0000 --- loss: 1.186802, loss_ss: 1.140516, loss_d: 0.046286
0.2463 --- loss: 1.185563, loss_ss: 1.142893, loss_d: 0.042670
0.4926 --- loss: 1.137543, loss_ss: 1.118639, loss_d: 0.018904
0.7389 --- loss: 1.173870, loss_ss: 1.132272, loss_d: 0.041599
0.9852 --- loss: 1.038521, loss_ss: 1.014817, loss_d: 0.023705
Epoch finished! Loss: 1.2447290033102036
Starting epoch 5/10.
0.0000 --- loss: 1.224079, loss_ss: 1.209485, loss_d: 0.014594
0.2463 --- loss: 1.112269, loss_ss: 1.045881, loss_d: 0.066388
0.4926 --- loss: 1.033578, loss_ss: 1.021394, loss_d: 0.012184
0.7389 --- loss: 1.222281, loss_ss: 1.211145, loss_d: 0.011136
0.9852 --- loss: 0.982528, loss_ss: 0.981388, loss_d: 0.001141
Epoch finished! Loss: 1.1282198697328567
Starting epoch 6/10.
0.0000 --- loss: 1.011871, loss_ss: 1.004252, loss_d: 0.007619
0.2463 --- loss: 1.365448, loss_ss: 1.068485, loss_d: 0.296963
0.4926 --- loss: 1.104030, loss_ss: 1.085793, loss_d: 0.018237
0.7389 --- loss: 1.065939, loss_ss: 1.060974, loss_d: 0.004965
0.9852 --- loss: 1.033816, loss_ss: 0.989453, loss_d: 0.044363
Epoch finished! Loss: 1.1123902216553687
Starting epoch 7/10.
0.0000 --- loss: 1.068303, loss_ss: 1.065138, loss_d: 0.003164
0.2463 --- loss: 0.971212, loss_ss: 0.966442, loss_d: 0.004770
0.4926 --- loss: 1.002431, loss_ss: 0.994108, loss_d: 0.008323
0.7389 --- loss: 0.975308, loss_ss: 0.960861, loss_d: 0.014447
0.9852 --- loss: 1.139734, loss_ss: 0.871273, loss_d: 0.268461
Epoch finished! Loss: 1.0401857629418374
Starting epoch 8/10.
0.0000 --- loss: 0.925493, loss_ss: 0.920581, loss_d: 0.004912
0.2463 --- loss: 0.949448, loss_ss: 0.940244, loss_d: 0.009204
0.4926 --- loss: 0.972447, loss_ss: 0.969901, loss_d: 0.002545
0.7389 --- loss: 1.258590, loss_ss: 1.236995, loss_d: 0.021595
0.9852 --- loss: 1.054233, loss_ss: 1.045603, loss_d: 0.008629
Epoch finished! Loss: 1.0263462632894516
Starting epoch 9/10.
0.0000 --- loss: 0.995335, loss_ss: 0.991124, loss_d: 0.004212
0.2463 --- loss: 0.961076, loss_ss: 0.946249, loss_d: 0.014827
0.4926 --- loss: 0.873366, loss_ss: 0.863074, loss_d: 0.010292
0.7389 --- loss: 0.850891, loss_ss: 0.836867, loss_d: 0.014024
0.9852 --- loss: 0.941328, loss_ss: 0.939911, loss_d: 0.001417
Epoch finished! Loss: 1.0129566192626953
Starting epoch 10/10.
0.0000 --- loss: 0.950561, loss_ss: 0.934090, loss_d: 0.016470
0.2463 --- loss: 0.773740, loss_ss: 0.765633, loss_d: 0.008106
0.4926 --- loss: 0.788657, loss_ss: 0.782434, loss_d: 0.006223
0.7389 --- loss: 0.832222, loss_ss: 0.822008, loss_d: 0.010214
0.9852 --- loss: 0.789015, loss_ss: 0.788065, loss_d: 0.000951
Epoch finished! Loss: 0.9122972741723061
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5592592592592592
             precision    recall  f1-score   support

        0.0       0.53      0.97      0.68       226
        1.0       0.00      0.00      0.00       357
        2.0       0.63      0.72      0.67       192
        3.0       0.10      1.00      0.18         2
        4.0       0.58      0.80      0.67       303

avg / total       0.38      0.56      0.45      1080
 


====== chp046-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  81.02   97.35   76.70  52.51     68.22
1  66.94    0.00  100.00   0.00      0.00
2  87.59   72.40   90.88  63.18     67.48
3  98.33  100.00   98.33  10.00     18.18
4  77.96   80.20   77.09  57.72     67.13
Total accuracy: 55.93%
Average sen: 69.99%
Average spec: 88.60%
Macro f1-score: 44.20%
Diagnosis acc on 90mins: 1.0
[0.99984813 1.         0.99999833 0.99057722 0.99999976 0.99987531]
pred: 0.9983831246693929, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp046-nsrr

=== Test on chp047-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.485502, loss_ss: 1.788344, loss_d: 0.697159
0.2451 --- loss: 2.123521, loss_ss: 1.566663, loss_d: 0.556858
0.4902 --- loss: 2.445709, loss_ss: 1.574685, loss_d: 0.871023
0.7353 --- loss: 2.084934, loss_ss: 1.449708, loss_d: 0.635226
0.9804 --- loss: 2.217231, loss_ss: 1.379861, loss_d: 0.837370
Epoch finished! Loss: 2.1630777448415754
Starting epoch 2/10.
0.0000 --- loss: 1.962467, loss_ss: 1.360567, loss_d: 0.601900
0.2451 --- loss: 1.961634, loss_ss: 1.350638, loss_d: 0.610995
0.4902 --- loss: 1.934703, loss_ss: 1.346378, loss_d: 0.588325
0.7353 --- loss: 1.708186, loss_ss: 1.325092, loss_d: 0.383094
0.9804 --- loss: 2.157849, loss_ss: 1.319263, loss_d: 0.838586
Epoch finished! Loss: 1.8643391400575637
Starting epoch 3/10.
0.0000 --- loss: 1.516807, loss_ss: 1.294448, loss_d: 0.222359
0.2451 --- loss: 1.475172, loss_ss: 1.322821, loss_d: 0.152351
0.4902 --- loss: 1.416118, loss_ss: 1.268374, loss_d: 0.147745
0.7353 --- loss: 1.246506, loss_ss: 1.207648, loss_d: 0.038858
0.9804 --- loss: 1.344360, loss_ss: 1.232843, loss_d: 0.111517
Epoch finished! Loss: 1.5269682168960572
Starting epoch 4/10.
0.0000 --- loss: 1.343403, loss_ss: 1.280338, loss_d: 0.063065
0.2451 --- loss: 1.197926, loss_ss: 1.161908, loss_d: 0.036018
0.4902 --- loss: 1.355688, loss_ss: 1.150029, loss_d: 0.205659
0.7353 --- loss: 1.355654, loss_ss: 1.146530, loss_d: 0.209124
0.9804 --- loss: 1.133633, loss_ss: 1.120156, loss_d: 0.013478
Epoch finished! Loss: 1.3260106652975083
Starting epoch 5/10.
0.0000 --- loss: 1.169636, loss_ss: 1.157109, loss_d: 0.012526
0.2451 --- loss: 1.561409, loss_ss: 1.141497, loss_d: 0.419913
0.4902 --- loss: 1.232080, loss_ss: 1.105790, loss_d: 0.126291
0.7353 --- loss: 1.177145, loss_ss: 1.118543, loss_d: 0.058602
0.9804 --- loss: 1.097650, loss_ss: 1.015920, loss_d: 0.081730
Epoch finished! Loss: 1.2142110615968704
Starting epoch 6/10.
0.0000 --- loss: 1.068715, loss_ss: 1.067318, loss_d: 0.001397
0.2451 --- loss: 1.015559, loss_ss: 0.972914, loss_d: 0.042645
0.4902 --- loss: 0.983698, loss_ss: 0.982019, loss_d: 0.001679
0.7353 --- loss: 0.973710, loss_ss: 0.973106, loss_d: 0.000605
0.9804 --- loss: 0.992400, loss_ss: 0.991823, loss_d: 0.000577
Epoch finished! Loss: 1.0897277265787124
Starting epoch 7/10.
0.0000 --- loss: 0.966210, loss_ss: 0.963930, loss_d: 0.002280
0.2451 --- loss: 0.954656, loss_ss: 0.949009, loss_d: 0.005647
0.4902 --- loss: 0.968425, loss_ss: 0.965281, loss_d: 0.003144
0.7353 --- loss: 1.111105, loss_ss: 1.104289, loss_d: 0.006816
0.9804 --- loss: 0.945486, loss_ss: 0.945218, loss_d: 0.000268
Epoch finished! Loss: 1.028199978172779
Starting epoch 8/10.
0.0000 --- loss: 1.032840, loss_ss: 1.032456, loss_d: 0.000384
0.2451 --- loss: 0.940813, loss_ss: 0.925577, loss_d: 0.015237
0.4902 --- loss: 1.011515, loss_ss: 0.977458, loss_d: 0.034058
0.7353 --- loss: 0.925042, loss_ss: 0.924619, loss_d: 0.000424
0.9804 --- loss: 0.894245, loss_ss: 0.893921, loss_d: 0.000323
Epoch finished! Loss: 0.9769790545105934
Starting epoch 9/10.
0.0000 --- loss: 0.865854, loss_ss: 0.864267, loss_d: 0.001587
0.2451 --- loss: 0.913308, loss_ss: 0.913178, loss_d: 0.000129
0.4902 --- loss: 0.965329, loss_ss: 0.965280, loss_d: 0.000048
0.7353 --- loss: 0.893105, loss_ss: 0.892109, loss_d: 0.000996
0.9804 --- loss: 0.728456, loss_ss: 0.725674, loss_d: 0.002782
Epoch finished! Loss: 0.9127364158630371
Starting epoch 10/10.
0.0000 --- loss: 0.825213, loss_ss: 0.825060, loss_d: 0.000153
0.2451 --- loss: 0.902564, loss_ss: 0.902322, loss_d: 0.000243
0.4902 --- loss: 0.728957, loss_ss: 0.728457, loss_d: 0.000499
0.7353 --- loss: 0.799230, loss_ss: 0.798948, loss_d: 0.000282
0.9804 --- loss: 0.971771, loss_ss: 0.971553, loss_d: 0.000218
Epoch finished! Loss: 0.8771789416670799
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4236111111111111
             precision    recall  f1-score   support

        0.0       0.71      0.57      0.63       224
        1.0       0.30      0.74      0.43       172
        2.0       0.59      0.18      0.28       233
        3.0       0.00      0.00      0.00        25
        4.0       0.18      0.14      0.15        66

avg / total       0.50      0.42      0.40       720
 


====== chp047-nsrr ======

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  79.44  56.70   89.72  71.35     63.18
1  53.06  73.84   46.53  30.24     42.91
2  69.44  18.03   94.05  59.15     27.63
3  96.53   0.00  100.00   0.00      0.00
4  86.25  13.64   93.58  17.65     15.38
Total accuracy: 42.36%
Average sen: 32.44%
Average spec: 84.77%
Macro f1-score: 29.82%
Diagnosis acc on 90mins: 1.0
[0.99999952 1.         1.         1.        ]
pred: 0.9999998807907104, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp047-nsrr

=== Test on chp048-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.460300, loss_ss: 1.695274, loss_d: 0.765026
0.2457 --- loss: 2.479215, loss_ss: 1.617871, loss_d: 0.861344
0.4914 --- loss: 2.228365, loss_ss: 1.546207, loss_d: 0.682158
0.7371 --- loss: 1.841488, loss_ss: 1.471513, loss_d: 0.369975
0.9828 --- loss: 2.031049, loss_ss: 1.446372, loss_d: 0.584678
Epoch finished! Loss: 2.260056641697884
Starting epoch 2/10.
0.0000 --- loss: 1.973303, loss_ss: 1.478500, loss_d: 0.494803
0.2457 --- loss: 2.031782, loss_ss: 1.589878, loss_d: 0.441904
0.4914 --- loss: 1.791286, loss_ss: 1.401393, loss_d: 0.389893
0.7371 --- loss: 1.773482, loss_ss: 1.363003, loss_d: 0.410479
0.9828 --- loss: 1.677409, loss_ss: 1.436014, loss_d: 0.241394
Epoch finished! Loss: 1.9396385699510574
Starting epoch 3/10.
0.0000 --- loss: 1.759179, loss_ss: 1.430238, loss_d: 0.328941
0.2457 --- loss: 1.438341, loss_ss: 1.331230, loss_d: 0.107111
0.4914 --- loss: 1.447097, loss_ss: 1.333835, loss_d: 0.113262
0.7371 --- loss: 1.445163, loss_ss: 1.375239, loss_d: 0.069924
0.9828 --- loss: 1.524111, loss_ss: 1.505514, loss_d: 0.018597
Epoch finished! Loss: 1.6226883709430695
Starting epoch 4/10.
0.0000 --- loss: 1.399698, loss_ss: 1.309962, loss_d: 0.089737
0.2457 --- loss: 1.342659, loss_ss: 1.322860, loss_d: 0.019799
0.4914 --- loss: 1.457810, loss_ss: 1.403832, loss_d: 0.053977
0.7371 --- loss: 1.441314, loss_ss: 1.237390, loss_d: 0.203924
0.9828 --- loss: 1.414100, loss_ss: 1.250790, loss_d: 0.163309
Epoch finished! Loss: 1.457977357506752
Starting epoch 5/10.
0.0000 --- loss: 1.369490, loss_ss: 1.358733, loss_d: 0.010757
0.2457 --- loss: 1.245726, loss_ss: 1.237429, loss_d: 0.008298
0.4914 --- loss: 1.379444, loss_ss: 1.205021, loss_d: 0.174424
0.7371 --- loss: 1.173392, loss_ss: 1.170632, loss_d: 0.002760
0.9828 --- loss: 1.192540, loss_ss: 1.175882, loss_d: 0.016657
Epoch finished! Loss: 1.3333021700382233
Starting epoch 6/10.
0.0000 --- loss: 1.172462, loss_ss: 1.167975, loss_d: 0.004486
0.2457 --- loss: 1.167156, loss_ss: 1.161306, loss_d: 0.005850
0.4914 --- loss: 1.052586, loss_ss: 1.048326, loss_d: 0.004260
0.7371 --- loss: 1.053628, loss_ss: 1.051672, loss_d: 0.001957
0.9828 --- loss: 1.211015, loss_ss: 1.210847, loss_d: 0.000169
Epoch finished! Loss: 1.1977919578552245
Starting epoch 7/10.
0.0000 --- loss: 1.082495, loss_ss: 1.081892, loss_d: 0.000603
0.2457 --- loss: 1.162081, loss_ss: 1.150980, loss_d: 0.011101
0.4914 --- loss: 1.253580, loss_ss: 1.235633, loss_d: 0.017947
0.7371 --- loss: 1.004459, loss_ss: 1.003731, loss_d: 0.000727
0.9828 --- loss: 1.160819, loss_ss: 1.159912, loss_d: 0.000907
Epoch finished! Loss: 1.1041335821151734
Starting epoch 8/10.
0.0000 --- loss: 1.092834, loss_ss: 1.090419, loss_d: 0.002414
0.2457 --- loss: 0.897616, loss_ss: 0.897081, loss_d: 0.000536
0.4914 --- loss: 0.983256, loss_ss: 0.982408, loss_d: 0.000848
0.7371 --- loss: 1.018751, loss_ss: 1.017681, loss_d: 0.001071
0.9828 --- loss: 0.908139, loss_ss: 0.907903, loss_d: 0.000236
Epoch finished! Loss: 1.0249298736453056
Starting epoch 9/10.
0.0000 --- loss: 0.860829, loss_ss: 0.858536, loss_d: 0.002292
0.2457 --- loss: 0.826778, loss_ss: 0.823419, loss_d: 0.003359
0.4914 --- loss: 0.929227, loss_ss: 0.928917, loss_d: 0.000310
0.7371 --- loss: 0.941841, loss_ss: 0.941743, loss_d: 0.000098
0.9828 --- loss: 0.914169, loss_ss: 0.913950, loss_d: 0.000219
Epoch finished! Loss: 0.9585221737623215
Starting epoch 10/10.
0.0000 --- loss: 0.922064, loss_ss: 0.921785, loss_d: 0.000279
0.2457 --- loss: 0.894902, loss_ss: 0.894427, loss_d: 0.000475
0.4914 --- loss: 0.889817, loss_ss: 0.889656, loss_d: 0.000161
0.7371 --- loss: 0.902098, loss_ss: 0.901888, loss_d: 0.000211
0.9828 --- loss: 0.949584, loss_ss: 0.949371, loss_d: 0.000213
Epoch finished! Loss: 0.9046144217252732
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.36666666666666664
             precision    recall  f1-score   support

        0.0       0.07      1.00      0.14        37
        1.0       0.12      0.01      0.01       126
        2.0       0.74      0.42      0.54       441
        3.0       0.87      0.32      0.47       107
        4.0       0.76      0.38      0.51       189

avg / total       0.65      0.37      0.43       900
 


====== chp048-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  47.78  100.00   45.54   7.30     13.60
1  85.33    0.79   99.10  12.50      1.49
2  64.44   42.18   85.84  74.10     53.76
3  91.33   31.78   99.37  87.18     46.58
4  84.44   38.10   96.77  75.79     50.70
Total accuracy: 36.67%
Average sen: 42.57%
Average spec: 85.32%
Macro f1-score: 33.23%
Diagnosis acc on 90mins: 1.0
[0.99997687 0.99982733 0.98822302 0.9479602  0.99999833]
pred: 0.9871971487998963, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp048-nsrr

=== Test on chp049-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.377918, loss_ss: 1.684756, loss_d: 0.693162
0.2463 --- loss: 1.992551, loss_ss: 1.576533, loss_d: 0.416018
0.4926 --- loss: 2.108603, loss_ss: 1.555340, loss_d: 0.553263
0.7389 --- loss: 2.025381, loss_ss: 1.502807, loss_d: 0.522574
0.9852 --- loss: 2.144891, loss_ss: 1.559063, loss_d: 0.585828
Epoch finished! Loss: 2.211301240324974
Starting epoch 2/10.
0.0000 --- loss: 1.826530, loss_ss: 1.484417, loss_d: 0.342113
0.2463 --- loss: 1.832207, loss_ss: 1.448522, loss_d: 0.383685
0.4926 --- loss: 1.778529, loss_ss: 1.397259, loss_d: 0.381269
0.7389 --- loss: 1.844881, loss_ss: 1.404787, loss_d: 0.440094
0.9852 --- loss: 2.058205, loss_ss: 1.398201, loss_d: 0.660004
Epoch finished! Loss: 1.9481392592191695
Starting epoch 3/10.
0.0000 --- loss: 1.606619, loss_ss: 1.368521, loss_d: 0.238097
0.2463 --- loss: 1.688590, loss_ss: 1.397844, loss_d: 0.290746
0.4926 --- loss: 1.411428, loss_ss: 1.296611, loss_d: 0.114817
0.7389 --- loss: 1.362271, loss_ss: 1.296822, loss_d: 0.065449
0.9852 --- loss: 1.777010, loss_ss: 1.305345, loss_d: 0.471665
Epoch finished! Loss: 1.6553463757038116
Starting epoch 4/10.
0.0000 --- loss: 1.333688, loss_ss: 1.292811, loss_d: 0.040877
0.2463 --- loss: 1.478724, loss_ss: 1.225540, loss_d: 0.253184
0.4926 --- loss: 1.372341, loss_ss: 1.299405, loss_d: 0.072936
0.7389 --- loss: 1.280141, loss_ss: 1.175275, loss_d: 0.104865
0.9852 --- loss: 2.258569, loss_ss: 1.224879, loss_d: 1.033691
Epoch finished! Loss: 1.4724929451942443
Starting epoch 5/10.
0.0000 --- loss: 1.258011, loss_ss: 1.201379, loss_d: 0.056631
0.2463 --- loss: 1.242730, loss_ss: 1.202333, loss_d: 0.040397
0.4926 --- loss: 1.278244, loss_ss: 1.223405, loss_d: 0.054839
0.7389 --- loss: 1.209339, loss_ss: 1.156878, loss_d: 0.052461
0.9852 --- loss: 1.201163, loss_ss: 1.182818, loss_d: 0.018346
Epoch finished! Loss: 1.3353312313556671
Starting epoch 6/10.
0.0000 --- loss: 1.117861, loss_ss: 1.111471, loss_d: 0.006390
0.2463 --- loss: 1.132431, loss_ss: 1.108195, loss_d: 0.024236
0.4926 --- loss: 1.118479, loss_ss: 1.111488, loss_d: 0.006991
0.7389 --- loss: 1.149800, loss_ss: 1.144767, loss_d: 0.005033
0.9852 --- loss: 1.053861, loss_ss: 1.052118, loss_d: 0.001743
Epoch finished! Loss: 1.18734150826931
Starting epoch 7/10.
0.0000 --- loss: 1.096309, loss_ss: 1.084604, loss_d: 0.011706
0.2463 --- loss: 1.148665, loss_ss: 1.055445, loss_d: 0.093221
0.4926 --- loss: 0.956292, loss_ss: 0.951327, loss_d: 0.004965
0.7389 --- loss: 1.147804, loss_ss: 1.145709, loss_d: 0.002096
0.9852 --- loss: 1.063319, loss_ss: 1.062247, loss_d: 0.001072
Epoch finished! Loss: 1.0688622832298278
Starting epoch 8/10.
0.0000 --- loss: 1.014600, loss_ss: 1.012417, loss_d: 0.002183
0.2463 --- loss: 1.041103, loss_ss: 1.034164, loss_d: 0.006939
0.4926 --- loss: 0.993802, loss_ss: 0.988721, loss_d: 0.005081
0.7389 --- loss: 0.953428, loss_ss: 0.950784, loss_d: 0.002644
0.9852 --- loss: 1.078431, loss_ss: 1.077359, loss_d: 0.001072
Epoch finished! Loss: 0.9873539239168168
Starting epoch 9/10.
0.0000 --- loss: 0.963503, loss_ss: 0.962880, loss_d: 0.000623
0.2463 --- loss: 0.951138, loss_ss: 0.950434, loss_d: 0.000704
0.4926 --- loss: 0.880154, loss_ss: 0.879880, loss_d: 0.000274
0.7389 --- loss: 0.815292, loss_ss: 0.814918, loss_d: 0.000374
0.9852 --- loss: 0.907434, loss_ss: 0.907140, loss_d: 0.000295
Epoch finished! Loss: 0.9308267056941986
Starting epoch 10/10.
0.0000 --- loss: 0.915728, loss_ss: 0.915473, loss_d: 0.000255
0.2463 --- loss: 0.863736, loss_ss: 0.863431, loss_d: 0.000305
0.4926 --- loss: 0.786114, loss_ss: 0.785824, loss_d: 0.000291
0.7389 --- loss: 0.962653, loss_ss: 0.962084, loss_d: 0.000569
0.9852 --- loss: 0.843082, loss_ss: 0.842449, loss_d: 0.000633
Epoch finished! Loss: 0.8856182560324669
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.38796296296296295
             precision    recall  f1-score   support

        0.0       0.41      0.55      0.47       108
        1.0       0.40      0.01      0.01       387
        2.0       0.50      0.68      0.58       360
        3.0       0.25      0.01      0.02        95
        4.0       0.26      0.87      0.40       130

avg / total       0.40      0.39      0.29      1080
 


====== chp049-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  87.50  54.63   91.15  40.69     46.64
1  64.07   0.52   99.57  40.00      1.02
2  66.94  67.78   66.53  50.31     57.75
3  91.02   1.05   99.70  25.00      2.02
4  68.06  86.92   65.47  25.62     39.58
Total accuracy: 38.80%
Average sen: 42.18%
Average spec: 84.48%
Macro f1-score: 29.40%
Diagnosis acc on 90mins: 1.0
[0.98018897 0.99976617 0.99884784 0.99995208 0.99999988 0.99999952]
pred: 0.9964590768019358, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp049-nsrr

=== Test on chp051-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.414548, loss_ss: 1.721526, loss_d: 0.693022
0.2463 --- loss: 2.280302, loss_ss: 1.596253, loss_d: 0.684049
0.4926 --- loss: 2.016598, loss_ss: 1.476764, loss_d: 0.539834
0.7389 --- loss: 2.310446, loss_ss: 1.479246, loss_d: 0.831201
0.9852 --- loss: 2.349547, loss_ss: 1.603002, loss_d: 0.746545
Epoch finished! Loss: 2.2249033957719804
Starting epoch 2/10.
0.0000 --- loss: 1.871310, loss_ss: 1.419279, loss_d: 0.452031
0.2463 --- loss: 1.932087, loss_ss: 1.450480, loss_d: 0.481607
0.4926 --- loss: 1.860844, loss_ss: 1.391276, loss_d: 0.469567
0.7389 --- loss: 1.712117, loss_ss: 1.370721, loss_d: 0.341396
0.9852 --- loss: 1.704640, loss_ss: 1.312499, loss_d: 0.392141
Epoch finished! Loss: 1.8925224393606186
Starting epoch 3/10.
0.0000 --- loss: 1.595192, loss_ss: 1.322097, loss_d: 0.273095
0.2463 --- loss: 1.610604, loss_ss: 1.251484, loss_d: 0.359120
0.4926 --- loss: 1.627358, loss_ss: 1.282743, loss_d: 0.344615
0.7389 --- loss: 1.407206, loss_ss: 1.266672, loss_d: 0.140534
0.9852 --- loss: 2.178398, loss_ss: 1.290743, loss_d: 0.887654
Epoch finished! Loss: 1.5221416652202606
Starting epoch 4/10.
0.0000 --- loss: 1.199680, loss_ss: 1.190431, loss_d: 0.009249
0.2463 --- loss: 1.321922, loss_ss: 1.207010, loss_d: 0.114912
0.4926 --- loss: 1.258168, loss_ss: 1.194206, loss_d: 0.063961
0.7389 --- loss: 1.359280, loss_ss: 1.264946, loss_d: 0.094334
0.9852 --- loss: 1.247290, loss_ss: 1.154269, loss_d: 0.093021
Epoch finished! Loss: 1.364661854505539
Starting epoch 5/10.
0.0000 --- loss: 1.109163, loss_ss: 1.102951, loss_d: 0.006212
0.2463 --- loss: 1.170307, loss_ss: 1.163162, loss_d: 0.007145
0.4926 --- loss: 1.151073, loss_ss: 1.132959, loss_d: 0.018114
0.7389 --- loss: 1.091015, loss_ss: 1.086689, loss_d: 0.004326
0.9852 --- loss: 1.170335, loss_ss: 1.042516, loss_d: 0.127820
Epoch finished! Loss: 1.1851415306329727
Starting epoch 6/10.
0.0000 --- loss: 1.156409, loss_ss: 1.110336, loss_d: 0.046073
0.2463 --- loss: 1.068421, loss_ss: 1.051905, loss_d: 0.016516
0.4926 --- loss: 1.123796, loss_ss: 1.060672, loss_d: 0.063124
0.7389 --- loss: 1.104764, loss_ss: 1.044158, loss_d: 0.060606
0.9852 --- loss: 1.031219, loss_ss: 1.027881, loss_d: 0.003338
Epoch finished! Loss: 1.0720796570181848
Starting epoch 7/10.
0.0000 --- loss: 1.052896, loss_ss: 1.052393, loss_d: 0.000502
0.2463 --- loss: 1.038655, loss_ss: 1.037661, loss_d: 0.000994
0.4926 --- loss: 0.944294, loss_ss: 0.942647, loss_d: 0.001646
0.7389 --- loss: 0.944747, loss_ss: 0.942861, loss_d: 0.001887
0.9852 --- loss: 0.977143, loss_ss: 0.971122, loss_d: 0.006021
Epoch finished! Loss: 1.0288907378911971
Starting epoch 8/10.
0.0000 --- loss: 0.968503, loss_ss: 0.967234, loss_d: 0.001269
0.2463 --- loss: 1.055879, loss_ss: 1.054122, loss_d: 0.001757
0.4926 --- loss: 0.908744, loss_ss: 0.907704, loss_d: 0.001040
0.7389 --- loss: 0.836270, loss_ss: 0.832557, loss_d: 0.003714
0.9852 --- loss: 0.950305, loss_ss: 0.935243, loss_d: 0.015062
Epoch finished! Loss: 0.968194967508316
Starting epoch 9/10.
0.0000 --- loss: 0.928932, loss_ss: 0.923935, loss_d: 0.004997
0.2463 --- loss: 0.912809, loss_ss: 0.911372, loss_d: 0.001436
0.4926 --- loss: 0.853576, loss_ss: 0.853204, loss_d: 0.000372
0.7389 --- loss: 0.954073, loss_ss: 0.952608, loss_d: 0.001466
0.9852 --- loss: 0.889098, loss_ss: 0.881479, loss_d: 0.007619
Epoch finished! Loss: 0.9219558879733085
Starting epoch 10/10.
0.0000 --- loss: 0.897271, loss_ss: 0.896359, loss_d: 0.000912
0.2463 --- loss: 0.815790, loss_ss: 0.815601, loss_d: 0.000189
0.4926 --- loss: 0.762653, loss_ss: 0.758947, loss_d: 0.003705
0.7389 --- loss: 0.844717, loss_ss: 0.844599, loss_d: 0.000118
0.9852 --- loss: 0.804168, loss_ss: 0.804037, loss_d: 0.000131
Epoch finished! Loss: 0.8820676937699318
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6268518518518519
             precision    recall  f1-score   support

        0.0       0.26      0.87      0.40        30
        1.0       0.21      0.24      0.22       136
        2.0       0.70      0.54      0.61       404
        3.0       0.98      0.67      0.80       239
        4.0       0.69      0.89      0.78       271

avg / total       0.68      0.63      0.64      1080
 


====== chp051-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  92.78  86.67   92.95  26.00     40.00
1  78.89  23.53   86.86  20.51     21.92
2  73.98  54.21   85.80  69.52     60.92
3  92.41  66.95   99.64  98.16     79.60
4  87.31  88.56   86.90  69.36     77.80
Total accuracy: 62.69%
Average sen: 63.98%
Average spec: 90.43%
Macro f1-score: 56.05%
Diagnosis acc on 90mins: 1.0
[0.99989748 0.99872309 0.99999762 0.99994886 0.99919027 0.99889141]
pred: 0.9994414548079172, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp051-nsrr

=== Test on chp052-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.588067, loss_ss: 1.930345, loss_d: 0.657722
0.2457 --- loss: 2.562268, loss_ss: 1.645180, loss_d: 0.917089
0.4914 --- loss: 2.277540, loss_ss: 1.643388, loss_d: 0.634152
0.7371 --- loss: 2.028203, loss_ss: 1.547455, loss_d: 0.480748
0.9828 --- loss: 1.958360, loss_ss: 1.511561, loss_d: 0.446799
Epoch finished! Loss: 2.3107774794101714
Starting epoch 2/10.
0.0000 --- loss: 2.080128, loss_ss: 1.590363, loss_d: 0.489765
0.2457 --- loss: 2.164322, loss_ss: 1.505910, loss_d: 0.658412
0.4914 --- loss: 1.911098, loss_ss: 1.560500, loss_d: 0.350598
0.7371 --- loss: 1.912698, loss_ss: 1.441682, loss_d: 0.471017
0.9828 --- loss: 1.909407, loss_ss: 1.401574, loss_d: 0.507833
Epoch finished! Loss: 1.9742976009845734
Starting epoch 3/10.
0.0000 --- loss: 1.796541, loss_ss: 1.489599, loss_d: 0.306942
0.2457 --- loss: 1.908584, loss_ss: 1.469519, loss_d: 0.439064
0.4914 --- loss: 1.402968, loss_ss: 1.354599, loss_d: 0.048368
0.7371 --- loss: 1.602237, loss_ss: 1.418062, loss_d: 0.184176
0.9828 --- loss: 1.421806, loss_ss: 1.391725, loss_d: 0.030081
Epoch finished! Loss: 1.6109353184700013
Starting epoch 4/10.
0.0000 --- loss: 1.401226, loss_ss: 1.392499, loss_d: 0.008728
0.2457 --- loss: 1.333221, loss_ss: 1.316433, loss_d: 0.016788
0.4914 --- loss: 1.322036, loss_ss: 1.309259, loss_d: 0.012777
0.7371 --- loss: 1.485278, loss_ss: 1.324766, loss_d: 0.160512
0.9828 --- loss: 1.336929, loss_ss: 1.313929, loss_d: 0.023001
Epoch finished! Loss: 1.419120293855667
Starting epoch 5/10.
0.0000 --- loss: 1.272961, loss_ss: 1.250592, loss_d: 0.022368
0.2457 --- loss: 1.173378, loss_ss: 1.168611, loss_d: 0.004767
0.4914 --- loss: 1.293491, loss_ss: 1.288015, loss_d: 0.005476
0.7371 --- loss: 1.348677, loss_ss: 1.232947, loss_d: 0.115730
0.9828 --- loss: 1.488536, loss_ss: 1.345403, loss_d: 0.143133
Epoch finished! Loss: 1.2802428871393203
Starting epoch 6/10.
0.0000 --- loss: 1.164053, loss_ss: 1.162255, loss_d: 0.001798
0.2457 --- loss: 1.113876, loss_ss: 1.107495, loss_d: 0.006381
0.4914 --- loss: 1.096403, loss_ss: 1.093531, loss_d: 0.002872
0.7371 --- loss: 1.169770, loss_ss: 1.109452, loss_d: 0.060318
0.9828 --- loss: 1.142705, loss_ss: 1.098527, loss_d: 0.044177
Epoch finished! Loss: 1.1915784150362014
Starting epoch 7/10.
0.0000 --- loss: 1.379289, loss_ss: 1.144156, loss_d: 0.235133
0.2457 --- loss: 1.242227, loss_ss: 1.009363, loss_d: 0.232864
0.4914 --- loss: 1.149745, loss_ss: 1.148609, loss_d: 0.001136
0.7371 --- loss: 0.984720, loss_ss: 0.954486, loss_d: 0.030234
0.9828 --- loss: 1.067805, loss_ss: 1.065900, loss_d: 0.001905
Epoch finished! Loss: 1.1310082376003265
Starting epoch 8/10.
0.0000 --- loss: 1.018282, loss_ss: 1.016518, loss_d: 0.001765
0.2457 --- loss: 0.987774, loss_ss: 0.986970, loss_d: 0.000804
0.4914 --- loss: 0.972218, loss_ss: 0.929691, loss_d: 0.042527
0.7371 --- loss: 1.056562, loss_ss: 1.024968, loss_d: 0.031594
0.9828 --- loss: 1.025589, loss_ss: 1.021972, loss_d: 0.003618
Epoch finished! Loss: 1.0427229478955269
Starting epoch 9/10.
0.0000 --- loss: 0.926838, loss_ss: 0.926330, loss_d: 0.000508
0.2457 --- loss: 1.066542, loss_ss: 1.058390, loss_d: 0.008152
0.4914 --- loss: 0.892725, loss_ss: 0.881446, loss_d: 0.011279
0.7371 --- loss: 0.910264, loss_ss: 0.907997, loss_d: 0.002267
0.9828 --- loss: 1.006507, loss_ss: 1.006470, loss_d: 0.000037
Epoch finished! Loss: 0.9814046502113343
Starting epoch 10/10.
0.0000 --- loss: 0.912385, loss_ss: 0.894079, loss_d: 0.018306
0.2457 --- loss: 0.802482, loss_ss: 0.799149, loss_d: 0.003333
0.4914 --- loss: 0.845441, loss_ss: 0.845312, loss_d: 0.000129
0.7371 --- loss: 0.974429, loss_ss: 0.974306, loss_d: 0.000123
0.9828 --- loss: 0.865491, loss_ss: 0.865292, loss_d: 0.000199
Epoch finished! Loss: 0.9317816510796547
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7277777777777777
             precision    recall  f1-score   support

        0.0       0.84      0.86      0.85       156
        1.0       0.33      0.01      0.03        76
        2.0       0.82      0.79      0.80       397
        3.0       1.00      0.05      0.09        66
        4.0       0.58      1.00      0.74       205

avg / total       0.74      0.73      0.68       900
 


====== chp052-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  94.67  85.90   96.51   83.75     84.81
1  91.44   1.32   99.76   33.33      2.53
2  82.78  78.84   85.88   81.51     80.15
3  93.00   4.55  100.00  100.00      8.70
4  83.67  99.51   78.99   58.29     73.51
Total accuracy: 72.78%
Average sen: 54.02%
Average spec: 92.23%
Macro f1-score: 49.94%
Diagnosis acc on 90mins: 1.0
[0.99501193 0.99402618 0.9710626  0.98905396 0.98877257]
pred: 0.98758544921875, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp052-nsrr

=== Test on chp053-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.338837, loss_ss: 1.651211, loss_d: 0.687627
0.2463 --- loss: 1.991457, loss_ss: 1.489860, loss_d: 0.501596
0.4926 --- loss: 2.085683, loss_ss: 1.503882, loss_d: 0.581801
0.7389 --- loss: 1.978413, loss_ss: 1.474730, loss_d: 0.503682
0.9852 --- loss: 2.048794, loss_ss: 1.418521, loss_d: 0.630273
Epoch finished! Loss: 2.1960424929857254
Starting epoch 2/10.
0.0000 --- loss: 1.821242, loss_ss: 1.409296, loss_d: 0.411947
0.2463 --- loss: 1.990204, loss_ss: 1.422250, loss_d: 0.567954
0.4926 --- loss: 1.935023, loss_ss: 1.391051, loss_d: 0.543972
0.7389 --- loss: 1.841392, loss_ss: 1.462909, loss_d: 0.378483
0.9852 --- loss: 1.769145, loss_ss: 1.386343, loss_d: 0.382802
Epoch finished! Loss: 1.92020925283432
Starting epoch 3/10.
0.0000 --- loss: 1.586193, loss_ss: 1.428766, loss_d: 0.157426
0.2463 --- loss: 1.725331, loss_ss: 1.364396, loss_d: 0.360936
0.4926 --- loss: 1.540385, loss_ss: 1.223516, loss_d: 0.316870
0.7389 --- loss: 1.460665, loss_ss: 1.289278, loss_d: 0.171387
0.9852 --- loss: 1.671123, loss_ss: 1.259110, loss_d: 0.412013
Epoch finished! Loss: 1.6785019218921662
Starting epoch 4/10.
0.0000 --- loss: 1.338646, loss_ss: 1.202471, loss_d: 0.136175
0.2463 --- loss: 1.289330, loss_ss: 1.194747, loss_d: 0.094582
0.4926 --- loss: 1.705556, loss_ss: 1.157181, loss_d: 0.548375
0.7389 --- loss: 1.346018, loss_ss: 1.304263, loss_d: 0.041755
0.9852 --- loss: 1.950137, loss_ss: 1.233723, loss_d: 0.716414
Epoch finished! Loss: 1.4372698068618774
Starting epoch 5/10.
0.0000 --- loss: 1.278939, loss_ss: 1.245168, loss_d: 0.033771
0.2463 --- loss: 1.275162, loss_ss: 1.097978, loss_d: 0.177183
0.4926 --- loss: 1.319595, loss_ss: 1.113695, loss_d: 0.205900
0.7389 --- loss: 1.486994, loss_ss: 1.368090, loss_d: 0.118904
0.9852 --- loss: 1.172217, loss_ss: 1.124866, loss_d: 0.047351
Epoch finished! Loss: 1.364794671535492
Starting epoch 6/10.
0.0000 --- loss: 1.417353, loss_ss: 1.129064, loss_d: 0.288289
0.2463 --- loss: 1.107795, loss_ss: 1.054679, loss_d: 0.053115
0.4926 --- loss: 1.149841, loss_ss: 1.134450, loss_d: 0.015391
0.7389 --- loss: 1.086671, loss_ss: 1.000687, loss_d: 0.085984
0.9852 --- loss: 1.027671, loss_ss: 0.963379, loss_d: 0.064292
Epoch finished! Loss: 1.1654736623167992
Starting epoch 7/10.
0.0000 --- loss: 1.158388, loss_ss: 1.152269, loss_d: 0.006119
0.2463 --- loss: 0.968527, loss_ss: 0.962520, loss_d: 0.006007
0.4926 --- loss: 1.436426, loss_ss: 1.023601, loss_d: 0.412825
0.7389 --- loss: 0.987796, loss_ss: 0.981608, loss_d: 0.006189
0.9852 --- loss: 1.099194, loss_ss: 1.098441, loss_d: 0.000753
Epoch finished! Loss: 1.0963050976395607
Starting epoch 8/10.
0.0000 --- loss: 0.925408, loss_ss: 0.924284, loss_d: 0.001124
0.2463 --- loss: 1.018381, loss_ss: 1.004868, loss_d: 0.013513
0.4926 --- loss: 1.037321, loss_ss: 1.035082, loss_d: 0.002239
0.7389 --- loss: 1.021810, loss_ss: 1.018636, loss_d: 0.003174
0.9852 --- loss: 0.930160, loss_ss: 0.929385, loss_d: 0.000774
Epoch finished! Loss: 1.0294613406062125
Starting epoch 9/10.
0.0000 --- loss: 0.860035, loss_ss: 0.858792, loss_d: 0.001243
0.2463 --- loss: 0.910413, loss_ss: 0.908901, loss_d: 0.001512
0.4926 --- loss: 0.940942, loss_ss: 0.938905, loss_d: 0.002037
0.7389 --- loss: 1.066446, loss_ss: 1.064805, loss_d: 0.001641
0.9852 --- loss: 1.003062, loss_ss: 0.975551, loss_d: 0.027511
Epoch finished! Loss: 0.9892997413873672
Starting epoch 10/10.
0.0000 --- loss: 0.893198, loss_ss: 0.879512, loss_d: 0.013687
0.2463 --- loss: 0.816201, loss_ss: 0.801695, loss_d: 0.014507
0.4926 --- loss: 0.936591, loss_ss: 0.931369, loss_d: 0.005221
0.7389 --- loss: 0.887197, loss_ss: 0.886193, loss_d: 0.001004
0.9852 --- loss: 1.491036, loss_ss: 0.944596, loss_d: 0.546440
Epoch finished! Loss: 0.9437725633382797
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6666666666666666
             precision    recall  f1-score   support

        0.0       0.94      0.58      0.72       251
        1.0       0.50      0.04      0.08       147
        2.0       0.71      0.86      0.78       305
        3.0       1.00      0.73      0.85       250
        4.0       0.34      0.98      0.51       127

avg / total       0.76      0.67      0.65      1080
 


====== chp053-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  89.35  58.17   98.79   93.59     71.74
1  86.39   4.08   99.36   50.00      7.55
2  86.20  85.57   86.45   71.31     77.79
3  93.80  73.20  100.00  100.00     84.53
4  77.59  97.64   74.92   34.16     50.61
Total accuracy: 66.67%
Average sen: 63.73%
Average spec: 91.90%
Macro f1-score: 58.44%
Diagnosis acc on 90mins: 1.0
[0.99671692 0.99999988 0.98117644 0.98421186 0.99888533 0.9997496 ]
pred: 0.9934566716353098, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp053-nsrr

=== Test on chp054-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.300456, loss_ss: 1.618693, loss_d: 0.681763
0.2463 --- loss: 2.150009, loss_ss: 1.456099, loss_d: 0.693909
0.4926 --- loss: 2.020348, loss_ss: 1.440085, loss_d: 0.580263
0.7389 --- loss: 1.860267, loss_ss: 1.352678, loss_d: 0.507589
0.9852 --- loss: 2.035530, loss_ss: 1.429986, loss_d: 0.605544
Epoch finished! Loss: 2.1245513200759887
Starting epoch 2/10.
0.0000 --- loss: 1.753287, loss_ss: 1.340781, loss_d: 0.412506
0.2463 --- loss: 1.600009, loss_ss: 1.381075, loss_d: 0.218934
0.4926 --- loss: 1.801721, loss_ss: 1.401395, loss_d: 0.400326
0.7389 --- loss: 1.824586, loss_ss: 1.353735, loss_d: 0.470851
0.9852 --- loss: 1.662953, loss_ss: 1.319078, loss_d: 0.343875
Epoch finished! Loss: 1.8751758903265
Starting epoch 3/10.
0.0000 --- loss: 1.495460, loss_ss: 1.282558, loss_d: 0.212902
0.2463 --- loss: 1.564973, loss_ss: 1.304549, loss_d: 0.260424
0.4926 --- loss: 1.594203, loss_ss: 1.435526, loss_d: 0.158677
0.7389 --- loss: 1.421693, loss_ss: 1.307486, loss_d: 0.114207
0.9852 --- loss: 1.534475, loss_ss: 1.285128, loss_d: 0.249347
Epoch finished! Loss: 1.5947919130325316
Starting epoch 4/10.
0.0000 --- loss: 1.488135, loss_ss: 1.295905, loss_d: 0.192230
0.2463 --- loss: 1.338498, loss_ss: 1.272906, loss_d: 0.065592
0.4926 --- loss: 1.398093, loss_ss: 1.385054, loss_d: 0.013039
0.7389 --- loss: 1.193649, loss_ss: 1.177040, loss_d: 0.016610
0.9852 --- loss: 1.837778, loss_ss: 1.443144, loss_d: 0.394634
Epoch finished! Loss: 1.416904702782631
Starting epoch 5/10.
0.0000 --- loss: 1.166406, loss_ss: 1.137034, loss_d: 0.029371
0.2463 --- loss: 1.317888, loss_ss: 1.301631, loss_d: 0.016258
0.4926 --- loss: 1.180516, loss_ss: 1.150552, loss_d: 0.029964
0.7389 --- loss: 1.376427, loss_ss: 1.151027, loss_d: 0.225400
0.9852 --- loss: 1.130710, loss_ss: 1.124661, loss_d: 0.006050
Epoch finished! Loss: 1.300874599814415
Starting epoch 6/10.
0.0000 --- loss: 1.127649, loss_ss: 1.117799, loss_d: 0.009850
0.2463 --- loss: 1.361976, loss_ss: 1.353408, loss_d: 0.008568
0.4926 --- loss: 1.055275, loss_ss: 1.047705, loss_d: 0.007570
0.7389 --- loss: 1.296113, loss_ss: 1.253902, loss_d: 0.042211
0.9852 --- loss: 0.941870, loss_ss: 0.941092, loss_d: 0.000777
Epoch finished! Loss: 1.220398510992527
Starting epoch 7/10.
0.0000 --- loss: 1.199334, loss_ss: 1.153086, loss_d: 0.046248
0.2463 --- loss: 1.186015, loss_ss: 1.163875, loss_d: 0.022140
0.4926 --- loss: 1.033217, loss_ss: 1.019927, loss_d: 0.013290
0.7389 --- loss: 1.061785, loss_ss: 1.060095, loss_d: 0.001690
0.9852 --- loss: 1.036954, loss_ss: 1.029480, loss_d: 0.007474
Epoch finished! Loss: 1.1090822011232375
Starting epoch 8/10.
0.0000 --- loss: 1.056816, loss_ss: 1.054199, loss_d: 0.002617
0.2463 --- loss: 1.011375, loss_ss: 1.010414, loss_d: 0.000961
0.4926 --- loss: 0.922186, loss_ss: 0.919603, loss_d: 0.002584
0.7389 --- loss: 1.003781, loss_ss: 1.002232, loss_d: 0.001549
0.9852 --- loss: 0.917890, loss_ss: 0.917621, loss_d: 0.000269
Epoch finished! Loss: 1.0418866947293282
Starting epoch 9/10.
0.0000 --- loss: 1.045079, loss_ss: 1.044481, loss_d: 0.000598
0.2463 --- loss: 1.073742, loss_ss: 1.071006, loss_d: 0.002736
0.4926 --- loss: 0.978313, loss_ss: 0.973880, loss_d: 0.004433
0.7389 --- loss: 1.005460, loss_ss: 1.005288, loss_d: 0.000172
0.9852 --- loss: 0.890111, loss_ss: 0.889571, loss_d: 0.000540
Epoch finished! Loss: 0.9956515148282051
Starting epoch 10/10.
0.0000 --- loss: 1.031120, loss_ss: 1.030879, loss_d: 0.000241
0.2463 --- loss: 1.059526, loss_ss: 1.057042, loss_d: 0.002484
0.4926 --- loss: 1.058497, loss_ss: 1.057007, loss_d: 0.001489
0.7389 --- loss: 1.107568, loss_ss: 1.105848, loss_d: 0.001720
0.9852 --- loss: 1.032740, loss_ss: 0.994138, loss_d: 0.038602
Epoch finished! Loss: 1.012476496398449
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6694444444444444
             precision    recall  f1-score   support

        0.0       0.85      0.40      0.55       228
        1.0       0.11      0.13      0.12        86
        2.0       0.82      0.79      0.81       451
        3.0       1.00      0.84      0.91        99
        4.0       0.51      0.83      0.63       216

avg / total       0.72      0.67      0.67      1080
 


====== chp054-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  85.93  40.35   98.12   85.19     54.76
1  84.81  12.79   91.05   11.00     11.83
2  84.07  79.16   87.60   82.07     80.59
3  98.52  83.84  100.00  100.00     91.21
4  80.56  83.33   79.86   50.85     63.16
Total accuracy: 66.94%
Average sen: 59.89%
Average spec: 91.33%
Macro f1-score: 60.31%
Diagnosis acc on 90mins: 1.0
[0.99997973 0.9860881  0.99999475 0.99565911 0.99999523 0.99985647]
pred: 0.9969289004802704, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp054-nsrr

=== Test on chp055-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.323904, loss_ss: 1.688258, loss_d: 0.635646
0.2463 --- loss: 2.094685, loss_ss: 1.504580, loss_d: 0.590105
0.4926 --- loss: 1.943884, loss_ss: 1.363030, loss_d: 0.580854
0.7389 --- loss: 2.092952, loss_ss: 1.393085, loss_d: 0.699867
0.9852 --- loss: 1.907116, loss_ss: 1.458457, loss_d: 0.448659
Epoch finished! Loss: 2.101962313055992
Starting epoch 2/10.
0.0000 --- loss: 1.761446, loss_ss: 1.336053, loss_d: 0.425394
0.2463 --- loss: 1.800816, loss_ss: 1.363928, loss_d: 0.436888
0.4926 --- loss: 1.693095, loss_ss: 1.316862, loss_d: 0.376232
0.7389 --- loss: 2.004316, loss_ss: 1.296485, loss_d: 0.707831
0.9852 --- loss: 1.533495, loss_ss: 1.139682, loss_d: 0.393813
Epoch finished! Loss: 1.7974130928516387
Starting epoch 3/10.
0.0000 --- loss: 1.758175, loss_ss: 1.244847, loss_d: 0.513328
0.2463 --- loss: 1.394123, loss_ss: 1.207800, loss_d: 0.186323
0.4926 --- loss: 1.187868, loss_ss: 1.074651, loss_d: 0.113217
0.7389 --- loss: 1.291567, loss_ss: 1.117667, loss_d: 0.173900
0.9852 --- loss: 1.470136, loss_ss: 1.124677, loss_d: 0.345459
Epoch finished! Loss: 1.4742691844701767
Starting epoch 4/10.
0.0000 --- loss: 1.185214, loss_ss: 1.155426, loss_d: 0.029788
0.2463 --- loss: 1.147815, loss_ss: 1.132910, loss_d: 0.014905
0.4926 --- loss: 1.096529, loss_ss: 1.023604, loss_d: 0.072925
0.7389 --- loss: 1.225437, loss_ss: 1.220110, loss_d: 0.005327
0.9852 --- loss: 1.393308, loss_ss: 1.047415, loss_d: 0.345893
Epoch finished! Loss: 1.2815064013004303
Starting epoch 5/10.
0.0000 --- loss: 1.135126, loss_ss: 1.055957, loss_d: 0.079169
0.2463 --- loss: 1.128032, loss_ss: 1.081524, loss_d: 0.046508
0.4926 --- loss: 1.175835, loss_ss: 1.126848, loss_d: 0.048988
0.7389 --- loss: 1.053271, loss_ss: 1.023748, loss_d: 0.029523
0.9852 --- loss: 1.099296, loss_ss: 1.040400, loss_d: 0.058896
Epoch finished! Loss: 1.1330163061618805
Starting epoch 6/10.
0.0000 --- loss: 1.033264, loss_ss: 1.028080, loss_d: 0.005184
0.2463 --- loss: 1.212360, loss_ss: 1.203895, loss_d: 0.008464
0.4926 --- loss: 1.099354, loss_ss: 1.065280, loss_d: 0.034073
0.7389 --- loss: 0.962278, loss_ss: 0.951357, loss_d: 0.010921
0.9852 --- loss: 0.914398, loss_ss: 0.910983, loss_d: 0.003416
Epoch finished! Loss: 1.0427854880690575
Starting epoch 7/10.
0.0000 --- loss: 1.055917, loss_ss: 1.054320, loss_d: 0.001597
0.2463 --- loss: 1.069611, loss_ss: 1.068675, loss_d: 0.000936
0.4926 --- loss: 0.870527, loss_ss: 0.867444, loss_d: 0.003083
0.7389 --- loss: 0.907793, loss_ss: 0.905448, loss_d: 0.002345
0.9852 --- loss: 0.949494, loss_ss: 0.948557, loss_d: 0.000937
Epoch finished! Loss: 0.9864375352859497
Starting epoch 8/10.
0.0000 --- loss: 0.957864, loss_ss: 0.956476, loss_d: 0.001388
0.2463 --- loss: 0.876058, loss_ss: 0.875867, loss_d: 0.000191
0.4926 --- loss: 0.952258, loss_ss: 0.951060, loss_d: 0.001198
0.7389 --- loss: 0.844746, loss_ss: 0.843977, loss_d: 0.000769
0.9852 --- loss: 0.981737, loss_ss: 0.981432, loss_d: 0.000305
Epoch finished! Loss: 0.9467612311244011
Starting epoch 9/10.
0.0000 --- loss: 1.014833, loss_ss: 0.978029, loss_d: 0.036805
0.2463 --- loss: 0.831595, loss_ss: 0.831148, loss_d: 0.000446
0.4926 --- loss: 0.988639, loss_ss: 0.987623, loss_d: 0.001016
0.7389 --- loss: 0.842557, loss_ss: 0.841347, loss_d: 0.001210
0.9852 --- loss: 0.840659, loss_ss: 0.840145, loss_d: 0.000514
Epoch finished! Loss: 0.9210263818502427
Starting epoch 10/10.
0.0000 --- loss: 0.771798, loss_ss: 0.771319, loss_d: 0.000480
0.2463 --- loss: 0.921928, loss_ss: 0.921554, loss_d: 0.000374
0.4926 --- loss: 0.892887, loss_ss: 0.891918, loss_d: 0.000968
0.7389 --- loss: 0.807508, loss_ss: 0.807386, loss_d: 0.000122
0.9852 --- loss: 0.888834, loss_ss: 0.888719, loss_d: 0.000114
Epoch finished! Loss: 0.8975404351949692
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.625
             precision    recall  f1-score   support

        0.0       0.76      0.92      0.84       211
        1.0       0.25      0.13      0.17       154
        2.0       0.68      0.84      0.75       408
        3.0       1.00      0.05      0.10       130
        4.0       0.47      0.62      0.53       177

avg / total       0.64      0.62      0.57      1080
 


====== chp055-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  92.87  92.42   92.98   76.17     83.51
1  82.13  12.99   93.63   25.32     17.17
2  79.07  84.31   75.89   67.98     75.27
3  88.61   5.38  100.00  100.00     10.22
4  82.31  61.58   86.38   46.98     53.30
Total accuracy: 62.50%
Average sen: 51.34%
Average spec: 89.78%
Macro f1-score: 47.89%
Diagnosis acc on 90mins: 1.0
[0.9988417  0.99982268 0.99998748 0.99999392 0.99842477 0.99988937]
pred: 0.9994933207829794, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp055-nsrr

=== Test on chp056-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.258750, loss_ss: 1.559411, loss_d: 0.699340
0.2463 --- loss: 2.014354, loss_ss: 1.485563, loss_d: 0.528790
0.4926 --- loss: 1.987048, loss_ss: 1.428485, loss_d: 0.558563
0.7389 --- loss: 1.798522, loss_ss: 1.433517, loss_d: 0.365005
0.9852 --- loss: 2.376599, loss_ss: 1.394331, loss_d: 0.982268
Epoch finished! Loss: 2.120065504312515
Starting epoch 2/10.
0.0000 --- loss: 2.063770, loss_ss: 1.367765, loss_d: 0.696005
0.2463 --- loss: 1.805795, loss_ss: 1.300212, loss_d: 0.505583
0.4926 --- loss: 1.908564, loss_ss: 1.303308, loss_d: 0.605256
0.7389 --- loss: 1.676027, loss_ss: 1.232350, loss_d: 0.443677
0.9852 --- loss: 1.531431, loss_ss: 1.337951, loss_d: 0.193480
Epoch finished! Loss: 1.8321024179458618
Starting epoch 3/10.
0.0000 --- loss: 1.664227, loss_ss: 1.257215, loss_d: 0.407012
0.2463 --- loss: 1.371123, loss_ss: 1.306916, loss_d: 0.064208
0.4926 --- loss: 1.299139, loss_ss: 1.281935, loss_d: 0.017204
0.7389 --- loss: 1.479871, loss_ss: 1.240059, loss_d: 0.239812
0.9852 --- loss: 1.427864, loss_ss: 1.182272, loss_d: 0.245592
Epoch finished! Loss: 1.4906744599342345
Starting epoch 4/10.
0.0000 --- loss: 1.281863, loss_ss: 1.231153, loss_d: 0.050710
0.2463 --- loss: 1.300887, loss_ss: 1.179334, loss_d: 0.121553
0.4926 --- loss: 1.233760, loss_ss: 1.155367, loss_d: 0.078393
0.7389 --- loss: 1.237633, loss_ss: 1.214543, loss_d: 0.023090
0.9852 --- loss: 1.217298, loss_ss: 1.185927, loss_d: 0.031371
Epoch finished! Loss: 1.2950572043657302
Starting epoch 5/10.
0.0000 --- loss: 1.069391, loss_ss: 1.065842, loss_d: 0.003549
0.2463 --- loss: 1.346270, loss_ss: 1.276776, loss_d: 0.069494
0.4926 --- loss: 1.079351, loss_ss: 1.070251, loss_d: 0.009100
0.7389 --- loss: 1.071057, loss_ss: 1.055434, loss_d: 0.015623
0.9852 --- loss: 1.044137, loss_ss: 1.043183, loss_d: 0.000953
Epoch finished! Loss: 1.150639832019806
Starting epoch 6/10.
0.0000 --- loss: 1.008294, loss_ss: 1.007774, loss_d: 0.000520
0.2463 --- loss: 1.021394, loss_ss: 1.019206, loss_d: 0.002188
0.4926 --- loss: 0.967205, loss_ss: 0.966033, loss_d: 0.001172
0.7389 --- loss: 0.950322, loss_ss: 0.949620, loss_d: 0.000703
0.9852 --- loss: 1.057808, loss_ss: 1.055413, loss_d: 0.002394
Epoch finished! Loss: 1.0751887276768683
Starting epoch 7/10.
0.0000 --- loss: 1.011537, loss_ss: 1.011389, loss_d: 0.000148
0.2463 --- loss: 0.926009, loss_ss: 0.925561, loss_d: 0.000448
0.4926 --- loss: 1.064752, loss_ss: 1.064629, loss_d: 0.000123
0.7389 --- loss: 1.050496, loss_ss: 1.049104, loss_d: 0.001392
0.9852 --- loss: 0.865742, loss_ss: 0.865074, loss_d: 0.000667
Epoch finished! Loss: 1.009148345887661
Starting epoch 8/10.
0.0000 --- loss: 0.922113, loss_ss: 0.918095, loss_d: 0.004019
0.2463 --- loss: 0.934687, loss_ss: 0.934494, loss_d: 0.000193
0.4926 --- loss: 0.833681, loss_ss: 0.833487, loss_d: 0.000194
0.7389 --- loss: 0.868525, loss_ss: 0.868388, loss_d: 0.000137
0.9852 --- loss: 1.141895, loss_ss: 1.084894, loss_d: 0.057001
Epoch finished! Loss: 0.9505918264389038
Starting epoch 9/10.
0.0000 --- loss: 0.866167, loss_ss: 0.865986, loss_d: 0.000181
0.2463 --- loss: 0.960833, loss_ss: 0.959765, loss_d: 0.001069
0.4926 --- loss: 0.828230, loss_ss: 0.825307, loss_d: 0.002922
0.7389 --- loss: 0.892019, loss_ss: 0.881925, loss_d: 0.010094
0.9852 --- loss: 1.311385, loss_ss: 0.909885, loss_d: 0.401500
Epoch finished! Loss: 0.9585837602615357
Starting epoch 10/10.
0.0000 --- loss: 0.799928, loss_ss: 0.796181, loss_d: 0.003748
0.2463 --- loss: 0.952431, loss_ss: 0.922016, loss_d: 0.030415
0.4926 --- loss: 0.903208, loss_ss: 0.900275, loss_d: 0.002933
0.7389 --- loss: 0.890395, loss_ss: 0.876660, loss_d: 0.013734
0.9852 --- loss: 0.976130, loss_ss: 0.975793, loss_d: 0.000336
Epoch finished! Loss: 0.9845615103840828
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5666666666666667
             precision    recall  f1-score   support

        0.0       0.33      0.56      0.42        78
        1.0       0.45      0.05      0.09       284
        2.0       0.61      0.88      0.72       258
        3.0       1.00      0.84      0.91       185
        4.0       0.44      0.62      0.51       275

avg / total       0.57      0.57      0.51      1080
 


====== chp056-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  88.70  56.41   91.22   33.33     41.90
1  73.43   5.28   97.74   45.45      9.46
2  83.89  87.98   82.60   61.35     72.29
3  97.22  83.78  100.00  100.00     91.18
4  70.09  62.18   72.80   43.85     51.43
Total accuracy: 56.67%
Average sen: 59.13%
Average spec: 88.87%
Macro f1-score: 53.25%
Diagnosis acc on 90mins: 1.0
[0.98316145 1.         0.99999821 0.9999994  0.99999821 1.        ]
pred: 0.9971928795178732, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp056-nsrr

=== Test on chp057-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.571639, loss_ss: 1.853571, loss_d: 0.718068
0.2463 --- loss: 2.333458, loss_ss: 1.634750, loss_d: 0.698708
0.4926 --- loss: 2.481296, loss_ss: 1.715654, loss_d: 0.765641
0.7389 --- loss: 2.252400, loss_ss: 1.651297, loss_d: 0.601103
0.9852 --- loss: 2.230960, loss_ss: 1.592769, loss_d: 0.638190
Epoch finished! Loss: 2.343694818019867
Starting epoch 2/10.
0.0000 --- loss: 2.050516, loss_ss: 1.550835, loss_d: 0.499682
0.2463 --- loss: 2.112349, loss_ss: 1.570804, loss_d: 0.541544
0.4926 --- loss: 2.121678, loss_ss: 1.504159, loss_d: 0.617519
0.7389 --- loss: 1.819733, loss_ss: 1.530344, loss_d: 0.289389
0.9852 --- loss: 1.777297, loss_ss: 1.451028, loss_d: 0.326269
Epoch finished! Loss: 1.9578703880310058
Starting epoch 3/10.
0.0000 --- loss: 1.661290, loss_ss: 1.513795, loss_d: 0.147495
0.2463 --- loss: 1.528607, loss_ss: 1.465877, loss_d: 0.062730
0.4926 --- loss: 1.514387, loss_ss: 1.410876, loss_d: 0.103511
0.7389 --- loss: 1.719393, loss_ss: 1.432527, loss_d: 0.286866
0.9852 --- loss: 1.761659, loss_ss: 1.441941, loss_d: 0.319717
Epoch finished! Loss: 1.6600784987211228
Starting epoch 4/10.
0.0000 --- loss: 1.471538, loss_ss: 1.383087, loss_d: 0.088451
0.2463 --- loss: 1.419532, loss_ss: 1.336494, loss_d: 0.083038
0.4926 --- loss: 1.411158, loss_ss: 1.374119, loss_d: 0.037039
0.7389 --- loss: 1.516042, loss_ss: 1.395298, loss_d: 0.120743
0.9852 --- loss: 1.423747, loss_ss: 1.405931, loss_d: 0.017816
Epoch finished! Loss: 1.4931746304035187
Starting epoch 5/10.
0.0000 --- loss: 1.546032, loss_ss: 1.310266, loss_d: 0.235766
0.2463 --- loss: 1.304475, loss_ss: 1.276803, loss_d: 0.027671
0.4926 --- loss: 1.460440, loss_ss: 1.258876, loss_d: 0.201564
0.7389 --- loss: 1.376822, loss_ss: 1.262599, loss_d: 0.114224
0.9852 --- loss: 1.259288, loss_ss: 1.259109, loss_d: 0.000179
Epoch finished! Loss: 1.3781573563814162
Starting epoch 6/10.
0.0000 --- loss: 1.254807, loss_ss: 1.217805, loss_d: 0.037003
0.2463 --- loss: 1.219188, loss_ss: 1.177198, loss_d: 0.041990
0.4926 --- loss: 1.209672, loss_ss: 1.207792, loss_d: 0.001881
0.7389 --- loss: 1.266913, loss_ss: 1.150736, loss_d: 0.116177
0.9852 --- loss: 1.115825, loss_ss: 1.115056, loss_d: 0.000770
Epoch finished! Loss: 1.24329152405262
Starting epoch 7/10.
0.0000 --- loss: 1.155733, loss_ss: 1.145504, loss_d: 0.010229
0.2463 --- loss: 1.205995, loss_ss: 1.205508, loss_d: 0.000487
0.4926 --- loss: 1.116877, loss_ss: 1.115605, loss_d: 0.001272
0.7389 --- loss: 1.164546, loss_ss: 1.163117, loss_d: 0.001429
0.9852 --- loss: 1.133584, loss_ss: 1.131012, loss_d: 0.002572
Epoch finished! Loss: 1.147521910071373
Starting epoch 8/10.
0.0000 --- loss: 1.020350, loss_ss: 1.016817, loss_d: 0.003533
0.2463 --- loss: 1.010149, loss_ss: 1.007828, loss_d: 0.002321
0.4926 --- loss: 1.015634, loss_ss: 1.014948, loss_d: 0.000686
0.7389 --- loss: 1.033837, loss_ss: 1.032686, loss_d: 0.001152
0.9852 --- loss: 1.085321, loss_ss: 1.085112, loss_d: 0.000209
Epoch finished! Loss: 1.0572930783033372
Starting epoch 9/10.
0.0000 --- loss: 1.024139, loss_ss: 1.023538, loss_d: 0.000601
0.2463 --- loss: 1.001527, loss_ss: 1.000958, loss_d: 0.000569
0.4926 --- loss: 0.970338, loss_ss: 0.970300, loss_d: 0.000038
0.7389 --- loss: 0.931628, loss_ss: 0.931476, loss_d: 0.000152
0.9852 --- loss: 0.916595, loss_ss: 0.915012, loss_d: 0.001583
Epoch finished! Loss: 0.9878903746604919
Starting epoch 10/10.
0.0000 --- loss: 0.897509, loss_ss: 0.896957, loss_d: 0.000552
0.2463 --- loss: 0.860473, loss_ss: 0.858829, loss_d: 0.001643
0.4926 --- loss: 0.848349, loss_ss: 0.840293, loss_d: 0.008056
0.7389 --- loss: 0.933541, loss_ss: 0.932740, loss_d: 0.000801
0.9852 --- loss: 0.938899, loss_ss: 0.938523, loss_d: 0.000376
Epoch finished! Loss: 0.935058756172657
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7451343836886005
             precision    recall  f1-score   support

        0.0       0.80      0.82      0.81       260
        1.0       0.51      0.18      0.27       142
        2.0       0.73      0.96      0.83       423
        3.0       0.95      0.26      0.40        74
        4.0       0.76      0.79      0.78       180

avg / total       0.74      0.75      0.71      1079
 


====== chp057-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  90.55  81.54   93.41  79.70     80.61
1  86.93  18.31   97.33  50.98     26.94
2  84.24  95.51   76.98  72.79     82.62
3  94.81  25.68   99.90  95.00     40.43
4  92.49  79.44   95.11  76.47     77.93
Total accuracy: 74.51%
Average sen: 60.10%
Average spec: 92.55%
Macro f1-score: 61.70%
Diagnosis acc on 90mins: 1.0
[0.99959522 0.82712382 0.99998963 0.9931798  0.99982685 0.94210958]
pred: 0.9603041509787241, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp057-nsrr

=== Test on chp058-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.459025, loss_ss: 1.696492, loss_d: 0.762533
0.2457 --- loss: 2.144006, loss_ss: 1.565492, loss_d: 0.578514
0.4914 --- loss: 2.001835, loss_ss: 1.383446, loss_d: 0.618389
0.7371 --- loss: 2.226561, loss_ss: 1.440799, loss_d: 0.785762
0.9828 --- loss: 2.255442, loss_ss: 1.673542, loss_d: 0.581900
Epoch finished! Loss: 2.172328123450279
Starting epoch 2/10.
0.0000 --- loss: 1.949748, loss_ss: 1.325069, loss_d: 0.624678
0.2457 --- loss: 1.695556, loss_ss: 1.325837, loss_d: 0.369719
0.4914 --- loss: 1.593430, loss_ss: 1.260993, loss_d: 0.332437
0.7371 --- loss: 1.826273, loss_ss: 1.347569, loss_d: 0.478705
0.9828 --- loss: 1.412353, loss_ss: 1.215553, loss_d: 0.196800
Epoch finished! Loss: 1.8596932619810105
Starting epoch 3/10.
0.0000 --- loss: 1.572176, loss_ss: 1.405759, loss_d: 0.166417
0.2457 --- loss: 1.413871, loss_ss: 1.258309, loss_d: 0.155563
0.4914 --- loss: 1.542568, loss_ss: 1.255070, loss_d: 0.287498
0.7371 --- loss: 1.450282, loss_ss: 1.243754, loss_d: 0.206528
0.9828 --- loss: 2.377177, loss_ss: 1.235269, loss_d: 1.141908
Epoch finished! Loss: 1.5765629798173904
Starting epoch 4/10.
0.0000 --- loss: 1.300755, loss_ss: 1.249044, loss_d: 0.051711
0.2457 --- loss: 1.274907, loss_ss: 1.212720, loss_d: 0.062187
0.4914 --- loss: 1.188807, loss_ss: 1.146974, loss_d: 0.041833
0.7371 --- loss: 1.278872, loss_ss: 1.187039, loss_d: 0.091833
0.9828 --- loss: 1.335995, loss_ss: 1.147041, loss_d: 0.188954
Epoch finished! Loss: 1.316483375430107
Starting epoch 5/10.
0.0000 --- loss: 1.246608, loss_ss: 1.104532, loss_d: 0.142076
0.2457 --- loss: 1.116589, loss_ss: 1.102496, loss_d: 0.014093
0.4914 --- loss: 1.216413, loss_ss: 1.197999, loss_d: 0.018413
0.7371 --- loss: 1.049976, loss_ss: 1.027428, loss_d: 0.022547
0.9828 --- loss: 1.113770, loss_ss: 1.109093, loss_d: 0.004677
Epoch finished! Loss: 1.1956805378198623
Starting epoch 6/10.
0.0000 --- loss: 1.116474, loss_ss: 1.105806, loss_d: 0.010667
0.2457 --- loss: 0.968218, loss_ss: 0.957407, loss_d: 0.010811
0.4914 --- loss: 1.106075, loss_ss: 1.091017, loss_d: 0.015058
0.7371 --- loss: 1.087798, loss_ss: 1.077816, loss_d: 0.009982
0.9828 --- loss: 1.134121, loss_ss: 1.119752, loss_d: 0.014368
Epoch finished! Loss: 1.107222306728363
Starting epoch 7/10.
0.0000 --- loss: 1.080804, loss_ss: 1.077116, loss_d: 0.003688
0.2457 --- loss: 0.988210, loss_ss: 0.985449, loss_d: 0.002761
0.4914 --- loss: 0.909761, loss_ss: 0.908146, loss_d: 0.001615
0.7371 --- loss: 0.946616, loss_ss: 0.939349, loss_d: 0.007267
0.9828 --- loss: 1.308754, loss_ss: 1.302679, loss_d: 0.006076
Epoch finished! Loss: 1.0356227159500122
Starting epoch 8/10.
0.0000 --- loss: 0.969984, loss_ss: 0.967276, loss_d: 0.002708
0.2457 --- loss: 0.993938, loss_ss: 0.993192, loss_d: 0.000746
0.4914 --- loss: 0.963786, loss_ss: 0.963551, loss_d: 0.000235
0.7371 --- loss: 0.968729, loss_ss: 0.962220, loss_d: 0.006509
0.9828 --- loss: 1.057240, loss_ss: 1.056577, loss_d: 0.000663
Epoch finished! Loss: 0.9952814429998398
Starting epoch 9/10.
0.0000 --- loss: 0.990283, loss_ss: 0.962807, loss_d: 0.027476
0.2457 --- loss: 0.843422, loss_ss: 0.842690, loss_d: 0.000731
0.4914 --- loss: 0.809026, loss_ss: 0.808755, loss_d: 0.000271
0.7371 --- loss: 1.071597, loss_ss: 1.071504, loss_d: 0.000094
0.9828 --- loss: 0.996992, loss_ss: 0.996965, loss_d: 0.000027
Epoch finished! Loss: 0.9555229261517525
Starting epoch 10/10.
0.0000 --- loss: 0.922404, loss_ss: 0.922308, loss_d: 0.000096
0.2457 --- loss: 0.818656, loss_ss: 0.818254, loss_d: 0.000402
0.4914 --- loss: 0.911641, loss_ss: 0.911275, loss_d: 0.000366
0.7371 --- loss: 0.798532, loss_ss: 0.796486, loss_d: 0.002046
0.9828 --- loss: 1.002185, loss_ss: 1.002075, loss_d: 0.000110
Epoch finished! Loss: 0.9182480126619339
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4866666666666667
             precision    recall  f1-score   support

        0.0       0.00      0.00      0.00       105
        1.0       0.09      0.36      0.14        44
        2.0       0.53      0.80      0.63       290
        3.0       1.00      0.28      0.44       228
        4.0       0.60      0.55      0.57       233

avg / total       0.58      0.49      0.47       900
 


====== chp058-nsrr ======

The f1-score of  0  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  88.22   0.00   99.87    0.00      0.00
1  78.11  36.36   80.26    8.65     13.97
2  70.33  79.66   65.90   52.62     63.37
3  81.78  28.07  100.00  100.00     43.84
4  78.89  54.51   87.41   60.19     57.21
Total accuracy: 48.67%
Average sen: 39.72%
Average spec: 86.69%
Macro f1-score: 35.68%
Diagnosis acc on 90mins: 1.0
[0.98477709 0.99926072 0.99999833 0.99996078 1.        ]
pred: 0.9967993855476379, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp058-nsrr

=== Test on chp059-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.276736, loss_ss: 1.619357, loss_d: 0.657380
0.2463 --- loss: 2.147376, loss_ss: 1.498378, loss_d: 0.648998
0.4926 --- loss: 1.922458, loss_ss: 1.440126, loss_d: 0.482331
0.7389 --- loss: 1.981261, loss_ss: 1.376640, loss_d: 0.604621
0.9852 --- loss: 1.847203, loss_ss: 1.354959, loss_d: 0.492244
Epoch finished! Loss: 2.106423705816269
Starting epoch 2/10.
0.0000 --- loss: 1.834808, loss_ss: 1.325489, loss_d: 0.509319
0.2463 --- loss: 1.799364, loss_ss: 1.329988, loss_d: 0.469377
0.4926 --- loss: 1.660833, loss_ss: 1.379119, loss_d: 0.281713
0.7389 --- loss: 1.713589, loss_ss: 1.295664, loss_d: 0.417925
0.9852 --- loss: 1.764365, loss_ss: 1.305314, loss_d: 0.459051
Epoch finished! Loss: 1.8257478535175324
Starting epoch 3/10.
0.0000 --- loss: 1.786886, loss_ss: 1.384841, loss_d: 0.402045
0.2463 --- loss: 1.615930, loss_ss: 1.299040, loss_d: 0.316890
0.4926 --- loss: 1.308295, loss_ss: 1.217545, loss_d: 0.090750
0.7389 --- loss: 1.515208, loss_ss: 1.269812, loss_d: 0.245396
0.9852 --- loss: 1.474084, loss_ss: 1.201995, loss_d: 0.272088
Epoch finished! Loss: 1.5128409445285798
Starting epoch 4/10.
0.0000 --- loss: 1.225130, loss_ss: 1.175258, loss_d: 0.049871
0.2463 --- loss: 1.336960, loss_ss: 1.306145, loss_d: 0.030815
0.4926 --- loss: 1.146437, loss_ss: 1.128980, loss_d: 0.017457
0.7389 --- loss: 1.354027, loss_ss: 1.181528, loss_d: 0.172498
0.9852 --- loss: 1.292785, loss_ss: 1.235970, loss_d: 0.056815
Epoch finished! Loss: 1.2599418610334396
Starting epoch 5/10.
0.0000 --- loss: 1.206313, loss_ss: 1.198667, loss_d: 0.007647
0.2463 --- loss: 1.159052, loss_ss: 1.064823, loss_d: 0.094229
0.4926 --- loss: 1.094158, loss_ss: 1.091473, loss_d: 0.002686
0.7389 --- loss: 1.068967, loss_ss: 1.061815, loss_d: 0.007153
0.9852 --- loss: 1.145522, loss_ss: 1.141567, loss_d: 0.003955
Epoch finished! Loss: 1.1529393777251244
Starting epoch 6/10.
0.0000 --- loss: 1.064794, loss_ss: 1.063351, loss_d: 0.001443
0.2463 --- loss: 1.043345, loss_ss: 1.038559, loss_d: 0.004786
0.4926 --- loss: 0.980941, loss_ss: 0.968225, loss_d: 0.012716
0.7389 --- loss: 0.928737, loss_ss: 0.926543, loss_d: 0.002195
0.9852 --- loss: 1.134960, loss_ss: 1.128543, loss_d: 0.006417
Epoch finished! Loss: 1.057095618546009
Starting epoch 7/10.
0.0000 --- loss: 0.995743, loss_ss: 0.995600, loss_d: 0.000144
0.2463 --- loss: 1.181263, loss_ss: 1.179754, loss_d: 0.001510
0.4926 --- loss: 0.879667, loss_ss: 0.878473, loss_d: 0.001195
0.7389 --- loss: 0.889869, loss_ss: 0.888961, loss_d: 0.000908
0.9852 --- loss: 0.840547, loss_ss: 0.840506, loss_d: 0.000041
Epoch finished! Loss: 0.9982114285230637
Starting epoch 8/10.
0.0000 --- loss: 1.001415, loss_ss: 1.001316, loss_d: 0.000099
0.2463 --- loss: 0.948164, loss_ss: 0.948071, loss_d: 0.000093
0.4926 --- loss: 0.862828, loss_ss: 0.862503, loss_d: 0.000326
0.7389 --- loss: 0.878676, loss_ss: 0.877040, loss_d: 0.001636
0.9852 --- loss: 0.814760, loss_ss: 0.814541, loss_d: 0.000219
Epoch finished! Loss: 0.9383099406957627
Starting epoch 9/10.
0.0000 --- loss: 0.862760, loss_ss: 0.862286, loss_d: 0.000474
0.2463 --- loss: 0.906228, loss_ss: 0.906182, loss_d: 0.000046
0.4926 --- loss: 0.948806, loss_ss: 0.948496, loss_d: 0.000311
0.7389 --- loss: 0.861716, loss_ss: 0.861367, loss_d: 0.000349
0.9852 --- loss: 0.788827, loss_ss: 0.784913, loss_d: 0.003914
Epoch finished! Loss: 0.9052036732435227
Starting epoch 10/10.
0.0000 --- loss: 0.785553, loss_ss: 0.785347, loss_d: 0.000206
0.2463 --- loss: 0.775771, loss_ss: 0.774757, loss_d: 0.001015
0.4926 --- loss: 0.934788, loss_ss: 0.933554, loss_d: 0.001234
0.7389 --- loss: 0.809426, loss_ss: 0.809143, loss_d: 0.000283
0.9852 --- loss: 0.766130, loss_ss: 0.765486, loss_d: 0.000645
Epoch finished! Loss: 0.8657304063439369
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5777777777777777
             precision    recall  f1-score   support

        0.0       0.91      0.77      0.84       233
        1.0       0.00      0.00      0.00       238
        2.0       0.64      0.82      0.72       355
        3.0       1.00      0.03      0.07        87
        4.0       0.35      0.90      0.51       167

avg / total       0.54      0.58      0.50      1080
 


====== chp059-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  93.52  77.25   97.99   91.37     83.72
1  77.96   0.00  100.00    0.00      0.00
2  79.17  81.69   77.93   64.44     72.05
3  92.22   3.45  100.00  100.00      6.67
4  72.69  90.42   69.44   35.12     50.59
Total accuracy: 57.78%
Average sen: 50.56%
Average spec: 89.07%
Macro f1-score: 42.60%
Diagnosis acc on 90mins: 1.0
[1.         0.99960679 0.9999963  0.9847036  0.99999428 0.99997878]
pred: 0.9973799586296082, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp059-nsrr

=== Test on chp060-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
Starting epoch 1/10.
0.0000 --- loss: 2.415186, loss_ss: 1.693502, loss_d: 0.721684
0.2469 --- loss: 1.977441, loss_ss: 1.501842, loss_d: 0.475599
0.4938 --- loss: 1.935826, loss_ss: 1.414208, loss_d: 0.521618
0.7407 --- loss: 2.045325, loss_ss: 1.349552, loss_d: 0.695773
0.9877 --- loss: 1.879085, loss_ss: 1.304957, loss_d: 0.574129
Epoch finished! Loss: 2.11192744076252
Starting epoch 2/10.
0.0000 --- loss: 1.617267, loss_ss: 1.256402, loss_d: 0.360865
0.2469 --- loss: 1.735425, loss_ss: 1.294739, loss_d: 0.440685
0.4938 --- loss: 1.662246, loss_ss: 1.352607, loss_d: 0.309639
0.7407 --- loss: 1.687180, loss_ss: 1.255359, loss_d: 0.431821
0.9877 --- loss: 1.481060, loss_ss: 1.324812, loss_d: 0.156248
Epoch finished! Loss: 1.7637571215629577
Starting epoch 3/10.
0.0000 --- loss: 1.597103, loss_ss: 1.271661, loss_d: 0.325442
0.2469 --- loss: 1.539665, loss_ss: 1.229308, loss_d: 0.310356
0.4938 --- loss: 1.494580, loss_ss: 1.060549, loss_d: 0.434031
0.7407 --- loss: 1.363359, loss_ss: 1.110841, loss_d: 0.252518
0.9877 --- loss: 1.358490, loss_ss: 1.268031, loss_d: 0.090459
Epoch finished! Loss: 1.4163113445043565
Starting epoch 4/10.
0.0000 --- loss: 1.185559, loss_ss: 1.139911, loss_d: 0.045648
0.2469 --- loss: 1.101192, loss_ss: 1.041256, loss_d: 0.059936
0.4938 --- loss: 1.263709, loss_ss: 1.168503, loss_d: 0.095206
0.7407 --- loss: 1.152817, loss_ss: 1.109853, loss_d: 0.042964
0.9877 --- loss: 1.058874, loss_ss: 1.056902, loss_d: 0.001972
Epoch finished! Loss: 1.1623855173587798
Starting epoch 5/10.
0.0000 --- loss: 1.046485, loss_ss: 1.043119, loss_d: 0.003366
0.2469 --- loss: 1.044708, loss_ss: 1.043161, loss_d: 0.001548
0.4938 --- loss: 1.021098, loss_ss: 1.010274, loss_d: 0.010824
0.7407 --- loss: 1.038373, loss_ss: 1.024394, loss_d: 0.013979
0.9877 --- loss: 1.060617, loss_ss: 1.057044, loss_d: 0.003573
Epoch finished! Loss: 1.0547259107232094
Starting epoch 6/10.
0.0000 --- loss: 1.208923, loss_ss: 1.207325, loss_d: 0.001598
0.2469 --- loss: 0.913749, loss_ss: 0.912616, loss_d: 0.001133
0.4938 --- loss: 1.001247, loss_ss: 0.982977, loss_d: 0.018270
0.7407 --- loss: 0.903555, loss_ss: 0.902471, loss_d: 0.001084
0.9877 --- loss: 1.304143, loss_ss: 1.248025, loss_d: 0.056117
Epoch finished! Loss: 0.9922423750162125
Starting epoch 7/10.
0.0000 --- loss: 0.900779, loss_ss: 0.898884, loss_d: 0.001894
0.2469 --- loss: 0.947001, loss_ss: 0.941685, loss_d: 0.005316
0.4938 --- loss: 1.012793, loss_ss: 1.011552, loss_d: 0.001240
0.7407 --- loss: 1.138924, loss_ss: 1.138686, loss_d: 0.000237
0.9877 --- loss: 0.824155, loss_ss: 0.823693, loss_d: 0.000462
Epoch finished! Loss: 0.9609034433960915
Starting epoch 8/10.
0.0000 --- loss: 0.827429, loss_ss: 0.827109, loss_d: 0.000320
0.2469 --- loss: 0.862768, loss_ss: 0.860793, loss_d: 0.001975
0.4938 --- loss: 0.938847, loss_ss: 0.938571, loss_d: 0.000275
0.7407 --- loss: 0.828888, loss_ss: 0.828661, loss_d: 0.000228
0.9877 --- loss: 0.993816, loss_ss: 0.993807, loss_d: 0.000009
Epoch finished! Loss: 0.9146116882562637
Starting epoch 9/10.
0.0000 --- loss: 0.938467, loss_ss: 0.938128, loss_d: 0.000338
0.2469 --- loss: 0.828639, loss_ss: 0.826276, loss_d: 0.002363
0.4938 --- loss: 0.741178, loss_ss: 0.736585, loss_d: 0.004593
0.7407 --- loss: 0.709429, loss_ss: 0.704732, loss_d: 0.004696
0.9877 --- loss: 0.807405, loss_ss: 0.801764, loss_d: 0.005641
Epoch finished! Loss: 0.9086679995059967
Starting epoch 10/10.
0.0000 --- loss: 1.070055, loss_ss: 0.927302, loss_d: 0.142754
0.2469 --- loss: 0.876250, loss_ss: 0.833785, loss_d: 0.042466
0.4938 --- loss: 0.870184, loss_ss: 0.868029, loss_d: 0.002154
0.7407 --- loss: 0.828004, loss_ss: 0.791257, loss_d: 0.036748
0.9877 --- loss: 1.107359, loss_ss: 0.918537, loss_d: 0.188822
Epoch finished! Loss: 1.0221044063568114
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4880952380952381
             precision    recall  f1-score   support

        0.0       0.89      0.39      0.55       519
        1.0       1.00      0.00      0.01       201
        2.0       0.55      0.93      0.69       228
        3.0       0.98      0.39      0.56       158
        4.0       0.23      0.87      0.37       154

avg / total       0.78      0.49      0.47      1260
 


====== chp060-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  73.02  39.50   96.49   88.74     54.67
1  84.13   0.50  100.00  100.00      0.99
2  85.00  93.42   83.14   55.04     69.27
3  92.30  39.24   99.91   98.41     56.11
4  63.17  87.01   59.86   23.18     36.61
Total accuracy: 48.81%
Average sen: 51.93%
Average spec: 87.88%
Macro f1-score: 43.53%
Diagnosis acc on 90mins: 1.0
[0.97371429 0.99832875 0.99996829 0.99893647 0.99980575 0.99737084
 0.99664897]
pred: 0.99496762241636, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp060-nsrr

====== all ======
   acc %  sen %  spec %  ppr %  f1-score
0  88.26  68.23   91.49  56.38     61.74
1  84.30  12.31   94.81  25.72     16.65
2  76.99  78.43   76.10  66.84     72.18
3  91.06  52.03   99.67  97.24     67.79
4  81.10  61.25   85.24  46.37     52.78
Total accuracy: 60.86%
Average sen: 54.45%
Average spec: 89.46%
Macro f1-score: 54.23%
Diagnosis acc on patients: 0.717948717948718

====== all ======
   acc %   sen %  spec %   ppr %  f1-score
0  71.79    4.35  100.00  100.00      8.33
1  71.79  100.00    4.35   71.43     83.33
Total accuracy: 71.79%
Average sen: 52.17%
Average spec: 52.17%
Macro f1-score: 45.83%
fpr: 0.0, tpr: 0.03636363636363636, threshold: 0.9999998807907104, 
fpr: 0.0, tpr: 0.07272727272727272, threshold: 0.9999935626983643, 
fpr: 0.043478260869565216, tpr: 0.07272727272727272, threshold: 0.9999335050582886, 
fpr: 0.043478260869565216, tpr: 0.09090909090909091, threshold: 0.9999191562334696, 
fpr: 0.08695652173913043, tpr: 0.09090909090909091, threshold: 0.9999113917350769, 
fpr: 0.08695652173913043, tpr: 0.32727272727272727, threshold: 0.9987442394097646, 
fpr: 0.13043478260869565, tpr: 0.32727272727272727, threshold: 0.9987092018127441, 
fpr: 0.13043478260869565, tpr: 0.4909090909090909, threshold: 0.9971928795178732, 
fpr: 0.21739130434782608, tpr: 0.4909090909090909, threshold: 0.9970817416906357, 
fpr: 0.21739130434782608, tpr: 0.6, threshold: 0.9964358448982239, 
fpr: 0.2608695652173913, tpr: 0.6, threshold: 0.9955119371414185, 
fpr: 0.2608695652173913, tpr: 0.6909090909090909, threshold: 0.9932459235191345, 
fpr: 0.30434782608695654, tpr: 0.6909090909090909, threshold: 0.9914678037166595, 
fpr: 0.30434782608695654, tpr: 0.7090909090909091, threshold: 0.9895509878794352, 
fpr: 0.34782608695652173, tpr: 0.7090909090909091, threshold: 0.9889833331108093, 
fpr: 0.34782608695652173, tpr: 0.8363636363636363, threshold: 0.979995846748352, 
fpr: 0.391304347826087, tpr: 0.8363636363636363, threshold: 0.9763016998767853, 
fpr: 0.391304347826087, tpr: 0.9090909090909091, threshold: 0.9603041509787241, 
fpr: 0.5652173913043478, tpr: 0.9090909090909091, threshold: 0.9283559024333954, 
fpr: 0.5652173913043478, tpr: 0.9636363636363636, threshold: 0.8752282957235972, 
fpr: 0.6521739130434783, tpr: 0.9636363636363636, threshold: 0.8371673405170441, 
fpr: 0.6521739130434783, tpr: 0.9818181818181818, threshold: 0.8260652273893356, 
fpr: 0.9565217391304348, tpr: 0.9818181818181818, threshold: 0.574913214892149, 
fpr: 0.9565217391304348, tpr: 1.0, threshold: 0.5385308712720871, 
fpr: 1.0, tpr: 1.0, threshold: 0.22273970320820807, 

=== best_threshold: 0.9603041509787241, best_fpr: 0.391304347826087, best_tpr: 0.9090909090909091 ===
fpr: 0.0, tpr: 0.0, threshold: 2.0, 
fpr: 0.009433962264150943, tpr: 0.06209150326797386, threshold: 1.0, 
fpr: 0.018867924528301886, tpr: 0.08823529411764706, threshold: 0.9999998807907104, 
fpr: 0.02830188679245283, tpr: 0.10784313725490197, threshold: 0.9999997615814209, 
fpr: 0.02830188679245283, tpr: 0.11764705882352941, threshold: 0.9999996423721313, 
fpr: 0.02830188679245283, tpr: 0.1437908496732026, threshold: 0.9999994039535522, 
fpr: 0.02830188679245283, tpr: 0.14705882352941177, threshold: 0.9999992847442627, 
fpr: 0.03773584905660377, tpr: 0.15359477124183007, threshold: 0.9999991655349731, 
fpr: 0.03773584905660377, tpr: 0.16339869281045752, threshold: 0.9999990463256836, 
fpr: 0.04716981132075472, tpr: 0.16339869281045752, threshold: 0.999998927116394, 
fpr: 0.04716981132075472, tpr: 0.16993464052287582, threshold: 0.9999985694885254, 
fpr: 0.04716981132075472, tpr: 0.1830065359477124, threshold: 0.9999983310699463, 
fpr: 0.04716981132075472, tpr: 0.19281045751633988, threshold: 0.9999982118606567, 
fpr: 0.04716981132075472, tpr: 0.19934640522875818, threshold: 0.9999980926513672, 
fpr: 0.04716981132075472, tpr: 0.20261437908496732, threshold: 0.9999978542327881, 
fpr: 0.05660377358490566, tpr: 0.20915032679738563, threshold: 0.999997615814209, 
fpr: 0.05660377358490566, tpr: 0.21895424836601307, threshold: 0.9999969005584717, 
fpr: 0.0660377358490566, tpr: 0.2222222222222222, threshold: 0.9999963045120239, 
fpr: 0.0660377358490566, tpr: 0.22549019607843138, threshold: 0.9999957084655762, 
fpr: 0.0660377358490566, tpr: 0.23202614379084968, threshold: 0.9999953508377075, 
fpr: 0.0660377358490566, tpr: 0.238562091503268, threshold: 0.9999949932098389, 
fpr: 0.07547169811320754, tpr: 0.238562091503268, threshold: 0.9999948740005493, 
fpr: 0.07547169811320754, tpr: 0.24509803921568626, threshold: 0.9999943971633911, 
fpr: 0.07547169811320754, tpr: 0.2581699346405229, threshold: 0.9999939203262329, 
fpr: 0.07547169811320754, tpr: 0.26143790849673204, threshold: 0.9999915361404419, 
fpr: 0.09433962264150944, tpr: 0.26143790849673204, threshold: 0.999990701675415, 
fpr: 0.09433962264150944, tpr: 0.2908496732026144, threshold: 0.9999860525131226, 
fpr: 0.10377358490566038, tpr: 0.29411764705882354, threshold: 0.999985933303833, 
fpr: 0.10377358490566038, tpr: 0.3104575163398693, threshold: 0.9999840259552002, 
fpr: 0.11320754716981132, tpr: 0.3104575163398693, threshold: 0.9999833106994629, 
fpr: 0.11320754716981132, tpr: 0.3137254901960784, threshold: 0.9999828338623047, 
fpr: 0.1320754716981132, tpr: 0.3137254901960784, threshold: 0.9999805688858032, 
fpr: 0.1320754716981132, tpr: 0.31699346405228757, threshold: 0.999980092048645, 
fpr: 0.1320754716981132, tpr: 0.3235294117647059, threshold: 0.9999797344207764, 
fpr: 0.1320754716981132, tpr: 0.3300653594771242, threshold: 0.9999768733978271, 
fpr: 0.14150943396226415, tpr: 0.3300653594771242, threshold: 0.999975323677063, 
fpr: 0.14150943396226415, tpr: 0.33986928104575165, threshold: 0.9999682903289795, 
fpr: 0.1509433962264151, tpr: 0.33986928104575165, threshold: 0.9999655485153198, 
fpr: 0.1509433962264151, tpr: 0.369281045751634, threshold: 0.9999591112136841, 
fpr: 0.1792452830188679, tpr: 0.369281045751634, threshold: 0.9999572038650513, 
fpr: 0.1792452830188679, tpr: 0.38562091503267976, threshold: 0.9999442100524902, 
fpr: 0.18867924528301888, tpr: 0.38562091503267976, threshold: 0.9999364614486694, 
fpr: 0.18867924528301888, tpr: 0.4019607843137255, threshold: 0.9999246597290039, 
fpr: 0.19811320754716982, tpr: 0.4019607843137255, threshold: 0.9999239444732666, 
fpr: 0.19811320754716982, tpr: 0.4117647058823529, threshold: 0.9999098777770996, 
fpr: 0.20754716981132076, tpr: 0.4117647058823529, threshold: 0.9999027252197266, 
fpr: 0.20754716981132076, tpr: 0.4150326797385621, threshold: 0.9999001026153564, 
fpr: 0.2169811320754717, tpr: 0.4150326797385621, threshold: 0.9998987913131714, 
fpr: 0.2169811320754717, tpr: 0.42483660130718953, threshold: 0.9998843669891357, 
fpr: 0.22641509433962265, tpr: 0.42483660130718953, threshold: 0.9998838901519775, 
fpr: 0.22641509433962265, tpr: 0.43790849673202614, threshold: 0.9998753070831299, 
fpr: 0.2358490566037736, tpr: 0.43790849673202614, threshold: 0.9998703002929688, 
fpr: 0.25471698113207547, tpr: 0.43790849673202614, threshold: 0.999869704246521, 
fpr: 0.25471698113207547, tpr: 0.4444444444444444, threshold: 0.9998600482940674, 
fpr: 0.2641509433962264, tpr: 0.4444444444444444, threshold: 0.9998569488525391, 
fpr: 0.2641509433962264, tpr: 0.4542483660130719, threshold: 0.9998481273651123, 
fpr: 0.27358490566037735, tpr: 0.4542483660130719, threshold: 0.9998399019241333, 
fpr: 0.27358490566037735, tpr: 0.45751633986928103, threshold: 0.9998350143432617, 
fpr: 0.2830188679245283, tpr: 0.45751633986928103, threshold: 0.9998334646224976, 
fpr: 0.2830188679245283, tpr: 0.477124183006536, threshold: 0.9998138546943665, 
fpr: 0.3018867924528302, tpr: 0.477124183006536, threshold: 0.9998109936714172, 
fpr: 0.3018867924528302, tpr: 0.4803921568627451, threshold: 0.9998093247413635, 
fpr: 0.3113207547169811, tpr: 0.4803921568627451, threshold: 0.999806821346283, 
fpr: 0.3113207547169811, tpr: 0.49019607843137253, threshold: 0.9997990727424622, 
fpr: 0.32075471698113206, tpr: 0.49019607843137253, threshold: 0.9997888207435608, 
fpr: 0.32075471698113206, tpr: 0.4934640522875817, threshold: 0.9997748732566833, 
fpr: 0.330188679245283, tpr: 0.4934640522875817, threshold: 0.9997727274894714, 
fpr: 0.330188679245283, tpr: 0.5065359477124183, threshold: 0.9997630715370178, 
fpr: 0.33962264150943394, tpr: 0.5065359477124183, threshold: 0.999762237071991, 
fpr: 0.33962264150943394, tpr: 0.5588235294117647, threshold: 0.9995952248573303, 
fpr: 0.3584905660377358, tpr: 0.5588235294117647, threshold: 0.999542236328125, 
fpr: 0.3584905660377358, tpr: 0.5816993464052288, threshold: 0.9994151592254639, 
fpr: 0.36792452830188677, tpr: 0.5816993464052288, threshold: 0.999403715133667, 
fpr: 0.36792452830188677, tpr: 0.5980392156862745, threshold: 0.9992802739143372, 
fpr: 0.37735849056603776, tpr: 0.5980392156862745, threshold: 0.9992708563804626, 
fpr: 0.37735849056603776, tpr: 0.6013071895424836, threshold: 0.9992607235908508, 
fpr: 0.3867924528301887, tpr: 0.6013071895424836, threshold: 0.9992561936378479, 
fpr: 0.3867924528301887, tpr: 0.6568627450980392, threshold: 0.9988712668418884, 
fpr: 0.39622641509433965, tpr: 0.6568627450980392, threshold: 0.9988583326339722, 
fpr: 0.39622641509433965, tpr: 0.6830065359477124, threshold: 0.9986520409584045, 
fpr: 0.4056603773584906, tpr: 0.6830065359477124, threshold: 0.9986459612846375, 
fpr: 0.4056603773584906, tpr: 0.6895424836601307, threshold: 0.998551070690155, 
fpr: 0.41509433962264153, tpr: 0.6895424836601307, threshold: 0.9984925985336304, 
fpr: 0.41509433962264153, tpr: 0.7156862745098039, threshold: 0.9982727766036987, 
fpr: 0.42452830188679247, tpr: 0.7156862745098039, threshold: 0.9981456995010376, 
fpr: 0.42452830188679247, tpr: 0.7352941176470589, threshold: 0.997914731502533, 
fpr: 0.4339622641509434, tpr: 0.7352941176470589, threshold: 0.9979131817817688, 
fpr: 0.4339622641509434, tpr: 0.7516339869281046, threshold: 0.9973708391189575, 
fpr: 0.44339622641509435, tpr: 0.7516339869281046, threshold: 0.9970366954803467, 
fpr: 0.44339622641509435, tpr: 0.7581699346405228, threshold: 0.9966489672660828, 
fpr: 0.46226415094339623, tpr: 0.7581699346405228, threshold: 0.9962816834449768, 
fpr: 0.46226415094339623, tpr: 0.7745098039215687, threshold: 0.9956583976745605, 
fpr: 0.4716981132075472, tpr: 0.7745098039215687, threshold: 0.9954496026039124, 
fpr: 0.4716981132075472, tpr: 0.7777777777777778, threshold: 0.9952300786972046, 
fpr: 0.4811320754716981, tpr: 0.7777777777777778, threshold: 0.9951605200767517, 
fpr: 0.4811320754716981, tpr: 0.8006535947712419, threshold: 0.9936933517456055, 
fpr: 0.49056603773584906, tpr: 0.8006535947712419, threshold: 0.993399977684021, 
fpr: 0.49056603773584906, tpr: 0.803921568627451, threshold: 0.9931797981262207, 
fpr: 0.5094339622641509, tpr: 0.803921568627451, threshold: 0.9923906922340393, 
fpr: 0.5094339622641509, tpr: 0.8104575163398693, threshold: 0.9913593530654907, 
fpr: 0.5188679245283019, tpr: 0.8104575163398693, threshold: 0.9911551475524902, 
fpr: 0.5188679245283019, tpr: 0.8137254901960784, threshold: 0.9910711050033569, 
fpr: 0.5283018867924528, tpr: 0.8137254901960784, threshold: 0.9909795522689819, 
fpr: 0.5283018867924528, tpr: 0.8562091503267973, threshold: 0.9876599907875061, 
fpr: 0.5377358490566038, tpr: 0.8562091503267973, threshold: 0.987628698348999, 
fpr: 0.5377358490566038, tpr: 0.8758169934640523, threshold: 0.9847036004066467, 
fpr: 0.5471698113207547, tpr: 0.8758169934640523, threshold: 0.984486997127533, 
fpr: 0.5471698113207547, tpr: 0.8823529411764706, threshold: 0.9842118620872498, 
fpr: 0.5566037735849056, tpr: 0.8823529411764706, threshold: 0.9842060804367065, 
fpr: 0.5566037735849056, tpr: 0.8856209150326797, threshold: 0.983161449432373, 
fpr: 0.5660377358490566, tpr: 0.8856209150326797, threshold: 0.9821516275405884, 
fpr: 0.5660377358490566, tpr: 0.8954248366013072, threshold: 0.9811764359474182, 
fpr: 0.5754716981132075, tpr: 0.8954248366013072, threshold: 0.9811541438102722, 
fpr: 0.5754716981132075, tpr: 0.9052287581699346, threshold: 0.9798105955123901, 
fpr: 0.5943396226415094, tpr: 0.9052287581699346, threshold: 0.9782010316848755, 
fpr: 0.5943396226415094, tpr: 0.9150326797385621, threshold: 0.9724097847938538, 
fpr: 0.6037735849056604, tpr: 0.9150326797385621, threshold: 0.9714995622634888, 
fpr: 0.6037735849056604, tpr: 0.9248366013071896, threshold: 0.9677298069000244, 
fpr: 0.6320754716981132, tpr: 0.9248366013071896, threshold: 0.962448000907898, 
fpr: 0.6320754716981132, tpr: 0.934640522875817, threshold: 0.9548095464706421, 
fpr: 0.6509433962264151, tpr: 0.934640522875817, threshold: 0.9486330151557922, 
fpr: 0.6509433962264151, tpr: 0.9411764705882353, threshold: 0.9459378719329834, 
fpr: 0.6698113207547169, tpr: 0.9411764705882353, threshold: 0.9452745318412781, 
fpr: 0.6698113207547169, tpr: 0.954248366013072, threshold: 0.9374164342880249, 
fpr: 0.6792452830188679, tpr: 0.954248366013072, threshold: 0.934179425239563, 
fpr: 0.6792452830188679, tpr: 0.9575163398692811, threshold: 0.9296436905860901, 
fpr: 0.6886792452830188, tpr: 0.9575163398692811, threshold: 0.9289140701293945, 
fpr: 0.6886792452830188, tpr: 0.9607843137254902, threshold: 0.9168344736099243, 
fpr: 0.6981132075471698, tpr: 0.9607843137254902, threshold: 0.9052789211273193, 
fpr: 0.6981132075471698, tpr: 0.9640522875816994, threshold: 0.9052004218101501, 
fpr: 0.7452830188679245, tpr: 0.9640522875816994, threshold: 0.8579924702644348, 
fpr: 0.7452830188679245, tpr: 0.9738562091503268, threshold: 0.8250766396522522, 
fpr: 0.7641509433962265, tpr: 0.9738562091503268, threshold: 0.7758045196533203, 
fpr: 0.7641509433962265, tpr: 0.9771241830065359, threshold: 0.7713033556938171, 
fpr: 0.8584905660377359, tpr: 0.9771241830065359, threshold: 0.5691736936569214, 
fpr: 0.8584905660377359, tpr: 0.9901960784313726, threshold: 0.4360734522342682, 
fpr: 0.9245283018867925, tpr: 0.9901960784313726, threshold: 0.24015796184539795, 
fpr: 0.9245283018867925, tpr: 0.9934640522875817, threshold: 0.2165488302707672, 
fpr: 0.9433962264150944, tpr: 0.9934640522875817, threshold: 0.16249600052833557, 
fpr: 0.9433962264150944, tpr: 1.0, threshold: 0.13432864844799042, 
fpr: 1.0, tpr: 1.0, threshold: 0.03538009151816368, 

=== best_threshold: 0.9847036004066467, best_fpr: 0.5377358490566038, best_tpr: 0.8758169934640523 ===
