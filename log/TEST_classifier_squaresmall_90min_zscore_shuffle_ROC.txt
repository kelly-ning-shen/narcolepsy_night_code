cuda:1
Subjects num: 78

90min inputs: chc001-nsrr (4)
90min inputs: chc004-nsrr (5)
90min inputs: chc005-nsrr (5)
90min inputs: chc006-nsrr (4)
90min inputs: chc008-nsrr (5)
90min inputs: chc009-nsrr (4)
90min inputs: chc010-nsrr (4)
90min inputs: chc012-nsrr (5)
90min inputs: chc013-nsrr (5)
90min inputs: chc014-nsrr (5)
90min inputs: chc015-nsrr (5)
90min inputs: chc016-nsrr (5)
90min inputs: chc022-nsrr (4)
90min inputs: chc025-nsrr (4)
90min inputs: chc027-nsrr (5)
90min inputs: chc028-nsrr (4)
90min inputs: chc033-nsrr (4)
90min inputs: chc035-nsrr (5)
90min inputs: chc037-nsrr (4)
90min inputs: chc040-nsrr (6)
90min inputs: chc041-nsrr (4)
90min inputs: chc052-nsrr (5)
90min inputs: chc056-nsrr (5)
90min inputs: chp001-nsrr (6)
90min inputs: chp002-nsrr (6)
90min inputs: chp003-nsrr (5)
90min inputs: chp004-nsrr (5)
90min inputs: chp005-nsrr (7)
90min inputs: chp006-nsrr (6)
90min inputs: chp007-nsrr (6)
90min inputs: chp008-nsrr (5)
90min inputs: chp009-nsrr (5)
90min inputs: chp010-nsrr (5)
90min inputs: chp011-nsrr (5)
90min inputs: chp012-nsrr (6)
90min inputs: chp013-nsrr (5)
90min inputs: chp014-nsrr (5)
90min inputs: chp015-nsrr (6)
90min inputs: chp016-nsrr (7)
90min inputs: chp017-nsrr (5)
90min inputs: chp018-nsrr (6)
90min inputs: chp019-nsrr (5)
90min inputs: chp020-nsrr (6)
90min inputs: chp022-nsrr (7)
90min inputs: chp024-nsrr (6)
90min inputs: chp025-nsrr (2)
90min inputs: chp026-nsrr (5)
90min inputs: chp028-nsrr (5)
90min inputs: chp029-nsrr (5)
90min inputs: chp030-nsrr (6)
90min inputs: chp031-nsrr (6)
90min inputs: chp032-nsrr (5)
90min inputs: chp033-nsrr (5)
90min inputs: chp034-nsrr (5)
90min inputs: chp036-nsrr (7)
90min inputs: chp037-nsrr (5)
90min inputs: chp038-nsrr (5)
90min inputs: chp039-nsrr (6)
90min inputs: chp040-nsrr (5)
90min inputs: chp041-nsrr (6)
90min inputs: chp042-nsrr (6)
90min inputs: chp043-nsrr (6)
90min inputs: chp044-nsrr (5)
90min inputs: chp045-nsrr (6)
90min inputs: chp046-nsrr (6)
90min inputs: chp047-nsrr (4)
90min inputs: chp048-nsrr (5)
90min inputs: chp049-nsrr (6)
90min inputs: chp051-nsrr (6)
90min inputs: chp052-nsrr (5)
90min inputs: chp053-nsrr (6)
90min inputs: chp054-nsrr (6)
90min inputs: chp055-nsrr (6)
90min inputs: chp056-nsrr (6)
90min inputs: chp057-nsrr (6)
90min inputs: chp058-nsrr (5)
90min inputs: chp059-nsrr (6)
90min inputs: chp060-nsrr (7)

=== Test on chc001-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.250469, loss_ss: 1.540815, loss_d: 0.709654
0.2451 --- loss: 1.881499, loss_ss: 1.409433, loss_d: 0.472066
0.4902 --- loss: 1.800284, loss_ss: 1.319668, loss_d: 0.480616
0.7353 --- loss: 1.641855, loss_ss: 1.341885, loss_d: 0.299969
0.9804 --- loss: 1.690843, loss_ss: 1.273524, loss_d: 0.417319
Epoch finished! Loss: 2.008290547132492
Starting epoch 2/10.
0.0000 --- loss: 1.626858, loss_ss: 1.224241, loss_d: 0.402616
0.2451 --- loss: 1.603666, loss_ss: 1.243554, loss_d: 0.360112
0.4902 --- loss: 1.735225, loss_ss: 1.189081, loss_d: 0.546144
0.7353 --- loss: 1.932572, loss_ss: 1.155356, loss_d: 0.777215
0.9804 --- loss: 1.819002, loss_ss: 1.081935, loss_d: 0.737067
Epoch finished! Loss: 1.7914007425308227
Starting epoch 3/10.
0.0000 --- loss: 1.798760, loss_ss: 1.310692, loss_d: 0.488067
0.2451 --- loss: 1.645552, loss_ss: 1.171427, loss_d: 0.474125
0.4902 --- loss: 1.671412, loss_ss: 1.103839, loss_d: 0.567574
0.7353 --- loss: 1.659764, loss_ss: 1.089257, loss_d: 0.570507
0.9804 --- loss: 1.407079, loss_ss: 1.122650, loss_d: 0.284428
Epoch finished! Loss: 1.6820284008979798
Starting epoch 4/10.
0.0000 --- loss: 1.397919, loss_ss: 1.173872, loss_d: 0.224046
0.2451 --- loss: 2.643838, loss_ss: 0.944731, loss_d: 1.699107
0.4902 --- loss: 1.305959, loss_ss: 1.049345, loss_d: 0.256614
0.7353 --- loss: 1.404397, loss_ss: 1.102408, loss_d: 0.301989
0.9804 --- loss: 1.557796, loss_ss: 1.120340, loss_d: 0.437455
Epoch finished! Loss: 1.5083619624376297
Starting epoch 5/10.
0.0000 --- loss: 1.229639, loss_ss: 1.095585, loss_d: 0.134054
0.2451 --- loss: 1.344854, loss_ss: 1.029885, loss_d: 0.314969
0.4902 --- loss: 1.581448, loss_ss: 1.209830, loss_d: 0.371618
0.7353 --- loss: 1.130978, loss_ss: 0.984188, loss_d: 0.146791
0.9804 --- loss: 1.171469, loss_ss: 1.010403, loss_d: 0.161066
Epoch finished! Loss: 1.4205440491437913
Starting epoch 6/10.
0.0000 --- loss: 1.427722, loss_ss: 1.078189, loss_d: 0.349533
0.2451 --- loss: 1.215388, loss_ss: 1.052357, loss_d: 0.163030
0.4902 --- loss: 1.202136, loss_ss: 1.163818, loss_d: 0.038319
0.7353 --- loss: 1.033724, loss_ss: 0.961018, loss_d: 0.072706
0.9804 --- loss: 1.239026, loss_ss: 1.184188, loss_d: 0.054837
Epoch finished! Loss: 1.2790749818086624
Starting epoch 7/10.
0.0000 --- loss: 1.293716, loss_ss: 1.263371, loss_d: 0.030346
0.2451 --- loss: 1.257121, loss_ss: 1.107220, loss_d: 0.149901
0.4902 --- loss: 1.467151, loss_ss: 0.962333, loss_d: 0.504818
0.7353 --- loss: 1.118777, loss_ss: 0.995739, loss_d: 0.123038
0.9804 --- loss: 1.241346, loss_ss: 1.200917, loss_d: 0.040429
Epoch finished! Loss: 1.2304442465305327
Starting epoch 8/10.
0.0000 --- loss: 1.100037, loss_ss: 1.050949, loss_d: 0.049088
0.2451 --- loss: 1.072463, loss_ss: 1.043521, loss_d: 0.028942
0.4902 --- loss: 1.108994, loss_ss: 1.041996, loss_d: 0.066997
0.7353 --- loss: 1.390660, loss_ss: 1.007819, loss_d: 0.382842
0.9804 --- loss: 1.076170, loss_ss: 0.969933, loss_d: 0.106237
Epoch finished! Loss: 1.1807741463184356
Starting epoch 9/10.
0.0000 --- loss: 1.092880, loss_ss: 1.056169, loss_d: 0.036711
0.2451 --- loss: 1.115041, loss_ss: 1.074908, loss_d: 0.040133
0.4902 --- loss: 1.266329, loss_ss: 1.125473, loss_d: 0.140857
0.7353 --- loss: 1.249962, loss_ss: 1.239460, loss_d: 0.010502
0.9804 --- loss: 1.011792, loss_ss: 0.995904, loss_d: 0.015888
Epoch finished! Loss: 1.1175053253769875
Starting epoch 10/10.
0.0000 --- loss: 0.911806, loss_ss: 0.900117, loss_d: 0.011689
0.2451 --- loss: 0.825817, loss_ss: 0.817750, loss_d: 0.008067
0.4902 --- loss: 0.952781, loss_ss: 0.866072, loss_d: 0.086709
0.7353 --- loss: 1.032934, loss_ss: 1.025443, loss_d: 0.007492
0.9804 --- loss: 1.017025, loss_ss: 1.011918, loss_d: 0.005106
Epoch finished! Loss: 1.0293462917208671
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7638888888888888
              precision    recall  f1-score   support

         0.0       0.52      0.91      0.66        77
         1.0       0.40      0.04      0.08        48
         2.0       0.84      0.86      0.85       340
         3.0       0.76      1.00      0.86       143
         4.0       1.00      0.37      0.54       112

    accuracy                           0.76       720
   macro avg       0.70      0.64      0.60       720
weighted avg       0.78      0.76      0.73       720
 


====== chc001-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  90.14   90.91   90.05   52.24     66.35
1  93.19    4.17   99.55   40.00      7.55
2  85.56   86.47   84.74   83.52     84.97
3  93.75  100.00   92.20   76.06     86.40
4  90.14   36.61  100.00  100.00     53.59
Total accuracy: 76.39%
Average sen: 63.63%
Average spec: 93.31%
Macro f1-score: 59.77%
Diagnosis acc on 90mins: 0.0
[0.70339245 0.98890591 0.99648464 0.98133415]
pred: 0.917529284954071, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc001-nsrr

=== Test on chc004-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.404825, loss_ss: 1.726488, loss_d: 0.678337
0.2457 --- loss: 2.201834, loss_ss: 1.614809, loss_d: 0.587025
0.4914 --- loss: 2.468138, loss_ss: 1.572837, loss_d: 0.895301
0.7371 --- loss: 1.977879, loss_ss: 1.485195, loss_d: 0.492683
0.9828 --- loss: 1.956489, loss_ss: 1.498518, loss_d: 0.457971
Epoch finished! Loss: 2.2746188163757326
Starting epoch 2/10.
0.0000 --- loss: 1.995363, loss_ss: 1.477205, loss_d: 0.518158
0.2457 --- loss: 2.108223, loss_ss: 1.501577, loss_d: 0.606646
0.4914 --- loss: 2.011226, loss_ss: 1.448044, loss_d: 0.563182
0.7371 --- loss: 1.782672, loss_ss: 1.431956, loss_d: 0.350716
0.9828 --- loss: 1.962792, loss_ss: 1.415447, loss_d: 0.547344
Epoch finished! Loss: 2.0189899861812592
Starting epoch 3/10.
0.0000 --- loss: 1.775008, loss_ss: 1.370237, loss_d: 0.404771
0.2457 --- loss: 1.870048, loss_ss: 1.406502, loss_d: 0.463547
0.4914 --- loss: 1.734937, loss_ss: 1.321873, loss_d: 0.413065
0.7371 --- loss: 1.666013, loss_ss: 1.342799, loss_d: 0.323213
0.9828 --- loss: 1.761020, loss_ss: 1.360858, loss_d: 0.400163
Epoch finished! Loss: 1.839658287167549
Starting epoch 4/10.
0.0000 --- loss: 1.572236, loss_ss: 1.337072, loss_d: 0.235164
0.2457 --- loss: 1.602305, loss_ss: 1.195438, loss_d: 0.406867
0.4914 --- loss: 1.970367, loss_ss: 1.259085, loss_d: 0.711282
0.7371 --- loss: 1.597291, loss_ss: 1.163010, loss_d: 0.434282
0.9828 --- loss: 1.521431, loss_ss: 1.237517, loss_d: 0.283914
Epoch finished! Loss: 1.7400112926959992
Starting epoch 5/10.
0.0000 --- loss: 1.584459, loss_ss: 1.195618, loss_d: 0.388841
0.2457 --- loss: 1.387107, loss_ss: 1.141777, loss_d: 0.245330
0.4914 --- loss: 1.587903, loss_ss: 1.061443, loss_d: 0.526460
0.7371 --- loss: 1.395245, loss_ss: 1.101249, loss_d: 0.293996
0.9828 --- loss: 1.454991, loss_ss: 1.199451, loss_d: 0.255540
Epoch finished! Loss: 1.5594953507184983
Starting epoch 6/10.
0.0000 --- loss: 1.516175, loss_ss: 1.146747, loss_d: 0.369428
0.2457 --- loss: 1.323416, loss_ss: 1.067647, loss_d: 0.255770
0.4914 --- loss: 1.499977, loss_ss: 1.012355, loss_d: 0.487622
0.7371 --- loss: 1.665371, loss_ss: 1.122784, loss_d: 0.542587
0.9828 --- loss: 1.584047, loss_ss: 1.132229, loss_d: 0.451818
Epoch finished! Loss: 1.515945240855217
Starting epoch 7/10.
0.0000 --- loss: 1.297214, loss_ss: 1.012386, loss_d: 0.284828
0.2457 --- loss: 1.210311, loss_ss: 1.116969, loss_d: 0.093343
0.4914 --- loss: 1.522403, loss_ss: 1.175194, loss_d: 0.347210
0.7371 --- loss: 1.258435, loss_ss: 1.142928, loss_d: 0.115507
0.9828 --- loss: 1.401335, loss_ss: 0.980188, loss_d: 0.421148
Epoch finished! Loss: 1.3818662285804748
Starting epoch 8/10.
0.0000 --- loss: 1.438916, loss_ss: 1.233131, loss_d: 0.205786
0.2457 --- loss: 1.128927, loss_ss: 1.052263, loss_d: 0.076664
0.4914 --- loss: 1.277628, loss_ss: 1.064238, loss_d: 0.213390
0.7371 --- loss: 1.143888, loss_ss: 1.064533, loss_d: 0.079355
0.9828 --- loss: 1.358931, loss_ss: 1.162124, loss_d: 0.196807
Epoch finished! Loss: 1.215964289009571
Starting epoch 9/10.
0.0000 --- loss: 1.281275, loss_ss: 1.194125, loss_d: 0.087150
0.2457 --- loss: 1.404214, loss_ss: 1.168137, loss_d: 0.236077
0.4914 --- loss: 1.107841, loss_ss: 0.983827, loss_d: 0.124014
0.7371 --- loss: 1.160427, loss_ss: 0.974067, loss_d: 0.186361
0.9828 --- loss: 1.560558, loss_ss: 1.160926, loss_d: 0.399632
Epoch finished! Loss: 1.1793838322162629
Starting epoch 10/10.
0.0000 --- loss: 0.956741, loss_ss: 0.937437, loss_d: 0.019303
0.2457 --- loss: 1.140665, loss_ss: 0.991336, loss_d: 0.149329
0.4914 --- loss: 1.150722, loss_ss: 0.927002, loss_d: 0.223720
0.7371 --- loss: 1.052308, loss_ss: 0.987744, loss_d: 0.064563
0.9828 --- loss: 1.210316, loss_ss: 1.100620, loss_d: 0.109696
Epoch finished! Loss: 1.1553764209151267
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8233333333333334
              precision    recall  f1-score   support

         0.0       0.84      0.58      0.69        74
         1.0       0.00      0.00      0.00        41
         2.0       0.84      0.90      0.87       467
         3.0       0.95      0.80      0.87       203
         4.0       0.65      1.00      0.78       115

    accuracy                           0.82       900
   macro avg       0.66      0.66      0.64       900
weighted avg       0.80      0.82      0.80       900
 


====== chc004-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  95.67   58.11   99.03  84.31     68.80
1  95.44    0.00  100.00   0.00      0.00
2  86.11   90.15   81.76  84.20     87.07
3  94.44   79.80   98.71  94.74     86.63
4  93.00  100.00   91.97  64.61     78.50
Total accuracy: 82.33%
Average sen: 65.61%
Average spec: 94.29%
Macro f1-score: 64.20%
Diagnosis acc on 90mins: 0.2
[0.77101529 0.00958415 0.90424448 0.66242594 0.99644059]
pred: 0.6687420886009932, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc004-nsrr

=== Test on chc005-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.239135, loss_ss: 1.570377, loss_d: 0.668758
0.2457 --- loss: 2.187305, loss_ss: 1.376266, loss_d: 0.811040
0.4914 --- loss: 1.933717, loss_ss: 1.354837, loss_d: 0.578880
0.7371 --- loss: 1.669227, loss_ss: 1.263775, loss_d: 0.405453
0.9828 --- loss: 1.733584, loss_ss: 1.345396, loss_d: 0.388189
Epoch finished! Loss: 2.0469074577093123
Starting epoch 2/10.
0.0000 --- loss: 1.763313, loss_ss: 1.209348, loss_d: 0.553966
0.2457 --- loss: 1.834936, loss_ss: 1.192870, loss_d: 0.642066
0.4914 --- loss: 1.584581, loss_ss: 1.181180, loss_d: 0.403401
0.7371 --- loss: 1.867376, loss_ss: 1.259976, loss_d: 0.607400
0.9828 --- loss: 1.837729, loss_ss: 1.231563, loss_d: 0.606166
Epoch finished! Loss: 1.807770735025406
Starting epoch 3/10.
0.0000 --- loss: 1.509778, loss_ss: 1.112248, loss_d: 0.397529
0.2457 --- loss: 1.577195, loss_ss: 1.157297, loss_d: 0.419897
0.4914 --- loss: 1.461627, loss_ss: 1.154712, loss_d: 0.306915
0.7371 --- loss: 1.753044, loss_ss: 1.127081, loss_d: 0.625962
0.9828 --- loss: 2.105818, loss_ss: 1.381259, loss_d: 0.724559
Epoch finished! Loss: 1.7493726104497909
Starting epoch 4/10.
0.0000 --- loss: 1.543740, loss_ss: 1.180633, loss_d: 0.363107
0.2457 --- loss: 1.548038, loss_ss: 1.093559, loss_d: 0.454479
0.4914 --- loss: 1.670802, loss_ss: 1.120302, loss_d: 0.550500
0.7371 --- loss: 1.828012, loss_ss: 1.130382, loss_d: 0.697630
0.9828 --- loss: 1.547548, loss_ss: 1.083956, loss_d: 0.463592
Epoch finished! Loss: 1.664056995511055
Starting epoch 5/10.
0.0000 --- loss: 1.658543, loss_ss: 1.152604, loss_d: 0.505939
0.2457 --- loss: 1.386560, loss_ss: 1.104534, loss_d: 0.282027
0.4914 --- loss: 1.540069, loss_ss: 1.155892, loss_d: 0.384177
0.7371 --- loss: 1.521336, loss_ss: 0.927460, loss_d: 0.593876
0.9828 --- loss: 1.288375, loss_ss: 0.975683, loss_d: 0.312692
Epoch finished! Loss: 1.5466613262891769
Starting epoch 6/10.
0.0000 --- loss: 1.405662, loss_ss: 1.026150, loss_d: 0.379512
0.2457 --- loss: 1.565868, loss_ss: 1.018574, loss_d: 0.547294
0.4914 --- loss: 1.506231, loss_ss: 1.237429, loss_d: 0.268802
0.7371 --- loss: 1.395882, loss_ss: 0.985534, loss_d: 0.410348
0.9828 --- loss: 1.362596, loss_ss: 0.980785, loss_d: 0.381811
Epoch finished! Loss: 1.5260017305612563
Starting epoch 7/10.
0.0000 --- loss: 1.247374, loss_ss: 0.965546, loss_d: 0.281828
0.2457 --- loss: 1.329776, loss_ss: 0.971396, loss_d: 0.358380
0.4914 --- loss: 1.917859, loss_ss: 1.009105, loss_d: 0.908754
0.7371 --- loss: 1.325951, loss_ss: 0.860092, loss_d: 0.465858
0.9828 --- loss: 1.376411, loss_ss: 1.079777, loss_d: 0.296634
Epoch finished! Loss: 1.4692550629377366
Starting epoch 8/10.
0.0000 --- loss: 1.202320, loss_ss: 1.072058, loss_d: 0.130263
0.2457 --- loss: 1.285854, loss_ss: 1.116030, loss_d: 0.169824
0.4914 --- loss: 1.063558, loss_ss: 0.902010, loss_d: 0.161547
0.7371 --- loss: 1.396951, loss_ss: 0.994670, loss_d: 0.402281
0.9828 --- loss: 1.085922, loss_ss: 0.932375, loss_d: 0.153547
Epoch finished! Loss: 1.3847725242376328
Starting epoch 9/10.
0.0000 --- loss: 1.335086, loss_ss: 0.984408, loss_d: 0.350679
0.2457 --- loss: 1.228205, loss_ss: 0.879470, loss_d: 0.348735
0.4914 --- loss: 1.400969, loss_ss: 0.978037, loss_d: 0.422933
0.7371 --- loss: 1.078142, loss_ss: 0.861751, loss_d: 0.216391
0.9828 --- loss: 1.203362, loss_ss: 0.942782, loss_d: 0.260580
Epoch finished! Loss: 1.2513346448540688
Starting epoch 10/10.
0.0000 --- loss: 1.121795, loss_ss: 0.900489, loss_d: 0.221306
0.2457 --- loss: 0.854611, loss_ss: 0.763914, loss_d: 0.090697
0.4914 --- loss: 1.138840, loss_ss: 1.099030, loss_d: 0.039810
0.7371 --- loss: 1.044433, loss_ss: 0.971317, loss_d: 0.073115
0.9828 --- loss: 0.947743, loss_ss: 0.899511, loss_d: 0.048233
Epoch finished! Loss: 1.1604742974042892
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7922222222222223
              precision    recall  f1-score   support

         0.0       0.29      0.95      0.45        40
         1.0       0.00      0.00      0.00        30
         2.0       0.89      0.83      0.86       504
         3.0       0.88      0.82      0.85       236
         4.0       0.77      0.69      0.73        90

    accuracy                           0.79       900
   macro avg       0.57      0.66      0.58       900
weighted avg       0.82      0.79      0.80       900
 


====== chc005-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  89.56  95.00   89.30  29.23     44.71
1  96.67   0.00  100.00   0.00      0.00
2  85.00  83.13   87.37  89.34     86.13
3  92.44  82.20   96.08  88.18     85.09
4  94.78  68.89   97.65  76.54     72.51
Total accuracy: 79.22%
Average sen: 65.85%
Average spec: 94.08%
Macro f1-score: 57.69%
Diagnosis acc on 90mins: 0.4
[0.56798214 0.11014419 0.74920845 0.36671105 0.98161227]
pred: 0.5551316186785697, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc005-nsrr

=== Test on chc006-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.368300, loss_ss: 1.645659, loss_d: 0.722642
0.2451 --- loss: 2.247856, loss_ss: 1.455701, loss_d: 0.792155
0.4902 --- loss: 1.849649, loss_ss: 1.345552, loss_d: 0.504097
0.7353 --- loss: 1.790502, loss_ss: 1.313325, loss_d: 0.477177
0.9804 --- loss: 2.101002, loss_ss: 1.348818, loss_d: 0.752184
Epoch finished! Loss: 2.098825070261955
Starting epoch 2/10.
0.0000 --- loss: 1.687157, loss_ss: 1.284070, loss_d: 0.403087
0.2451 --- loss: 1.988849, loss_ss: 1.291946, loss_d: 0.696904
0.4902 --- loss: 1.559474, loss_ss: 1.285557, loss_d: 0.273917
0.7353 --- loss: 1.755910, loss_ss: 1.181781, loss_d: 0.574129
0.9804 --- loss: 1.586970, loss_ss: 1.230449, loss_d: 0.356521
Epoch finished! Loss: 1.8542186915874481
Starting epoch 3/10.
0.0000 --- loss: 1.490105, loss_ss: 1.210886, loss_d: 0.279219
0.2451 --- loss: 1.918365, loss_ss: 1.313609, loss_d: 0.604755
0.4902 --- loss: 1.697845, loss_ss: 1.277222, loss_d: 0.420623
0.7353 --- loss: 1.732835, loss_ss: 1.335792, loss_d: 0.397043
0.9804 --- loss: 1.943710, loss_ss: 1.293774, loss_d: 0.649936
Epoch finished! Loss: 1.772238275408745
Starting epoch 4/10.
0.0000 --- loss: 1.607791, loss_ss: 1.170364, loss_d: 0.437427
0.2451 --- loss: 1.821774, loss_ss: 1.191085, loss_d: 0.630689
0.4902 --- loss: 1.441883, loss_ss: 1.079355, loss_d: 0.362528
0.7353 --- loss: 1.680078, loss_ss: 1.155053, loss_d: 0.525025
0.9804 --- loss: 1.434935, loss_ss: 1.169736, loss_d: 0.265199
Epoch finished! Loss: 1.6493497341871262
Starting epoch 5/10.
0.0000 --- loss: 1.331378, loss_ss: 1.114316, loss_d: 0.217062
0.2451 --- loss: 1.720916, loss_ss: 1.119530, loss_d: 0.601386
0.4902 --- loss: 1.488440, loss_ss: 1.218659, loss_d: 0.269781
0.7353 --- loss: 1.573885, loss_ss: 1.190160, loss_d: 0.383725
0.9804 --- loss: 1.197718, loss_ss: 1.102226, loss_d: 0.095492
Epoch finished! Loss: 1.482101047039032
Starting epoch 6/10.
0.0000 --- loss: 1.425952, loss_ss: 1.134594, loss_d: 0.291358
0.2451 --- loss: 1.257596, loss_ss: 1.081463, loss_d: 0.176133
0.4902 --- loss: 1.306075, loss_ss: 1.070153, loss_d: 0.235922
0.7353 --- loss: 1.175700, loss_ss: 1.011037, loss_d: 0.164663
0.9804 --- loss: 1.356954, loss_ss: 1.015948, loss_d: 0.341007
Epoch finished! Loss: 1.3995185434818267
Starting epoch 7/10.
0.0000 --- loss: 1.054950, loss_ss: 1.017498, loss_d: 0.037452
0.2451 --- loss: 1.146376, loss_ss: 1.099697, loss_d: 0.046679
0.4902 --- loss: 1.165645, loss_ss: 1.049404, loss_d: 0.116241
0.7353 --- loss: 1.122073, loss_ss: 1.046310, loss_d: 0.075763
0.9804 --- loss: 1.086169, loss_ss: 1.038959, loss_d: 0.047210
Epoch finished! Loss: 1.223078328371048
Starting epoch 8/10.
0.0000 --- loss: 1.141650, loss_ss: 0.969421, loss_d: 0.172229
0.2451 --- loss: 1.061706, loss_ss: 1.034117, loss_d: 0.027589
0.4902 --- loss: 1.180368, loss_ss: 1.103857, loss_d: 0.076511
0.7353 --- loss: 1.026357, loss_ss: 0.956886, loss_d: 0.069471
0.9804 --- loss: 1.202582, loss_ss: 1.081705, loss_d: 0.120877
Epoch finished! Loss: 1.216703636944294
Starting epoch 9/10.
0.0000 --- loss: 0.975220, loss_ss: 0.906474, loss_d: 0.068746
0.2451 --- loss: 1.149697, loss_ss: 1.040386, loss_d: 0.109311
0.4902 --- loss: 1.043700, loss_ss: 0.998704, loss_d: 0.044996
0.7353 --- loss: 0.958575, loss_ss: 0.935455, loss_d: 0.023120
0.9804 --- loss: 1.001214, loss_ss: 0.963807, loss_d: 0.037406
Epoch finished! Loss: 1.0801148489117622
Starting epoch 10/10.
0.0000 --- loss: 0.828643, loss_ss: 0.821141, loss_d: 0.007502
0.2451 --- loss: 1.027909, loss_ss: 1.014010, loss_d: 0.013899
0.4902 --- loss: 0.794019, loss_ss: 0.787631, loss_d: 0.006388
0.7353 --- loss: 0.854021, loss_ss: 0.841159, loss_d: 0.012862
0.9804 --- loss: 0.843809, loss_ss: 0.841395, loss_d: 0.002414
Epoch finished! Loss: 0.9882978141307831
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6597222222222222
              precision    recall  f1-score   support

         0.0       0.68      0.51      0.59       103
         1.0       0.00      0.00      0.00        87
         2.0       0.83      0.72      0.77       300
         3.0       0.98      0.87      0.92       133
         4.0       0.34      0.93      0.50        97

    accuracy                           0.66       720
   macro avg       0.57      0.61      0.56       720
weighted avg       0.67      0.66      0.64       720
 


====== chc006-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  89.58  51.46   95.95  67.95     58.56
1  87.92   0.00  100.00   0.00      0.00
2  82.22  72.00   89.52  83.08     77.14
3  97.36  87.22   99.66  98.31     92.43
4  74.86  92.78   72.07  34.09     49.86
Total accuracy: 65.97%
Average sen: 60.69%
Average spec: 91.44%
Macro f1-score: 55.60%
Diagnosis acc on 90mins: 0.25
[0.970658   0.99997222 0.34902024 0.99926203]
pred: 0.8297281265258789, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc006-nsrr

=== Test on chc008-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.381030, loss_ss: 1.607833, loss_d: 0.773197
0.2457 --- loss: 2.017861, loss_ss: 1.525761, loss_d: 0.492100
0.4914 --- loss: 1.947557, loss_ss: 1.501872, loss_d: 0.445685
0.7371 --- loss: 2.115096, loss_ss: 1.511179, loss_d: 0.603917
0.9828 --- loss: 1.917175, loss_ss: 1.331335, loss_d: 0.585840
Epoch finished! Loss: 2.1389339715242386
Starting epoch 2/10.
0.0000 --- loss: 1.710011, loss_ss: 1.406450, loss_d: 0.303561
0.2457 --- loss: 1.897816, loss_ss: 1.444617, loss_d: 0.453200
0.4914 --- loss: 1.694309, loss_ss: 1.306261, loss_d: 0.388048
0.7371 --- loss: 2.144769, loss_ss: 1.347674, loss_d: 0.797095
0.9828 --- loss: 1.748711, loss_ss: 1.321933, loss_d: 0.426778
Epoch finished! Loss: 1.9631246417760848
Starting epoch 3/10.
0.0000 --- loss: 1.865475, loss_ss: 1.326804, loss_d: 0.538671
0.2457 --- loss: 1.717437, loss_ss: 1.295043, loss_d: 0.422394
0.4914 --- loss: 1.714717, loss_ss: 1.256361, loss_d: 0.458356
0.7371 --- loss: 1.979769, loss_ss: 1.268358, loss_d: 0.711410
0.9828 --- loss: 1.779252, loss_ss: 1.254321, loss_d: 0.524932
Epoch finished! Loss: 1.81675728559494
Starting epoch 4/10.
0.0000 --- loss: 1.802899, loss_ss: 1.178430, loss_d: 0.624469
0.2457 --- loss: 1.429254, loss_ss: 1.162765, loss_d: 0.266489
0.4914 --- loss: 1.690057, loss_ss: 1.185184, loss_d: 0.504873
0.7371 --- loss: 1.502644, loss_ss: 1.224432, loss_d: 0.278212
0.9828 --- loss: 1.779028, loss_ss: 1.108698, loss_d: 0.670331
Epoch finished! Loss: 1.6855891823768616
Starting epoch 5/10.
0.0000 --- loss: 1.654092, loss_ss: 1.220566, loss_d: 0.433526
0.2457 --- loss: 1.450405, loss_ss: 1.111727, loss_d: 0.338678
0.4914 --- loss: 1.371006, loss_ss: 1.083287, loss_d: 0.287719
0.7371 --- loss: 1.474093, loss_ss: 1.163886, loss_d: 0.310207
0.9828 --- loss: 1.476734, loss_ss: 1.018690, loss_d: 0.458044
Epoch finished! Loss: 1.5107066094875337
Starting epoch 6/10.
0.0000 --- loss: 1.193087, loss_ss: 1.048465, loss_d: 0.144622
0.2457 --- loss: 1.282724, loss_ss: 1.017175, loss_d: 0.265549
0.4914 --- loss: 1.232419, loss_ss: 1.099832, loss_d: 0.132588
0.7371 --- loss: 1.608403, loss_ss: 0.938817, loss_d: 0.669587
0.9828 --- loss: 1.312160, loss_ss: 1.010988, loss_d: 0.301172
Epoch finished! Loss: 1.3706691652536391
Starting epoch 7/10.
0.0000 --- loss: 1.826866, loss_ss: 0.916572, loss_d: 0.910294
0.2457 --- loss: 1.126777, loss_ss: 1.072969, loss_d: 0.053808
0.4914 --- loss: 0.950652, loss_ss: 0.893719, loss_d: 0.056932
0.7371 --- loss: 1.292452, loss_ss: 1.058265, loss_d: 0.234187
0.9828 --- loss: 1.191820, loss_ss: 1.068923, loss_d: 0.122897
Epoch finished! Loss: 1.231278881430626
Starting epoch 8/10.
0.0000 --- loss: 1.214415, loss_ss: 1.179515, loss_d: 0.034899
0.2457 --- loss: 1.147896, loss_ss: 0.908116, loss_d: 0.239780
0.4914 --- loss: 0.904765, loss_ss: 0.876361, loss_d: 0.028404
0.7371 --- loss: 1.540750, loss_ss: 0.895411, loss_d: 0.645339
0.9828 --- loss: 1.026278, loss_ss: 0.883903, loss_d: 0.142375
Epoch finished! Loss: 1.0807720184326173
Starting epoch 9/10.
0.0000 --- loss: 0.933639, loss_ss: 0.871496, loss_d: 0.062144
0.2457 --- loss: 1.070203, loss_ss: 1.060412, loss_d: 0.009791
0.4914 --- loss: 1.004875, loss_ss: 0.982361, loss_d: 0.022514
0.7371 --- loss: 0.876979, loss_ss: 0.819418, loss_d: 0.057561
0.9828 --- loss: 1.515103, loss_ss: 0.789490, loss_d: 0.725613
Epoch finished! Loss: 1.0538901329040526
Starting epoch 10/10.
0.0000 --- loss: 1.092746, loss_ss: 1.082825, loss_d: 0.009921
0.2457 --- loss: 1.035562, loss_ss: 1.011688, loss_d: 0.023874
0.4914 --- loss: 0.842857, loss_ss: 0.821249, loss_d: 0.021607
0.7371 --- loss: 0.840355, loss_ss: 0.834767, loss_d: 0.005589
0.9828 --- loss: 0.968111, loss_ss: 0.924346, loss_d: 0.043765
Epoch finished! Loss: 1.0017525479197502
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6277777777777778
              precision    recall  f1-score   support

         0.0       0.56      1.00      0.72       144
         1.0       0.56      0.06      0.11        80
         2.0       0.64      0.72      0.68       344
         3.0       1.00      0.41      0.58       227
         4.0       0.50      0.73      0.59       105

    accuracy                           0.63       900
   macro avg       0.65      0.58      0.53       900
weighted avg       0.69      0.63      0.60       900
 


====== chc008-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  87.33  100.00   84.92   55.81     71.64
1  91.22    6.25   99.51   55.56     11.24
2  73.78   71.80   75.00   63.99     67.67
3  85.00   40.53  100.00  100.00     57.68
4  88.22   73.33   90.19   49.68     59.23
Total accuracy: 62.78%
Average sen: 58.38%
Average spec: 89.92%
Macro f1-score: 53.49%
Diagnosis acc on 90mins: 0.2
[0.00471271 0.96907961 0.99927145 0.99319035 0.90853417]
pred: 0.7749576580710709, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc008-nsrr

=== Test on chc009-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.342001, loss_ss: 1.671092, loss_d: 0.670909
0.2451 --- loss: 2.035356, loss_ss: 1.482961, loss_d: 0.552395
0.4902 --- loss: 1.827235, loss_ss: 1.348889, loss_d: 0.478346
0.7353 --- loss: 1.775435, loss_ss: 1.295279, loss_d: 0.480156
0.9804 --- loss: 1.708538, loss_ss: 1.239091, loss_d: 0.469447
Epoch finished! Loss: 2.058456394076347
Starting epoch 2/10.
0.0000 --- loss: 1.923249, loss_ss: 1.317500, loss_d: 0.605749
0.2451 --- loss: 1.676397, loss_ss: 1.229779, loss_d: 0.446618
0.4902 --- loss: 1.551993, loss_ss: 1.267976, loss_d: 0.284017
0.7353 --- loss: 1.848267, loss_ss: 1.218720, loss_d: 0.629547
0.9804 --- loss: 1.933466, loss_ss: 1.183690, loss_d: 0.749776
Epoch finished! Loss: 1.8229988068342209
Starting epoch 3/10.
0.0000 --- loss: 1.557960, loss_ss: 1.188601, loss_d: 0.369358
0.2451 --- loss: 1.526549, loss_ss: 1.137719, loss_d: 0.388830
0.4902 --- loss: 1.846033, loss_ss: 1.181458, loss_d: 0.664576
0.7353 --- loss: 1.584836, loss_ss: 1.114083, loss_d: 0.470753
0.9804 --- loss: 1.623410, loss_ss: 1.194846, loss_d: 0.428564
Epoch finished! Loss: 1.7375466644763946
Starting epoch 4/10.
0.0000 --- loss: 1.352900, loss_ss: 1.081108, loss_d: 0.271793
0.2451 --- loss: 1.787106, loss_ss: 1.153704, loss_d: 0.633402
0.4902 --- loss: 1.518951, loss_ss: 1.089064, loss_d: 0.429888
0.7353 --- loss: 1.753025, loss_ss: 1.076126, loss_d: 0.676899
0.9804 --- loss: 1.580741, loss_ss: 1.080828, loss_d: 0.499913
Epoch finished! Loss: 1.6575468897819519
Starting epoch 5/10.
0.0000 --- loss: 1.478345, loss_ss: 1.060697, loss_d: 0.417648
0.2451 --- loss: 1.640215, loss_ss: 1.094511, loss_d: 0.545704
0.4902 --- loss: 1.506153, loss_ss: 1.011867, loss_d: 0.494286
0.7353 --- loss: 1.456396, loss_ss: 1.166057, loss_d: 0.290338
0.9804 --- loss: 1.480622, loss_ss: 1.035422, loss_d: 0.445200
Epoch finished! Loss: 1.5784576416015625
Starting epoch 6/10.
0.0000 --- loss: 1.491739, loss_ss: 1.109417, loss_d: 0.382322
0.2451 --- loss: 1.527795, loss_ss: 1.176814, loss_d: 0.350982
0.4902 --- loss: 1.356036, loss_ss: 1.090094, loss_d: 0.265942
0.7353 --- loss: 1.343535, loss_ss: 1.139976, loss_d: 0.203560
0.9804 --- loss: 1.759409, loss_ss: 1.184446, loss_d: 0.574964
Epoch finished! Loss: 1.4998948991298675
Starting epoch 7/10.
0.0000 --- loss: 1.234522, loss_ss: 0.904969, loss_d: 0.329554
0.2451 --- loss: 1.147637, loss_ss: 0.992328, loss_d: 0.155308
0.4902 --- loss: 1.354130, loss_ss: 1.186519, loss_d: 0.167611
0.7353 --- loss: 1.245306, loss_ss: 1.197348, loss_d: 0.047958
0.9804 --- loss: 1.227327, loss_ss: 1.066314, loss_d: 0.161013
Epoch finished! Loss: 1.3376911908388138
Starting epoch 8/10.
0.0000 --- loss: 1.130298, loss_ss: 1.057174, loss_d: 0.073124
0.2451 --- loss: 1.265660, loss_ss: 1.024255, loss_d: 0.241405
0.4902 --- loss: 1.214556, loss_ss: 1.069510, loss_d: 0.145045
0.7353 --- loss: 0.994922, loss_ss: 0.931064, loss_d: 0.063858
0.9804 --- loss: 1.447185, loss_ss: 1.050808, loss_d: 0.396377
Epoch finished! Loss: 1.3190231621265411
Starting epoch 9/10.
0.0000 --- loss: 1.117260, loss_ss: 0.902698, loss_d: 0.214562
0.2451 --- loss: 1.014582, loss_ss: 0.976820, loss_d: 0.037762
0.4902 --- loss: 1.000949, loss_ss: 0.997647, loss_d: 0.003302
0.7353 --- loss: 1.050592, loss_ss: 0.952633, loss_d: 0.097959
0.9804 --- loss: 1.256181, loss_ss: 0.929243, loss_d: 0.326938
Epoch finished! Loss: 1.1064201310276984
Starting epoch 10/10.
0.0000 --- loss: 0.974150, loss_ss: 0.970106, loss_d: 0.004045
0.2451 --- loss: 1.078648, loss_ss: 1.046721, loss_d: 0.031928
0.4902 --- loss: 1.023619, loss_ss: 0.983873, loss_d: 0.039745
0.7353 --- loss: 1.283634, loss_ss: 1.013497, loss_d: 0.270136
0.9804 --- loss: 0.972462, loss_ss: 0.957706, loss_d: 0.014756
Epoch finished! Loss: 1.177477692067623
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8194444444444444
              precision    recall  f1-score   support

         0.0       0.51      0.96      0.67        57
         1.0       0.10      0.03      0.04        36
         2.0       0.87      0.86      0.87       376
         3.0       0.96      0.79      0.86       196
         4.0       0.82      1.00      0.90        55

    accuracy                           0.82       720
   macro avg       0.65      0.73      0.67       720
weighted avg       0.82      0.82      0.81       720
 


====== chc009-nsrr ======
   acc %   sen %  spec %  ppr %  f1-score
0  92.36   96.49   92.01  50.93     66.67
1  93.89    2.78   98.68  10.00      4.35
2  86.11   86.44   85.76  86.90     86.67
3  93.19   78.57   98.66  95.65     86.27
4  98.33  100.00   98.20  82.09     90.16
Total accuracy: 81.94%
Average sen: 72.86%
Average spec: 94.66%
Macro f1-score: 66.82%
Diagnosis acc on 90mins: 0.25
[0.0292472  0.91190386 0.87425518 0.55036521]
pred: 0.5914428629912436, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc009-nsrr

=== Test on chc010-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.319230, loss_ss: 1.679773, loss_d: 0.639456
0.2451 --- loss: 2.299875, loss_ss: 1.660684, loss_d: 0.639191
0.4902 --- loss: 2.046191, loss_ss: 1.582502, loss_d: 0.463689
0.7353 --- loss: 2.373343, loss_ss: 1.609151, loss_d: 0.764192
0.9804 --- loss: 2.394928, loss_ss: 1.597422, loss_d: 0.797507
Epoch finished! Loss: 2.2988161742687225
Starting epoch 2/10.
0.0000 --- loss: 1.956790, loss_ss: 1.521118, loss_d: 0.435672
0.2451 --- loss: 2.096270, loss_ss: 1.457967, loss_d: 0.638303
0.4902 --- loss: 2.086377, loss_ss: 1.443143, loss_d: 0.643234
0.7353 --- loss: 1.797432, loss_ss: 1.428518, loss_d: 0.368915
0.9804 --- loss: 1.804106, loss_ss: 1.328664, loss_d: 0.475442
Epoch finished! Loss: 2.004267519712448
Starting epoch 3/10.
0.0000 --- loss: 1.824849, loss_ss: 1.404751, loss_d: 0.420098
0.2451 --- loss: 1.575142, loss_ss: 1.328053, loss_d: 0.247089
0.4902 --- loss: 1.747515, loss_ss: 1.292096, loss_d: 0.455420
0.7353 --- loss: 1.902266, loss_ss: 1.307419, loss_d: 0.594847
0.9804 --- loss: 1.712714, loss_ss: 1.292721, loss_d: 0.419994
Epoch finished! Loss: 1.8589880883693695
Starting epoch 4/10.
0.0000 --- loss: 1.798068, loss_ss: 1.246678, loss_d: 0.551390
0.2451 --- loss: 1.426035, loss_ss: 1.218093, loss_d: 0.207943
0.4902 --- loss: 1.702744, loss_ss: 1.284748, loss_d: 0.417995
0.7353 --- loss: 1.639715, loss_ss: 1.312379, loss_d: 0.327337
0.9804 --- loss: 1.560119, loss_ss: 1.211925, loss_d: 0.348194
Epoch finished! Loss: 1.6859082460403443
Starting epoch 5/10.
0.0000 --- loss: 1.455691, loss_ss: 1.252491, loss_d: 0.203200
0.2451 --- loss: 1.389551, loss_ss: 1.208318, loss_d: 0.181233
0.4902 --- loss: 1.779160, loss_ss: 1.302602, loss_d: 0.476558
0.7353 --- loss: 1.631566, loss_ss: 1.112805, loss_d: 0.518761
0.9804 --- loss: 1.982572, loss_ss: 1.123403, loss_d: 0.859169
Epoch finished! Loss: 1.5414688259363174
Starting epoch 6/10.
0.0000 --- loss: 1.437261, loss_ss: 1.232865, loss_d: 0.204395
0.2451 --- loss: 1.465515, loss_ss: 1.172698, loss_d: 0.292816
0.4902 --- loss: 1.247639, loss_ss: 1.119437, loss_d: 0.128202
0.7353 --- loss: 1.276620, loss_ss: 1.094142, loss_d: 0.182478
0.9804 --- loss: 1.748044, loss_ss: 1.279929, loss_d: 0.468115
Epoch finished! Loss: 1.409208545088768
Starting epoch 7/10.
0.0000 --- loss: 1.314691, loss_ss: 1.047601, loss_d: 0.267090
0.2451 --- loss: 1.104742, loss_ss: 1.065526, loss_d: 0.039215
0.4902 --- loss: 1.111673, loss_ss: 1.091406, loss_d: 0.020267
0.7353 --- loss: 1.271155, loss_ss: 1.137835, loss_d: 0.133321
0.9804 --- loss: 1.497918, loss_ss: 1.281389, loss_d: 0.216529
Epoch finished! Loss: 1.2903345197439193
Starting epoch 8/10.
0.0000 --- loss: 1.594687, loss_ss: 1.027062, loss_d: 0.567625
0.2451 --- loss: 1.409146, loss_ss: 1.167338, loss_d: 0.241808
0.4902 --- loss: 1.067400, loss_ss: 1.047830, loss_d: 0.019570
0.7353 --- loss: 1.314106, loss_ss: 1.106505, loss_d: 0.207601
0.9804 --- loss: 1.124187, loss_ss: 1.032116, loss_d: 0.092071
Epoch finished! Loss: 1.2922592550516128
Starting epoch 9/10.
0.0000 --- loss: 1.128221, loss_ss: 1.088149, loss_d: 0.040072
0.2451 --- loss: 1.169140, loss_ss: 1.157825, loss_d: 0.011314
0.4902 --- loss: 1.086528, loss_ss: 0.989648, loss_d: 0.096880
0.7353 --- loss: 1.159528, loss_ss: 1.075346, loss_d: 0.084182
0.9804 --- loss: 0.928824, loss_ss: 0.922967, loss_d: 0.005858
Epoch finished! Loss: 1.2146712958812713
Starting epoch 10/10.
0.0000 --- loss: 1.107545, loss_ss: 1.100658, loss_d: 0.006887
0.2451 --- loss: 1.259988, loss_ss: 1.254953, loss_d: 0.005036
0.4902 --- loss: 0.947182, loss_ss: 0.914543, loss_d: 0.032639
0.7353 --- loss: 1.051417, loss_ss: 1.048784, loss_d: 0.002633
0.9804 --- loss: 1.001919, loss_ss: 1.001196, loss_d: 0.000723
Epoch finished! Loss: 1.0973347947001457
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5444444444444444
              precision    recall  f1-score   support

         0.0       0.42      0.39      0.41       123
         1.0       0.13      0.16      0.15        43
         2.0       0.62      0.94      0.75       324
         3.0       0.65      0.21      0.32       149
         4.0       0.00      0.00      0.00        81

    accuracy                           0.54       720
   macro avg       0.37      0.34      0.32       720
weighted avg       0.49      0.54      0.48       720
 


====== chc010-nsrr ======

The f1-score of  4  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  80.42  39.02   88.94  42.11     40.51
1  88.75  16.28   93.35  13.46     14.74
2  71.25  94.14   52.53  61.87     74.66
3  81.39  21.48   97.02  65.31     32.32
4  87.08   0.00   98.12   0.00      0.00
Total accuracy: 54.44%
Average sen: 34.18%
Average spec: 85.99%
Macro f1-score: 32.45%
Diagnosis acc on 90mins: 0.25
[0.76028091 0.07907729 0.99989772 0.58175176]
pred: 0.605251919478178, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc010-nsrr

=== Test on chc012-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.284600, loss_ss: 1.633266, loss_d: 0.651333
0.2457 --- loss: 2.130715, loss_ss: 1.392427, loss_d: 0.738288
0.4914 --- loss: 1.926532, loss_ss: 1.301962, loss_d: 0.624570
0.7371 --- loss: 1.703090, loss_ss: 1.297001, loss_d: 0.406089
0.9828 --- loss: 1.846845, loss_ss: 1.233283, loss_d: 0.613562
Epoch finished! Loss: 2.0354733616113663
Starting epoch 2/10.
0.0000 --- loss: 1.942529, loss_ss: 1.300428, loss_d: 0.642102
0.2457 --- loss: 2.002682, loss_ss: 1.217882, loss_d: 0.784799
0.4914 --- loss: 2.098067, loss_ss: 1.187580, loss_d: 0.910487
0.7371 --- loss: 1.968435, loss_ss: 1.359092, loss_d: 0.609343
0.9828 --- loss: 1.771640, loss_ss: 1.063151, loss_d: 0.708488
Epoch finished! Loss: 1.8325546324253081
Starting epoch 3/10.
0.0000 --- loss: 1.920736, loss_ss: 1.192603, loss_d: 0.728133
0.2457 --- loss: 1.689937, loss_ss: 1.193314, loss_d: 0.496622
0.4914 --- loss: 1.656894, loss_ss: 1.129145, loss_d: 0.527749
0.7371 --- loss: 1.588026, loss_ss: 1.060638, loss_d: 0.527388
0.9828 --- loss: 1.578241, loss_ss: 1.135950, loss_d: 0.442291
Epoch finished! Loss: 1.6985883265733719
Starting epoch 4/10.
0.0000 --- loss: 1.616869, loss_ss: 1.132254, loss_d: 0.484615
0.2457 --- loss: 1.460527, loss_ss: 1.088681, loss_d: 0.371847
0.4914 --- loss: 1.687782, loss_ss: 1.017973, loss_d: 0.669808
0.7371 --- loss: 1.630383, loss_ss: 1.114741, loss_d: 0.515642
0.9828 --- loss: 2.214746, loss_ss: 1.222939, loss_d: 0.991807
Epoch finished! Loss: 1.5969448745250703
Starting epoch 5/10.
0.0000 --- loss: 1.323405, loss_ss: 1.044109, loss_d: 0.279296
0.2457 --- loss: 1.349442, loss_ss: 0.989184, loss_d: 0.360258
0.4914 --- loss: 1.658908, loss_ss: 1.041399, loss_d: 0.617510
0.7371 --- loss: 1.344603, loss_ss: 1.224229, loss_d: 0.120374
0.9828 --- loss: 1.134862, loss_ss: 0.903097, loss_d: 0.231765
Epoch finished! Loss: 1.4387124866247176
Starting epoch 6/10.
0.0000 --- loss: 1.227621, loss_ss: 0.978432, loss_d: 0.249188
0.2457 --- loss: 1.460686, loss_ss: 1.178079, loss_d: 0.282607
0.4914 --- loss: 1.259238, loss_ss: 1.100906, loss_d: 0.158333
0.7371 --- loss: 1.532065, loss_ss: 1.069142, loss_d: 0.462923
0.9828 --- loss: 1.170762, loss_ss: 1.046359, loss_d: 0.124404
Epoch finished! Loss: 1.3879119783639908
Starting epoch 7/10.
0.0000 --- loss: 1.258917, loss_ss: 1.085498, loss_d: 0.173419
0.2457 --- loss: 1.032928, loss_ss: 0.839184, loss_d: 0.193745
0.4914 --- loss: 1.192670, loss_ss: 0.935058, loss_d: 0.257612
0.7371 --- loss: 1.085850, loss_ss: 0.976596, loss_d: 0.109254
0.9828 --- loss: 1.145956, loss_ss: 1.103557, loss_d: 0.042399
Epoch finished! Loss: 1.2916240036487578
Starting epoch 8/10.
0.0000 --- loss: 1.257930, loss_ss: 1.061848, loss_d: 0.196082
0.2457 --- loss: 1.672173, loss_ss: 1.066976, loss_d: 0.605197
0.4914 --- loss: 1.206804, loss_ss: 0.901268, loss_d: 0.305536
0.7371 --- loss: 1.203954, loss_ss: 0.946923, loss_d: 0.257030
0.9828 --- loss: 1.420182, loss_ss: 1.061603, loss_d: 0.358579
Epoch finished! Loss: 1.353076735138893
Starting epoch 9/10.
0.0000 --- loss: 0.972491, loss_ss: 0.934679, loss_d: 0.037812
0.2457 --- loss: 1.152064, loss_ss: 1.078297, loss_d: 0.073767
0.4914 --- loss: 1.043197, loss_ss: 1.017298, loss_d: 0.025899
0.7371 --- loss: 1.262602, loss_ss: 0.908005, loss_d: 0.354598
0.9828 --- loss: 1.477994, loss_ss: 1.046214, loss_d: 0.431779
Epoch finished! Loss: 1.139929586648941
Starting epoch 10/10.
0.0000 --- loss: 1.020735, loss_ss: 0.910333, loss_d: 0.110402
0.2457 --- loss: 0.958189, loss_ss: 0.904957, loss_d: 0.053231
0.4914 --- loss: 0.925580, loss_ss: 0.920227, loss_d: 0.005353
0.7371 --- loss: 1.125507, loss_ss: 0.965075, loss_d: 0.160433
0.9828 --- loss: 1.135093, loss_ss: 1.030431, loss_d: 0.104662
Epoch finished! Loss: 1.110224349796772
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7322222222222222
              precision    recall  f1-score   support

         0.0       0.64      0.57      0.61        63
         1.0       0.00      0.00      0.00        22
         2.0       0.80      0.86      0.83       541
         3.0       1.00      0.45      0.62       204
         4.0       0.39      0.96      0.55        70

    accuracy                           0.73       900
   macro avg       0.57      0.57      0.52       900
weighted avg       0.78      0.73      0.72       900
 


====== chc012-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  94.78  57.14   97.61   64.29     60.50
1  97.56   0.00  100.00    0.00      0.00
2  78.67  85.77   67.97   80.14     82.86
3  87.56  45.10  100.00  100.00     62.16
4  87.89  95.71   87.23   38.73     55.14
Total accuracy: 73.22%
Average sen: 56.74%
Average spec: 90.56%
Macro f1-score: 52.13%
Diagnosis acc on 90mins: 0.0
[0.89282197 0.99986649 0.90231591 0.97606295 0.98294765]
pred: 0.950802993774414, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc012-nsrr

=== Test on chc013-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.422956, loss_ss: 1.709866, loss_d: 0.713089
0.2457 --- loss: 2.653111, loss_ss: 1.433111, loss_d: 1.220000
0.4914 --- loss: 2.134725, loss_ss: 1.472146, loss_d: 0.662579
0.7371 --- loss: 1.851679, loss_ss: 1.452730, loss_d: 0.398949
0.9828 --- loss: 1.940258, loss_ss: 1.332524, loss_d: 0.607735
Epoch finished! Loss: 2.1542825907468797
Starting epoch 2/10.
0.0000 --- loss: 1.797696, loss_ss: 1.366528, loss_d: 0.431168
0.2457 --- loss: 1.789688, loss_ss: 1.354135, loss_d: 0.435553
0.4914 --- loss: 1.830319, loss_ss: 1.349121, loss_d: 0.481199
0.7371 --- loss: 1.705019, loss_ss: 1.338392, loss_d: 0.366626
0.9828 --- loss: 1.703255, loss_ss: 1.258230, loss_d: 0.445025
Epoch finished! Loss: 1.9339265525341034
Starting epoch 3/10.
0.0000 --- loss: 1.833322, loss_ss: 1.324191, loss_d: 0.509132
0.2457 --- loss: 1.508545, loss_ss: 1.236984, loss_d: 0.271560
0.4914 --- loss: 1.711037, loss_ss: 1.197014, loss_d: 0.514022
0.7371 --- loss: 1.505089, loss_ss: 1.199588, loss_d: 0.305501
0.9828 --- loss: 1.803911, loss_ss: 1.142731, loss_d: 0.661180
Epoch finished! Loss: 1.7850845366716386
Starting epoch 4/10.
0.0000 --- loss: 1.728203, loss_ss: 1.186219, loss_d: 0.541984
0.2457 --- loss: 1.482832, loss_ss: 1.227867, loss_d: 0.254964
0.4914 --- loss: 2.471740, loss_ss: 1.241960, loss_d: 1.229779
0.7371 --- loss: 1.780135, loss_ss: 1.184301, loss_d: 0.595834
0.9828 --- loss: 1.416855, loss_ss: 1.159622, loss_d: 0.257233
Epoch finished! Loss: 1.6889234393835069
Starting epoch 5/10.
0.0000 --- loss: 1.339651, loss_ss: 1.060381, loss_d: 0.279270
0.2457 --- loss: 1.515609, loss_ss: 1.114095, loss_d: 0.401514
0.4914 --- loss: 1.455503, loss_ss: 1.087197, loss_d: 0.368306
0.7371 --- loss: 2.358562, loss_ss: 1.097509, loss_d: 1.261053
0.9828 --- loss: 1.571171, loss_ss: 1.074741, loss_d: 0.496431
Epoch finished! Loss: 1.5253620624542237
Starting epoch 6/10.
0.0000 --- loss: 1.325618, loss_ss: 1.100200, loss_d: 0.225418
0.2457 --- loss: 1.298025, loss_ss: 1.003362, loss_d: 0.294663
0.4914 --- loss: 1.305776, loss_ss: 1.061521, loss_d: 0.244254
0.7371 --- loss: 1.369464, loss_ss: 1.078882, loss_d: 0.290582
0.9828 --- loss: 1.195546, loss_ss: 1.020058, loss_d: 0.175488
Epoch finished! Loss: 1.390598365664482
Starting epoch 7/10.
0.0000 --- loss: 1.316669, loss_ss: 1.072120, loss_d: 0.244548
0.2457 --- loss: 1.444879, loss_ss: 1.101222, loss_d: 0.343657
0.4914 --- loss: 1.604459, loss_ss: 1.046425, loss_d: 0.558033
0.7371 --- loss: 1.577347, loss_ss: 1.138839, loss_d: 0.438508
0.9828 --- loss: 1.049132, loss_ss: 0.951025, loss_d: 0.098107
Epoch finished! Loss: 1.3591687023639678
Starting epoch 8/10.
0.0000 --- loss: 1.594807, loss_ss: 1.126440, loss_d: 0.468367
0.2457 --- loss: 1.413932, loss_ss: 1.244175, loss_d: 0.169758
0.4914 --- loss: 1.077386, loss_ss: 0.977963, loss_d: 0.099423
0.7371 --- loss: 1.273461, loss_ss: 1.065735, loss_d: 0.207726
0.9828 --- loss: 0.901383, loss_ss: 0.874292, loss_d: 0.027091
Epoch finished! Loss: 1.188909824192524
Starting epoch 9/10.
0.0000 --- loss: 1.329340, loss_ss: 1.156844, loss_d: 0.172496
0.2457 --- loss: 0.933904, loss_ss: 0.925371, loss_d: 0.008533
0.4914 --- loss: 0.911108, loss_ss: 0.900895, loss_d: 0.010213
0.7371 --- loss: 1.350187, loss_ss: 1.041045, loss_d: 0.309142
0.9828 --- loss: 1.400753, loss_ss: 1.001082, loss_d: 0.399671
Epoch finished! Loss: 1.102976131439209
Starting epoch 10/10.
0.0000 --- loss: 1.042099, loss_ss: 1.014650, loss_d: 0.027449
0.2457 --- loss: 0.840930, loss_ss: 0.833059, loss_d: 0.007870
0.4914 --- loss: 0.990139, loss_ss: 0.970476, loss_d: 0.019664
0.7371 --- loss: 1.355026, loss_ss: 1.101671, loss_d: 0.253355
0.9828 --- loss: 0.967152, loss_ss: 0.952932, loss_d: 0.014220
Epoch finished! Loss: 1.111459918320179
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7166666666666667
              precision    recall  f1-score   support

         0.0       0.53      0.23      0.32        69
         1.0       0.00      0.00      0.00        38
         2.0       0.81      0.79      0.80       410
         3.0       0.95      0.68      0.79       228
         4.0       0.50      0.98      0.66       155

    accuracy                           0.72       900
   macro avg       0.56      0.54      0.51       900
weighted avg       0.74      0.72      0.70       900
 


====== chc013-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  92.56  23.19   98.32  53.33     32.32
1  95.56   0.00   99.77   0.00      0.00
2  81.89  78.54   84.69  81.11     79.80
3  90.89  67.98   98.66  94.51     79.08
4  82.44  98.06   79.19  49.51     65.80
Total accuracy: 71.67%
Average sen: 53.55%
Average spec: 92.13%
Macro f1-score: 51.40%
Diagnosis acc on 90mins: 0.4
[0.37980559 0.87548405 0.39160696 0.99875855 0.99980229]
pred: 0.729091489315033, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc013-nsrr

=== Test on chc014-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.371409, loss_ss: 1.721992, loss_d: 0.649416
0.2457 --- loss: 2.187628, loss_ss: 1.560747, loss_d: 0.626882
0.4914 --- loss: 2.393700, loss_ss: 1.497780, loss_d: 0.895920
0.7371 --- loss: 1.875276, loss_ss: 1.482883, loss_d: 0.392393
0.9828 --- loss: 2.480539, loss_ss: 1.363004, loss_d: 1.117535
Epoch finished! Loss: 2.226790374517441
Starting epoch 2/10.
0.0000 --- loss: 1.898616, loss_ss: 1.377957, loss_d: 0.520658
0.2457 --- loss: 2.153811, loss_ss: 1.467068, loss_d: 0.686744
0.4914 --- loss: 1.991817, loss_ss: 1.363312, loss_d: 0.628505
0.7371 --- loss: 1.805439, loss_ss: 1.407566, loss_d: 0.397873
0.9828 --- loss: 1.912460, loss_ss: 1.356774, loss_d: 0.555686
Epoch finished! Loss: 2.0100793302059174
Starting epoch 3/10.
0.0000 --- loss: 1.995360, loss_ss: 1.396537, loss_d: 0.598823
0.2457 --- loss: 1.869011, loss_ss: 1.259235, loss_d: 0.609775
0.4914 --- loss: 2.184434, loss_ss: 1.248582, loss_d: 0.935852
0.7371 --- loss: 1.643035, loss_ss: 1.245275, loss_d: 0.397760
0.9828 --- loss: 1.602524, loss_ss: 1.259888, loss_d: 0.342636
Epoch finished! Loss: 1.8644471734762191
Starting epoch 4/10.
0.0000 --- loss: 1.706873, loss_ss: 1.222393, loss_d: 0.484480
0.2457 --- loss: 1.962548, loss_ss: 1.268206, loss_d: 0.694342
0.4914 --- loss: 1.612232, loss_ss: 1.188610, loss_d: 0.423622
0.7371 --- loss: 1.620871, loss_ss: 1.184880, loss_d: 0.435991
0.9828 --- loss: 1.752575, loss_ss: 1.375945, loss_d: 0.376630
Epoch finished! Loss: 1.7393034905195237
Starting epoch 5/10.
0.0000 --- loss: 1.437121, loss_ss: 1.129180, loss_d: 0.307941
0.2457 --- loss: 1.395247, loss_ss: 1.131420, loss_d: 0.263828
0.4914 --- loss: 1.548045, loss_ss: 1.102665, loss_d: 0.445380
0.7371 --- loss: 1.522682, loss_ss: 1.174493, loss_d: 0.348189
0.9828 --- loss: 1.947803, loss_ss: 1.057120, loss_d: 0.890683
Epoch finished! Loss: 1.61382494866848
Starting epoch 6/10.
0.0000 --- loss: 1.500244, loss_ss: 1.222228, loss_d: 0.278016
0.2457 --- loss: 1.651185, loss_ss: 1.163284, loss_d: 0.487901
0.4914 --- loss: 1.457157, loss_ss: 1.057336, loss_d: 0.399821
0.7371 --- loss: 1.378636, loss_ss: 1.041870, loss_d: 0.336766
0.9828 --- loss: 1.585016, loss_ss: 1.083878, loss_d: 0.501138
Epoch finished! Loss: 1.525709581375122
Starting epoch 7/10.
0.0000 --- loss: 1.455967, loss_ss: 1.202187, loss_d: 0.253780
0.2457 --- loss: 1.427620, loss_ss: 1.132802, loss_d: 0.294818
0.4914 --- loss: 1.121420, loss_ss: 0.997293, loss_d: 0.124127
0.7371 --- loss: 1.041331, loss_ss: 0.964002, loss_d: 0.077329
0.9828 --- loss: 1.550594, loss_ss: 1.054657, loss_d: 0.495937
Epoch finished! Loss: 1.3025454849004745
Starting epoch 8/10.
0.0000 --- loss: 1.199040, loss_ss: 1.004163, loss_d: 0.194876
0.2457 --- loss: 1.409843, loss_ss: 1.085057, loss_d: 0.324786
0.4914 --- loss: 1.219023, loss_ss: 1.084898, loss_d: 0.134125
0.7371 --- loss: 1.148588, loss_ss: 1.134930, loss_d: 0.013659
0.9828 --- loss: 1.971830, loss_ss: 1.005131, loss_d: 0.966699
Epoch finished! Loss: 1.318277534842491
Starting epoch 9/10.
0.0000 --- loss: 1.306597, loss_ss: 1.107679, loss_d: 0.198917
0.2457 --- loss: 1.174392, loss_ss: 0.984726, loss_d: 0.189667
0.4914 --- loss: 1.294684, loss_ss: 1.057796, loss_d: 0.236888
0.7371 --- loss: 1.040507, loss_ss: 1.018950, loss_d: 0.021556
0.9828 --- loss: 1.047437, loss_ss: 1.009984, loss_d: 0.037453
Epoch finished! Loss: 1.1653937116265296
Starting epoch 10/10.
0.0000 --- loss: 0.958741, loss_ss: 0.921641, loss_d: 0.037100
0.2457 --- loss: 0.934762, loss_ss: 0.929602, loss_d: 0.005160
0.4914 --- loss: 0.982110, loss_ss: 0.977394, loss_d: 0.004716
0.7371 --- loss: 0.749287, loss_ss: 0.725999, loss_d: 0.023288
0.9828 --- loss: 1.106410, loss_ss: 1.075549, loss_d: 0.030861
Epoch finished! Loss: 1.0548299610614777
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.8155555555555556
              precision    recall  f1-score   support

         0.0       1.00      0.67      0.80       240
         1.0       0.00      0.00      0.00         6
         2.0       0.81      0.96      0.88       436
         3.0       0.90      0.64      0.75       143
         4.0       0.51      0.85      0.64        75

    accuracy                           0.82       900
   macro avg       0.65      0.62      0.61       900
weighted avg       0.85      0.82      0.81       900
 


====== chc014-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  91.22  67.08  100.00  100.00     80.30
1  99.33   0.00  100.00    0.00      0.00
2  87.44  95.87   79.53   81.48     88.09
3  93.11  63.64   98.68   90.10     74.59
4  92.00  85.33   92.61   51.20     64.00
Total accuracy: 81.56%
Average sen: 62.38%
Average spec: 94.16%
Macro f1-score: 61.40%
Diagnosis acc on 90mins: 0.0
[0.99430907 0.93136305 0.86332244 0.89120787 0.98795867]
pred: 0.9336322188377381, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc014-nsrr

=== Test on chc015-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.471423, loss_ss: 1.749568, loss_d: 0.721855
0.2457 --- loss: 2.110172, loss_ss: 1.597074, loss_d: 0.513098
0.4914 --- loss: 2.339383, loss_ss: 1.462367, loss_d: 0.877016
0.7371 --- loss: 2.352060, loss_ss: 1.446196, loss_d: 0.905865
0.9828 --- loss: 1.914676, loss_ss: 1.496529, loss_d: 0.418147
Epoch finished! Loss: 2.222789686918259
Starting epoch 2/10.
0.0000 --- loss: 2.006832, loss_ss: 1.487279, loss_d: 0.519553
0.2457 --- loss: 1.894062, loss_ss: 1.409026, loss_d: 0.485036
0.4914 --- loss: 2.032088, loss_ss: 1.415162, loss_d: 0.616925
0.7371 --- loss: 2.615035, loss_ss: 1.524175, loss_d: 1.090860
0.9828 --- loss: 1.874590, loss_ss: 1.426167, loss_d: 0.448423
Epoch finished! Loss: 2.0283235192298887
Starting epoch 3/10.
0.0000 --- loss: 1.905136, loss_ss: 1.467477, loss_d: 0.437659
0.2457 --- loss: 2.050863, loss_ss: 1.355878, loss_d: 0.694985
0.4914 --- loss: 1.944600, loss_ss: 1.354209, loss_d: 0.590391
0.7371 --- loss: 1.892485, loss_ss: 1.415976, loss_d: 0.476509
0.9828 --- loss: 2.311307, loss_ss: 1.283716, loss_d: 1.027591
Epoch finished! Loss: 1.8905676126480102
Starting epoch 4/10.
0.0000 --- loss: 1.708141, loss_ss: 1.332121, loss_d: 0.376021
0.2457 --- loss: 1.577886, loss_ss: 1.228664, loss_d: 0.349222
0.4914 --- loss: 1.757046, loss_ss: 1.296222, loss_d: 0.460824
0.7371 --- loss: 1.607610, loss_ss: 1.333465, loss_d: 0.274145
0.9828 --- loss: 1.481503, loss_ss: 1.268246, loss_d: 0.213257
Epoch finished! Loss: 1.7734230905771255
Starting epoch 5/10.
0.0000 --- loss: 1.499715, loss_ss: 1.287685, loss_d: 0.212030
0.2457 --- loss: 1.447487, loss_ss: 1.243013, loss_d: 0.204474
0.4914 --- loss: 1.669248, loss_ss: 1.208829, loss_d: 0.460419
0.7371 --- loss: 1.596471, loss_ss: 1.227982, loss_d: 0.368489
0.9828 --- loss: 1.710636, loss_ss: 1.220068, loss_d: 0.490568
Epoch finished! Loss: 1.7089762747287751
Starting epoch 6/10.
0.0000 --- loss: 1.453289, loss_ss: 1.230122, loss_d: 0.223167
0.2457 --- loss: 1.632248, loss_ss: 1.265328, loss_d: 0.366920
0.4914 --- loss: 1.459363, loss_ss: 1.187854, loss_d: 0.271510
0.7371 --- loss: 1.650186, loss_ss: 1.196481, loss_d: 0.453705
0.9828 --- loss: 1.683045, loss_ss: 1.215272, loss_d: 0.467773
Epoch finished! Loss: 1.640407559275627
Starting epoch 7/10.
0.0000 --- loss: 1.405628, loss_ss: 1.196407, loss_d: 0.209221
0.2457 --- loss: 1.361009, loss_ss: 1.163171, loss_d: 0.197838
0.4914 --- loss: 1.453246, loss_ss: 1.226206, loss_d: 0.227040
0.7371 --- loss: 1.239053, loss_ss: 1.159856, loss_d: 0.079197
0.9828 --- loss: 1.402009, loss_ss: 1.197616, loss_d: 0.204394
Epoch finished! Loss: 1.4894850850105286
Starting epoch 8/10.
0.0000 --- loss: 1.697425, loss_ss: 1.224304, loss_d: 0.473121
0.2457 --- loss: 1.143174, loss_ss: 1.091887, loss_d: 0.051286
0.4914 --- loss: 1.905635, loss_ss: 1.289127, loss_d: 0.616508
0.7371 --- loss: 1.367406, loss_ss: 1.137444, loss_d: 0.229961
0.9828 --- loss: 1.514241, loss_ss: 1.285896, loss_d: 0.228345
Epoch finished! Loss: 1.4967260777950286
Starting epoch 9/10.
0.0000 --- loss: 1.209179, loss_ss: 1.153963, loss_d: 0.055216
0.2457 --- loss: 1.490759, loss_ss: 1.115418, loss_d: 0.375341
0.4914 --- loss: 1.159139, loss_ss: 1.078860, loss_d: 0.080280
0.7371 --- loss: 1.469046, loss_ss: 1.272120, loss_d: 0.196926
0.9828 --- loss: 1.422412, loss_ss: 1.040003, loss_d: 0.382409
Epoch finished! Loss: 1.35968759059906
Starting epoch 10/10.
0.0000 --- loss: 1.273153, loss_ss: 1.202679, loss_d: 0.070474
0.2457 --- loss: 1.222304, loss_ss: 1.100479, loss_d: 0.121825
0.4914 --- loss: 1.106581, loss_ss: 1.055485, loss_d: 0.051096
0.7371 --- loss: 1.120987, loss_ss: 1.072035, loss_d: 0.048953
0.9828 --- loss: 1.141156, loss_ss: 0.994542, loss_d: 0.146614
Epoch finished! Loss: 1.23380815833807
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6677777777777778
              precision    recall  f1-score   support

         0.0       0.30      0.84      0.44        37
         1.0       1.00      0.01      0.02        82
         2.0       0.75      0.74      0.75       474
         3.0       0.62      1.00      0.76       166
         4.0       0.93      0.35      0.51       141

    accuracy                           0.67       900
   macro avg       0.72      0.59      0.50       900
weighted avg       0.76      0.67      0.63       900
 


====== chc015-nsrr ======
   acc %   sen %  spec %   ppr %  f1-score
0  91.22   83.78   91.54   29.81     43.97
1  91.00    1.22  100.00  100.00      2.41
2  73.33   74.47   72.07   74.79     74.63
3  88.56  100.00   85.97   61.71     76.32
4  89.44   35.46   99.47   92.59     51.28
Total accuracy: 66.78%
Average sen: 58.99%
Average spec: 89.81%
Macro f1-score: 49.72%
Diagnosis acc on 90mins: 0.0
[0.58630961 0.97019523 0.53895777 0.9920643  0.99893028]
pred: 0.8172914385795593, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc015-nsrr

=== Test on chc016-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.382584, loss_ss: 1.675649, loss_d: 0.706935
0.2457 --- loss: 2.135432, loss_ss: 1.488418, loss_d: 0.647014
0.4914 --- loss: 2.015100, loss_ss: 1.444153, loss_d: 0.570947
0.7371 --- loss: 2.196640, loss_ss: 1.314858, loss_d: 0.881782
0.9828 --- loss: 2.431051, loss_ss: 1.337020, loss_d: 1.094031
Epoch finished! Loss: 2.1136183351278306
Starting epoch 2/10.
0.0000 --- loss: 1.772792, loss_ss: 1.383781, loss_d: 0.389011
0.2457 --- loss: 1.849446, loss_ss: 1.423808, loss_d: 0.425638
0.4914 --- loss: 2.104086, loss_ss: 1.255344, loss_d: 0.848742
0.7371 --- loss: 1.766360, loss_ss: 1.207893, loss_d: 0.558467
0.9828 --- loss: 1.696040, loss_ss: 1.364419, loss_d: 0.331621
Epoch finished! Loss: 1.9000450819730759
Starting epoch 3/10.
0.0000 --- loss: 1.817005, loss_ss: 1.301098, loss_d: 0.515907
0.2457 --- loss: 1.513067, loss_ss: 1.234474, loss_d: 0.278593
0.4914 --- loss: 1.591594, loss_ss: 1.271124, loss_d: 0.320471
0.7371 --- loss: 2.115887, loss_ss: 1.230143, loss_d: 0.885744
0.9828 --- loss: 1.594036, loss_ss: 1.217284, loss_d: 0.376752
Epoch finished! Loss: 1.864809387922287
Starting epoch 4/10.
0.0000 --- loss: 1.596538, loss_ss: 1.112818, loss_d: 0.483720
0.2457 --- loss: 1.574054, loss_ss: 1.215090, loss_d: 0.358964
0.4914 --- loss: 1.517492, loss_ss: 1.131999, loss_d: 0.385493
0.7371 --- loss: 1.537405, loss_ss: 1.149662, loss_d: 0.387743
0.9828 --- loss: 1.988410, loss_ss: 1.097637, loss_d: 0.890773
Epoch finished! Loss: 1.7662390261888503
Starting epoch 5/10.
0.0000 --- loss: 1.523474, loss_ss: 1.247997, loss_d: 0.275477
0.2457 --- loss: 1.478327, loss_ss: 1.062272, loss_d: 0.416055
0.4914 --- loss: 1.788223, loss_ss: 1.135593, loss_d: 0.652630
0.7371 --- loss: 1.526161, loss_ss: 1.184713, loss_d: 0.341448
0.9828 --- loss: 1.541114, loss_ss: 1.025657, loss_d: 0.515457
Epoch finished! Loss: 1.6403620451688767
Starting epoch 6/10.
0.0000 --- loss: 1.484951, loss_ss: 1.145738, loss_d: 0.339212
0.2457 --- loss: 1.506360, loss_ss: 1.041131, loss_d: 0.465228
0.4914 --- loss: 1.616471, loss_ss: 1.082102, loss_d: 0.534368
0.7371 --- loss: 1.652912, loss_ss: 1.111032, loss_d: 0.541881
0.9828 --- loss: 1.377125, loss_ss: 1.018534, loss_d: 0.358591
Epoch finished! Loss: 1.5745765745639801
Starting epoch 7/10.
0.0000 --- loss: 1.302926, loss_ss: 1.010077, loss_d: 0.292849
0.2457 --- loss: 1.372325, loss_ss: 1.073587, loss_d: 0.298738
0.4914 --- loss: 1.484927, loss_ss: 1.136278, loss_d: 0.348649
0.7371 --- loss: 1.396202, loss_ss: 1.208361, loss_d: 0.187841
0.9828 --- loss: 1.310401, loss_ss: 1.091655, loss_d: 0.218746
Epoch finished! Loss: 1.4955890834331513
Starting epoch 8/10.
0.0000 --- loss: 1.442262, loss_ss: 1.120087, loss_d: 0.322175
0.2457 --- loss: 1.627946, loss_ss: 1.174877, loss_d: 0.453069
0.4914 --- loss: 1.096850, loss_ss: 0.932233, loss_d: 0.164617
0.7371 --- loss: 1.543132, loss_ss: 1.018488, loss_d: 0.524644
0.9828 --- loss: 1.447366, loss_ss: 1.066752, loss_d: 0.380614
Epoch finished! Loss: 1.4423939019441605
Starting epoch 9/10.
0.0000 --- loss: 1.134097, loss_ss: 0.981180, loss_d: 0.152917
0.2457 --- loss: 1.235201, loss_ss: 1.096003, loss_d: 0.139199
0.4914 --- loss: 1.216756, loss_ss: 0.990878, loss_d: 0.225877
0.7371 --- loss: 1.645784, loss_ss: 1.037173, loss_d: 0.608611
0.9828 --- loss: 1.569501, loss_ss: 1.200526, loss_d: 0.368975
Epoch finished! Loss: 1.3174091771245002
Starting epoch 10/10.
0.0000 --- loss: 1.069893, loss_ss: 1.030962, loss_d: 0.038931
0.2457 --- loss: 1.209959, loss_ss: 0.960475, loss_d: 0.249484
0.4914 --- loss: 1.164151, loss_ss: 0.953497, loss_d: 0.210655
0.7371 --- loss: 1.138571, loss_ss: 0.912077, loss_d: 0.226494
0.9828 --- loss: 0.888567, loss_ss: 0.854569, loss_d: 0.033998
Epoch finished! Loss: 1.274388951063156
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7611111111111111
              precision    recall  f1-score   support

         0.0       0.81      0.70      0.75       226
         1.0       0.00      0.00      0.00        55
         2.0       0.76      0.96      0.85       410
         3.0       1.00      0.65      0.79       108
         4.0       0.53      0.62      0.58       101

    accuracy                           0.76       900
   macro avg       0.62      0.59      0.59       900
weighted avg       0.73      0.76      0.73       900
 


====== chc016-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  88.44  70.35   94.51   81.12     75.36
1  93.89   0.00  100.00    0.00      0.00
2  84.44  95.85   74.90   76.16     84.88
3  95.78  64.81  100.00  100.00     78.65
4  89.67  62.38   93.12   53.39     57.53
Total accuracy: 76.11%
Average sen: 58.68%
Average spec: 92.50%
Macro f1-score: 59.28%
Diagnosis acc on 90mins: 0.8
[0.99999392 0.1475924  0.16524741 0.25530192 0.23329155]
pred: 0.36028544008731844, label: 0
Right! Diagnosis: Other
Save 90mins of subject chc016-nsrr

=== Test on chc022-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.437389, loss_ss: 1.758482, loss_d: 0.678907
0.2451 --- loss: 2.350073, loss_ss: 1.621986, loss_d: 0.728087
0.4902 --- loss: 1.643499, loss_ss: 1.348018, loss_d: 0.295481
0.7353 --- loss: 1.888722, loss_ss: 1.334033, loss_d: 0.554689
0.9804 --- loss: 2.010246, loss_ss: 1.381776, loss_d: 0.628470
Epoch finished! Loss: 2.0875704675912856
Starting epoch 2/10.
0.0000 --- loss: 2.110187, loss_ss: 1.333518, loss_d: 0.776669
0.2451 --- loss: 1.983817, loss_ss: 1.239852, loss_d: 0.743965
0.4902 --- loss: 1.981631, loss_ss: 1.450250, loss_d: 0.531381
0.7353 --- loss: 1.913988, loss_ss: 1.219061, loss_d: 0.694927
0.9804 --- loss: 1.886022, loss_ss: 1.391097, loss_d: 0.494925
Epoch finished! Loss: 1.8692941606044768
Starting epoch 3/10.
0.0000 --- loss: 1.484877, loss_ss: 1.258570, loss_d: 0.226307
0.2451 --- loss: 2.073740, loss_ss: 1.250977, loss_d: 0.822763
0.4902 --- loss: 1.582645, loss_ss: 1.216642, loss_d: 0.366004
0.7353 --- loss: 1.696748, loss_ss: 1.187760, loss_d: 0.508987
0.9804 --- loss: 1.682145, loss_ss: 1.417786, loss_d: 0.264360
Epoch finished! Loss: 1.7586820363998412
Starting epoch 4/10.
0.0000 --- loss: 1.476344, loss_ss: 1.335479, loss_d: 0.140865
0.2451 --- loss: 1.267716, loss_ss: 1.062797, loss_d: 0.204919
0.4902 --- loss: 1.546999, loss_ss: 1.380549, loss_d: 0.166449
0.7353 --- loss: 1.612918, loss_ss: 1.233253, loss_d: 0.379666
0.9804 --- loss: 1.346685, loss_ss: 1.139204, loss_d: 0.207480
Epoch finished! Loss: 1.6277991116046906
Starting epoch 5/10.
0.0000 --- loss: 1.273939, loss_ss: 1.199915, loss_d: 0.074024
0.2451 --- loss: 1.862195, loss_ss: 1.323357, loss_d: 0.538839
0.4902 --- loss: 1.518696, loss_ss: 1.340560, loss_d: 0.178136
0.7353 --- loss: 1.886308, loss_ss: 1.345325, loss_d: 0.540983
0.9804 --- loss: 1.407883, loss_ss: 1.178280, loss_d: 0.229602
Epoch finished! Loss: 1.5077764064073562
Starting epoch 6/10.
0.0000 --- loss: 1.403565, loss_ss: 1.192037, loss_d: 0.211527
0.2451 --- loss: 1.348944, loss_ss: 1.101750, loss_d: 0.247194
0.4902 --- loss: 1.365891, loss_ss: 1.304701, loss_d: 0.061190
0.7353 --- loss: 1.482282, loss_ss: 1.194399, loss_d: 0.287883
0.9804 --- loss: 1.391267, loss_ss: 1.358960, loss_d: 0.032307
Epoch finished! Loss: 1.4182505548000335
Starting epoch 7/10.
0.0000 --- loss: 1.272303, loss_ss: 1.228889, loss_d: 0.043414
0.2451 --- loss: 1.072653, loss_ss: 1.054675, loss_d: 0.017979
0.4902 --- loss: 1.494651, loss_ss: 1.231702, loss_d: 0.262948
0.7353 --- loss: 1.433282, loss_ss: 1.201934, loss_d: 0.231347
0.9804 --- loss: 1.152363, loss_ss: 1.088528, loss_d: 0.063835
Epoch finished! Loss: 1.2982941776514054
Starting epoch 8/10.
0.0000 --- loss: 1.230573, loss_ss: 1.095718, loss_d: 0.134855
0.2451 --- loss: 1.307100, loss_ss: 1.256209, loss_d: 0.050891
0.4902 --- loss: 1.212185, loss_ss: 1.186839, loss_d: 0.025346
0.7353 --- loss: 1.346897, loss_ss: 1.213503, loss_d: 0.133394
0.9804 --- loss: 1.526991, loss_ss: 1.150540, loss_d: 0.376451
Epoch finished! Loss: 1.3172931954264642
Starting epoch 9/10.
0.0000 --- loss: 1.303166, loss_ss: 1.164880, loss_d: 0.138286
0.2451 --- loss: 1.207462, loss_ss: 1.166945, loss_d: 0.040518
0.4902 --- loss: 1.249628, loss_ss: 1.177186, loss_d: 0.072442
0.7353 --- loss: 1.525149, loss_ss: 1.294056, loss_d: 0.231094
0.9804 --- loss: 1.298925, loss_ss: 1.154348, loss_d: 0.144578
Epoch finished! Loss: 1.356310111284256
Starting epoch 10/10.
0.0000 --- loss: 1.186162, loss_ss: 1.120108, loss_d: 0.066055
0.2451 --- loss: 1.147992, loss_ss: 1.101670, loss_d: 0.046322
0.4902 --- loss: 1.176038, loss_ss: 1.169522, loss_d: 0.006515
0.7353 --- loss: 1.274417, loss_ss: 1.242478, loss_d: 0.031939
0.9804 --- loss: 1.051974, loss_ss: 1.048930, loss_d: 0.003044
Epoch finished! Loss: 1.187524823844433
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5888888888888889
              precision    recall  f1-score   support

         0.0       0.95      0.22      0.36        91
         1.0       0.00      0.00      0.00         5
         2.0       0.60      0.98      0.74       328
         3.0       0.00      0.00      0.00       187
         4.0       0.51      0.74      0.61       109

    accuracy                           0.59       720
   macro avg       0.41      0.39      0.34       720
weighted avg       0.47      0.59      0.48       720
 


====== chc022-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  90.00  21.98   99.84  95.24     35.71
1  99.31   0.00  100.00   0.00      0.00
2  69.03  98.48   44.39  59.70     74.34
3  74.03   0.00  100.00   0.00      0.00
4  85.42  74.31   87.40  51.27     60.67
Total accuracy: 58.89%
Average sen: 38.95%
Average spec: 86.33%
Macro f1-score: 34.15%
Diagnosis acc on 90mins: 0.25
[0.99781114 0.76486808 0.05355914 0.99667609]
pred: 0.7032286124303937, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc022-nsrr

=== Test on chc025-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.388463, loss_ss: 1.823997, loss_d: 0.564465
0.2451 --- loss: 2.488494, loss_ss: 1.645196, loss_d: 0.843298
0.4902 --- loss: 2.175578, loss_ss: 1.640240, loss_d: 0.535338
0.7353 --- loss: 2.212264, loss_ss: 1.562610, loss_d: 0.649654
0.9804 --- loss: 2.295144, loss_ss: 1.576847, loss_d: 0.718297
Epoch finished! Loss: 2.3162803947925568
Starting epoch 2/10.
0.0000 --- loss: 1.968136, loss_ss: 1.479447, loss_d: 0.488689
0.2451 --- loss: 1.922915, loss_ss: 1.506048, loss_d: 0.416867
0.4902 --- loss: 2.134732, loss_ss: 1.481067, loss_d: 0.653666
0.7353 --- loss: 1.962432, loss_ss: 1.501971, loss_d: 0.460461
0.9804 --- loss: 2.010209, loss_ss: 1.384045, loss_d: 0.626164
Epoch finished! Loss: 2.124428763985634
Starting epoch 3/10.
0.0000 --- loss: 2.327022, loss_ss: 1.653512, loss_d: 0.673510
0.2451 --- loss: 1.912181, loss_ss: 1.333100, loss_d: 0.579081
0.4902 --- loss: 1.959981, loss_ss: 1.396327, loss_d: 0.563654
0.7353 --- loss: 1.825855, loss_ss: 1.458698, loss_d: 0.367157
0.9804 --- loss: 1.794316, loss_ss: 1.355025, loss_d: 0.439291
Epoch finished! Loss: 2.029614582657814
Starting epoch 4/10.
0.0000 --- loss: 1.722444, loss_ss: 1.318100, loss_d: 0.404344
0.2451 --- loss: 1.566407, loss_ss: 1.314192, loss_d: 0.252215
0.4902 --- loss: 2.015241, loss_ss: 1.293158, loss_d: 0.722082
0.7353 --- loss: 1.791424, loss_ss: 1.271202, loss_d: 0.520222
0.9804 --- loss: 1.909466, loss_ss: 1.223060, loss_d: 0.686405
Epoch finished! Loss: 1.963897231221199
Starting epoch 5/10.
0.0000 --- loss: 1.747629, loss_ss: 1.273262, loss_d: 0.474367
0.2451 --- loss: 1.848169, loss_ss: 1.306979, loss_d: 0.541190
0.4902 --- loss: 1.854489, loss_ss: 1.176171, loss_d: 0.678319
0.7353 --- loss: 1.793364, loss_ss: 1.287142, loss_d: 0.506222
0.9804 --- loss: 1.646138, loss_ss: 1.309836, loss_d: 0.336302
Epoch finished! Loss: 1.8416722118854523
Starting epoch 6/10.
0.0000 --- loss: 1.546724, loss_ss: 1.211350, loss_d: 0.335374
0.2451 --- loss: 1.724285, loss_ss: 1.213335, loss_d: 0.510949
0.4902 --- loss: 1.871786, loss_ss: 1.240799, loss_d: 0.630986
0.7353 --- loss: 1.558378, loss_ss: 1.228339, loss_d: 0.330039
0.9804 --- loss: 1.572715, loss_ss: 1.141347, loss_d: 0.431367
Epoch finished! Loss: 1.7049555897712707
Starting epoch 7/10.
0.0000 --- loss: 1.531546, loss_ss: 1.075472, loss_d: 0.456075
0.2451 --- loss: 1.410209, loss_ss: 1.145599, loss_d: 0.264610
0.4902 --- loss: 1.507856, loss_ss: 1.181284, loss_d: 0.326572
0.7353 --- loss: 1.549723, loss_ss: 1.124049, loss_d: 0.425674
0.9804 --- loss: 1.789078, loss_ss: 1.231113, loss_d: 0.557965
Epoch finished! Loss: 1.6684083044528961
Starting epoch 8/10.
0.0000 --- loss: 1.490757, loss_ss: 1.093279, loss_d: 0.397478
0.2451 --- loss: 1.468368, loss_ss: 1.011974, loss_d: 0.456394
0.4902 --- loss: 1.808423, loss_ss: 1.059251, loss_d: 0.749172
0.7353 --- loss: 1.525800, loss_ss: 1.137747, loss_d: 0.388053
0.9804 --- loss: 1.779229, loss_ss: 1.132571, loss_d: 0.646658
Epoch finished! Loss: 1.6270021557807923
Starting epoch 9/10.
0.0000 --- loss: 1.672039, loss_ss: 1.124658, loss_d: 0.547381
0.2451 --- loss: 1.476077, loss_ss: 1.037976, loss_d: 0.438101
0.4902 --- loss: 1.466885, loss_ss: 1.020977, loss_d: 0.445908
0.7353 --- loss: 1.284227, loss_ss: 1.154189, loss_d: 0.130038
0.9804 --- loss: 1.777454, loss_ss: 0.945081, loss_d: 0.832373
Epoch finished! Loss: 1.5067591190338134
Starting epoch 10/10.
0.0000 --- loss: 1.682012, loss_ss: 1.064186, loss_d: 0.617826
0.2451 --- loss: 1.134512, loss_ss: 1.019644, loss_d: 0.114869
0.4902 --- loss: 1.196998, loss_ss: 1.013817, loss_d: 0.183180
0.7353 --- loss: 1.568310, loss_ss: 0.993142, loss_d: 0.575168
0.9804 --- loss: 1.796177, loss_ss: 1.020085, loss_d: 0.776092
Epoch finished! Loss: 1.4452856749296188
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7291666666666666
              precision    recall  f1-score   support

         0.0       0.35      0.62      0.45        21
         1.0       0.00      0.00      0.00        39
         2.0       0.77      0.87      0.82       382
         3.0       0.91      0.69      0.79       114
         4.0       0.62      0.60      0.61       164

    accuracy                           0.73       720
   macro avg       0.53      0.56      0.53       720
weighted avg       0.70      0.73      0.71       720
 


====== chc025-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.56  61.90   96.57  35.14     44.83
1  94.58   0.00  100.00   0.00      0.00
2  79.17  87.43   69.82  76.61     81.66
3  94.03  69.30   98.68  90.80     78.61
4  82.50  60.37   89.03  61.88     61.11
Total accuracy: 72.92%
Average sen: 55.80%
Average spec: 90.82%
Macro f1-score: 53.24%
Diagnosis acc on 90mins: 0.0
[0.99143046 0.80205661 0.96708184 0.98988134]
pred: 0.9376125633716583, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc025-nsrr

=== Test on chc027-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.327321, loss_ss: 1.644922, loss_d: 0.682399
0.2457 --- loss: 2.419344, loss_ss: 1.592743, loss_d: 0.826601
0.4914 --- loss: 1.866817, loss_ss: 1.476171, loss_d: 0.390646
0.7371 --- loss: 1.914712, loss_ss: 1.469939, loss_d: 0.444773
0.9828 --- loss: 1.900379, loss_ss: 1.359897, loss_d: 0.540483
Epoch finished! Loss: 2.2058077603578568
Starting epoch 2/10.
0.0000 --- loss: 1.836421, loss_ss: 1.369408, loss_d: 0.467012
0.2457 --- loss: 1.938369, loss_ss: 1.376744, loss_d: 0.561625
0.4914 --- loss: 1.582095, loss_ss: 1.332674, loss_d: 0.249421
0.7371 --- loss: 1.919702, loss_ss: 1.342439, loss_d: 0.577264
0.9828 --- loss: 1.696882, loss_ss: 1.314410, loss_d: 0.382472
Epoch finished! Loss: 1.941988691687584
Starting epoch 3/10.
0.0000 --- loss: 1.649681, loss_ss: 1.269541, loss_d: 0.380140
0.2457 --- loss: 1.636185, loss_ss: 1.214129, loss_d: 0.422056
0.4914 --- loss: 1.753164, loss_ss: 1.220415, loss_d: 0.532749
0.7371 --- loss: 1.714286, loss_ss: 1.280960, loss_d: 0.433326
0.9828 --- loss: 1.624011, loss_ss: 1.315828, loss_d: 0.308183
Epoch finished! Loss: 1.8614995360374451
Starting epoch 4/10.
0.0000 --- loss: 1.573300, loss_ss: 1.272760, loss_d: 0.300540
0.2457 --- loss: 1.503358, loss_ss: 1.182865, loss_d: 0.320493
0.4914 --- loss: 1.620922, loss_ss: 1.297520, loss_d: 0.323401
0.7371 --- loss: 2.045716, loss_ss: 1.270768, loss_d: 0.774947
0.9828 --- loss: 1.737477, loss_ss: 1.198200, loss_d: 0.539277
Epoch finished! Loss: 1.768202969431877
Starting epoch 5/10.
0.0000 --- loss: 1.673000, loss_ss: 1.255363, loss_d: 0.417637
0.2457 --- loss: 1.729493, loss_ss: 1.270926, loss_d: 0.458567
0.4914 --- loss: 1.409793, loss_ss: 1.210490, loss_d: 0.199303
0.7371 --- loss: 1.441520, loss_ss: 1.139764, loss_d: 0.301756
0.9828 --- loss: 1.432372, loss_ss: 1.085441, loss_d: 0.346931
Epoch finished! Loss: 1.7011407285928726
Starting epoch 6/10.
0.0000 --- loss: 1.858295, loss_ss: 1.103782, loss_d: 0.754513
0.2457 --- loss: 1.662359, loss_ss: 1.246583, loss_d: 0.415777
0.4914 --- loss: 1.729857, loss_ss: 1.251182, loss_d: 0.478675
0.7371 --- loss: 1.623163, loss_ss: 1.155475, loss_d: 0.467688
0.9828 --- loss: 2.240701, loss_ss: 1.142505, loss_d: 1.098196
Epoch finished! Loss: 1.6762613862752915
Starting epoch 7/10.
0.0000 --- loss: 1.382527, loss_ss: 0.979493, loss_d: 0.403034
0.2457 --- loss: 1.265048, loss_ss: 1.081491, loss_d: 0.183557
0.4914 --- loss: 1.721253, loss_ss: 1.076903, loss_d: 0.644350
0.7371 --- loss: 1.844449, loss_ss: 1.034266, loss_d: 0.810183
0.9828 --- loss: 1.652235, loss_ss: 1.091857, loss_d: 0.560378
Epoch finished! Loss: 1.577273291349411
Starting epoch 8/10.
0.0000 --- loss: 1.463506, loss_ss: 1.216386, loss_d: 0.247120
0.2457 --- loss: 1.141720, loss_ss: 0.966719, loss_d: 0.175001
0.4914 --- loss: 1.331721, loss_ss: 1.117006, loss_d: 0.214715
0.7371 --- loss: 1.067159, loss_ss: 0.960171, loss_d: 0.106988
0.9828 --- loss: 1.303320, loss_ss: 1.108636, loss_d: 0.194684
Epoch finished! Loss: 1.4275443464517594
Starting epoch 9/10.
0.0000 --- loss: 1.376045, loss_ss: 1.164729, loss_d: 0.211316
0.2457 --- loss: 1.600972, loss_ss: 1.206601, loss_d: 0.394372
0.4914 --- loss: 1.832881, loss_ss: 1.253643, loss_d: 0.579238
0.7371 --- loss: 1.531382, loss_ss: 1.050333, loss_d: 0.481049
0.9828 --- loss: 1.580186, loss_ss: 1.373371, loss_d: 0.206815
Epoch finished! Loss: 1.4864003390073777
Starting epoch 10/10.
0.0000 --- loss: 1.185324, loss_ss: 1.041107, loss_d: 0.144218
0.2457 --- loss: 1.217373, loss_ss: 1.137418, loss_d: 0.079954
0.4914 --- loss: 1.121784, loss_ss: 1.008325, loss_d: 0.113459
0.7371 --- loss: 1.274988, loss_ss: 1.180021, loss_d: 0.094967
0.9828 --- loss: 1.290015, loss_ss: 1.154683, loss_d: 0.135332
Epoch finished! Loss: 1.238746953010559
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6811111111111111
              precision    recall  f1-score   support

         0.0       0.71      0.70      0.71       277
         1.0       0.53      0.12      0.20        66
         2.0       0.60      0.98      0.74       293
         3.0       1.00      0.30      0.46       189
         4.0       0.87      0.89      0.88        75

    accuracy                           0.68       900
   macro avg       0.74      0.60      0.60       900
weighted avg       0.74      0.68      0.64       900
 


====== chc027-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  82.22  70.40   87.48   71.43     70.91
1  92.78  12.12   99.16   53.33     19.75
2  78.00  97.95   68.37   59.92     74.35
3  85.22  29.63  100.00  100.00     45.71
4  98.00  89.33   98.79   87.01     88.16
Total accuracy: 68.11%
Average sen: 59.89%
Average spec: 90.76%
Macro f1-score: 59.78%
Diagnosis acc on 90mins: 0.0
[0.99871802 0.93417722 0.72849613 0.85784751 0.69243592]
pred: 0.8423349618911743, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc027-nsrr

=== Test on chc028-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.370842, loss_ss: 1.656063, loss_d: 0.714780
0.2451 --- loss: 2.697590, loss_ss: 1.420646, loss_d: 1.276945
0.4902 --- loss: 2.137626, loss_ss: 1.388952, loss_d: 0.748674
0.7353 --- loss: 1.941432, loss_ss: 1.298098, loss_d: 0.643335
0.9804 --- loss: 1.996683, loss_ss: 1.374573, loss_d: 0.622110
Epoch finished! Loss: 2.1249191403388976
Starting epoch 2/10.
0.0000 --- loss: 1.969138, loss_ss: 1.315394, loss_d: 0.653745
0.2451 --- loss: 2.207434, loss_ss: 1.416853, loss_d: 0.790580
0.4902 --- loss: 1.679291, loss_ss: 1.235670, loss_d: 0.443620
0.7353 --- loss: 1.679959, loss_ss: 1.203653, loss_d: 0.476306
0.9804 --- loss: 2.254307, loss_ss: 1.319335, loss_d: 0.934972
Epoch finished! Loss: 1.869571641087532
Starting epoch 3/10.
0.0000 --- loss: 1.675150, loss_ss: 1.227509, loss_d: 0.447641
0.2451 --- loss: 1.788631, loss_ss: 1.211850, loss_d: 0.576781
0.4902 --- loss: 1.499608, loss_ss: 1.160833, loss_d: 0.338775
0.7353 --- loss: 1.868984, loss_ss: 1.193593, loss_d: 0.675391
0.9804 --- loss: 1.581074, loss_ss: 1.101475, loss_d: 0.479599
Epoch finished! Loss: 1.7891879081726074
Starting epoch 4/10.
0.0000 --- loss: 1.678879, loss_ss: 1.318225, loss_d: 0.360654
0.2451 --- loss: 1.762053, loss_ss: 1.083951, loss_d: 0.678103
0.4902 --- loss: 1.675554, loss_ss: 1.048482, loss_d: 0.627072
0.7353 --- loss: 1.496998, loss_ss: 1.184636, loss_d: 0.312362
0.9804 --- loss: 1.720754, loss_ss: 1.214263, loss_d: 0.506490
Epoch finished! Loss: 1.6862325221300125
Starting epoch 5/10.
0.0000 --- loss: 1.626154, loss_ss: 1.085697, loss_d: 0.540457
0.2451 --- loss: 1.580909, loss_ss: 1.066722, loss_d: 0.514187
0.4902 --- loss: 1.579673, loss_ss: 1.161155, loss_d: 0.418518
0.7353 --- loss: 1.483825, loss_ss: 1.006506, loss_d: 0.477319
0.9804 --- loss: 2.088072, loss_ss: 1.163636, loss_d: 0.924435
Epoch finished! Loss: 1.6373463183641435
Starting epoch 6/10.
0.0000 --- loss: 1.504677, loss_ss: 1.170769, loss_d: 0.333908
0.2451 --- loss: 1.496457, loss_ss: 1.089400, loss_d: 0.407057
0.4902 --- loss: 1.391420, loss_ss: 1.053001, loss_d: 0.338419
0.7353 --- loss: 1.446869, loss_ss: 1.170650, loss_d: 0.276219
0.9804 --- loss: 1.987898, loss_ss: 1.039734, loss_d: 0.948164
Epoch finished! Loss: 1.5650777459144591
Starting epoch 7/10.
0.0000 --- loss: 1.735767, loss_ss: 1.228467, loss_d: 0.507300
0.2451 --- loss: 1.538538, loss_ss: 1.244898, loss_d: 0.293641
0.4902 --- loss: 1.814177, loss_ss: 1.043118, loss_d: 0.771059
0.7353 --- loss: 1.718955, loss_ss: 1.017801, loss_d: 0.701154
0.9804 --- loss: 1.153417, loss_ss: 0.932415, loss_d: 0.221002
Epoch finished! Loss: 1.487274670600891
Starting epoch 8/10.
0.0000 --- loss: 1.487139, loss_ss: 0.973866, loss_d: 0.513272
0.2451 --- loss: 1.643705, loss_ss: 1.221597, loss_d: 0.422108
0.4902 --- loss: 1.502101, loss_ss: 1.017650, loss_d: 0.484451
0.7353 --- loss: 1.399255, loss_ss: 0.838029, loss_d: 0.561225
0.9804 --- loss: 1.150362, loss_ss: 0.925215, loss_d: 0.225147
Epoch finished! Loss: 1.4451876401901245
Starting epoch 9/10.
0.0000 --- loss: 1.123595, loss_ss: 0.913179, loss_d: 0.210417
0.2451 --- loss: 1.174449, loss_ss: 1.039490, loss_d: 0.134959
0.4902 --- loss: 1.308609, loss_ss: 1.064242, loss_d: 0.244367
0.7353 --- loss: 2.237027, loss_ss: 0.948684, loss_d: 1.288343
0.9804 --- loss: 1.417957, loss_ss: 1.181112, loss_d: 0.236845
Epoch finished! Loss: 1.3598907470703125
Starting epoch 10/10.
0.0000 --- loss: 1.331939, loss_ss: 1.137471, loss_d: 0.194468
0.2451 --- loss: 1.245433, loss_ss: 0.986296, loss_d: 0.259138
0.4902 --- loss: 1.286244, loss_ss: 1.052188, loss_d: 0.234056
0.7353 --- loss: 1.232348, loss_ss: 1.003662, loss_d: 0.228686
0.9804 --- loss: 1.045552, loss_ss: 0.969068, loss_d: 0.076484
Epoch finished! Loss: 1.2654834702610969
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7458333333333333
              precision    recall  f1-score   support

         0.0       0.89      0.73      0.80        98
         1.0       0.00      0.00      0.00        44
         2.0       0.77      0.83      0.80       359
         3.0       0.83      0.81      0.82       145
         4.0       0.45      0.66      0.53        74

    accuracy                           0.75       720
   macro avg       0.59      0.61      0.59       720
weighted avg       0.72      0.75      0.73       720
 


====== chc028-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.14  73.47   98.55  88.89     80.45
1  93.89   0.00  100.00   0.00      0.00
2  79.17  83.01   75.35  77.00     79.89
3  92.92  81.38   95.83  83.10     82.23
4  88.06  66.22   90.56  44.55     53.26
Total accuracy: 74.58%
Average sen: 60.81%
Average spec: 92.06%
Macro f1-score: 59.17%
Diagnosis acc on 90mins: 0.75
[0.82187986 0.31740505 0.07756798 0.20311607]
pred: 0.35499224066734314, label: 0
Right! Diagnosis: Other
Save 90mins of subject chc028-nsrr

=== Test on chc033-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.135231, loss_ss: 1.438529, loss_d: 0.696702
0.2451 --- loss: 2.219011, loss_ss: 1.465951, loss_d: 0.753060
0.4902 --- loss: 1.749070, loss_ss: 1.351096, loss_d: 0.397974
0.7353 --- loss: 1.899081, loss_ss: 1.260708, loss_d: 0.638373
0.9804 --- loss: 1.740858, loss_ss: 1.164432, loss_d: 0.576426
Epoch finished! Loss: 2.050242429971695
Starting epoch 2/10.
0.0000 --- loss: 1.667909, loss_ss: 1.187191, loss_d: 0.480719
0.2451 --- loss: 1.889405, loss_ss: 1.233644, loss_d: 0.655761
0.4902 --- loss: 1.658863, loss_ss: 1.095714, loss_d: 0.563149
0.7353 --- loss: 1.936342, loss_ss: 1.180833, loss_d: 0.755509
0.9804 --- loss: 1.549591, loss_ss: 1.125342, loss_d: 0.424249
Epoch finished! Loss: 1.8085234045982361
Starting epoch 3/10.
0.0000 --- loss: 1.838885, loss_ss: 1.204314, loss_d: 0.634572
0.2451 --- loss: 1.415950, loss_ss: 1.135349, loss_d: 0.280601
0.4902 --- loss: 1.646756, loss_ss: 1.191464, loss_d: 0.455292
0.7353 --- loss: 1.547917, loss_ss: 1.050720, loss_d: 0.497197
0.9804 --- loss: 1.536285, loss_ss: 1.278805, loss_d: 0.257480
Epoch finished! Loss: 1.6737451285123826
Starting epoch 4/10.
0.0000 --- loss: 1.489032, loss_ss: 1.105926, loss_d: 0.383106
0.2451 --- loss: 1.408452, loss_ss: 1.116996, loss_d: 0.291456
0.4902 --- loss: 1.346088, loss_ss: 1.137906, loss_d: 0.208182
0.7353 --- loss: 1.360025, loss_ss: 1.112304, loss_d: 0.247721
0.9804 --- loss: 1.380861, loss_ss: 1.051298, loss_d: 0.329563
Epoch finished! Loss: 1.5438291817903518
Starting epoch 5/10.
0.0000 --- loss: 1.337352, loss_ss: 1.082717, loss_d: 0.254635
0.2451 --- loss: 1.225040, loss_ss: 0.961792, loss_d: 0.263247
0.4902 --- loss: 1.243451, loss_ss: 1.042988, loss_d: 0.200463
0.7353 --- loss: 1.547127, loss_ss: 1.074152, loss_d: 0.472975
0.9804 --- loss: 1.642675, loss_ss: 1.230734, loss_d: 0.411941
Epoch finished! Loss: 1.4604216158390044
Starting epoch 6/10.
0.0000 --- loss: 1.299878, loss_ss: 1.023563, loss_d: 0.276315
0.2451 --- loss: 1.280390, loss_ss: 1.187880, loss_d: 0.092510
0.4902 --- loss: 1.240597, loss_ss: 1.004161, loss_d: 0.236436
0.7353 --- loss: 1.510635, loss_ss: 1.311872, loss_d: 0.198763
0.9804 --- loss: 1.601807, loss_ss: 1.118089, loss_d: 0.483718
Epoch finished! Loss: 1.4096577227115632
Starting epoch 7/10.
0.0000 --- loss: 1.436937, loss_ss: 1.258610, loss_d: 0.178327
0.2451 --- loss: 1.291737, loss_ss: 0.945136, loss_d: 0.346601
0.4902 --- loss: 1.290663, loss_ss: 1.104642, loss_d: 0.186022
0.7353 --- loss: 1.085430, loss_ss: 1.009743, loss_d: 0.075687
0.9804 --- loss: 1.673396, loss_ss: 1.308693, loss_d: 0.364703
Epoch finished! Loss: 1.282679434120655
Starting epoch 8/10.
0.0000 --- loss: 1.061237, loss_ss: 1.033481, loss_d: 0.027755
0.2451 --- loss: 1.163167, loss_ss: 1.149918, loss_d: 0.013249
0.4902 --- loss: 1.209495, loss_ss: 1.161872, loss_d: 0.047623
0.7353 --- loss: 0.933578, loss_ss: 0.854100, loss_d: 0.079479
0.9804 --- loss: 1.017139, loss_ss: 0.972466, loss_d: 0.044673
Epoch finished! Loss: 1.0939277052879333
Starting epoch 9/10.
0.0000 --- loss: 1.190785, loss_ss: 1.083224, loss_d: 0.107562
0.2451 --- loss: 1.085746, loss_ss: 1.027961, loss_d: 0.057784
0.4902 --- loss: 0.935635, loss_ss: 0.925010, loss_d: 0.010625
0.7353 --- loss: 1.068946, loss_ss: 1.063102, loss_d: 0.005844
0.9804 --- loss: 1.010742, loss_ss: 0.987685, loss_d: 0.023058
Epoch finished! Loss: 1.0829887360334396
Starting epoch 10/10.
0.0000 --- loss: 0.968734, loss_ss: 0.962192, loss_d: 0.006542
0.2451 --- loss: 1.117260, loss_ss: 1.111638, loss_d: 0.005622
0.4902 --- loss: 1.377348, loss_ss: 1.160422, loss_d: 0.216926
0.7353 --- loss: 1.332553, loss_ss: 1.328446, loss_d: 0.004107
0.9804 --- loss: 1.235705, loss_ss: 0.780379, loss_d: 0.455326
Epoch finished! Loss: 1.128493818640709
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        59
         1.0       0.00      0.00      0.00        56
         2.0       0.82      0.60      0.69       358
         3.0       0.55      1.00      0.71       151
         4.0       0.36      0.69      0.48        96

    accuracy                           0.60       720
   macro avg       0.35      0.46      0.38       720
weighted avg       0.57      0.60      0.56       720
 


====== chc033-nsrr ======

The ppr of  0  has ZeroDivisionError.

The f1-score of  0  has ZeroDivisionError.

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  91.81    0.00  100.00   0.00      0.00
1  92.22    0.00  100.00   0.00      0.00
2  73.61   60.06   87.02  82.06     69.35
3  82.50  100.00   77.86  54.51     70.56
4  79.86   68.75   81.57  36.46     47.65
Total accuracy: 60.00%
Average sen: 45.76%
Average spec: 89.29%
Macro f1-score: 37.51%
Diagnosis acc on 90mins: 0.25
[0.92948794 0.07511461 0.99973112 0.99999237]
pred: 0.7510815113782883, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc033-nsrr

=== Test on chc035-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.265033, loss_ss: 1.554371, loss_d: 0.710662
0.2457 --- loss: 2.192000, loss_ss: 1.304505, loss_d: 0.887494
0.4914 --- loss: 1.847300, loss_ss: 1.390446, loss_d: 0.456854
0.7371 --- loss: 2.046422, loss_ss: 1.339288, loss_d: 0.707135
0.9828 --- loss: 1.966949, loss_ss: 1.365122, loss_d: 0.601827
Epoch finished! Loss: 2.0580174565315246
Starting epoch 2/10.
0.0000 --- loss: 1.781705, loss_ss: 1.279178, loss_d: 0.502527
0.2457 --- loss: 1.985103, loss_ss: 1.252936, loss_d: 0.732167
0.4914 --- loss: 1.896149, loss_ss: 1.231318, loss_d: 0.664831
0.7371 --- loss: 1.842834, loss_ss: 1.295976, loss_d: 0.546858
0.9828 --- loss: 1.833991, loss_ss: 1.233481, loss_d: 0.600510
Epoch finished! Loss: 1.8279290109872819
Starting epoch 3/10.
0.0000 --- loss: 1.890504, loss_ss: 1.253254, loss_d: 0.637250
0.2457 --- loss: 1.701632, loss_ss: 1.211845, loss_d: 0.489787
0.4914 --- loss: 1.632221, loss_ss: 1.270647, loss_d: 0.361574
0.7371 --- loss: 1.742489, loss_ss: 1.264651, loss_d: 0.477839
0.9828 --- loss: 1.633590, loss_ss: 1.264194, loss_d: 0.369396
Epoch finished! Loss: 1.755235916376114
Starting epoch 4/10.
0.0000 --- loss: 1.608028, loss_ss: 1.156873, loss_d: 0.451155
0.2457 --- loss: 1.621993, loss_ss: 1.137851, loss_d: 0.484142
0.4914 --- loss: 1.554806, loss_ss: 1.051482, loss_d: 0.503324
0.7371 --- loss: 1.426855, loss_ss: 1.104709, loss_d: 0.322146
0.9828 --- loss: 1.585104, loss_ss: 1.163957, loss_d: 0.421147
Epoch finished! Loss: 1.646848002076149
Starting epoch 5/10.
0.0000 --- loss: 1.404220, loss_ss: 1.155870, loss_d: 0.248349
0.2457 --- loss: 1.492426, loss_ss: 1.134036, loss_d: 0.358390
0.4914 --- loss: 1.522380, loss_ss: 1.191085, loss_d: 0.331295
0.7371 --- loss: 1.443438, loss_ss: 1.105044, loss_d: 0.338393
0.9828 --- loss: 2.361767, loss_ss: 1.130323, loss_d: 1.231444
Epoch finished! Loss: 1.5322595357894897
Starting epoch 6/10.
0.0000 --- loss: 1.433204, loss_ss: 1.172904, loss_d: 0.260299
0.2457 --- loss: 1.410136, loss_ss: 1.145016, loss_d: 0.265119
0.4914 --- loss: 1.317549, loss_ss: 0.989083, loss_d: 0.328465
0.7371 --- loss: 1.517313, loss_ss: 1.118389, loss_d: 0.398924
0.9828 --- loss: 1.374932, loss_ss: 1.080297, loss_d: 0.294635
Epoch finished! Loss: 1.4073948323726655
Starting epoch 7/10.
0.0000 --- loss: 1.377821, loss_ss: 1.115695, loss_d: 0.262126
0.2457 --- loss: 1.088955, loss_ss: 1.020626, loss_d: 0.068329
0.4914 --- loss: 1.353698, loss_ss: 0.974376, loss_d: 0.379323
0.7371 --- loss: 1.160254, loss_ss: 1.053264, loss_d: 0.106990
0.9828 --- loss: 0.982115, loss_ss: 0.943529, loss_d: 0.038586
Epoch finished! Loss: 1.1717196986079217
Starting epoch 8/10.
0.0000 --- loss: 1.193319, loss_ss: 1.051468, loss_d: 0.141852
0.2457 --- loss: 0.984173, loss_ss: 0.943021, loss_d: 0.041152
0.4914 --- loss: 1.163112, loss_ss: 1.127455, loss_d: 0.035657
0.7371 --- loss: 1.117582, loss_ss: 0.926615, loss_d: 0.190967
0.9828 --- loss: 1.199848, loss_ss: 0.984820, loss_d: 0.215028
Epoch finished! Loss: 1.178598216176033
Starting epoch 9/10.
0.0000 --- loss: 1.196304, loss_ss: 1.022278, loss_d: 0.174026
0.2457 --- loss: 0.899143, loss_ss: 0.882095, loss_d: 0.017048
0.4914 --- loss: 1.161841, loss_ss: 0.943684, loss_d: 0.218156
0.7371 --- loss: 1.084052, loss_ss: 0.984863, loss_d: 0.099190
0.9828 --- loss: 1.047752, loss_ss: 0.968379, loss_d: 0.079373
Epoch finished! Loss: 1.1022674322128296
Starting epoch 10/10.
0.0000 --- loss: 1.010585, loss_ss: 1.008230, loss_d: 0.002355
0.2457 --- loss: 0.953788, loss_ss: 0.936498, loss_d: 0.017290
0.4914 --- loss: 0.955323, loss_ss: 0.946342, loss_d: 0.008981
0.7371 --- loss: 0.900744, loss_ss: 0.822309, loss_d: 0.078434
0.9828 --- loss: 1.243457, loss_ss: 1.241246, loss_d: 0.002211
Epoch finished! Loss: 0.999289371073246
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6777777777777778
              precision    recall  f1-score   support

         0.0       0.34      0.97      0.50        29
         1.0       0.33      0.09      0.14        57
         2.0       0.63      0.93      0.75       391
         3.0       0.97      0.68      0.80       250
         4.0       0.91      0.25      0.39       173

    accuracy                           0.68       900
   macro avg       0.64      0.58      0.52       900
weighted avg       0.75      0.68      0.65       900
 


====== chc035-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  93.78  96.55   93.69  33.73     50.00
1  93.11   8.77   98.81  33.33     13.89
2  73.11  93.35   57.56  62.82     75.10
3  90.44  67.60   99.23  97.13     79.72
4  85.11  24.86   99.45  91.49     39.09
Total accuracy: 67.78%
Average sen: 58.23%
Average spec: 89.75%
Macro f1-score: 51.56%
Diagnosis acc on 90mins: 0.4
[0.28683966 0.72298688 0.96069467 0.0095655  0.99521244]
pred: 0.5950598295778036, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc035-nsrr

=== Test on chc037-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.441526, loss_ss: 1.730685, loss_d: 0.710842
0.2451 --- loss: 2.434133, loss_ss: 1.502528, loss_d: 0.931605
0.4902 --- loss: 2.102218, loss_ss: 1.500109, loss_d: 0.602109
0.7353 --- loss: 1.935838, loss_ss: 1.410153, loss_d: 0.525685
0.9804 --- loss: 1.939109, loss_ss: 1.361596, loss_d: 0.577513
Epoch finished! Loss: 2.134293630719185
Starting epoch 2/10.
0.0000 --- loss: 1.854617, loss_ss: 1.351850, loss_d: 0.502767
0.2451 --- loss: 1.773716, loss_ss: 1.280193, loss_d: 0.493523
0.4902 --- loss: 1.842753, loss_ss: 1.418645, loss_d: 0.424108
0.7353 --- loss: 1.635524, loss_ss: 1.268584, loss_d: 0.366940
0.9804 --- loss: 2.103992, loss_ss: 1.290762, loss_d: 0.813230
Epoch finished! Loss: 1.904057052731514
Starting epoch 3/10.
0.0000 --- loss: 1.814137, loss_ss: 1.271781, loss_d: 0.542356
0.2451 --- loss: 1.993179, loss_ss: 1.347106, loss_d: 0.646072
0.4902 --- loss: 1.573660, loss_ss: 1.263237, loss_d: 0.310423
0.7353 --- loss: 1.604663, loss_ss: 1.207242, loss_d: 0.397421
0.9804 --- loss: 1.477626, loss_ss: 1.193822, loss_d: 0.283804
Epoch finished! Loss: 1.7297509461641312
Starting epoch 4/10.
0.0000 --- loss: 1.933611, loss_ss: 1.111544, loss_d: 0.822067
0.2451 --- loss: 1.595562, loss_ss: 1.245121, loss_d: 0.350440
0.4902 --- loss: 1.426732, loss_ss: 1.163403, loss_d: 0.263330
0.7353 --- loss: 1.607703, loss_ss: 1.051204, loss_d: 0.556500
0.9804 --- loss: 1.347255, loss_ss: 1.131556, loss_d: 0.215699
Epoch finished! Loss: 1.570968896150589
Starting epoch 5/10.
0.0000 --- loss: 1.358217, loss_ss: 1.196257, loss_d: 0.161960
0.2451 --- loss: 1.360632, loss_ss: 1.096991, loss_d: 0.263641
0.4902 --- loss: 1.225241, loss_ss: 1.032389, loss_d: 0.192852
0.7353 --- loss: 1.324866, loss_ss: 1.250272, loss_d: 0.074594
0.9804 --- loss: 1.363801, loss_ss: 1.218613, loss_d: 0.145189
Epoch finished! Loss: 1.4540473699569703
Starting epoch 6/10.
0.0000 --- loss: 1.249340, loss_ss: 1.030257, loss_d: 0.219083
0.2451 --- loss: 1.195184, loss_ss: 1.056189, loss_d: 0.138995
0.4902 --- loss: 1.112720, loss_ss: 1.087857, loss_d: 0.024864
0.7353 --- loss: 1.075623, loss_ss: 1.003661, loss_d: 0.071962
0.9804 --- loss: 1.145187, loss_ss: 1.101566, loss_d: 0.043621
Epoch finished! Loss: 1.253717941045761
Starting epoch 7/10.
0.0000 --- loss: 0.934148, loss_ss: 0.921662, loss_d: 0.012486
0.2451 --- loss: 1.688041, loss_ss: 1.091917, loss_d: 0.596125
0.4902 --- loss: 1.127305, loss_ss: 1.094861, loss_d: 0.032444
0.7353 --- loss: 1.553185, loss_ss: 0.992380, loss_d: 0.560804
0.9804 --- loss: 1.326481, loss_ss: 1.222409, loss_d: 0.104072
Epoch finished! Loss: 1.2863084957003594
Starting epoch 8/10.
0.0000 --- loss: 1.046571, loss_ss: 0.954515, loss_d: 0.092056
0.2451 --- loss: 0.980826, loss_ss: 0.909263, loss_d: 0.071564
0.4902 --- loss: 1.510072, loss_ss: 1.013546, loss_d: 0.496526
0.7353 --- loss: 1.002579, loss_ss: 0.926276, loss_d: 0.076304
0.9804 --- loss: 1.202108, loss_ss: 0.974614, loss_d: 0.227494
Epoch finished! Loss: 1.1389474838972091
Starting epoch 9/10.
0.0000 --- loss: 0.969236, loss_ss: 0.956979, loss_d: 0.012257
0.2451 --- loss: 1.052041, loss_ss: 0.998839, loss_d: 0.053201
0.4902 --- loss: 0.954763, loss_ss: 0.926071, loss_d: 0.028692
0.7353 --- loss: 0.949331, loss_ss: 0.929850, loss_d: 0.019481
0.9804 --- loss: 1.023082, loss_ss: 1.011720, loss_d: 0.011363
Epoch finished! Loss: 1.0186908572912217
Starting epoch 10/10.
0.0000 --- loss: 1.018651, loss_ss: 0.940396, loss_d: 0.078254
0.2451 --- loss: 0.991827, loss_ss: 0.940176, loss_d: 0.051651
0.4902 --- loss: 1.022222, loss_ss: 1.011878, loss_d: 0.010343
0.7353 --- loss: 1.015421, loss_ss: 1.006916, loss_d: 0.008505
0.9804 --- loss: 1.047274, loss_ss: 0.902002, loss_d: 0.145271
Epoch finished! Loss: 0.9787578076124192
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6930555555555555
              precision    recall  f1-score   support

         0.0       0.83      0.37      0.51       154
         1.0       0.00      0.00      0.00        30
         2.0       0.70      0.78      0.74       259
         3.0       0.99      0.81      0.89       168
         4.0       0.47      0.94      0.62       109

    accuracy                           0.69       720
   macro avg       0.60      0.58      0.55       720
weighted avg       0.73      0.69      0.68       720
 


====== chc037-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  84.86  37.01   97.88  82.61     51.12
1  95.69   0.00   99.86   0.00      0.00
2  80.00  78.38   80.91  69.76     73.82
3  95.28  80.95   99.64  98.55     88.89
4  82.78  94.50   80.69  46.61     62.42
Total accuracy: 69.31%
Average sen: 58.17%
Average spec: 91.79%
Macro f1-score: 55.25%
Diagnosis acc on 90mins: 0.5
[0.00113719 0.95614773 0.31158099 0.99990869]
pred: 0.5671936491853558, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc037-nsrr

=== Test on chc040-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.355608, loss_ss: 1.619751, loss_d: 0.735857
0.2463 --- loss: 2.119501, loss_ss: 1.549557, loss_d: 0.569944
0.4926 --- loss: 1.945303, loss_ss: 1.448865, loss_d: 0.496438
0.7389 --- loss: 1.955371, loss_ss: 1.463839, loss_d: 0.491533
0.9852 --- loss: 1.786917, loss_ss: 1.314320, loss_d: 0.472597
Epoch finished! Loss: 2.132599428296089
Starting epoch 2/10.
0.0000 --- loss: 1.697348, loss_ss: 1.339283, loss_d: 0.358065
0.2463 --- loss: 1.627923, loss_ss: 1.286413, loss_d: 0.341510
0.4926 --- loss: 2.191121, loss_ss: 1.239300, loss_d: 0.951821
0.7389 --- loss: 1.888978, loss_ss: 1.225168, loss_d: 0.663810
0.9852 --- loss: 1.656004, loss_ss: 1.301357, loss_d: 0.354647
Epoch finished! Loss: 1.8686574548482895
Starting epoch 3/10.
0.0000 --- loss: 1.691402, loss_ss: 1.239570, loss_d: 0.451832
0.2463 --- loss: 1.742794, loss_ss: 1.219924, loss_d: 0.522870
0.4926 --- loss: 1.725374, loss_ss: 1.254064, loss_d: 0.471310
0.7389 --- loss: 1.628321, loss_ss: 1.188103, loss_d: 0.440218
0.9852 --- loss: 2.273713, loss_ss: 1.125199, loss_d: 1.148514
Epoch finished! Loss: 1.7676533132791519
Starting epoch 4/10.
0.0000 --- loss: 1.581270, loss_ss: 1.182621, loss_d: 0.398649
0.2463 --- loss: 1.543025, loss_ss: 1.106365, loss_d: 0.436660
0.4926 --- loss: 1.509372, loss_ss: 1.129179, loss_d: 0.380193
0.7389 --- loss: 1.334234, loss_ss: 1.115183, loss_d: 0.219051
0.9852 --- loss: 1.927347, loss_ss: 1.173486, loss_d: 0.753861
Epoch finished! Loss: 1.6307226985692977
Starting epoch 5/10.
0.0000 --- loss: 1.259548, loss_ss: 1.101493, loss_d: 0.158055
0.2463 --- loss: 1.453896, loss_ss: 0.985102, loss_d: 0.468793
0.4926 --- loss: 1.565892, loss_ss: 0.995384, loss_d: 0.570508
0.7389 --- loss: 1.288752, loss_ss: 1.055619, loss_d: 0.233133
0.9852 --- loss: 1.382841, loss_ss: 1.133001, loss_d: 0.249840
Epoch finished! Loss: 1.4718403935432434
Starting epoch 6/10.
0.0000 --- loss: 1.242537, loss_ss: 1.032495, loss_d: 0.210042
0.2463 --- loss: 1.154902, loss_ss: 1.034827, loss_d: 0.120075
0.4926 --- loss: 1.265874, loss_ss: 0.949998, loss_d: 0.315876
0.7389 --- loss: 1.346850, loss_ss: 1.184566, loss_d: 0.162284
0.9852 --- loss: 1.243315, loss_ss: 0.963007, loss_d: 0.280308
Epoch finished! Loss: 1.3981034338474274
Starting epoch 7/10.
0.0000 --- loss: 1.160671, loss_ss: 0.970036, loss_d: 0.190635
0.2463 --- loss: 1.130109, loss_ss: 0.918878, loss_d: 0.211231
0.4926 --- loss: 1.142705, loss_ss: 0.999922, loss_d: 0.142783
0.7389 --- loss: 1.073870, loss_ss: 0.966287, loss_d: 0.107583
0.9852 --- loss: 1.377572, loss_ss: 0.978404, loss_d: 0.399167
Epoch finished! Loss: 1.2239654213190079
Starting epoch 8/10.
0.0000 --- loss: 1.040965, loss_ss: 1.003807, loss_d: 0.037157
0.2463 --- loss: 1.103278, loss_ss: 1.066418, loss_d: 0.036859
0.4926 --- loss: 1.083928, loss_ss: 0.937927, loss_d: 0.146001
0.7389 --- loss: 1.087129, loss_ss: 0.927795, loss_d: 0.159334
0.9852 --- loss: 1.208768, loss_ss: 0.909659, loss_d: 0.299109
Epoch finished! Loss: 1.1906538799405098
Starting epoch 9/10.
0.0000 --- loss: 0.989952, loss_ss: 0.868060, loss_d: 0.121892
0.2463 --- loss: 1.162662, loss_ss: 0.943341, loss_d: 0.219320
0.4926 --- loss: 0.897966, loss_ss: 0.878261, loss_d: 0.019705
0.7389 --- loss: 0.912483, loss_ss: 0.862099, loss_d: 0.050384
0.9852 --- loss: 1.008301, loss_ss: 0.998179, loss_d: 0.010122
Epoch finished! Loss: 1.0982738599181174
Starting epoch 10/10.
0.0000 --- loss: 0.897585, loss_ss: 0.882089, loss_d: 0.015496
0.2463 --- loss: 0.930105, loss_ss: 0.893846, loss_d: 0.036259
0.4926 --- loss: 1.019320, loss_ss: 1.002834, loss_d: 0.016486
0.7389 --- loss: 0.989464, loss_ss: 0.917606, loss_d: 0.071858
0.9852 --- loss: 0.976191, loss_ss: 0.973066, loss_d: 0.003125
Epoch finished! Loss: 0.9890241384506225
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6268518518518519
              precision    recall  f1-score   support

         0.0       0.88      0.25      0.39       185
         1.0       0.03      0.02      0.02        50
         2.0       0.79      0.77      0.78       483
         3.0       0.94      0.54      0.69       216
         4.0       0.36      0.95      0.52       146

    accuracy                           0.63      1080
   macro avg       0.60      0.51      0.48      1080
weighted avg       0.74      0.63      0.62      1080
 


====== chc040-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  86.57  24.86   99.33  88.46     38.82
1  91.94   2.00   96.31   2.56      2.25
2  80.65  77.43   83.25  78.90     78.16
3  90.19  54.17   99.19  94.35     68.82
4  76.02  95.21   73.02  35.55     51.77
Total accuracy: 62.69%
Average sen: 50.73%
Average spec: 90.22%
Macro f1-score: 47.96%
Diagnosis acc on 90mins: 0.16666666666666666
[0.99347186 0.99177426 1.         0.00169484 0.92422146 0.99782592]
pred: 0.8181647235566439, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc040-nsrr

=== Test on chc041-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.415651, loss_ss: 1.687775, loss_d: 0.727876
0.2451 --- loss: 2.101905, loss_ss: 1.437428, loss_d: 0.664477
0.4902 --- loss: 2.093403, loss_ss: 1.456519, loss_d: 0.636884
0.7353 --- loss: 1.725948, loss_ss: 1.331054, loss_d: 0.394894
0.9804 --- loss: 1.965241, loss_ss: 1.354832, loss_d: 0.610409
Epoch finished! Loss: 2.060507982969284
Starting epoch 2/10.
0.0000 --- loss: 1.811098, loss_ss: 1.283744, loss_d: 0.527354
0.2451 --- loss: 2.081003, loss_ss: 1.347788, loss_d: 0.733215
0.4902 --- loss: 1.655970, loss_ss: 1.222452, loss_d: 0.433519
0.7353 --- loss: 1.724958, loss_ss: 1.149813, loss_d: 0.575146
0.9804 --- loss: 1.677771, loss_ss: 1.135636, loss_d: 0.542135
Epoch finished! Loss: 1.8756862103939056
Starting epoch 3/10.
0.0000 --- loss: 1.748239, loss_ss: 1.233229, loss_d: 0.515010
0.2451 --- loss: 1.631712, loss_ss: 1.234148, loss_d: 0.397564
0.4902 --- loss: 1.713533, loss_ss: 1.087488, loss_d: 0.626045
0.7353 --- loss: 2.069349, loss_ss: 1.101131, loss_d: 0.968218
0.9804 --- loss: 1.363565, loss_ss: 1.084718, loss_d: 0.278846
Epoch finished! Loss: 1.8038232982158662
Starting epoch 4/10.
0.0000 --- loss: 1.626752, loss_ss: 1.061127, loss_d: 0.565625
0.2451 --- loss: 1.654462, loss_ss: 1.086383, loss_d: 0.568078
0.4902 --- loss: 1.730205, loss_ss: 1.147888, loss_d: 0.582317
0.7353 --- loss: 1.549672, loss_ss: 1.081755, loss_d: 0.467917
0.9804 --- loss: 1.605867, loss_ss: 1.171341, loss_d: 0.434525
Epoch finished! Loss: 1.7413827359676362
Starting epoch 5/10.
0.0000 --- loss: 1.844345, loss_ss: 1.039730, loss_d: 0.804615
0.2451 --- loss: 1.462059, loss_ss: 1.005376, loss_d: 0.456683
0.4902 --- loss: 1.465407, loss_ss: 1.154190, loss_d: 0.311218
0.7353 --- loss: 1.696908, loss_ss: 1.197605, loss_d: 0.499303
0.9804 --- loss: 1.459248, loss_ss: 1.153095, loss_d: 0.306154
Epoch finished! Loss: 1.632875418663025
Starting epoch 6/10.
0.0000 --- loss: 1.545455, loss_ss: 1.264741, loss_d: 0.280713
0.2451 --- loss: 1.484331, loss_ss: 1.148471, loss_d: 0.335861
0.4902 --- loss: 1.418859, loss_ss: 0.961541, loss_d: 0.457318
0.7353 --- loss: 1.312942, loss_ss: 1.127686, loss_d: 0.185256
0.9804 --- loss: 1.785833, loss_ss: 1.025344, loss_d: 0.760488
Epoch finished! Loss: 1.532566350698471
Starting epoch 7/10.
0.0000 --- loss: 1.208855, loss_ss: 0.996625, loss_d: 0.212230
0.2451 --- loss: 1.544884, loss_ss: 1.279617, loss_d: 0.265267
0.4902 --- loss: 1.706791, loss_ss: 1.268534, loss_d: 0.438257
0.7353 --- loss: 1.130056, loss_ss: 1.012957, loss_d: 0.117098
0.9804 --- loss: 1.761137, loss_ss: 1.216902, loss_d: 0.544235
Epoch finished! Loss: 1.427438747882843
Starting epoch 8/10.
0.0000 --- loss: 1.136584, loss_ss: 1.064119, loss_d: 0.072465
0.2451 --- loss: 1.410022, loss_ss: 0.905087, loss_d: 0.504935
0.4902 --- loss: 1.194035, loss_ss: 1.052112, loss_d: 0.141923
0.7353 --- loss: 1.375820, loss_ss: 1.055434, loss_d: 0.320385
0.9804 --- loss: 1.109370, loss_ss: 1.057328, loss_d: 0.052042
Epoch finished! Loss: 1.3049135833978653
Starting epoch 9/10.
0.0000 --- loss: 1.257934, loss_ss: 1.193032, loss_d: 0.064901
0.2451 --- loss: 1.155555, loss_ss: 1.098855, loss_d: 0.056699
0.4902 --- loss: 0.957629, loss_ss: 0.867696, loss_d: 0.089934
0.7353 --- loss: 1.054757, loss_ss: 0.998484, loss_d: 0.056273
0.9804 --- loss: 1.226183, loss_ss: 1.134489, loss_d: 0.091694
Epoch finished! Loss: 1.1400262966752053
Starting epoch 10/10.
0.0000 --- loss: 1.276391, loss_ss: 1.251395, loss_d: 0.024996
0.2451 --- loss: 1.067374, loss_ss: 1.022159, loss_d: 0.045215
0.4902 --- loss: 1.064013, loss_ss: 1.031602, loss_d: 0.032412
0.7353 --- loss: 0.919518, loss_ss: 0.882149, loss_d: 0.037369
0.9804 --- loss: 1.291811, loss_ss: 1.279651, loss_d: 0.012160
Epoch finished! Loss: 1.0631314724683762
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7833333333333333
              precision    recall  f1-score   support

         0.0       0.47      0.69      0.56        55
         1.0       0.00      0.00      0.00        35
         2.0       0.87      0.82      0.84       336
         3.0       0.83      0.94      0.88       166
         4.0       0.70      0.74      0.72       128

    accuracy                           0.78       720
   macro avg       0.57      0.64      0.60       720
weighted avg       0.76      0.78      0.77       720
 


====== chc041-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  91.81  69.09   93.68  47.50     56.30
1  95.14   0.00  100.00   0.00      0.00
2  85.83  81.85   89.32  87.03     84.36
3  94.03  93.98   94.04  82.54     87.89
4  89.86  74.22   93.24  70.37     72.24
Total accuracy: 78.33%
Average sen: 63.83%
Average spec: 94.06%
Macro f1-score: 60.16%
Diagnosis acc on 90mins: 0.25
[0.99331433 0.95411557 0.99925977 0.00828652]
pred: 0.7387440458405763, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc041-nsrr

=== Test on chc052-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.293777, loss_ss: 1.625886, loss_d: 0.667891
0.2457 --- loss: 2.067560, loss_ss: 1.331372, loss_d: 0.736188
0.4914 --- loss: 1.895410, loss_ss: 1.468287, loss_d: 0.427123
0.7371 --- loss: 2.234155, loss_ss: 1.345819, loss_d: 0.888336
0.9828 --- loss: 2.074444, loss_ss: 1.288130, loss_d: 0.786314
Epoch finished! Loss: 2.1035858392715454
Starting epoch 2/10.
0.0000 --- loss: 2.050130, loss_ss: 1.387455, loss_d: 0.662675
0.2457 --- loss: 1.922344, loss_ss: 1.344501, loss_d: 0.577842
0.4914 --- loss: 1.810666, loss_ss: 1.218214, loss_d: 0.592452
0.7371 --- loss: 1.551090, loss_ss: 1.306949, loss_d: 0.244141
0.9828 --- loss: 2.008206, loss_ss: 1.257878, loss_d: 0.750327
Epoch finished! Loss: 1.8856088638305664
Starting epoch 3/10.
0.0000 --- loss: 1.690693, loss_ss: 1.436342, loss_d: 0.254351
0.2457 --- loss: 1.747595, loss_ss: 1.239928, loss_d: 0.507666
0.4914 --- loss: 1.694463, loss_ss: 1.300464, loss_d: 0.393999
0.7371 --- loss: 1.742702, loss_ss: 1.224946, loss_d: 0.517756
0.9828 --- loss: 1.802755, loss_ss: 1.255208, loss_d: 0.547547
Epoch finished! Loss: 1.8105631828308106
Starting epoch 4/10.
0.0000 --- loss: 1.591562, loss_ss: 1.139541, loss_d: 0.452021
0.2457 --- loss: 1.540895, loss_ss: 1.176775, loss_d: 0.364121
0.4914 --- loss: 1.868981, loss_ss: 1.110251, loss_d: 0.758730
0.7371 --- loss: 1.592980, loss_ss: 1.147245, loss_d: 0.445735
0.9828 --- loss: 1.735675, loss_ss: 1.288914, loss_d: 0.446760
Epoch finished! Loss: 1.6864646673202515
Starting epoch 5/10.
0.0000 --- loss: 1.507659, loss_ss: 1.063327, loss_d: 0.444332
0.2457 --- loss: 1.621922, loss_ss: 1.214539, loss_d: 0.407384
0.4914 --- loss: 1.503215, loss_ss: 1.135566, loss_d: 0.367649
0.7371 --- loss: 1.577904, loss_ss: 1.362559, loss_d: 0.215344
0.9828 --- loss: 1.618509, loss_ss: 1.122399, loss_d: 0.496110
Epoch finished! Loss: 1.6016270041465759
Starting epoch 6/10.
0.0000 --- loss: 1.359875, loss_ss: 1.198540, loss_d: 0.161336
0.2457 --- loss: 1.501410, loss_ss: 1.259522, loss_d: 0.241889
0.4914 --- loss: 1.376475, loss_ss: 1.095189, loss_d: 0.281286
0.7371 --- loss: 1.262459, loss_ss: 0.953421, loss_d: 0.309038
0.9828 --- loss: 1.486634, loss_ss: 1.051101, loss_d: 0.435533
Epoch finished! Loss: 1.50722676217556
Starting epoch 7/10.
0.0000 --- loss: 1.298292, loss_ss: 1.063192, loss_d: 0.235100
0.2457 --- loss: 1.602659, loss_ss: 1.269401, loss_d: 0.333259
0.4914 --- loss: 1.525790, loss_ss: 1.062763, loss_d: 0.463027
0.7371 --- loss: 1.195586, loss_ss: 0.976786, loss_d: 0.218800
0.9828 --- loss: 1.395838, loss_ss: 1.081365, loss_d: 0.314472
Epoch finished! Loss: 1.424655795097351
Starting epoch 8/10.
0.0000 --- loss: 1.145418, loss_ss: 0.961245, loss_d: 0.184172
0.2457 --- loss: 1.513339, loss_ss: 1.197921, loss_d: 0.315418
0.4914 --- loss: 1.445265, loss_ss: 1.199291, loss_d: 0.245974
0.7371 --- loss: 1.159190, loss_ss: 0.924918, loss_d: 0.234273
0.9828 --- loss: 1.181535, loss_ss: 1.062632, loss_d: 0.118902
Epoch finished! Loss: 1.2859427154064178
Starting epoch 9/10.
0.0000 --- loss: 1.114336, loss_ss: 0.985790, loss_d: 0.128546
0.2457 --- loss: 1.235686, loss_ss: 1.133740, loss_d: 0.101945
0.4914 --- loss: 1.242171, loss_ss: 0.834143, loss_d: 0.408028
0.7371 --- loss: 1.260389, loss_ss: 1.098281, loss_d: 0.162108
0.9828 --- loss: 0.987359, loss_ss: 0.954156, loss_d: 0.033202
Epoch finished! Loss: 1.2273259729146957
Starting epoch 10/10.
0.0000 --- loss: 1.297114, loss_ss: 1.119401, loss_d: 0.177713
0.2457 --- loss: 1.638155, loss_ss: 0.911120, loss_d: 0.727035
0.4914 --- loss: 1.165333, loss_ss: 1.008597, loss_d: 0.156736
0.7371 --- loss: 1.520691, loss_ss: 1.090845, loss_d: 0.429846
0.9828 --- loss: 1.208428, loss_ss: 0.854656, loss_d: 0.353772
Epoch finished! Loss: 1.2637905284762383
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7
              precision    recall  f1-score   support

         0.0       0.85      0.73      0.78       142
         1.0       0.00      0.00      0.00        23
         2.0       0.88      0.61      0.72       466
         3.0       0.55      0.97      0.71       167
         4.0       0.49      0.78      0.60       102

    accuracy                           0.70       900
   macro avg       0.55      0.62      0.56       900
weighted avg       0.75      0.70      0.70       900
 


====== chc052-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  93.67  73.24   97.49  84.55     78.49
1  97.44   0.00  100.00   0.00      0.00
2  75.56  60.94   91.24  88.20     72.08
3  85.00  97.01   82.26  55.48     70.59
4  88.33  78.43   89.60  49.08     60.38
Total accuracy: 70.00%
Average sen: 61.92%
Average spec: 92.12%
Macro f1-score: 56.31%
Diagnosis acc on 90mins: 0.4
[0.25012937 0.97167599 0.68725032 0.80516034 0.48251009]
pred: 0.6393452227115631, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc052-nsrr

=== Test on chc056-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.502535, loss_ss: 1.787589, loss_d: 0.714945
0.2457 --- loss: 2.074607, loss_ss: 1.524395, loss_d: 0.550213
0.4914 --- loss: 1.929632, loss_ss: 1.355734, loss_d: 0.573899
0.7371 --- loss: 1.942093, loss_ss: 1.495278, loss_d: 0.446815
0.9828 --- loss: 2.373929, loss_ss: 1.486400, loss_d: 0.887529
Epoch finished! Loss: 2.1773538172245024
Starting epoch 2/10.
0.0000 --- loss: 1.881944, loss_ss: 1.537805, loss_d: 0.344139
0.2457 --- loss: 1.717481, loss_ss: 1.296872, loss_d: 0.420609
0.4914 --- loss: 2.082568, loss_ss: 1.277251, loss_d: 0.805317
0.7371 --- loss: 1.961592, loss_ss: 1.416533, loss_d: 0.545060
0.9828 --- loss: 2.261963, loss_ss: 1.277323, loss_d: 0.984640
Epoch finished! Loss: 2.0075286507606505
Starting epoch 3/10.
0.0000 --- loss: 1.743741, loss_ss: 1.312324, loss_d: 0.431418
0.2457 --- loss: 1.765251, loss_ss: 1.436719, loss_d: 0.328532
0.4914 --- loss: 1.888429, loss_ss: 1.272924, loss_d: 0.615505
0.7371 --- loss: 1.929095, loss_ss: 1.347036, loss_d: 0.582058
0.9828 --- loss: 2.105200, loss_ss: 1.270807, loss_d: 0.834393
Epoch finished! Loss: 1.9292329788208007
Starting epoch 4/10.
0.0000 --- loss: 1.846156, loss_ss: 1.389703, loss_d: 0.456453
0.2457 --- loss: 2.126911, loss_ss: 1.235041, loss_d: 0.891870
0.4914 --- loss: 1.924461, loss_ss: 1.291260, loss_d: 0.633201
0.7371 --- loss: 1.749182, loss_ss: 1.211942, loss_d: 0.537240
0.9828 --- loss: 1.396696, loss_ss: 1.165290, loss_d: 0.231407
Epoch finished! Loss: 1.844611194729805
Starting epoch 5/10.
0.0000 --- loss: 1.730659, loss_ss: 1.375081, loss_d: 0.355578
0.2457 --- loss: 1.617712, loss_ss: 1.387010, loss_d: 0.230702
0.4914 --- loss: 1.851892, loss_ss: 1.246358, loss_d: 0.605534
0.7371 --- loss: 1.750298, loss_ss: 1.404627, loss_d: 0.345670
0.9828 --- loss: 2.345677, loss_ss: 1.255279, loss_d: 1.090398
Epoch finished! Loss: 1.7601138710975648
Starting epoch 6/10.
0.0000 --- loss: 1.978305, loss_ss: 1.337073, loss_d: 0.641232
0.2457 --- loss: 1.731372, loss_ss: 1.244844, loss_d: 0.486527
0.4914 --- loss: 1.504692, loss_ss: 1.131088, loss_d: 0.373604
0.7371 --- loss: 1.391995, loss_ss: 1.214184, loss_d: 0.177811
0.9828 --- loss: 1.541517, loss_ss: 1.294247, loss_d: 0.247270
Epoch finished! Loss: 1.6618926674127579
Starting epoch 7/10.
0.0000 --- loss: 1.617684, loss_ss: 1.392207, loss_d: 0.225476
0.2457 --- loss: 1.559984, loss_ss: 1.322447, loss_d: 0.237537
0.4914 --- loss: 1.616541, loss_ss: 1.210490, loss_d: 0.406050
0.7371 --- loss: 1.726597, loss_ss: 1.232230, loss_d: 0.494367
0.9828 --- loss: 1.521847, loss_ss: 1.094868, loss_d: 0.426979
Epoch finished! Loss: 1.5157849609851837
Starting epoch 8/10.
0.0000 --- loss: 1.624842, loss_ss: 1.355820, loss_d: 0.269022
0.2457 --- loss: 1.532324, loss_ss: 1.229557, loss_d: 0.302767
0.4914 --- loss: 1.606308, loss_ss: 1.321392, loss_d: 0.284916
0.7371 --- loss: 1.123194, loss_ss: 1.045446, loss_d: 0.077748
0.9828 --- loss: 1.239622, loss_ss: 1.185134, loss_d: 0.054487
Epoch finished! Loss: 1.4897746175527573
Starting epoch 9/10.
0.0000 --- loss: 1.283269, loss_ss: 1.196683, loss_d: 0.086586
0.2457 --- loss: 1.062908, loss_ss: 1.034192, loss_d: 0.028716
0.4914 --- loss: 1.237530, loss_ss: 1.190262, loss_d: 0.047268
0.7371 --- loss: 1.085580, loss_ss: 1.072127, loss_d: 0.013453
0.9828 --- loss: 1.711425, loss_ss: 1.159628, loss_d: 0.551797
Epoch finished! Loss: 1.3072715267539023
Starting epoch 10/10.
0.0000 --- loss: 1.146795, loss_ss: 1.101011, loss_d: 0.045784
0.2457 --- loss: 1.305500, loss_ss: 0.924678, loss_d: 0.380821
0.4914 --- loss: 1.507311, loss_ss: 1.228337, loss_d: 0.278974
0.7371 --- loss: 1.076817, loss_ss: 1.036897, loss_d: 0.039920
0.9828 --- loss: 1.590963, loss_ss: 1.442473, loss_d: 0.148490
Epoch finished! Loss: 1.2553346559405327
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.73
              precision    recall  f1-score   support

         0.0       0.59      0.92      0.72       175
         1.0       0.00      0.00      0.00        86
         2.0       0.75      0.97      0.84       396
         3.0       0.98      0.74      0.84       153
         4.0       0.00      0.00      0.00        90

    accuracy                           0.73       900
   macro avg       0.46      0.53      0.48       900
weighted avg       0.61      0.73      0.65       900
 


====== chc056-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.

The ppr of  4  has ZeroDivisionError.

The f1-score of  4  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  86.22  92.00   84.83  59.41     72.20
1  90.44   0.00  100.00   0.00      0.00
2  84.00  96.72   74.01  74.51     84.18
3  95.33  73.86   99.73  98.26     84.33
4  90.00   0.00  100.00   0.00      0.00
Total accuracy: 73.00%
Average sen: 52.51%
Average spec: 91.71%
Macro f1-score: 48.14%
Diagnosis acc on 90mins: 0.0
[0.99961674 0.98942661 0.8540684  0.78225881 0.98355073]
pred: 0.9217842578887939, label: 0
Wrong!!! Real Diagnosis: Other
Save 90mins of subject chc056-nsrr

=== Test on chp001-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.142372, loss_ss: 1.521098, loss_d: 0.621274
0.2463 --- loss: 2.060455, loss_ss: 1.494369, loss_d: 0.566086
0.4926 --- loss: 2.029635, loss_ss: 1.516390, loss_d: 0.513245
0.7389 --- loss: 2.025723, loss_ss: 1.336160, loss_d: 0.689564
0.9852 --- loss: 1.698903, loss_ss: 1.295916, loss_d: 0.402987
Epoch finished! Loss: 2.1063834577798843
Starting epoch 2/10.
0.0000 --- loss: 1.837469, loss_ss: 1.277829, loss_d: 0.559639
0.2463 --- loss: 1.698134, loss_ss: 1.291925, loss_d: 0.406209
0.4926 --- loss: 1.875830, loss_ss: 1.212391, loss_d: 0.663439
0.7389 --- loss: 1.784885, loss_ss: 1.308185, loss_d: 0.476699
0.9852 --- loss: 1.822353, loss_ss: 1.073343, loss_d: 0.749010
Epoch finished! Loss: 1.8098120093345642
Starting epoch 3/10.
0.0000 --- loss: 1.758666, loss_ss: 1.283159, loss_d: 0.475507
0.2463 --- loss: 2.022985, loss_ss: 1.293544, loss_d: 0.729441
0.4926 --- loss: 1.834592, loss_ss: 1.310559, loss_d: 0.524033
0.7389 --- loss: 1.670601, loss_ss: 1.083120, loss_d: 0.587481
0.9852 --- loss: 1.527210, loss_ss: 1.138292, loss_d: 0.388918
Epoch finished! Loss: 1.7919210642576218
Starting epoch 4/10.
0.0000 --- loss: 1.552417, loss_ss: 1.224628, loss_d: 0.327789
0.2463 --- loss: 1.841610, loss_ss: 1.233032, loss_d: 0.608579
0.4926 --- loss: 1.208626, loss_ss: 1.052102, loss_d: 0.156524
0.7389 --- loss: 1.557356, loss_ss: 1.123535, loss_d: 0.433820
0.9852 --- loss: 1.831184, loss_ss: 1.280429, loss_d: 0.550755
Epoch finished! Loss: 1.6594070196151733
Starting epoch 5/10.
0.0000 --- loss: 1.419879, loss_ss: 1.066226, loss_d: 0.353653
0.2463 --- loss: 1.576281, loss_ss: 1.191960, loss_d: 0.384321
0.4926 --- loss: 1.598341, loss_ss: 1.077204, loss_d: 0.521137
0.7389 --- loss: 1.558094, loss_ss: 1.018590, loss_d: 0.539505
0.9852 --- loss: 1.275710, loss_ss: 1.044793, loss_d: 0.230917
Epoch finished! Loss: 1.5555290758609772
Starting epoch 6/10.
0.0000 --- loss: 1.345942, loss_ss: 1.074432, loss_d: 0.271510
0.2463 --- loss: 1.633247, loss_ss: 0.947241, loss_d: 0.686006
0.4926 --- loss: 1.177762, loss_ss: 0.969086, loss_d: 0.208676
0.7389 --- loss: 1.940129, loss_ss: 1.185945, loss_d: 0.754185
0.9852 --- loss: 1.841108, loss_ss: 1.186559, loss_d: 0.654549
Epoch finished! Loss: 1.418790079653263
Starting epoch 7/10.
0.0000 --- loss: 1.633703, loss_ss: 1.033703, loss_d: 0.600000
0.2463 --- loss: 1.282601, loss_ss: 1.045370, loss_d: 0.237231
0.4926 --- loss: 1.428034, loss_ss: 1.142620, loss_d: 0.285415
0.7389 --- loss: 1.016126, loss_ss: 0.882993, loss_d: 0.133133
0.9852 --- loss: 1.031335, loss_ss: 0.871839, loss_d: 0.159495
Epoch finished! Loss: 1.389220654964447
Starting epoch 8/10.
0.0000 --- loss: 1.083758, loss_ss: 1.006155, loss_d: 0.077603
0.2463 --- loss: 1.133510, loss_ss: 0.931708, loss_d: 0.201802
0.4926 --- loss: 1.474272, loss_ss: 1.096071, loss_d: 0.378200
0.7389 --- loss: 1.032511, loss_ss: 0.919847, loss_d: 0.112664
0.9852 --- loss: 1.445418, loss_ss: 1.054753, loss_d: 0.390665
Epoch finished! Loss: 1.2992813482880592
Starting epoch 9/10.
0.0000 --- loss: 1.280627, loss_ss: 1.118875, loss_d: 0.161752
0.2463 --- loss: 1.126500, loss_ss: 1.014044, loss_d: 0.112456
0.4926 --- loss: 1.071051, loss_ss: 0.956154, loss_d: 0.114897
0.7389 --- loss: 1.291282, loss_ss: 0.918214, loss_d: 0.373068
0.9852 --- loss: 1.040885, loss_ss: 1.011154, loss_d: 0.029731
Epoch finished! Loss: 1.2025113627314568
Starting epoch 10/10.
0.0000 --- loss: 1.098797, loss_ss: 0.962083, loss_d: 0.136714
0.2463 --- loss: 0.914448, loss_ss: 0.863950, loss_d: 0.050498
0.4926 --- loss: 1.166505, loss_ss: 1.058945, loss_d: 0.107560
0.7389 --- loss: 1.279333, loss_ss: 0.949616, loss_d: 0.329716
0.9852 --- loss: 1.096535, loss_ss: 0.860231, loss_d: 0.236304
Epoch finished! Loss: 1.1621423482894897
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5518518518518518
              precision    recall  f1-score   support

         0.0       0.07      0.88      0.13        25
         1.0       0.00      0.00      0.00        77
         2.0       0.71      0.87      0.78       553
         3.0       0.91      0.74      0.82        69
         4.0       0.86      0.12      0.21       356

    accuracy                           0.55      1080
   macro avg       0.51      0.52      0.39      1080
weighted avg       0.71      0.55      0.53      1080
 


====== chp001-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  73.89  88.00   73.55   7.31     13.50
1  92.87   0.00  100.00   0.00      0.00
2  75.37  86.80   63.38  71.32     78.30
3  97.87  73.91   99.51  91.07     81.60
4  70.37  12.08   99.03  86.00     21.18
Total accuracy: 55.19%
Average sen: 52.16%
Average spec: 87.09%
Macro f1-score: 38.92%
Diagnosis acc on 90mins: 0.8333333333333334
[0.986292   0.96403825 0.01379189 0.9428215  0.92751718 0.7101835 ]
pred: 0.7574407219265898, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp001-nsrr

=== Test on chp002-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.480653, loss_ss: 1.789659, loss_d: 0.690994
0.2463 --- loss: 1.949578, loss_ss: 1.515380, loss_d: 0.434198
0.4926 --- loss: 1.729607, loss_ss: 1.410574, loss_d: 0.319033
0.7389 --- loss: 2.318482, loss_ss: 1.417657, loss_d: 0.900824
0.9852 --- loss: 1.832541, loss_ss: 1.330098, loss_d: 0.502443
Epoch finished! Loss: 2.186328023672104
Starting epoch 2/10.
0.0000 --- loss: 2.012165, loss_ss: 1.439595, loss_d: 0.572570
0.2463 --- loss: 1.927328, loss_ss: 1.421936, loss_d: 0.505392
0.4926 --- loss: 1.647191, loss_ss: 1.291540, loss_d: 0.355651
0.7389 --- loss: 2.181684, loss_ss: 1.512534, loss_d: 0.669151
0.9852 --- loss: 1.942793, loss_ss: 1.458757, loss_d: 0.484037
Epoch finished! Loss: 1.9859744131565094
Starting epoch 3/10.
0.0000 --- loss: 2.034426, loss_ss: 1.348865, loss_d: 0.685561
0.2463 --- loss: 1.839904, loss_ss: 1.331406, loss_d: 0.508498
0.4926 --- loss: 1.522858, loss_ss: 1.216681, loss_d: 0.306177
0.7389 --- loss: 1.558902, loss_ss: 1.156918, loss_d: 0.401984
0.9852 --- loss: 1.687616, loss_ss: 1.174292, loss_d: 0.513324
Epoch finished! Loss: 1.8351446837186813
Starting epoch 4/10.
0.0000 --- loss: 1.567041, loss_ss: 1.219868, loss_d: 0.347173
0.2463 --- loss: 1.814534, loss_ss: 1.240592, loss_d: 0.573942
0.4926 --- loss: 1.848237, loss_ss: 1.190771, loss_d: 0.657466
0.7389 --- loss: 1.605436, loss_ss: 1.155699, loss_d: 0.449737
0.9852 --- loss: 1.896564, loss_ss: 1.254288, loss_d: 0.642276
Epoch finished! Loss: 1.771940642595291
Starting epoch 5/10.
0.0000 --- loss: 1.537290, loss_ss: 1.174522, loss_d: 0.362768
0.2463 --- loss: 1.430191, loss_ss: 1.095848, loss_d: 0.334343
0.4926 --- loss: 1.393237, loss_ss: 1.228470, loss_d: 0.164767
0.7389 --- loss: 1.603651, loss_ss: 1.102500, loss_d: 0.501151
0.9852 --- loss: 1.673526, loss_ss: 1.222203, loss_d: 0.451323
Epoch finished! Loss: 1.6303611516952514
Starting epoch 6/10.
0.0000 --- loss: 1.639102, loss_ss: 1.073388, loss_d: 0.565714
0.2463 --- loss: 1.365117, loss_ss: 1.036005, loss_d: 0.329112
0.4926 --- loss: 1.254285, loss_ss: 1.018328, loss_d: 0.235957
0.7389 --- loss: 1.382013, loss_ss: 1.134992, loss_d: 0.247021
0.9852 --- loss: 1.697027, loss_ss: 0.944544, loss_d: 0.752483
Epoch finished! Loss: 1.5233077943325042
Starting epoch 7/10.
0.0000 --- loss: 1.223090, loss_ss: 0.998897, loss_d: 0.224193
0.2463 --- loss: 1.188733, loss_ss: 1.066988, loss_d: 0.121745
0.4926 --- loss: 1.359711, loss_ss: 1.104169, loss_d: 0.255542
0.7389 --- loss: 1.632971, loss_ss: 1.081495, loss_d: 0.551475
0.9852 --- loss: 1.356907, loss_ss: 0.952271, loss_d: 0.404636
Epoch finished! Loss: 1.4195004165172578
Starting epoch 8/10.
0.0000 --- loss: 1.411654, loss_ss: 1.109144, loss_d: 0.302510
0.2463 --- loss: 1.229477, loss_ss: 1.096635, loss_d: 0.132842
0.4926 --- loss: 1.144874, loss_ss: 1.043078, loss_d: 0.101796
0.7389 --- loss: 1.552048, loss_ss: 1.125306, loss_d: 0.426743
0.9852 --- loss: 1.592037, loss_ss: 0.944543, loss_d: 0.647494
Epoch finished! Loss: 1.3674516826868057
Starting epoch 9/10.
0.0000 --- loss: 1.192926, loss_ss: 1.056449, loss_d: 0.136477
0.2463 --- loss: 1.060955, loss_ss: 0.976732, loss_d: 0.084223
0.4926 --- loss: 1.402900, loss_ss: 0.925844, loss_d: 0.477055
0.7389 --- loss: 0.972560, loss_ss: 0.892636, loss_d: 0.079923
0.9852 --- loss: 1.404893, loss_ss: 1.203697, loss_d: 0.201196
Epoch finished! Loss: 1.1533885568380355
Starting epoch 10/10.
0.0000 --- loss: 1.598754, loss_ss: 1.077772, loss_d: 0.520982
0.2463 --- loss: 1.074022, loss_ss: 1.002388, loss_d: 0.071634
0.4926 --- loss: 0.986666, loss_ss: 0.965803, loss_d: 0.020864
0.7389 --- loss: 1.034751, loss_ss: 0.921903, loss_d: 0.112848
0.9852 --- loss: 0.983276, loss_ss: 0.914224, loss_d: 0.069052
Epoch finished! Loss: 1.1692422300577163
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5611111111111111
              precision    recall  f1-score   support

         0.0       0.86      0.36      0.51       260
         1.0       0.00      0.00      0.00       248
         2.0       0.66      0.85      0.74       375
         3.0       0.58      1.00      0.73       169
         4.0       0.12      0.86      0.21        28

    accuracy                           0.56      1080
   macro avg       0.45      0.61      0.44      1080
weighted avg       0.53      0.56      0.50      1080
 


====== chp002-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  83.24   36.15   98.17  86.24     50.95
1  77.04    0.00  100.00   0.00      0.00
2  79.63   85.07   76.74  66.05     74.36
3  88.70  100.00   86.61  58.08     73.48
4  83.61   85.71   83.56  12.18     21.33
Total accuracy: 56.11%
Average sen: 61.39%
Average spec: 89.01%
Macro f1-score: 44.02%
Diagnosis acc on 90mins: 0.8333333333333334
[1.         0.69529158 0.71211129 0.99904877 0.42687258 0.99994993]
pred: 0.8055456926425298, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp002-nsrr

=== Test on chp003-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.281682, loss_ss: 1.643446, loss_d: 0.638237
0.2457 --- loss: 2.040661, loss_ss: 1.434661, loss_d: 0.606000
0.4914 --- loss: 1.974310, loss_ss: 1.349949, loss_d: 0.624361
0.7371 --- loss: 1.903929, loss_ss: 1.288321, loss_d: 0.615608
0.9828 --- loss: 1.802830, loss_ss: 1.297565, loss_d: 0.505265
Epoch finished! Loss: 2.034364938735962
Starting epoch 2/10.
0.0000 --- loss: 1.813521, loss_ss: 1.307593, loss_d: 0.505928
0.2457 --- loss: 1.650898, loss_ss: 1.266479, loss_d: 0.384419
0.4914 --- loss: 1.770571, loss_ss: 1.257234, loss_d: 0.513337
0.7371 --- loss: 1.897764, loss_ss: 1.263187, loss_d: 0.634576
0.9828 --- loss: 1.452664, loss_ss: 1.204441, loss_d: 0.248222
Epoch finished! Loss: 1.8896563351154327
Starting epoch 3/10.
0.0000 --- loss: 1.946639, loss_ss: 1.207898, loss_d: 0.738742
0.2457 --- loss: 1.717440, loss_ss: 1.214717, loss_d: 0.502723
0.4914 --- loss: 1.763617, loss_ss: 1.181702, loss_d: 0.581916
0.7371 --- loss: 1.643092, loss_ss: 1.119329, loss_d: 0.523763
0.9828 --- loss: 1.550756, loss_ss: 1.284787, loss_d: 0.265969
Epoch finished! Loss: 1.8365012526512146
Starting epoch 4/10.
0.0000 --- loss: 1.611567, loss_ss: 1.157737, loss_d: 0.453830
0.2457 --- loss: 1.805151, loss_ss: 1.026186, loss_d: 0.778965
0.4914 --- loss: 1.784358, loss_ss: 1.093607, loss_d: 0.690751
0.7371 --- loss: 1.472960, loss_ss: 1.079947, loss_d: 0.393013
0.9828 --- loss: 1.731081, loss_ss: 1.291690, loss_d: 0.439391
Epoch finished! Loss: 1.7565849781036378
Starting epoch 5/10.
0.0000 --- loss: 1.500199, loss_ss: 1.084940, loss_d: 0.415260
0.2457 --- loss: 1.757327, loss_ss: 1.122428, loss_d: 0.634899
0.4914 --- loss: 1.451699, loss_ss: 1.067849, loss_d: 0.383851
0.7371 --- loss: 1.888887, loss_ss: 1.051358, loss_d: 0.837529
0.9828 --- loss: 1.373118, loss_ss: 1.021276, loss_d: 0.351842
Epoch finished! Loss: 1.6485825568437575
Starting epoch 6/10.
0.0000 --- loss: 1.546948, loss_ss: 1.074480, loss_d: 0.472468
0.2457 --- loss: 1.576527, loss_ss: 1.148808, loss_d: 0.427719
0.4914 --- loss: 1.693621, loss_ss: 1.022531, loss_d: 0.671090
0.7371 --- loss: 1.368751, loss_ss: 0.965972, loss_d: 0.402779
0.9828 --- loss: 1.518172, loss_ss: 0.958774, loss_d: 0.559398
Epoch finished! Loss: 1.6034786254167557
Starting epoch 7/10.
0.0000 --- loss: 1.506888, loss_ss: 1.056481, loss_d: 0.450408
0.2457 --- loss: 1.328910, loss_ss: 1.067059, loss_d: 0.261851
0.4914 --- loss: 1.295896, loss_ss: 0.932371, loss_d: 0.363524
0.7371 --- loss: 1.454050, loss_ss: 1.067992, loss_d: 0.386059
0.9828 --- loss: 1.530260, loss_ss: 1.096359, loss_d: 0.433901
Epoch finished! Loss: 1.5234201014041902
Starting epoch 8/10.
0.0000 --- loss: 1.294642, loss_ss: 0.937573, loss_d: 0.357069
0.2457 --- loss: 1.289230, loss_ss: 0.912985, loss_d: 0.376245
0.4914 --- loss: 1.336177, loss_ss: 0.983971, loss_d: 0.352207
0.7371 --- loss: 1.296881, loss_ss: 0.939198, loss_d: 0.357683
0.9828 --- loss: 1.636712, loss_ss: 1.164874, loss_d: 0.471839
Epoch finished! Loss: 1.4901109695434571
Starting epoch 9/10.
0.0000 --- loss: 1.453739, loss_ss: 1.113655, loss_d: 0.340084
0.2457 --- loss: 1.299136, loss_ss: 1.075617, loss_d: 0.223519
0.4914 --- loss: 1.356367, loss_ss: 1.016322, loss_d: 0.340045
0.7371 --- loss: 1.298287, loss_ss: 1.005309, loss_d: 0.292978
0.9828 --- loss: 1.346290, loss_ss: 0.859140, loss_d: 0.487150
Epoch finished! Loss: 1.4070486396551132
Starting epoch 10/10.
0.0000 --- loss: 1.184465, loss_ss: 0.979455, loss_d: 0.205011
0.2457 --- loss: 1.206235, loss_ss: 0.953880, loss_d: 0.252355
0.4914 --- loss: 1.627707, loss_ss: 1.242979, loss_d: 0.384728
0.7371 --- loss: 0.934471, loss_ss: 0.825300, loss_d: 0.109171
0.9828 --- loss: 0.904533, loss_ss: 0.851126, loss_d: 0.053408
Epoch finished! Loss: 1.2707635834813118
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7911111111111111
              precision    recall  f1-score   support

         0.0       0.73      0.27      0.40        59
         1.0       0.00      0.00      0.00        27
         2.0       0.80      0.86      0.83       468
         3.0       0.87      0.95      0.91       196
         4.0       0.67      0.70      0.68       150

    accuracy                           0.79       900
   macro avg       0.61      0.56      0.56       900
weighted avg       0.76      0.79      0.77       900
 


====== chp003-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  94.56  27.12   99.29  72.73     39.51
1  97.00   0.00  100.00   0.00      0.00
2  81.44  86.32   76.16  79.68     82.87
3  96.00  95.41   96.16  87.38     91.22
4  89.22  70.00   93.07  66.88     68.40
Total accuracy: 79.11%
Average sen: 55.77%
Average spec: 92.94%
Macro f1-score: 56.40%
Diagnosis acc on 90mins: 0.4
[0.38206059 0.97474438 0.30997503 0.44600224 0.95508426]
pred: 0.6135733008384705, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp003-nsrr

=== Test on chp004-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.367398, loss_ss: 1.654041, loss_d: 0.713357
0.2457 --- loss: 2.305624, loss_ss: 1.568740, loss_d: 0.736884
0.4914 --- loss: 2.088303, loss_ss: 1.464624, loss_d: 0.623679
0.7371 --- loss: 2.140152, loss_ss: 1.467650, loss_d: 0.672502
0.9828 --- loss: 1.924376, loss_ss: 1.382063, loss_d: 0.542313
Epoch finished! Loss: 2.2071205586194993
Starting epoch 2/10.
0.0000 --- loss: 2.140564, loss_ss: 1.409532, loss_d: 0.731032
0.2457 --- loss: 1.941302, loss_ss: 1.387140, loss_d: 0.554162
0.4914 --- loss: 2.048165, loss_ss: 1.312680, loss_d: 0.735485
0.7371 --- loss: 2.414666, loss_ss: 1.327103, loss_d: 1.087563
0.9828 --- loss: 2.048179, loss_ss: 1.443876, loss_d: 0.604303
Epoch finished! Loss: 1.9550471514463426
Starting epoch 3/10.
0.0000 --- loss: 1.663787, loss_ss: 1.236522, loss_d: 0.427265
0.2457 --- loss: 1.826970, loss_ss: 1.232487, loss_d: 0.594483
0.4914 --- loss: 1.674538, loss_ss: 1.274624, loss_d: 0.399915
0.7371 --- loss: 1.786187, loss_ss: 1.386939, loss_d: 0.399248
0.9828 --- loss: 1.627000, loss_ss: 1.339629, loss_d: 0.287371
Epoch finished! Loss: 1.8289506554603576
Starting epoch 4/10.
0.0000 --- loss: 1.872669, loss_ss: 1.255065, loss_d: 0.617605
0.2457 --- loss: 1.430632, loss_ss: 1.102605, loss_d: 0.328028
0.4914 --- loss: 2.038543, loss_ss: 1.141761, loss_d: 0.896782
0.7371 --- loss: 1.395491, loss_ss: 1.130004, loss_d: 0.265487
0.9828 --- loss: 1.629524, loss_ss: 1.063006, loss_d: 0.566518
Epoch finished! Loss: 1.673907259106636
Starting epoch 5/10.
0.0000 --- loss: 1.606435, loss_ss: 1.058106, loss_d: 0.548329
0.2457 --- loss: 1.316352, loss_ss: 1.030275, loss_d: 0.286076
0.4914 --- loss: 1.565271, loss_ss: 1.115457, loss_d: 0.449814
0.7371 --- loss: 1.717684, loss_ss: 1.115153, loss_d: 0.602531
0.9828 --- loss: 1.516125, loss_ss: 0.971859, loss_d: 0.544267
Epoch finished! Loss: 1.5831998109817504
Starting epoch 6/10.
0.0000 --- loss: 1.208036, loss_ss: 1.061035, loss_d: 0.147001
0.2457 --- loss: 1.380699, loss_ss: 1.089915, loss_d: 0.290784
0.4914 --- loss: 1.279507, loss_ss: 1.014970, loss_d: 0.264537
0.7371 --- loss: 1.188201, loss_ss: 1.040373, loss_d: 0.147829
0.9828 --- loss: 1.431168, loss_ss: 1.284196, loss_d: 0.146972
Epoch finished! Loss: 1.4228528976440429
Starting epoch 7/10.
0.0000 --- loss: 1.175859, loss_ss: 1.020448, loss_d: 0.155411
0.2457 --- loss: 1.389182, loss_ss: 1.152165, loss_d: 0.237017
0.4914 --- loss: 1.402496, loss_ss: 1.189314, loss_d: 0.213182
0.7371 --- loss: 1.106461, loss_ss: 1.004743, loss_d: 0.101717
0.9828 --- loss: 1.202420, loss_ss: 1.050448, loss_d: 0.151973
Epoch finished! Loss: 1.3145604938268662
Starting epoch 8/10.
0.0000 --- loss: 0.856184, loss_ss: 0.834017, loss_d: 0.022167
0.2457 --- loss: 1.005191, loss_ss: 0.989056, loss_d: 0.016136
0.4914 --- loss: 1.115974, loss_ss: 0.969523, loss_d: 0.146452
0.7371 --- loss: 1.054877, loss_ss: 1.029243, loss_d: 0.025634
0.9828 --- loss: 1.105214, loss_ss: 1.042796, loss_d: 0.062419
Epoch finished! Loss: 1.2730955138802529
Starting epoch 9/10.
0.0000 --- loss: 0.977094, loss_ss: 0.937745, loss_d: 0.039349
0.2457 --- loss: 1.032402, loss_ss: 0.974643, loss_d: 0.057760
0.4914 --- loss: 1.123444, loss_ss: 0.947530, loss_d: 0.175914
0.7371 --- loss: 1.283785, loss_ss: 1.197522, loss_d: 0.086263
0.9828 --- loss: 1.040035, loss_ss: 0.973284, loss_d: 0.066751
Epoch finished! Loss: 1.108006289601326
Starting epoch 10/10.
0.0000 --- loss: 0.960018, loss_ss: 0.947118, loss_d: 0.012900
0.2457 --- loss: 1.071907, loss_ss: 1.038885, loss_d: 0.033022
0.4914 --- loss: 0.903696, loss_ss: 0.887462, loss_d: 0.016234
0.7371 --- loss: 1.077067, loss_ss: 1.023170, loss_d: 0.053897
0.9828 --- loss: 0.892214, loss_ss: 0.888307, loss_d: 0.003907
Epoch finished! Loss: 1.0266466915607453
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6611111111111111
              precision    recall  f1-score   support

         0.0       0.75      0.36      0.49       105
         1.0       0.00      0.00      0.00       123
         2.0       0.65      0.89      0.75       354
         3.0       0.87      0.73      0.80       197
         4.0       0.49      0.80      0.61       121

    accuracy                           0.66       900
   macro avg       0.55      0.56      0.53       900
weighted avg       0.60      0.66      0.61       900
 


====== chp004-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  91.11  36.19   98.36  74.51     48.72
1  86.33   0.00  100.00   0.00      0.00
2  76.89  89.27   68.86  65.02     75.24
3  91.78  73.10   97.01  87.27     79.56
4  86.11  80.17   87.03  48.99     60.82
Total accuracy: 66.11%
Average sen: 55.74%
Average spec: 90.26%
Macro f1-score: 52.87%
Diagnosis acc on 90mins: 1.0
[0.99691558 0.99459141 0.99748385 0.99981576 0.94159353]
pred: 0.9860800266265869, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp004-nsrr

=== Test on chp005-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.311440, loss_ss: 1.680865, loss_d: 0.630575
0.2469 --- loss: 2.381694, loss_ss: 1.526136, loss_d: 0.855558
0.4938 --- loss: 2.207196, loss_ss: 1.484200, loss_d: 0.722997
0.7407 --- loss: 2.284384, loss_ss: 1.425069, loss_d: 0.859315
0.9877 --- loss: 1.658232, loss_ss: 1.261478, loss_d: 0.396754
Epoch finished! Loss: 2.1516556441783905
Starting epoch 2/10.
0.0000 --- loss: 1.797068, loss_ss: 1.265971, loss_d: 0.531096
0.2469 --- loss: 1.878755, loss_ss: 1.389746, loss_d: 0.489010
0.4938 --- loss: 1.740706, loss_ss: 1.359513, loss_d: 0.381193
0.7407 --- loss: 2.158975, loss_ss: 1.280105, loss_d: 0.878870
0.9877 --- loss: 1.994833, loss_ss: 1.193350, loss_d: 0.801482
Epoch finished! Loss: 1.9270894974470139
Starting epoch 3/10.
0.0000 --- loss: 1.821878, loss_ss: 1.232683, loss_d: 0.589195
0.2469 --- loss: 1.655995, loss_ss: 1.214286, loss_d: 0.441709
0.4938 --- loss: 1.855896, loss_ss: 1.246466, loss_d: 0.609431
0.7407 --- loss: 1.857174, loss_ss: 1.185892, loss_d: 0.671282
0.9877 --- loss: 1.752374, loss_ss: 1.426647, loss_d: 0.325727
Epoch finished! Loss: 1.833575788140297
Starting epoch 4/10.
0.0000 --- loss: 1.712947, loss_ss: 1.316663, loss_d: 0.396284
0.2469 --- loss: 1.724235, loss_ss: 1.259818, loss_d: 0.464417
0.4938 --- loss: 1.512277, loss_ss: 1.150242, loss_d: 0.362035
0.7407 --- loss: 1.595780, loss_ss: 1.090691, loss_d: 0.505088
0.9877 --- loss: 1.894450, loss_ss: 1.391582, loss_d: 0.502868
Epoch finished! Loss: 1.7633063286542892
Starting epoch 5/10.
0.0000 --- loss: 1.690252, loss_ss: 1.229137, loss_d: 0.461114
0.2469 --- loss: 1.536546, loss_ss: 1.180322, loss_d: 0.356224
0.4938 --- loss: 1.539288, loss_ss: 1.143229, loss_d: 0.396058
0.7407 --- loss: 1.530643, loss_ss: 1.010415, loss_d: 0.520228
0.9877 --- loss: 1.820786, loss_ss: 1.198875, loss_d: 0.621911
Epoch finished! Loss: 1.676255452632904
Starting epoch 6/10.
0.0000 --- loss: 1.730011, loss_ss: 1.212690, loss_d: 0.517322
0.2469 --- loss: 1.567122, loss_ss: 1.097813, loss_d: 0.469308
0.4938 --- loss: 1.903520, loss_ss: 1.118617, loss_d: 0.784903
0.7407 --- loss: 1.514800, loss_ss: 1.150675, loss_d: 0.364125
0.9877 --- loss: 1.319495, loss_ss: 1.120483, loss_d: 0.199012
Epoch finished! Loss: 1.5914191454648972
Starting epoch 7/10.
0.0000 --- loss: 1.258424, loss_ss: 0.959448, loss_d: 0.298976
0.2469 --- loss: 1.468775, loss_ss: 1.147623, loss_d: 0.321152
0.4938 --- loss: 1.237404, loss_ss: 1.001786, loss_d: 0.235618
0.7407 --- loss: 1.155403, loss_ss: 0.941530, loss_d: 0.213873
0.9877 --- loss: 1.094840, loss_ss: 0.936827, loss_d: 0.158013
Epoch finished! Loss: 1.4630814641714096
Starting epoch 8/10.
0.0000 --- loss: 1.415213, loss_ss: 1.103781, loss_d: 0.311432
0.2469 --- loss: 1.215433, loss_ss: 1.054890, loss_d: 0.160544
0.4938 --- loss: 1.060878, loss_ss: 0.913479, loss_d: 0.147399
0.7407 --- loss: 1.837160, loss_ss: 1.535233, loss_d: 0.301927
0.9877 --- loss: 1.633747, loss_ss: 0.895252, loss_d: 0.738495
Epoch finished! Loss: 1.3776670575141907
Starting epoch 9/10.
0.0000 --- loss: 1.101422, loss_ss: 0.957659, loss_d: 0.143763
0.2469 --- loss: 1.467328, loss_ss: 1.125142, loss_d: 0.342186
0.4938 --- loss: 1.058112, loss_ss: 0.963279, loss_d: 0.094833
0.7407 --- loss: 1.420206, loss_ss: 1.012342, loss_d: 0.407864
0.9877 --- loss: 1.029334, loss_ss: 1.004905, loss_d: 0.024429
Epoch finished! Loss: 1.2606994450092315
Starting epoch 10/10.
0.0000 --- loss: 1.198997, loss_ss: 1.110855, loss_d: 0.088142
0.2469 --- loss: 1.189052, loss_ss: 1.035419, loss_d: 0.153633
0.4938 --- loss: 1.184849, loss_ss: 1.063437, loss_d: 0.121412
0.7407 --- loss: 0.935867, loss_ss: 0.910983, loss_d: 0.024885
0.9877 --- loss: 1.338477, loss_ss: 1.154399, loss_d: 0.184078
Epoch finished! Loss: 1.1889237731695175
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6396825396825396
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        63
         1.0       0.00      0.00      0.00       235
         2.0       0.61      0.96      0.75       565
         3.0       0.95      0.69      0.80       136
         4.0       0.62      0.66      0.64       261

    accuracy                           0.64      1260
   macro avg       0.44      0.46      0.44      1260
weighted avg       0.50      0.64      0.55      1260
 


====== chp005-nsrr ======

The ppr of  0  has ZeroDivisionError.

The f1-score of  0  has ZeroDivisionError.

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.00   0.00  100.00   0.00      0.00
1  81.35   0.00  100.00   0.00      0.00
2  70.79  95.75   50.50  61.13     74.62
3  96.27  69.12   99.56  94.95     80.00
4  84.52  65.52   89.49  61.96     63.69
Total accuracy: 63.97%
Average sen: 46.08%
Average spec: 87.91%
Macro f1-score: 43.66%
Diagnosis acc on 90mins: 1.0
[0.99983025 0.99995363 0.99985933 0.998456   0.99537283 0.99290085
 0.99999678]
pred: 0.9980528099196297, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp005-nsrr

=== Test on chp006-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.277262, loss_ss: 1.577982, loss_d: 0.699280
0.2463 --- loss: 2.154357, loss_ss: 1.580646, loss_d: 0.573711
0.4926 --- loss: 2.144710, loss_ss: 1.424542, loss_d: 0.720168
0.7389 --- loss: 2.291072, loss_ss: 1.396050, loss_d: 0.895023
0.9852 --- loss: 2.026154, loss_ss: 1.325608, loss_d: 0.700546
Epoch finished! Loss: 2.176065754890442
Starting epoch 2/10.
0.0000 --- loss: 1.827519, loss_ss: 1.393712, loss_d: 0.433806
0.2463 --- loss: 1.852203, loss_ss: 1.334257, loss_d: 0.517945
0.4926 --- loss: 1.782557, loss_ss: 1.314353, loss_d: 0.468204
0.7389 --- loss: 2.269856, loss_ss: 1.393822, loss_d: 0.876034
0.9852 --- loss: 1.797795, loss_ss: 1.202003, loss_d: 0.595792
Epoch finished! Loss: 1.9345529526472092
Starting epoch 3/10.
0.0000 --- loss: 1.886417, loss_ss: 1.274574, loss_d: 0.611843
0.2463 --- loss: 1.835902, loss_ss: 1.191796, loss_d: 0.644106
0.4926 --- loss: 1.585116, loss_ss: 1.166909, loss_d: 0.418207
0.7389 --- loss: 1.812154, loss_ss: 1.363759, loss_d: 0.448395
0.9852 --- loss: 1.853916, loss_ss: 1.478756, loss_d: 0.375160
Epoch finished! Loss: 1.8072119057178497
Starting epoch 4/10.
0.0000 --- loss: 1.493034, loss_ss: 1.197115, loss_d: 0.295920
0.2463 --- loss: 1.568941, loss_ss: 1.285180, loss_d: 0.283761
0.4926 --- loss: 1.497003, loss_ss: 1.104174, loss_d: 0.392829
0.7389 --- loss: 1.501724, loss_ss: 1.146151, loss_d: 0.355573
0.9852 --- loss: 1.718936, loss_ss: 1.154410, loss_d: 0.564526
Epoch finished! Loss: 1.6589641124010086
Starting epoch 5/10.
0.0000 --- loss: 1.303928, loss_ss: 1.059226, loss_d: 0.244701
0.2463 --- loss: 1.919418, loss_ss: 1.217492, loss_d: 0.701925
0.4926 --- loss: 1.440676, loss_ss: 1.210185, loss_d: 0.230492
0.7389 --- loss: 1.314075, loss_ss: 1.058161, loss_d: 0.255914
0.9852 --- loss: 1.877838, loss_ss: 1.253848, loss_d: 0.623990
Epoch finished! Loss: 1.5971879661083221
Starting epoch 6/10.
0.0000 --- loss: 1.445882, loss_ss: 1.139358, loss_d: 0.306524
0.2463 --- loss: 1.510275, loss_ss: 1.129288, loss_d: 0.380987
0.4926 --- loss: 1.230306, loss_ss: 1.060772, loss_d: 0.169534
0.7389 --- loss: 1.198860, loss_ss: 1.022970, loss_d: 0.175890
0.9852 --- loss: 1.414878, loss_ss: 1.179890, loss_d: 0.234988
Epoch finished! Loss: 1.4762514263391495
Starting epoch 7/10.
0.0000 --- loss: 1.441147, loss_ss: 1.053257, loss_d: 0.387890
0.2463 --- loss: 1.544655, loss_ss: 1.311292, loss_d: 0.233363
0.4926 --- loss: 1.322362, loss_ss: 1.087987, loss_d: 0.234375
0.7389 --- loss: 1.229623, loss_ss: 1.131709, loss_d: 0.097914
0.9852 --- loss: 1.325670, loss_ss: 1.201017, loss_d: 0.124653
Epoch finished! Loss: 1.3839924693107606
Starting epoch 8/10.
0.0000 --- loss: 1.202485, loss_ss: 0.993107, loss_d: 0.209378
0.2463 --- loss: 1.166231, loss_ss: 1.117606, loss_d: 0.048625
0.4926 --- loss: 1.216500, loss_ss: 1.102753, loss_d: 0.113747
0.7389 --- loss: 1.217404, loss_ss: 1.188816, loss_d: 0.028587
0.9852 --- loss: 1.040490, loss_ss: 1.024539, loss_d: 0.015950
Epoch finished! Loss: 1.2653312042355538
Starting epoch 9/10.
0.0000 --- loss: 1.191470, loss_ss: 1.176674, loss_d: 0.014796
0.2463 --- loss: 1.360086, loss_ss: 1.263320, loss_d: 0.096766
0.4926 --- loss: 1.019268, loss_ss: 0.992409, loss_d: 0.026859
0.7389 --- loss: 1.081287, loss_ss: 1.058617, loss_d: 0.022671
0.9852 --- loss: 1.177656, loss_ss: 1.155854, loss_d: 0.021802
Epoch finished! Loss: 1.2066296100616456
Starting epoch 10/10.
0.0000 --- loss: 1.087775, loss_ss: 1.025516, loss_d: 0.062259
0.2463 --- loss: 1.219471, loss_ss: 1.215241, loss_d: 0.004230
0.4926 --- loss: 1.027914, loss_ss: 1.018870, loss_d: 0.009044
0.7389 --- loss: 0.985073, loss_ss: 0.981399, loss_d: 0.003674
0.9852 --- loss: 1.128150, loss_ss: 1.002475, loss_d: 0.125675
Epoch finished! Loss: 1.1494771897792817
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.537962962962963
              precision    recall  f1-score   support

         0.0       1.00      0.03      0.05       120
         1.0       0.00      0.00      0.00       322
         2.0       0.41      0.97      0.58       274
         3.0       0.96      0.92      0.94       224
         4.0       0.49      0.74      0.59       140

    accuracy                           0.54      1080
   macro avg       0.57      0.53      0.43      1080
weighted avg       0.48      0.54      0.42      1080
 


====== chp006-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  89.17   2.50  100.00  100.00      4.88
1  70.19   0.00  100.00    0.00      0.00
2  63.80  97.45   52.36   41.01     57.73
3  97.69  92.41   99.07   96.28     94.31
4  86.76  74.29   88.62   49.29     59.26
Total accuracy: 53.80%
Average sen: 53.33%
Average spec: 88.01%
Macro f1-score: 43.23%
Diagnosis acc on 90mins: 1.0
[0.92931801 0.99999988 0.99924386 0.96286392 0.9921748  0.988478  ]
pred: 0.978679746389389, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp006-nsrr

=== Test on chp007-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.368682, loss_ss: 1.655081, loss_d: 0.713602
0.2463 --- loss: 2.244746, loss_ss: 1.555260, loss_d: 0.689486
0.4926 --- loss: 2.057326, loss_ss: 1.444138, loss_d: 0.613188
0.7389 --- loss: 1.825818, loss_ss: 1.454323, loss_d: 0.371495
0.9852 --- loss: 1.913901, loss_ss: 1.368730, loss_d: 0.545171
Epoch finished! Loss: 2.2019692033529283
Starting epoch 2/10.
0.0000 --- loss: 1.834200, loss_ss: 1.343891, loss_d: 0.490309
0.2463 --- loss: 1.856884, loss_ss: 1.343281, loss_d: 0.513603
0.4926 --- loss: 1.597005, loss_ss: 1.426872, loss_d: 0.170133
0.7389 --- loss: 2.076990, loss_ss: 1.350506, loss_d: 0.726484
0.9852 --- loss: 1.922674, loss_ss: 1.344030, loss_d: 0.578643
Epoch finished! Loss: 1.959390777349472
Starting epoch 3/10.
0.0000 --- loss: 1.764238, loss_ss: 1.262764, loss_d: 0.501474
0.2463 --- loss: 1.741009, loss_ss: 1.312420, loss_d: 0.428588
0.4926 --- loss: 1.697901, loss_ss: 1.352897, loss_d: 0.345003
0.7389 --- loss: 1.893917, loss_ss: 1.301240, loss_d: 0.592677
0.9852 --- loss: 2.081968, loss_ss: 1.115033, loss_d: 0.966934
Epoch finished! Loss: 1.9105539709329604
Starting epoch 4/10.
0.0000 --- loss: 1.678705, loss_ss: 1.196621, loss_d: 0.482085
0.2463 --- loss: 1.877340, loss_ss: 1.160591, loss_d: 0.716749
0.4926 --- loss: 1.777349, loss_ss: 1.171060, loss_d: 0.606289
0.7389 --- loss: 1.629715, loss_ss: 1.258980, loss_d: 0.370735
0.9852 --- loss: 1.464883, loss_ss: 1.147456, loss_d: 0.317427
Epoch finished! Loss: 1.802180963754654
Starting epoch 5/10.
0.0000 --- loss: 1.843445, loss_ss: 1.282715, loss_d: 0.560730
0.2463 --- loss: 1.601759, loss_ss: 1.185158, loss_d: 0.416601
0.4926 --- loss: 1.762724, loss_ss: 1.371295, loss_d: 0.391429
0.7389 --- loss: 1.796819, loss_ss: 1.117797, loss_d: 0.679023
0.9852 --- loss: 1.601252, loss_ss: 1.186696, loss_d: 0.414556
Epoch finished! Loss: 1.7465210825204849
Starting epoch 6/10.
0.0000 --- loss: 1.862252, loss_ss: 1.175457, loss_d: 0.686795
0.2463 --- loss: 1.595126, loss_ss: 1.150106, loss_d: 0.445019
0.4926 --- loss: 1.422651, loss_ss: 1.138173, loss_d: 0.284478
0.7389 --- loss: 2.237415, loss_ss: 1.033328, loss_d: 1.204087
0.9852 --- loss: 2.235725, loss_ss: 1.116643, loss_d: 1.119082
Epoch finished! Loss: 1.6248353004455567
Starting epoch 7/10.
0.0000 --- loss: 1.520001, loss_ss: 1.110126, loss_d: 0.409875
0.2463 --- loss: 1.509660, loss_ss: 1.088327, loss_d: 0.421333
0.4926 --- loss: 1.630898, loss_ss: 1.140468, loss_d: 0.490430
0.7389 --- loss: 1.713393, loss_ss: 1.134020, loss_d: 0.579373
0.9852 --- loss: 1.744933, loss_ss: 1.260806, loss_d: 0.484127
Epoch finished! Loss: 1.5377147942781448
Starting epoch 8/10.
0.0000 --- loss: 1.313889, loss_ss: 1.048622, loss_d: 0.265267
0.2463 --- loss: 1.576243, loss_ss: 1.031400, loss_d: 0.544843
0.4926 --- loss: 1.337939, loss_ss: 1.066511, loss_d: 0.271427
0.7389 --- loss: 1.662052, loss_ss: 1.179100, loss_d: 0.482952
0.9852 --- loss: 1.843908, loss_ss: 1.044208, loss_d: 0.799700
Epoch finished! Loss: 1.3911467730998992
Starting epoch 9/10.
0.0000 --- loss: 1.211992, loss_ss: 1.072631, loss_d: 0.139361
0.2463 --- loss: 1.256410, loss_ss: 1.038983, loss_d: 0.217427
0.4926 --- loss: 1.154559, loss_ss: 1.045198, loss_d: 0.109360
0.7389 --- loss: 1.503688, loss_ss: 1.070532, loss_d: 0.433156
0.9852 --- loss: 1.158585, loss_ss: 1.016823, loss_d: 0.141762
Epoch finished! Loss: 1.3103053957223891
Starting epoch 10/10.
0.0000 --- loss: 1.130449, loss_ss: 1.081987, loss_d: 0.048462
0.2463 --- loss: 1.102343, loss_ss: 0.934033, loss_d: 0.168310
0.4926 --- loss: 1.046016, loss_ss: 0.951726, loss_d: 0.094289
0.7389 --- loss: 1.205161, loss_ss: 0.983876, loss_d: 0.221286
0.9852 --- loss: 1.507646, loss_ss: 1.259366, loss_d: 0.248280
Epoch finished! Loss: 1.228129842877388
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6787037037037037
              precision    recall  f1-score   support

         0.0       0.54      0.48      0.50       166
         1.0       0.00      0.00      0.00        58
         2.0       0.63      0.93      0.75       369
         3.0       1.00      0.89      0.94       135
         4.0       0.71      0.54      0.61       352

    accuracy                           0.68      1080
   macro avg       0.58      0.57      0.56      1080
weighted avg       0.65      0.68      0.65      1080
 


====== chp007-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  85.65  47.59   92.56   53.74     50.48
1  94.63   0.00  100.00    0.00      0.00
2  78.98  93.22   71.59   63.00     75.19
3  98.61  88.89  100.00  100.00     94.12
4  77.87  53.98   89.42   71.16     61.39
Total accuracy: 67.87%
Average sen: 56.74%
Average spec: 90.71%
Macro f1-score: 56.24%
Diagnosis acc on 90mins: 1.0
[0.99199682 0.94629693 0.78439963 0.9893384  0.58744842 0.9824239 ]
pred: 0.8803173502286276, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp007-nsrr

=== Test on chp008-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.314401, loss_ss: 1.598938, loss_d: 0.715463
0.2457 --- loss: 2.236576, loss_ss: 1.367417, loss_d: 0.869158
0.4914 --- loss: 1.904449, loss_ss: 1.341056, loss_d: 0.563393
0.7371 --- loss: 1.821301, loss_ss: 1.352642, loss_d: 0.468659
0.9828 --- loss: 2.233348, loss_ss: 1.279922, loss_d: 0.953426
Epoch finished! Loss: 2.0296891033649445
Starting epoch 2/10.
0.0000 --- loss: 2.028727, loss_ss: 1.281575, loss_d: 0.747153
0.2457 --- loss: 2.026276, loss_ss: 1.288002, loss_d: 0.738274
0.4914 --- loss: 1.693943, loss_ss: 1.290531, loss_d: 0.403412
0.7371 --- loss: 1.652451, loss_ss: 1.195683, loss_d: 0.456768
0.9828 --- loss: 2.023768, loss_ss: 1.229856, loss_d: 0.793912
Epoch finished! Loss: 1.8663883239030838
Starting epoch 3/10.
0.0000 --- loss: 1.824877, loss_ss: 1.221330, loss_d: 0.603546
0.2457 --- loss: 1.733893, loss_ss: 1.264755, loss_d: 0.469138
0.4914 --- loss: 1.751961, loss_ss: 1.156894, loss_d: 0.595067
0.7371 --- loss: 1.622749, loss_ss: 1.201390, loss_d: 0.421359
0.9828 --- loss: 2.254765, loss_ss: 1.244052, loss_d: 1.010713
Epoch finished! Loss: 1.742307749390602
Starting epoch 4/10.
0.0000 --- loss: 1.628292, loss_ss: 1.176670, loss_d: 0.451622
0.2457 --- loss: 1.623926, loss_ss: 1.111277, loss_d: 0.512650
0.4914 --- loss: 1.639958, loss_ss: 1.287463, loss_d: 0.352495
0.7371 --- loss: 1.745829, loss_ss: 1.193057, loss_d: 0.552772
0.9828 --- loss: 1.601302, loss_ss: 1.177393, loss_d: 0.423909
Epoch finished! Loss: 1.6930315375328064
Starting epoch 5/10.
0.0000 --- loss: 1.393010, loss_ss: 1.064337, loss_d: 0.328674
0.2457 --- loss: 1.448289, loss_ss: 1.161868, loss_d: 0.286422
0.4914 --- loss: 1.287725, loss_ss: 0.987950, loss_d: 0.299775
0.7371 --- loss: 1.267646, loss_ss: 1.080606, loss_d: 0.187040
0.9828 --- loss: 1.413077, loss_ss: 1.363643, loss_d: 0.049434
Epoch finished! Loss: 1.4551594465970994
Starting epoch 6/10.
0.0000 --- loss: 1.702430, loss_ss: 1.302354, loss_d: 0.400075
0.2457 --- loss: 1.235769, loss_ss: 1.133109, loss_d: 0.102660
0.4914 --- loss: 1.287693, loss_ss: 1.097830, loss_d: 0.189863
0.7371 --- loss: 1.288642, loss_ss: 1.191447, loss_d: 0.097195
0.9828 --- loss: 1.957454, loss_ss: 1.109606, loss_d: 0.847848
Epoch finished! Loss: 1.4591819524765015
Starting epoch 7/10.
0.0000 --- loss: 1.319165, loss_ss: 1.188650, loss_d: 0.130515
0.2457 --- loss: 1.448921, loss_ss: 1.210802, loss_d: 0.238119
0.4914 --- loss: 1.078876, loss_ss: 1.011715, loss_d: 0.067161
0.7371 --- loss: 1.229175, loss_ss: 1.074962, loss_d: 0.154213
0.9828 --- loss: 1.005591, loss_ss: 0.967617, loss_d: 0.037974
Epoch finished! Loss: 1.244277185201645
Starting epoch 8/10.
0.0000 --- loss: 1.096880, loss_ss: 1.037184, loss_d: 0.059696
0.2457 --- loss: 1.262272, loss_ss: 0.968346, loss_d: 0.293925
0.4914 --- loss: 1.185182, loss_ss: 1.152672, loss_d: 0.032510
0.7371 --- loss: 1.151025, loss_ss: 1.143148, loss_d: 0.007877
0.9828 --- loss: 1.055505, loss_ss: 1.028308, loss_d: 0.027198
Epoch finished! Loss: 1.1242594957351684
Starting epoch 9/10.
0.0000 --- loss: 1.379155, loss_ss: 1.376747, loss_d: 0.002408
0.2457 --- loss: 0.947685, loss_ss: 0.944546, loss_d: 0.003139
0.4914 --- loss: 0.987401, loss_ss: 0.983690, loss_d: 0.003711
0.7371 --- loss: 1.336488, loss_ss: 1.155576, loss_d: 0.180912
0.9828 --- loss: 0.972358, loss_ss: 0.959543, loss_d: 0.012815
Epoch finished! Loss: 1.118513822555542
Starting epoch 10/10.
0.0000 --- loss: 1.079887, loss_ss: 1.062814, loss_d: 0.017073
0.2457 --- loss: 0.962102, loss_ss: 0.938390, loss_d: 0.023712
0.4914 --- loss: 0.983180, loss_ss: 0.972437, loss_d: 0.010743
0.7371 --- loss: 0.967209, loss_ss: 0.911416, loss_d: 0.055793
0.9828 --- loss: 0.948229, loss_ss: 0.932128, loss_d: 0.016102
Epoch finished! Loss: 1.1391586348414422
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6711111111111111
              precision    recall  f1-score   support

         0.0       0.35      0.87      0.50        89
         1.0       0.00      0.00      0.00        37
         2.0       0.91      0.50      0.64       387
         3.0       0.78      0.94      0.85       263
         4.0       0.56      0.71      0.63       124

    accuracy                           0.67       900
   macro avg       0.52      0.60      0.53       900
weighted avg       0.73      0.67      0.66       900
 


====== chp008-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  82.89  86.52   82.49  35.16     50.00
1  95.89   0.00  100.00   0.00      0.00
2  76.33  49.61   96.49  91.43     64.32
3  90.67  93.92   89.32  78.41     85.47
4  88.44  70.97   91.24  56.41     62.86
Total accuracy: 67.11%
Average sen: 60.20%
Average spec: 91.91%
Macro f1-score: 52.53%
Diagnosis acc on 90mins: 1.0
[0.9944647  0.99999213 0.98719329 0.86957473 0.9787007 ]
pred: 0.965985107421875, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp008-nsrr

=== Test on chp009-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.409888, loss_ss: 1.760978, loss_d: 0.648910
0.2457 --- loss: 2.136984, loss_ss: 1.632684, loss_d: 0.504300
0.4914 --- loss: 2.185123, loss_ss: 1.496331, loss_d: 0.688793
0.7371 --- loss: 1.880286, loss_ss: 1.408720, loss_d: 0.471567
0.9828 --- loss: 1.942183, loss_ss: 1.544876, loss_d: 0.397307
Epoch finished! Loss: 2.2547029286623
Starting epoch 2/10.
0.0000 --- loss: 1.842678, loss_ss: 1.370574, loss_d: 0.472104
0.2457 --- loss: 2.454223, loss_ss: 1.366098, loss_d: 1.088125
0.4914 --- loss: 2.216354, loss_ss: 1.376587, loss_d: 0.839767
0.7371 --- loss: 2.073369, loss_ss: 1.390157, loss_d: 0.683212
0.9828 --- loss: 1.756716, loss_ss: 1.299660, loss_d: 0.457056
Epoch finished! Loss: 1.9779501974582672
Starting epoch 3/10.
0.0000 --- loss: 1.759958, loss_ss: 1.287257, loss_d: 0.472700
0.2457 --- loss: 2.062810, loss_ss: 1.202727, loss_d: 0.860083
0.4914 --- loss: 1.829823, loss_ss: 1.320471, loss_d: 0.509352
0.7371 --- loss: 1.900943, loss_ss: 1.461900, loss_d: 0.439043
0.9828 --- loss: 1.920903, loss_ss: 1.496682, loss_d: 0.424221
Epoch finished! Loss: 1.9214207231998444
Starting epoch 4/10.
0.0000 --- loss: 1.761947, loss_ss: 1.220429, loss_d: 0.541518
0.2457 --- loss: 1.678092, loss_ss: 1.212772, loss_d: 0.465320
0.4914 --- loss: 1.798707, loss_ss: 1.195518, loss_d: 0.603189
0.7371 --- loss: 1.521028, loss_ss: 1.171868, loss_d: 0.349160
0.9828 --- loss: 1.959759, loss_ss: 1.256826, loss_d: 0.702932
Epoch finished! Loss: 1.8062197774648667
Starting epoch 5/10.
0.0000 --- loss: 1.557009, loss_ss: 1.231894, loss_d: 0.325115
0.2457 --- loss: 1.573134, loss_ss: 1.171014, loss_d: 0.402120
0.4914 --- loss: 1.417797, loss_ss: 1.110122, loss_d: 0.307675
0.7371 --- loss: 1.563172, loss_ss: 1.244141, loss_d: 0.319031
0.9828 --- loss: 1.653095, loss_ss: 1.236273, loss_d: 0.416822
Epoch finished! Loss: 1.6675734370946884
Starting epoch 6/10.
0.0000 --- loss: 1.356302, loss_ss: 1.084491, loss_d: 0.271812
0.2457 --- loss: 1.335806, loss_ss: 1.173075, loss_d: 0.162731
0.4914 --- loss: 1.663584, loss_ss: 1.097589, loss_d: 0.565995
0.7371 --- loss: 1.783509, loss_ss: 1.111703, loss_d: 0.671806
0.9828 --- loss: 1.794883, loss_ss: 1.209752, loss_d: 0.585131
Epoch finished! Loss: 1.6113056808710098
Starting epoch 7/10.
0.0000 --- loss: 1.377816, loss_ss: 1.146649, loss_d: 0.231166
0.2457 --- loss: 1.415101, loss_ss: 1.043842, loss_d: 0.371259
0.4914 --- loss: 1.837469, loss_ss: 1.346748, loss_d: 0.490721
0.7371 --- loss: 1.581223, loss_ss: 1.014753, loss_d: 0.566470
0.9828 --- loss: 1.155241, loss_ss: 1.039541, loss_d: 0.115700
Epoch finished! Loss: 1.530392387509346
Starting epoch 8/10.
0.0000 --- loss: 1.213386, loss_ss: 1.057524, loss_d: 0.155863
0.2457 --- loss: 1.241357, loss_ss: 1.028893, loss_d: 0.212464
0.4914 --- loss: 1.377816, loss_ss: 1.071109, loss_d: 0.306707
0.7371 --- loss: 1.655695, loss_ss: 1.049253, loss_d: 0.606442
0.9828 --- loss: 1.811753, loss_ss: 1.021754, loss_d: 0.790000
Epoch finished! Loss: 1.419524574279785
Starting epoch 9/10.
0.0000 --- loss: 1.227962, loss_ss: 1.136148, loss_d: 0.091815
0.2457 --- loss: 1.754554, loss_ss: 0.945319, loss_d: 0.809235
0.4914 --- loss: 1.120955, loss_ss: 0.970101, loss_d: 0.150854
0.7371 --- loss: 1.145603, loss_ss: 1.022907, loss_d: 0.122695
0.9828 --- loss: 1.324257, loss_ss: 1.115537, loss_d: 0.208721
Epoch finished! Loss: 1.323539912700653
Starting epoch 10/10.
0.0000 --- loss: 1.126629, loss_ss: 1.067845, loss_d: 0.058784
0.2457 --- loss: 1.355551, loss_ss: 1.107820, loss_d: 0.247731
0.4914 --- loss: 0.978092, loss_ss: 0.926440, loss_d: 0.051652
0.7371 --- loss: 1.125712, loss_ss: 0.941486, loss_d: 0.184226
0.9828 --- loss: 1.117455, loss_ss: 1.038252, loss_d: 0.079203
Epoch finished! Loss: 1.2020183399319648
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7422222222222222
              precision    recall  f1-score   support

         0.0       0.77      0.67      0.72        96
         1.0       1.00      0.01      0.02        98
         2.0       0.71      0.91      0.79       340
         3.0       0.98      0.95      0.96       192
         4.0       0.58      0.65      0.61       174

    accuracy                           0.74       900
   macro avg       0.81      0.64      0.62       900
weighted avg       0.78      0.74      0.70       900
 


====== chp009-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  94.33  66.67   97.64   77.11     71.51
1  89.22   1.02  100.00  100.00      2.02
2  82.33  90.59   77.32   70.80     79.48
3  98.44  94.79   99.44   97.85     96.30
4  84.11  64.94   88.71   57.95     61.25
Total accuracy: 74.22%
Average sen: 63.60%
Average spec: 92.62%
Macro f1-score: 62.11%
Diagnosis acc on 90mins: 0.6
[0.40138331 0.67279029 0.8135559  0.94857723 0.3226608 ]
pred: 0.6317935049533844, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp009-nsrr

=== Test on chp010-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.466475, loss_ss: 1.795519, loss_d: 0.670956
0.2457 --- loss: 2.094234, loss_ss: 1.433307, loss_d: 0.660927
0.4914 --- loss: 2.036243, loss_ss: 1.423924, loss_d: 0.612319
0.7371 --- loss: 2.107809, loss_ss: 1.347078, loss_d: 0.760730
0.9828 --- loss: 1.825139, loss_ss: 1.317126, loss_d: 0.508013
Epoch finished! Loss: 2.1984742671251296
Starting epoch 2/10.
0.0000 --- loss: 1.789688, loss_ss: 1.328291, loss_d: 0.461398
0.2457 --- loss: 1.860833, loss_ss: 1.227168, loss_d: 0.633665
0.4914 --- loss: 2.073225, loss_ss: 1.209090, loss_d: 0.864136
0.7371 --- loss: 1.849423, loss_ss: 1.250454, loss_d: 0.598969
0.9828 --- loss: 1.929273, loss_ss: 1.340669, loss_d: 0.588604
Epoch finished! Loss: 1.889220443367958
Starting epoch 3/10.
0.0000 --- loss: 1.722499, loss_ss: 1.241673, loss_d: 0.480826
0.2457 --- loss: 1.850767, loss_ss: 1.378968, loss_d: 0.471799
0.4914 --- loss: 1.762954, loss_ss: 1.144320, loss_d: 0.618633
0.7371 --- loss: 1.784771, loss_ss: 1.096756, loss_d: 0.688015
0.9828 --- loss: 1.830003, loss_ss: 1.085856, loss_d: 0.744146
Epoch finished! Loss: 1.7557427346706391
Starting epoch 4/10.
0.0000 --- loss: 1.659179, loss_ss: 1.117374, loss_d: 0.541806
0.2457 --- loss: 1.599071, loss_ss: 1.246299, loss_d: 0.352772
0.4914 --- loss: 1.672521, loss_ss: 1.212956, loss_d: 0.459565
0.7371 --- loss: 1.576453, loss_ss: 1.105577, loss_d: 0.470875
0.9828 --- loss: 1.465098, loss_ss: 1.138092, loss_d: 0.327007
Epoch finished! Loss: 1.6850685715675353
Starting epoch 5/10.
0.0000 --- loss: 1.700260, loss_ss: 1.170771, loss_d: 0.529488
0.2457 --- loss: 1.473330, loss_ss: 1.130427, loss_d: 0.342903
0.4914 --- loss: 1.603994, loss_ss: 1.065901, loss_d: 0.538094
0.7371 --- loss: 1.500044, loss_ss: 1.108092, loss_d: 0.391952
0.9828 --- loss: 1.385373, loss_ss: 1.095273, loss_d: 0.290099
Epoch finished! Loss: 1.584787479043007
Starting epoch 6/10.
0.0000 --- loss: 1.632717, loss_ss: 0.999865, loss_d: 0.632852
0.2457 --- loss: 1.287498, loss_ss: 0.967016, loss_d: 0.320482
0.4914 --- loss: 1.677199, loss_ss: 1.163056, loss_d: 0.514143
0.7371 --- loss: 1.472441, loss_ss: 1.047951, loss_d: 0.424490
0.9828 --- loss: 1.511395, loss_ss: 0.986643, loss_d: 0.524751
Epoch finished! Loss: 1.5168633222579957
Starting epoch 7/10.
0.0000 --- loss: 1.294612, loss_ss: 0.986703, loss_d: 0.307909
0.2457 --- loss: 1.525665, loss_ss: 1.061357, loss_d: 0.464308
0.4914 --- loss: 1.368493, loss_ss: 1.006588, loss_d: 0.361904
0.7371 --- loss: 1.227614, loss_ss: 0.932911, loss_d: 0.294703
0.9828 --- loss: 1.171772, loss_ss: 1.035750, loss_d: 0.136022
Epoch finished! Loss: 1.4169030994176866
Starting epoch 8/10.
0.0000 --- loss: 1.057253, loss_ss: 0.854948, loss_d: 0.202304
0.2457 --- loss: 1.613959, loss_ss: 1.007519, loss_d: 0.606440
0.4914 --- loss: 1.331545, loss_ss: 1.096685, loss_d: 0.234859
0.7371 --- loss: 1.563116, loss_ss: 1.018517, loss_d: 0.544598
0.9828 --- loss: 1.237134, loss_ss: 0.929155, loss_d: 0.307979
Epoch finished! Loss: 1.362713734805584
Starting epoch 9/10.
0.0000 --- loss: 1.152380, loss_ss: 0.975003, loss_d: 0.177377
0.2457 --- loss: 1.314412, loss_ss: 1.022750, loss_d: 0.291662
0.4914 --- loss: 1.094858, loss_ss: 0.949063, loss_d: 0.145796
0.7371 --- loss: 1.162813, loss_ss: 0.892554, loss_d: 0.270259
0.9828 --- loss: 1.295520, loss_ss: 0.976475, loss_d: 0.319045
Epoch finished! Loss: 1.2645105555653573
Starting epoch 10/10.
0.0000 --- loss: 1.025586, loss_ss: 0.824165, loss_d: 0.201420
0.2457 --- loss: 1.095803, loss_ss: 0.929840, loss_d: 0.165964
0.4914 --- loss: 1.016406, loss_ss: 0.976518, loss_d: 0.039889
0.7371 --- loss: 1.260529, loss_ss: 1.094817, loss_d: 0.165713
0.9828 --- loss: 1.001649, loss_ss: 0.841560, loss_d: 0.160089
Epoch finished! Loss: 1.212865126132965
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7422222222222222
              precision    recall  f1-score   support

         0.0       0.44      0.81      0.57        54
         1.0       0.00      0.00      0.00        45
         2.0       0.98      0.68      0.80       493
         3.0       0.57      0.97      0.72        90
         4.0       0.66      0.94      0.78       218

    accuracy                           0.74       900
   macro avg       0.53      0.68      0.57       900
weighted avg       0.78      0.74      0.73       900
 


====== chp010-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  92.67  81.48   93.38  44.00     57.14
1  95.00   0.00  100.00   0.00      0.00
2  81.44  67.55   98.28  97.94     79.95
3  92.44  96.67   91.98  57.24     71.90
4  86.89  93.58   84.75  66.23     77.57
Total accuracy: 74.22%
Average sen: 67.85%
Average spec: 93.68%
Macro f1-score: 57.31%
Diagnosis acc on 90mins: 1.0
[0.98399621 0.97723877 0.91615236 0.99902189 0.72216499]
pred: 0.9197148442268371, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp010-nsrr

=== Test on chp011-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.593601, loss_ss: 1.870405, loss_d: 0.723196
0.2457 --- loss: 2.198956, loss_ss: 1.751023, loss_d: 0.447934
0.4914 --- loss: 2.160786, loss_ss: 1.540670, loss_d: 0.620115
0.7371 --- loss: 2.179470, loss_ss: 1.500408, loss_d: 0.679062
0.9828 --- loss: 2.462706, loss_ss: 1.642024, loss_d: 0.820682
Epoch finished! Loss: 2.2965800166130066
Starting epoch 2/10.
0.0000 --- loss: 2.105951, loss_ss: 1.520227, loss_d: 0.585724
0.2457 --- loss: 2.090397, loss_ss: 1.471477, loss_d: 0.618921
0.4914 --- loss: 2.065351, loss_ss: 1.433482, loss_d: 0.631869
0.7371 --- loss: 2.153379, loss_ss: 1.334619, loss_d: 0.818760
0.9828 --- loss: 1.700975, loss_ss: 1.301896, loss_d: 0.399079
Epoch finished! Loss: 2.030026465654373
Starting epoch 3/10.
0.0000 --- loss: 2.334289, loss_ss: 1.358214, loss_d: 0.976074
0.2457 --- loss: 1.847608, loss_ss: 1.244929, loss_d: 0.602679
0.4914 --- loss: 2.172608, loss_ss: 1.367360, loss_d: 0.805248
0.7371 --- loss: 1.798074, loss_ss: 1.327605, loss_d: 0.470468
0.9828 --- loss: 1.706815, loss_ss: 1.326630, loss_d: 0.380185
Epoch finished! Loss: 1.896952646970749
Starting epoch 4/10.
0.0000 --- loss: 1.566615, loss_ss: 1.229620, loss_d: 0.336995
0.2457 --- loss: 1.618079, loss_ss: 1.335545, loss_d: 0.282534
0.4914 --- loss: 1.738942, loss_ss: 1.218032, loss_d: 0.520910
0.7371 --- loss: 1.727828, loss_ss: 1.200987, loss_d: 0.526842
0.9828 --- loss: 2.092184, loss_ss: 1.301627, loss_d: 0.790557
Epoch finished! Loss: 1.7625085443258286
Starting epoch 5/10.
0.0000 --- loss: 1.579299, loss_ss: 1.199278, loss_d: 0.380021
0.2457 --- loss: 1.664273, loss_ss: 1.237557, loss_d: 0.426715
0.4914 --- loss: 1.666819, loss_ss: 1.196191, loss_d: 0.470628
0.7371 --- loss: 1.673088, loss_ss: 1.316784, loss_d: 0.356304
0.9828 --- loss: 1.477871, loss_ss: 1.147272, loss_d: 0.330599
Epoch finished! Loss: 1.636761114001274
Starting epoch 6/10.
0.0000 --- loss: 1.495109, loss_ss: 1.191427, loss_d: 0.303683
0.2457 --- loss: 1.475231, loss_ss: 1.276879, loss_d: 0.198352
0.4914 --- loss: 1.482737, loss_ss: 1.181614, loss_d: 0.301123
0.7371 --- loss: 1.345946, loss_ss: 1.115191, loss_d: 0.230755
0.9828 --- loss: 1.522150, loss_ss: 1.294364, loss_d: 0.227787
Epoch finished! Loss: 1.4696309983730316
Starting epoch 7/10.
0.0000 --- loss: 1.414671, loss_ss: 1.219760, loss_d: 0.194911
0.2457 --- loss: 1.225590, loss_ss: 1.131019, loss_d: 0.094571
0.4914 --- loss: 1.594470, loss_ss: 1.195216, loss_d: 0.399254
0.7371 --- loss: 1.283297, loss_ss: 1.181026, loss_d: 0.102271
0.9828 --- loss: 1.231742, loss_ss: 0.939842, loss_d: 0.291899
Epoch finished! Loss: 1.4254663050174714
Starting epoch 8/10.
0.0000 --- loss: 1.331227, loss_ss: 1.225961, loss_d: 0.105266
0.2457 --- loss: 1.178254, loss_ss: 1.019282, loss_d: 0.158973
0.4914 --- loss: 1.421454, loss_ss: 1.244602, loss_d: 0.176852
0.7371 --- loss: 1.111776, loss_ss: 0.992303, loss_d: 0.119473
0.9828 --- loss: 1.164770, loss_ss: 1.098311, loss_d: 0.066459
Epoch finished! Loss: 1.3460055381059646
Starting epoch 9/10.
0.0000 --- loss: 1.046656, loss_ss: 0.886001, loss_d: 0.160655
0.2457 --- loss: 1.138217, loss_ss: 1.100541, loss_d: 0.037676
0.4914 --- loss: 0.951829, loss_ss: 0.902966, loss_d: 0.048863
0.7371 --- loss: 1.149837, loss_ss: 1.087821, loss_d: 0.062017
0.9828 --- loss: 1.428668, loss_ss: 1.303799, loss_d: 0.124869
Epoch finished! Loss: 1.1689098939299583
Starting epoch 10/10.
0.0000 --- loss: 1.044130, loss_ss: 1.018177, loss_d: 0.025953
0.2457 --- loss: 1.309307, loss_ss: 0.994506, loss_d: 0.314801
0.4914 --- loss: 1.432807, loss_ss: 1.278225, loss_d: 0.154581
0.7371 --- loss: 1.074078, loss_ss: 0.936466, loss_d: 0.137612
0.9828 --- loss: 1.338252, loss_ss: 0.878397, loss_d: 0.459855
Epoch finished! Loss: 1.1247727662324905
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6166666666666667
              precision    recall  f1-score   support

         0.0       0.50      0.60      0.55       129
         1.0       0.39      0.18      0.25       143
         2.0       0.46      0.85      0.60       221
         3.0       1.00      0.72      0.84       271
         4.0       0.91      0.49      0.64       136

    accuracy                           0.62       900
   macro avg       0.65      0.57      0.57       900
weighted avg       0.69      0.62      0.61       900
 


====== chp011-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  85.67  60.47   89.88   50.00     54.74
1  82.56  18.18   94.72   39.39     24.88
2  71.89  85.07   67.60   46.08     59.78
3  91.67  72.32  100.00  100.00     83.94
4  91.56  49.26   99.08   90.54     63.81
Total accuracy: 61.67%
Average sen: 57.06%
Average spec: 90.26%
Macro f1-score: 57.43%
Diagnosis acc on 90mins: 1.0
[0.99993908 0.91152304 0.99994612 0.99904281 0.99413139]
pred: 0.9809164881706238, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp011-nsrr

=== Test on chp012-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.281995, loss_ss: 1.612287, loss_d: 0.669708
0.2463 --- loss: 2.086882, loss_ss: 1.371755, loss_d: 0.715128
0.4926 --- loss: 2.469536, loss_ss: 1.286481, loss_d: 1.183055
0.7389 --- loss: 1.900897, loss_ss: 1.337823, loss_d: 0.563074
0.9852 --- loss: 1.893701, loss_ss: 1.183942, loss_d: 0.709759
Epoch finished! Loss: 2.0354868680238725
Starting epoch 2/10.
0.0000 --- loss: 1.771750, loss_ss: 1.238750, loss_d: 0.533001
0.2463 --- loss: 1.801185, loss_ss: 1.303222, loss_d: 0.497964
0.4926 --- loss: 1.723452, loss_ss: 1.286444, loss_d: 0.437008
0.7389 --- loss: 1.828645, loss_ss: 1.350170, loss_d: 0.478475
0.9852 --- loss: 2.038993, loss_ss: 1.278307, loss_d: 0.760685
Epoch finished! Loss: 1.8263704746961593
Starting epoch 3/10.
0.0000 --- loss: 1.614747, loss_ss: 1.137659, loss_d: 0.477088
0.2463 --- loss: 1.708151, loss_ss: 1.146735, loss_d: 0.561415
0.4926 --- loss: 1.856887, loss_ss: 1.051057, loss_d: 0.805830
0.7389 --- loss: 1.585681, loss_ss: 1.100023, loss_d: 0.485658
0.9852 --- loss: 1.410536, loss_ss: 1.085725, loss_d: 0.324812
Epoch finished! Loss: 1.7453052312135697
Starting epoch 4/10.
0.0000 --- loss: 1.611978, loss_ss: 1.264729, loss_d: 0.347249
0.2463 --- loss: 1.847340, loss_ss: 1.118288, loss_d: 0.729052
0.4926 --- loss: 1.538140, loss_ss: 1.166459, loss_d: 0.371681
0.7389 --- loss: 1.691961, loss_ss: 1.136693, loss_d: 0.555268
0.9852 --- loss: 1.446648, loss_ss: 1.069419, loss_d: 0.377229
Epoch finished! Loss: 1.652030485868454
Starting epoch 5/10.
0.0000 --- loss: 1.382474, loss_ss: 1.095846, loss_d: 0.286628
0.2463 --- loss: 1.421161, loss_ss: 1.117978, loss_d: 0.303182
0.4926 --- loss: 1.558228, loss_ss: 1.000790, loss_d: 0.557438
0.7389 --- loss: 1.515060, loss_ss: 1.203969, loss_d: 0.311092
0.9852 --- loss: 1.279067, loss_ss: 1.064004, loss_d: 0.215062
Epoch finished! Loss: 1.526192769408226
Starting epoch 6/10.
0.0000 --- loss: 1.478839, loss_ss: 1.214252, loss_d: 0.264587
0.2463 --- loss: 1.061594, loss_ss: 0.927782, loss_d: 0.133812
0.4926 --- loss: 1.117460, loss_ss: 0.985635, loss_d: 0.131826
0.7389 --- loss: 1.382463, loss_ss: 1.117287, loss_d: 0.265176
0.9852 --- loss: 1.490381, loss_ss: 1.100851, loss_d: 0.389530
Epoch finished! Loss: 1.4414631307125092
Starting epoch 7/10.
0.0000 --- loss: 1.400028, loss_ss: 0.931049, loss_d: 0.468979
0.2463 --- loss: 1.380624, loss_ss: 1.067139, loss_d: 0.313484
0.4926 --- loss: 1.623934, loss_ss: 1.011717, loss_d: 0.612217
0.7389 --- loss: 1.664822, loss_ss: 1.229290, loss_d: 0.435533
0.9852 --- loss: 1.248952, loss_ss: 0.922660, loss_d: 0.326292
Epoch finished! Loss: 1.3443192005157472
Starting epoch 8/10.
0.0000 --- loss: 1.869818, loss_ss: 1.010337, loss_d: 0.859482
0.2463 --- loss: 1.249369, loss_ss: 0.989957, loss_d: 0.259412
0.4926 --- loss: 1.286976, loss_ss: 1.051559, loss_d: 0.235416
0.7389 --- loss: 1.070801, loss_ss: 0.984203, loss_d: 0.086598
0.9852 --- loss: 1.491864, loss_ss: 1.086993, loss_d: 0.404871
Epoch finished! Loss: 1.2971002206206321
Starting epoch 9/10.
0.0000 --- loss: 1.203905, loss_ss: 0.897125, loss_d: 0.306781
0.2463 --- loss: 1.081986, loss_ss: 0.883236, loss_d: 0.198750
0.4926 --- loss: 1.298153, loss_ss: 1.276682, loss_d: 0.021471
0.7389 --- loss: 1.265403, loss_ss: 1.169298, loss_d: 0.096105
0.9852 --- loss: 0.901202, loss_ss: 0.880379, loss_d: 0.020823
Epoch finished! Loss: 1.1800046846270562
Starting epoch 10/10.
0.0000 --- loss: 1.178330, loss_ss: 1.009577, loss_d: 0.168752
0.2463 --- loss: 0.934374, loss_ss: 0.891517, loss_d: 0.042857
0.4926 --- loss: 1.422821, loss_ss: 0.904000, loss_d: 0.518821
0.7389 --- loss: 1.483385, loss_ss: 1.015785, loss_d: 0.467599
0.9852 --- loss: 1.176059, loss_ss: 1.095953, loss_d: 0.080107
Epoch finished! Loss: 1.2305753380060196
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6305555555555555
              precision    recall  f1-score   support

         0.0       0.24      0.57      0.34        23
         1.0       0.00      0.00      0.00       178
         2.0       0.57      0.74      0.64       379
         3.0       0.75      0.96      0.84       203
         4.0       0.71      0.64      0.67       297

    accuracy                           0.63      1080
   macro avg       0.45      0.58      0.50      1080
weighted avg       0.54      0.63      0.58      1080
 


====== chp012-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  95.28  56.52   96.12  24.07     33.77
1  83.52   0.00  100.00   0.00      0.00
2  71.20  74.41   69.47  56.85     64.46
3  93.15  96.06   92.47  74.71     84.05
4  82.96  64.31   90.04  71.00     67.49
Total accuracy: 63.06%
Average sen: 58.26%
Average spec: 89.62%
Macro f1-score: 49.95%
Diagnosis acc on 90mins: 0.6666666666666666
[0.90339094 0.47292587 0.24238628 0.6676687  0.94737631 0.82959366]
pred: 0.6772236277659734, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp012-nsrr

=== Test on chp013-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.342354, loss_ss: 1.675964, loss_d: 0.666390
0.2457 --- loss: 1.829639, loss_ss: 1.625199, loss_d: 0.204441
0.4914 --- loss: 2.199283, loss_ss: 1.609265, loss_d: 0.590019
0.7371 --- loss: 2.106593, loss_ss: 1.403920, loss_d: 0.702673
0.9828 --- loss: 2.164227, loss_ss: 1.385313, loss_d: 0.778914
Epoch finished! Loss: 2.203486314415932
Starting epoch 2/10.
0.0000 --- loss: 1.881567, loss_ss: 1.458264, loss_d: 0.423304
0.2457 --- loss: 1.926207, loss_ss: 1.376636, loss_d: 0.549571
0.4914 --- loss: 1.944143, loss_ss: 1.391890, loss_d: 0.552253
0.7371 --- loss: 1.999714, loss_ss: 1.348981, loss_d: 0.650734
0.9828 --- loss: 1.843885, loss_ss: 1.365019, loss_d: 0.478866
Epoch finished! Loss: 1.9524454176425934
Starting epoch 3/10.
0.0000 --- loss: 1.763737, loss_ss: 1.318432, loss_d: 0.445306
0.2457 --- loss: 1.765813, loss_ss: 1.312073, loss_d: 0.453739
0.4914 --- loss: 1.541564, loss_ss: 1.258561, loss_d: 0.283003
0.7371 --- loss: 1.769513, loss_ss: 1.219132, loss_d: 0.550382
0.9828 --- loss: 1.607215, loss_ss: 1.275655, loss_d: 0.331560
Epoch finished! Loss: 1.8182515293359756
Starting epoch 4/10.
0.0000 --- loss: 1.672319, loss_ss: 1.176337, loss_d: 0.495982
0.2457 --- loss: 1.538526, loss_ss: 1.251814, loss_d: 0.286713
0.4914 --- loss: 1.506509, loss_ss: 1.153939, loss_d: 0.352570
0.7371 --- loss: 1.396586, loss_ss: 1.143008, loss_d: 0.253578
0.9828 --- loss: 1.543193, loss_ss: 1.096517, loss_d: 0.446675
Epoch finished! Loss: 1.6571637719869614
Starting epoch 5/10.
0.0000 --- loss: 1.510417, loss_ss: 1.363253, loss_d: 0.147164
0.2457 --- loss: 1.728566, loss_ss: 1.108031, loss_d: 0.620535
0.4914 --- loss: 1.631749, loss_ss: 1.241238, loss_d: 0.390510
0.7371 --- loss: 1.552673, loss_ss: 1.144961, loss_d: 0.407712
0.9828 --- loss: 1.469986, loss_ss: 1.064826, loss_d: 0.405160
Epoch finished! Loss: 1.6030220299959184
Starting epoch 6/10.
0.0000 --- loss: 1.212453, loss_ss: 1.074988, loss_d: 0.137465
0.2457 --- loss: 1.504534, loss_ss: 1.221914, loss_d: 0.282620
0.4914 --- loss: 1.307974, loss_ss: 1.137016, loss_d: 0.170959
0.7371 --- loss: 1.368027, loss_ss: 1.092573, loss_d: 0.275454
0.9828 --- loss: 1.721993, loss_ss: 1.160457, loss_d: 0.561535
Epoch finished! Loss: 1.4069432199001313
Starting epoch 7/10.
0.0000 --- loss: 1.188998, loss_ss: 1.174950, loss_d: 0.014048
0.2457 --- loss: 1.221232, loss_ss: 1.061289, loss_d: 0.159943
0.4914 --- loss: 1.369491, loss_ss: 1.024120, loss_d: 0.345371
0.7371 --- loss: 1.780224, loss_ss: 1.146852, loss_d: 0.633373
0.9828 --- loss: 1.150880, loss_ss: 1.112207, loss_d: 0.038673
Epoch finished! Loss: 1.285200160741806
Starting epoch 8/10.
0.0000 --- loss: 1.036708, loss_ss: 1.014946, loss_d: 0.021762
0.2457 --- loss: 1.073575, loss_ss: 1.046518, loss_d: 0.027057
0.4914 --- loss: 0.965409, loss_ss: 0.909603, loss_d: 0.055806
0.7371 --- loss: 1.113002, loss_ss: 1.076112, loss_d: 0.036891
0.9828 --- loss: 1.382668, loss_ss: 1.296868, loss_d: 0.085800
Epoch finished! Loss: 1.1824531465768815
Starting epoch 9/10.
0.0000 --- loss: 1.097024, loss_ss: 1.084254, loss_d: 0.012770
0.2457 --- loss: 1.036494, loss_ss: 0.888630, loss_d: 0.147864
0.4914 --- loss: 1.029893, loss_ss: 1.014609, loss_d: 0.015284
0.7371 --- loss: 1.098248, loss_ss: 1.091876, loss_d: 0.006372
0.9828 --- loss: 1.148770, loss_ss: 1.109681, loss_d: 0.039089
Epoch finished! Loss: 1.064223150908947
Starting epoch 10/10.
0.0000 --- loss: 0.986625, loss_ss: 0.982143, loss_d: 0.004482
0.2457 --- loss: 0.963646, loss_ss: 0.960449, loss_d: 0.003197
0.4914 --- loss: 1.068610, loss_ss: 1.062843, loss_d: 0.005767
0.7371 --- loss: 0.870736, loss_ss: 0.867404, loss_d: 0.003332
0.9828 --- loss: 0.988253, loss_ss: 0.980710, loss_d: 0.007543
Epoch finished! Loss: 0.9953282937407494
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6755555555555556
              precision    recall  f1-score   support

         0.0       0.42      0.85      0.56        27
         1.0       0.00      0.00      0.00       107
         2.0       0.77      0.70      0.73       425
         3.0       0.63      0.81      0.71       189
         4.0       0.65      0.89      0.75       152

    accuracy                           0.68       900
   macro avg       0.49      0.65      0.55       900
weighted avg       0.62      0.68      0.64       900
 


====== chp013-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  96.00  85.19   96.33  41.82     56.10
1  87.33   0.00   99.12   0.00      0.00
2  75.78  69.88   81.05  76.74     73.15
3  86.11  80.95   87.48  63.22     71.00
4  89.89  88.82   90.11  64.59     74.79
Total accuracy: 67.56%
Average sen: 64.97%
Average spec: 90.82%
Macro f1-score: 55.01%
Diagnosis acc on 90mins: 0.6
[0.96897864 0.04108176 0.39455363 0.99830651 0.99999917]
pred: 0.680583942681551, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp013-nsrr

=== Test on chp014-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.371675, loss_ss: 1.641165, loss_d: 0.730511
0.2457 --- loss: 2.047228, loss_ss: 1.546075, loss_d: 0.501153
0.4914 --- loss: 2.395939, loss_ss: 1.486935, loss_d: 0.909004
0.7371 --- loss: 2.032070, loss_ss: 1.443612, loss_d: 0.588458
0.9828 --- loss: 1.874495, loss_ss: 1.295538, loss_d: 0.578956
Epoch finished! Loss: 2.140843853354454
Starting epoch 2/10.
0.0000 --- loss: 2.038790, loss_ss: 1.386909, loss_d: 0.651881
0.2457 --- loss: 1.935582, loss_ss: 1.350388, loss_d: 0.585193
0.4914 --- loss: 1.738433, loss_ss: 1.359879, loss_d: 0.378554
0.7371 --- loss: 1.897595, loss_ss: 1.359288, loss_d: 0.538308
0.9828 --- loss: 1.573885, loss_ss: 1.267496, loss_d: 0.306389
Epoch finished! Loss: 1.9631155461072922
Starting epoch 3/10.
0.0000 --- loss: 1.834648, loss_ss: 1.238299, loss_d: 0.596349
0.2457 --- loss: 1.675969, loss_ss: 1.243075, loss_d: 0.432894
0.4914 --- loss: 1.799679, loss_ss: 1.249051, loss_d: 0.550628
0.7371 --- loss: 1.845563, loss_ss: 1.119643, loss_d: 0.725920
0.9828 --- loss: 1.556477, loss_ss: 1.083408, loss_d: 0.473069
Epoch finished! Loss: 1.8429444253444671
Starting epoch 4/10.
0.0000 --- loss: 1.601020, loss_ss: 1.273910, loss_d: 0.327110
0.2457 --- loss: 1.913031, loss_ss: 1.108495, loss_d: 0.804537
0.4914 --- loss: 1.819487, loss_ss: 1.195315, loss_d: 0.624171
0.7371 --- loss: 1.757583, loss_ss: 1.122746, loss_d: 0.634837
0.9828 --- loss: 1.511803, loss_ss: 1.214193, loss_d: 0.297610
Epoch finished! Loss: 1.7552128463983536
Starting epoch 5/10.
0.0000 --- loss: 1.558361, loss_ss: 1.115716, loss_d: 0.442645
0.2457 --- loss: 1.585157, loss_ss: 1.175303, loss_d: 0.409855
0.4914 --- loss: 1.813249, loss_ss: 1.137047, loss_d: 0.676202
0.7371 --- loss: 1.857207, loss_ss: 1.132906, loss_d: 0.724301
0.9828 --- loss: 1.719933, loss_ss: 1.309908, loss_d: 0.410025
Epoch finished! Loss: 1.6741862028837204
Starting epoch 6/10.
0.0000 --- loss: 1.514811, loss_ss: 1.063728, loss_d: 0.451083
0.2457 --- loss: 1.384153, loss_ss: 1.102187, loss_d: 0.281967
0.4914 --- loss: 1.607520, loss_ss: 1.320003, loss_d: 0.287517
0.7371 --- loss: 1.471685, loss_ss: 1.017085, loss_d: 0.454600
0.9828 --- loss: 1.328390, loss_ss: 1.099928, loss_d: 0.228462
Epoch finished! Loss: 1.5719045668840408
Starting epoch 7/10.
0.0000 --- loss: 1.389860, loss_ss: 1.019709, loss_d: 0.370150
0.2457 --- loss: 1.291298, loss_ss: 1.079048, loss_d: 0.212250
0.4914 --- loss: 1.601768, loss_ss: 1.216428, loss_d: 0.385340
0.7371 --- loss: 1.409324, loss_ss: 1.093780, loss_d: 0.315544
0.9828 --- loss: 1.467367, loss_ss: 1.290850, loss_d: 0.176517
Epoch finished! Loss: 1.4589657425880431
Starting epoch 8/10.
0.0000 --- loss: 1.259378, loss_ss: 0.991255, loss_d: 0.268123
0.2457 --- loss: 1.517208, loss_ss: 1.110399, loss_d: 0.406809
0.4914 --- loss: 1.290403, loss_ss: 1.066234, loss_d: 0.224169
0.7371 --- loss: 1.299681, loss_ss: 1.024546, loss_d: 0.275134
0.9828 --- loss: 1.449609, loss_ss: 1.192829, loss_d: 0.256779
Epoch finished! Loss: 1.418610629439354
Starting epoch 9/10.
0.0000 --- loss: 1.068304, loss_ss: 0.983017, loss_d: 0.085287
0.2457 --- loss: 1.422200, loss_ss: 1.024857, loss_d: 0.397343
0.4914 --- loss: 1.165751, loss_ss: 0.900401, loss_d: 0.265350
0.7371 --- loss: 1.286699, loss_ss: 1.187679, loss_d: 0.099020
0.9828 --- loss: 1.067690, loss_ss: 0.980749, loss_d: 0.086942
Epoch finished! Loss: 1.2927905678749085
Starting epoch 10/10.
0.0000 --- loss: 1.048237, loss_ss: 0.997532, loss_d: 0.050705
0.2457 --- loss: 1.093709, loss_ss: 0.953622, loss_d: 0.140087
0.4914 --- loss: 1.135508, loss_ss: 1.009599, loss_d: 0.125910
0.7371 --- loss: 1.225335, loss_ss: 1.213085, loss_d: 0.012250
0.9828 --- loss: 0.911770, loss_ss: 0.906946, loss_d: 0.004824
Epoch finished! Loss: 1.1133977711200713
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7266666666666667
              precision    recall  f1-score   support

         0.0       0.65      0.94      0.77       170
         1.0       0.00      0.00      0.00        55
         2.0       0.71      0.97      0.82       363
         3.0       1.00      0.54      0.70       146
         4.0       0.78      0.39      0.52       166

    accuracy                           0.73       900
   macro avg       0.63      0.57      0.56       900
weighted avg       0.72      0.73      0.69       900
 


====== chp014-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  89.33  94.12   88.22   65.04     76.92
1  93.89   0.00  100.00    0.00      0.00
2  82.89  96.69   73.56   71.20     82.01
3  92.56  54.11  100.00  100.00     70.22
4  86.67  38.55   97.55   78.05     51.61
Total accuracy: 72.67%
Average sen: 56.70%
Average spec: 91.86%
Macro f1-score: 56.15%
Diagnosis acc on 90mins: 0.8
[0.99591148 0.97876942 0.16252118 0.9926185  0.98842686]
pred: 0.8236494898796082, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp014-nsrr

=== Test on chp015-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.237342, loss_ss: 1.554768, loss_d: 0.682574
0.2463 --- loss: 2.263415, loss_ss: 1.513902, loss_d: 0.749513
0.4926 --- loss: 2.106446, loss_ss: 1.474958, loss_d: 0.631488
0.7389 --- loss: 1.849603, loss_ss: 1.336072, loss_d: 0.513531
0.9852 --- loss: 1.962412, loss_ss: 1.392229, loss_d: 0.570182
Epoch finished! Loss: 2.1299822121858596
Starting epoch 2/10.
0.0000 --- loss: 1.731355, loss_ss: 1.330536, loss_d: 0.400819
0.2463 --- loss: 1.914778, loss_ss: 1.314223, loss_d: 0.600555
0.4926 --- loss: 1.692889, loss_ss: 1.307850, loss_d: 0.385039
0.7389 --- loss: 2.102191, loss_ss: 1.354385, loss_d: 0.747806
0.9852 --- loss: 1.959438, loss_ss: 1.316024, loss_d: 0.643414
Epoch finished! Loss: 1.9247260123491288
Starting epoch 3/10.
0.0000 --- loss: 1.603833, loss_ss: 1.319126, loss_d: 0.284707
0.2463 --- loss: 1.746120, loss_ss: 1.281215, loss_d: 0.464904
0.4926 --- loss: 1.992060, loss_ss: 1.223945, loss_d: 0.768115
0.7389 --- loss: 1.787377, loss_ss: 1.242481, loss_d: 0.544896
0.9852 --- loss: 1.891046, loss_ss: 1.442445, loss_d: 0.448602
Epoch finished! Loss: 1.874244251847267
Starting epoch 4/10.
0.0000 --- loss: 1.700260, loss_ss: 1.303528, loss_d: 0.396732
0.2463 --- loss: 1.553424, loss_ss: 1.148128, loss_d: 0.405296
0.4926 --- loss: 1.535161, loss_ss: 1.180798, loss_d: 0.354362
0.7389 --- loss: 1.998482, loss_ss: 1.202930, loss_d: 0.795552
0.9852 --- loss: 1.988219, loss_ss: 1.195886, loss_d: 0.792334
Epoch finished! Loss: 1.748498436808586
Starting epoch 5/10.
0.0000 --- loss: 1.719019, loss_ss: 1.185493, loss_d: 0.533526
0.2463 --- loss: 1.540241, loss_ss: 1.164025, loss_d: 0.376216
0.4926 --- loss: 1.639390, loss_ss: 1.093745, loss_d: 0.545646
0.7389 --- loss: 1.757595, loss_ss: 1.182823, loss_d: 0.574771
0.9852 --- loss: 1.423996, loss_ss: 1.228487, loss_d: 0.195510
Epoch finished! Loss: 1.6604833960533143
Starting epoch 6/10.
0.0000 --- loss: 1.531405, loss_ss: 1.054332, loss_d: 0.477073
0.2463 --- loss: 1.467189, loss_ss: 1.210095, loss_d: 0.257095
0.4926 --- loss: 1.686566, loss_ss: 1.123481, loss_d: 0.563085
0.7389 --- loss: 1.416359, loss_ss: 1.182303, loss_d: 0.234056
0.9852 --- loss: 1.526984, loss_ss: 1.166121, loss_d: 0.360863
Epoch finished! Loss: 1.495125588774681
Starting epoch 7/10.
0.0000 --- loss: 1.316812, loss_ss: 1.100348, loss_d: 0.216464
0.2463 --- loss: 1.191434, loss_ss: 1.084506, loss_d: 0.106927
0.4926 --- loss: 1.476166, loss_ss: 1.146391, loss_d: 0.329775
0.7389 --- loss: 1.410279, loss_ss: 1.099152, loss_d: 0.311127
0.9852 --- loss: 1.272783, loss_ss: 0.964910, loss_d: 0.307873
Epoch finished! Loss: 1.4278003454208374
Starting epoch 8/10.
0.0000 --- loss: 1.191324, loss_ss: 1.065699, loss_d: 0.125626
0.2463 --- loss: 1.749466, loss_ss: 1.586386, loss_d: 0.163080
0.4926 --- loss: 1.162279, loss_ss: 1.023888, loss_d: 0.138391
0.7389 --- loss: 1.649487, loss_ss: 1.077475, loss_d: 0.572012
0.9852 --- loss: 1.202390, loss_ss: 1.094330, loss_d: 0.108060
Epoch finished! Loss: 1.2996753245592116
Starting epoch 9/10.
0.0000 --- loss: 1.072227, loss_ss: 1.043002, loss_d: 0.029225
0.2463 --- loss: 1.110604, loss_ss: 1.046936, loss_d: 0.063668
0.4926 --- loss: 1.004696, loss_ss: 0.982103, loss_d: 0.022594
0.7389 --- loss: 1.379539, loss_ss: 0.998331, loss_d: 0.381208
0.9852 --- loss: 1.060038, loss_ss: 0.912789, loss_d: 0.147249
Epoch finished! Loss: 1.1811837688088418
Starting epoch 10/10.
0.0000 --- loss: 1.080699, loss_ss: 1.071586, loss_d: 0.009113
0.2463 --- loss: 1.204466, loss_ss: 1.188069, loss_d: 0.016397
0.4926 --- loss: 1.369519, loss_ss: 1.045170, loss_d: 0.324349
0.7389 --- loss: 1.228344, loss_ss: 1.079707, loss_d: 0.148637
0.9852 --- loss: 1.031207, loss_ss: 1.026796, loss_d: 0.004411
Epoch finished! Loss: 1.158689334988594
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5638888888888889
              precision    recall  f1-score   support

         0.0       0.20      0.72      0.31        67
         1.0       0.00      0.00      0.00       257
         2.0       0.58      0.91      0.71       304
         3.0       0.99      0.80      0.89       259
         4.0       0.52      0.40      0.45       193

    accuracy                           0.56      1080
   macro avg       0.46      0.57      0.47      1080
weighted avg       0.51      0.56      0.51      1080
 


====== chp015-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  80.09  71.64   80.65  19.67     30.87
1  75.83   0.00   99.51   0.00      0.00
2  79.17  90.79   74.61  58.35     71.04
3  95.09  80.31   99.76  99.05     88.70
4  82.59  39.90   91.88  51.68     45.03
Total accuracy: 56.39%
Average sen: 56.53%
Average spec: 89.28%
Macro f1-score: 47.13%
Diagnosis acc on 90mins: 0.8333333333333334
[0.99907076 0.8849414  0.99995017 0.99999988 0.99309289 0.31796676]
pred: 0.8658369779586792, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp015-nsrr

=== Test on chp016-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.553442, loss_ss: 1.857509, loss_d: 0.695934
0.2469 --- loss: 1.860914, loss_ss: 1.609828, loss_d: 0.251087
0.4938 --- loss: 2.159901, loss_ss: 1.389747, loss_d: 0.770154
0.7407 --- loss: 2.364340, loss_ss: 1.392147, loss_d: 0.972194
0.9877 --- loss: 2.293967, loss_ss: 1.297866, loss_d: 0.996101
Epoch finished! Loss: 2.2495772689580917
Starting epoch 2/10.
0.0000 --- loss: 1.815274, loss_ss: 1.418476, loss_d: 0.396798
0.2469 --- loss: 1.957741, loss_ss: 1.470420, loss_d: 0.487321
0.4938 --- loss: 1.855298, loss_ss: 1.394597, loss_d: 0.460701
0.7407 --- loss: 1.947678, loss_ss: 1.424445, loss_d: 0.523233
0.9877 --- loss: 2.547083, loss_ss: 1.351104, loss_d: 1.195978
Epoch finished! Loss: 2.026500791311264
Starting epoch 3/10.
0.0000 --- loss: 1.831617, loss_ss: 1.356629, loss_d: 0.474988
0.2469 --- loss: 1.962404, loss_ss: 1.410442, loss_d: 0.551962
0.4938 --- loss: 2.395577, loss_ss: 1.338988, loss_d: 1.056590
0.7407 --- loss: 2.299038, loss_ss: 1.405686, loss_d: 0.893352
0.9877 --- loss: 2.531975, loss_ss: 1.226666, loss_d: 1.305309
Epoch finished! Loss: 1.9122506350278854
Starting epoch 4/10.
0.0000 --- loss: 1.690012, loss_ss: 1.280727, loss_d: 0.409285
0.2469 --- loss: 1.764619, loss_ss: 1.363643, loss_d: 0.400976
0.4938 --- loss: 1.707429, loss_ss: 1.258785, loss_d: 0.448644
0.7407 --- loss: 1.613469, loss_ss: 1.162613, loss_d: 0.450856
0.9877 --- loss: 2.321342, loss_ss: 1.267178, loss_d: 1.054163
Epoch finished! Loss: 1.802816140651703
Starting epoch 5/10.
0.0000 --- loss: 1.530367, loss_ss: 1.187076, loss_d: 0.343291
0.2469 --- loss: 1.651342, loss_ss: 1.222363, loss_d: 0.428979
0.4938 --- loss: 1.684723, loss_ss: 1.234842, loss_d: 0.449881
0.7407 --- loss: 1.376201, loss_ss: 1.097652, loss_d: 0.278549
0.9877 --- loss: 1.465330, loss_ss: 1.157672, loss_d: 0.307657
Epoch finished! Loss: 1.644342964887619
Starting epoch 6/10.
0.0000 --- loss: 1.415644, loss_ss: 1.083891, loss_d: 0.331753
0.2469 --- loss: 1.504620, loss_ss: 1.151989, loss_d: 0.352631
0.4938 --- loss: 1.335445, loss_ss: 1.175940, loss_d: 0.159505
0.7407 --- loss: 1.755793, loss_ss: 1.127591, loss_d: 0.628201
0.9877 --- loss: 1.725336, loss_ss: 1.071258, loss_d: 0.654078
Epoch finished! Loss: 1.589493289589882
Starting epoch 7/10.
0.0000 --- loss: 1.496104, loss_ss: 1.127141, loss_d: 0.368963
0.2469 --- loss: 1.419913, loss_ss: 1.115227, loss_d: 0.304687
0.4938 --- loss: 1.604691, loss_ss: 1.097825, loss_d: 0.506866
0.7407 --- loss: 1.283669, loss_ss: 0.993782, loss_d: 0.289887
0.9877 --- loss: 1.122208, loss_ss: 1.008197, loss_d: 0.114011
Epoch finished! Loss: 1.3882836014032365
Starting epoch 8/10.
0.0000 --- loss: 1.104929, loss_ss: 1.036774, loss_d: 0.068155
0.2469 --- loss: 1.087203, loss_ss: 1.006006, loss_d: 0.081197
0.4938 --- loss: 1.499604, loss_ss: 0.907025, loss_d: 0.592578
0.7407 --- loss: 1.212977, loss_ss: 1.191340, loss_d: 0.021637
0.9877 --- loss: 1.416227, loss_ss: 1.022023, loss_d: 0.394204
Epoch finished! Loss: 1.2059120565652848
Starting epoch 9/10.
0.0000 --- loss: 1.169716, loss_ss: 0.966833, loss_d: 0.202883
0.2469 --- loss: 0.882392, loss_ss: 0.830923, loss_d: 0.051470
0.4938 --- loss: 1.173138, loss_ss: 0.940194, loss_d: 0.232944
0.7407 --- loss: 1.390452, loss_ss: 1.092084, loss_d: 0.298367
0.9877 --- loss: 1.135411, loss_ss: 0.884715, loss_d: 0.250696
Epoch finished! Loss: 1.2150933980941772
Starting epoch 10/10.
0.0000 --- loss: 1.002356, loss_ss: 0.988830, loss_d: 0.013526
0.2469 --- loss: 1.162637, loss_ss: 0.867946, loss_d: 0.294691
0.4938 --- loss: 0.996456, loss_ss: 0.853425, loss_d: 0.143031
0.7407 --- loss: 1.038464, loss_ss: 0.982895, loss_d: 0.055569
0.9877 --- loss: 1.254623, loss_ss: 1.125432, loss_d: 0.129191
Epoch finished! Loss: 1.1437693148851396
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6261904761904762
              precision    recall  f1-score   support

         0.0       0.93      0.88      0.90       297
         1.0       0.00      0.00      0.00       289
         2.0       0.42      0.80      0.55       330
         3.0       0.62      1.00      0.76       133
         4.0       0.95      0.62      0.75       211

    accuracy                           0.63      1260
   macro avg       0.58      0.66      0.59      1260
weighted avg       0.55      0.63      0.56      1260
 


====== chp016-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  95.56   87.88   97.92  92.88     90.31
1  77.06    0.00  100.00   0.00      0.00
2  66.19   80.30   61.18  42.33     55.44
3  93.41  100.00   92.64  61.57     76.22
4  93.02   61.61   99.33  94.89     74.71
Total accuracy: 62.62%
Average sen: 65.96%
Average spec: 90.21%
Macro f1-score: 59.34%
Diagnosis acc on 90mins: 1.0
[0.60802531 0.60631353 0.99834239 0.97736561 0.99504012 0.75453031
 0.99275559]
pred: 0.8474818382944379, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp016-nsrr

=== Test on chp017-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.446257, loss_ss: 1.743551, loss_d: 0.702706
0.2457 --- loss: 2.142390, loss_ss: 1.658344, loss_d: 0.484047
0.4914 --- loss: 2.314523, loss_ss: 1.638436, loss_d: 0.676086
0.7371 --- loss: 2.085222, loss_ss: 1.437364, loss_d: 0.647858
0.9828 --- loss: 2.059204, loss_ss: 1.483806, loss_d: 0.575398
Epoch finished! Loss: 2.209361359477043
Starting epoch 2/10.
0.0000 --- loss: 1.960966, loss_ss: 1.407822, loss_d: 0.553144
0.2457 --- loss: 2.118396, loss_ss: 1.504214, loss_d: 0.614183
0.4914 --- loss: 2.236143, loss_ss: 1.426980, loss_d: 0.809162
0.7371 --- loss: 1.980424, loss_ss: 1.331144, loss_d: 0.649280
0.9828 --- loss: 1.692696, loss_ss: 1.274340, loss_d: 0.418356
Epoch finished! Loss: 1.991702026128769
Starting epoch 3/10.
0.0000 --- loss: 1.827610, loss_ss: 1.286689, loss_d: 0.540921
0.2457 --- loss: 1.946846, loss_ss: 1.351744, loss_d: 0.595102
0.4914 --- loss: 1.647665, loss_ss: 1.275335, loss_d: 0.372330
0.7371 --- loss: 1.604598, loss_ss: 1.271913, loss_d: 0.332685
0.9828 --- loss: 1.680915, loss_ss: 1.217121, loss_d: 0.463794
Epoch finished! Loss: 1.8565719485282899
Starting epoch 4/10.
0.0000 --- loss: 1.821440, loss_ss: 1.350676, loss_d: 0.470764
0.2457 --- loss: 1.596672, loss_ss: 1.266415, loss_d: 0.330257
0.4914 --- loss: 1.723459, loss_ss: 1.090663, loss_d: 0.632795
0.7371 --- loss: 1.708888, loss_ss: 1.170167, loss_d: 0.538721
0.9828 --- loss: 1.379729, loss_ss: 1.090038, loss_d: 0.289691
Epoch finished! Loss: 1.7285306811332704
Starting epoch 5/10.
0.0000 --- loss: 1.403682, loss_ss: 1.180870, loss_d: 0.222812
0.2457 --- loss: 1.189346, loss_ss: 1.026837, loss_d: 0.162509
0.4914 --- loss: 1.274988, loss_ss: 1.142195, loss_d: 0.132793
0.7371 --- loss: 2.130330, loss_ss: 1.058401, loss_d: 1.071929
0.9828 --- loss: 1.756391, loss_ss: 1.249899, loss_d: 0.506492
Epoch finished! Loss: 1.644751814007759
Starting epoch 6/10.
0.0000 --- loss: 1.415464, loss_ss: 1.121068, loss_d: 0.294396
0.2457 --- loss: 1.560780, loss_ss: 1.196340, loss_d: 0.364439
0.4914 --- loss: 1.773161, loss_ss: 1.289794, loss_d: 0.483367
0.7371 --- loss: 1.372796, loss_ss: 1.152240, loss_d: 0.220556
0.9828 --- loss: 1.326705, loss_ss: 1.066596, loss_d: 0.260109
Epoch finished! Loss: 1.5781755179166794
Starting epoch 7/10.
0.0000 --- loss: 1.475053, loss_ss: 1.207582, loss_d: 0.267471
0.2457 --- loss: 1.318447, loss_ss: 1.095670, loss_d: 0.222776
0.4914 --- loss: 1.142528, loss_ss: 1.011513, loss_d: 0.131015
0.7371 --- loss: 1.081494, loss_ss: 1.009058, loss_d: 0.072436
0.9828 --- loss: 1.507475, loss_ss: 1.092001, loss_d: 0.415474
Epoch finished! Loss: 1.3793001621961594
Starting epoch 8/10.
0.0000 --- loss: 1.029388, loss_ss: 1.001827, loss_d: 0.027561
0.2457 --- loss: 1.424252, loss_ss: 1.067034, loss_d: 0.357217
0.4914 --- loss: 1.094171, loss_ss: 1.016354, loss_d: 0.077817
0.7371 --- loss: 1.377933, loss_ss: 1.253126, loss_d: 0.124807
0.9828 --- loss: 1.340741, loss_ss: 1.130239, loss_d: 0.210502
Epoch finished! Loss: 1.2755318582057953
Starting epoch 9/10.
0.0000 --- loss: 1.196245, loss_ss: 1.123899, loss_d: 0.072346
0.2457 --- loss: 1.250000, loss_ss: 1.015231, loss_d: 0.234769
0.4914 --- loss: 1.323289, loss_ss: 1.200990, loss_d: 0.122299
0.7371 --- loss: 1.155080, loss_ss: 0.972467, loss_d: 0.182613
0.9828 --- loss: 1.961305, loss_ss: 1.129801, loss_d: 0.831505
Epoch finished! Loss: 1.273697516322136
Starting epoch 10/10.
0.0000 --- loss: 1.140835, loss_ss: 1.084398, loss_d: 0.056437
0.2457 --- loss: 1.160501, loss_ss: 1.078824, loss_d: 0.081676
0.4914 --- loss: 1.452136, loss_ss: 1.388716, loss_d: 0.063420
0.7371 --- loss: 1.219100, loss_ss: 1.116436, loss_d: 0.102664
0.9828 --- loss: 1.290149, loss_ss: 1.252041, loss_d: 0.038108
Epoch finished! Loss: 1.1608490288257598
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.24555555555555555
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00       232
         1.0       0.00      0.00      0.00       237
         2.0       0.37      0.67      0.48       181
         3.0       0.54      0.25      0.35       201
         4.0       0.10      1.00      0.19        49

    accuracy                           0.25       900
   macro avg       0.20      0.38      0.20       900
weighted avg       0.20      0.25      0.18       900
 


====== chp017-nsrr ======

The ppr of  0  has ZeroDivisionError.

The f1-score of  0  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  74.22    0.00  100.00   0.00      0.00
1  73.44    0.00   99.70   0.00      0.00
2  70.33   66.85   71.21  36.89     47.54
3  78.56   25.37   93.85  54.26     34.58
4  52.56  100.00   49.82  10.29     18.67
Total accuracy: 24.56%
Average sen: 38.44%
Average spec: 82.92%
Macro f1-score: 20.16%
Diagnosis acc on 90mins: 0.6
[0.45956284 0.96667659 0.96043068 0.04138013 0.88311231]
pred: 0.6622325107455254, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp017-nsrr

=== Test on chp018-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.429695, loss_ss: 1.741989, loss_d: 0.687706
0.2463 --- loss: 2.305884, loss_ss: 1.721873, loss_d: 0.584010
0.4926 --- loss: 2.250861, loss_ss: 1.692746, loss_d: 0.558116
0.7389 --- loss: 2.213053, loss_ss: 1.717477, loss_d: 0.495576
0.9852 --- loss: 1.977557, loss_ss: 1.568214, loss_d: 0.409343
Epoch finished! Loss: 2.4051323741674424
Starting epoch 2/10.
0.0000 --- loss: 2.135014, loss_ss: 1.664967, loss_d: 0.470047
0.2463 --- loss: 2.257776, loss_ss: 1.530530, loss_d: 0.727245
0.4926 --- loss: 2.268403, loss_ss: 1.529804, loss_d: 0.738599
0.7389 --- loss: 1.936350, loss_ss: 1.479588, loss_d: 0.456762
0.9852 --- loss: 1.931993, loss_ss: 1.600470, loss_d: 0.331524
Epoch finished! Loss: 2.2170283406972886
Starting epoch 3/10.
0.0000 --- loss: 2.500944, loss_ss: 1.579611, loss_d: 0.921332
0.2463 --- loss: 2.089966, loss_ss: 1.491030, loss_d: 0.598936
0.4926 --- loss: 2.310307, loss_ss: 1.488817, loss_d: 0.821490
0.7389 --- loss: 1.693772, loss_ss: 1.362156, loss_d: 0.331616
0.9852 --- loss: 1.858347, loss_ss: 1.401539, loss_d: 0.456808
Epoch finished! Loss: 2.027036541700363
Starting epoch 4/10.
0.0000 --- loss: 1.843257, loss_ss: 1.402110, loss_d: 0.441147
0.2463 --- loss: 1.645577, loss_ss: 1.279868, loss_d: 0.365709
0.4926 --- loss: 1.582283, loss_ss: 1.360951, loss_d: 0.221332
0.7389 --- loss: 1.731132, loss_ss: 1.241711, loss_d: 0.489421
0.9852 --- loss: 1.985630, loss_ss: 1.371195, loss_d: 0.614435
Epoch finished! Loss: 1.7776644855737687
Starting epoch 5/10.
0.0000 --- loss: 1.413559, loss_ss: 1.221895, loss_d: 0.191665
0.2463 --- loss: 2.632586, loss_ss: 1.245539, loss_d: 1.387047
0.4926 --- loss: 1.302608, loss_ss: 1.141345, loss_d: 0.161263
0.7389 --- loss: 1.512519, loss_ss: 1.150488, loss_d: 0.362031
0.9852 --- loss: 1.863438, loss_ss: 1.180984, loss_d: 0.682453
Epoch finished! Loss: 1.666766992211342
Starting epoch 6/10.
0.0000 --- loss: 1.743599, loss_ss: 1.325926, loss_d: 0.417673
0.2463 --- loss: 1.585862, loss_ss: 1.259583, loss_d: 0.326278
0.4926 --- loss: 1.312234, loss_ss: 1.264961, loss_d: 0.047273
0.7389 --- loss: 1.461485, loss_ss: 1.051771, loss_d: 0.409714
0.9852 --- loss: 1.459123, loss_ss: 1.108514, loss_d: 0.350609
Epoch finished! Loss: 1.4698460072278976
Starting epoch 7/10.
0.0000 --- loss: 1.234178, loss_ss: 1.126616, loss_d: 0.107562
0.2463 --- loss: 1.261962, loss_ss: 1.213130, loss_d: 0.048833
0.4926 --- loss: 1.425663, loss_ss: 1.163683, loss_d: 0.261980
0.7389 --- loss: 1.293280, loss_ss: 1.134188, loss_d: 0.159092
0.9852 --- loss: 1.039798, loss_ss: 0.898812, loss_d: 0.140987
Epoch finished! Loss: 1.3296070963144302
Starting epoch 8/10.
0.0000 --- loss: 1.143048, loss_ss: 1.053192, loss_d: 0.089857
0.2463 --- loss: 1.171306, loss_ss: 1.123443, loss_d: 0.047863
0.4926 --- loss: 1.194697, loss_ss: 1.177574, loss_d: 0.017123
0.7389 --- loss: 1.477521, loss_ss: 1.190078, loss_d: 0.287444
0.9852 --- loss: 1.065364, loss_ss: 0.969451, loss_d: 0.095913
Epoch finished! Loss: 1.2127702802419662
Starting epoch 9/10.
0.0000 --- loss: 1.126175, loss_ss: 1.029186, loss_d: 0.096988
0.2463 --- loss: 1.270904, loss_ss: 1.045188, loss_d: 0.225716
0.4926 --- loss: 0.934746, loss_ss: 0.918625, loss_d: 0.016122
0.7389 --- loss: 1.052239, loss_ss: 1.025823, loss_d: 0.026416
0.9852 --- loss: 1.722875, loss_ss: 1.377988, loss_d: 0.344887
Epoch finished! Loss: 1.1138479828834533
Starting epoch 10/10.
0.0000 --- loss: 0.886172, loss_ss: 0.883224, loss_d: 0.002949
0.2463 --- loss: 1.017765, loss_ss: 1.015867, loss_d: 0.001898
0.4926 --- loss: 1.032134, loss_ss: 0.992629, loss_d: 0.039505
0.7389 --- loss: 0.977880, loss_ss: 0.975664, loss_d: 0.002216
0.9852 --- loss: 0.997565, loss_ss: 0.978346, loss_d: 0.019220
Epoch finished! Loss: 1.0250290140509606
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6657407407407407
              precision    recall  f1-score   support

         0.0       0.88      0.56      0.68       138
         1.0       0.27      0.03      0.06       117
         2.0       0.28      0.71      0.40       119
         3.0       0.90      0.90      0.90       363
         4.0       0.73      0.66      0.70       343

    accuracy                           0.67      1080
   macro avg       0.61      0.57      0.55      1080
weighted avg       0.71      0.67      0.66      1080
 


====== chp018-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  93.33  55.80   98.83  87.50     68.14
1  88.52   3.42   98.86  26.67      6.06
2  76.39  70.59   77.11  27.63     39.72
3  93.33  90.08   94.98  90.08     90.08
4  81.57  66.18   88.74  73.23     69.53
Total accuracy: 66.57%
Average sen: 57.21%
Average spec: 91.70%
Macro f1-score: 54.71%
Diagnosis acc on 90mins: 0.6666666666666666
[0.99967659 0.98280299 0.98689449 0.04048868 0.37698904 0.60448807]
pred: 0.665223308528463, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp018-nsrr

=== Test on chp019-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.486122, loss_ss: 1.760421, loss_d: 0.725702
0.2457 --- loss: 1.691316, loss_ss: 1.583086, loss_d: 0.108229
0.4914 --- loss: 2.249746, loss_ss: 1.446099, loss_d: 0.803647
0.7371 --- loss: 1.891516, loss_ss: 1.411889, loss_d: 0.479627
0.9828 --- loss: 1.908962, loss_ss: 1.507627, loss_d: 0.401334
Epoch finished! Loss: 2.2034258037805556
Starting epoch 2/10.
0.0000 --- loss: 1.912870, loss_ss: 1.516573, loss_d: 0.396297
0.2457 --- loss: 2.088340, loss_ss: 1.502910, loss_d: 0.585430
0.4914 --- loss: 1.801922, loss_ss: 1.444358, loss_d: 0.357564
0.7371 --- loss: 2.000389, loss_ss: 1.393440, loss_d: 0.606948
0.9828 --- loss: 1.898164, loss_ss: 1.389279, loss_d: 0.508885
Epoch finished! Loss: 1.9213906288146974
Starting epoch 3/10.
0.0000 --- loss: 1.778689, loss_ss: 1.302501, loss_d: 0.476188
0.2457 --- loss: 1.615337, loss_ss: 1.248561, loss_d: 0.366777
0.4914 --- loss: 1.719398, loss_ss: 1.311337, loss_d: 0.408060
0.7371 --- loss: 1.486316, loss_ss: 1.276302, loss_d: 0.210015
0.9828 --- loss: 1.674182, loss_ss: 1.378919, loss_d: 0.295263
Epoch finished! Loss: 1.7280463427305222
Starting epoch 4/10.
0.0000 --- loss: 1.688461, loss_ss: 1.369192, loss_d: 0.319269
0.2457 --- loss: 1.420750, loss_ss: 1.289951, loss_d: 0.130799
0.4914 --- loss: 1.378080, loss_ss: 1.260798, loss_d: 0.117282
0.7371 --- loss: 1.527342, loss_ss: 1.095019, loss_d: 0.432323
0.9828 --- loss: 1.830805, loss_ss: 1.314920, loss_d: 0.515885
Epoch finished! Loss: 1.605319020152092
Starting epoch 5/10.
0.0000 --- loss: 1.436906, loss_ss: 1.296454, loss_d: 0.140452
0.2457 --- loss: 1.310252, loss_ss: 1.231323, loss_d: 0.078930
0.4914 --- loss: 1.374959, loss_ss: 1.257022, loss_d: 0.117937
0.7371 --- loss: 1.308728, loss_ss: 1.159348, loss_d: 0.149380
0.9828 --- loss: 1.600680, loss_ss: 1.066149, loss_d: 0.534531
Epoch finished! Loss: 1.4933502733707429
Starting epoch 6/10.
0.0000 --- loss: 1.186397, loss_ss: 1.141864, loss_d: 0.044533
0.2457 --- loss: 1.551677, loss_ss: 1.226179, loss_d: 0.325497
0.4914 --- loss: 1.253581, loss_ss: 1.231062, loss_d: 0.022519
0.7371 --- loss: 1.250761, loss_ss: 1.197660, loss_d: 0.053101
0.9828 --- loss: 1.991349, loss_ss: 1.178263, loss_d: 0.813086
Epoch finished! Loss: 1.3997736781835557
Starting epoch 7/10.
0.0000 --- loss: 1.083187, loss_ss: 1.030898, loss_d: 0.052289
0.2457 --- loss: 1.114912, loss_ss: 1.096091, loss_d: 0.018821
0.4914 --- loss: 1.267964, loss_ss: 1.250978, loss_d: 0.016987
0.7371 --- loss: 1.218188, loss_ss: 1.099949, loss_d: 0.118239
0.9828 --- loss: 1.143997, loss_ss: 1.048887, loss_d: 0.095110
Epoch finished! Loss: 1.2224425673484802
Starting epoch 8/10.
0.0000 --- loss: 1.017399, loss_ss: 1.007092, loss_d: 0.010307
0.2457 --- loss: 1.107950, loss_ss: 1.104677, loss_d: 0.003273
0.4914 --- loss: 1.000973, loss_ss: 0.997063, loss_d: 0.003911
0.7371 --- loss: 0.926488, loss_ss: 0.923503, loss_d: 0.002984
0.9828 --- loss: 1.062000, loss_ss: 1.056690, loss_d: 0.005310
Epoch finished! Loss: 1.1624387323856353
Starting epoch 9/10.
0.0000 --- loss: 1.186244, loss_ss: 1.183868, loss_d: 0.002376
0.2457 --- loss: 0.986878, loss_ss: 0.942268, loss_d: 0.044609
0.4914 --- loss: 1.031577, loss_ss: 1.025048, loss_d: 0.006529
0.7371 --- loss: 0.950597, loss_ss: 0.937584, loss_d: 0.013012
0.9828 --- loss: 1.688275, loss_ss: 1.110924, loss_d: 0.577352
Epoch finished! Loss: 1.1290319040417671
Starting epoch 10/10.
0.0000 --- loss: 0.965254, loss_ss: 0.963623, loss_d: 0.001631
0.2457 --- loss: 1.074630, loss_ss: 1.060181, loss_d: 0.014449
0.4914 --- loss: 1.227597, loss_ss: 1.223720, loss_d: 0.003878
0.7371 --- loss: 1.055632, loss_ss: 1.046905, loss_d: 0.008727
0.9828 --- loss: 0.997648, loss_ss: 0.994248, loss_d: 0.003400
Epoch finished! Loss: 1.147981409728527
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.51
              precision    recall  f1-score   support

         0.0       0.78      0.19      0.31        36
         1.0       0.00      0.00      0.00       108
         2.0       0.33      0.96      0.49       215
         3.0       0.96      0.84      0.90       223
         4.0       0.93      0.18      0.30       318

    accuracy                           0.51       900
   macro avg       0.60      0.44      0.40       900
weighted avg       0.68      0.51      0.46       900
 


====== chp019-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  96.56  19.44   99.77  77.78     31.11
1  88.00   0.00  100.00   0.00      0.00
2  51.67  96.28   37.66  32.65     48.76
3  95.22  84.30   98.82  95.92     89.74
4  70.56  17.92   99.31  93.44     30.08
Total accuracy: 51.00%
Average sen: 43.59%
Average spec: 87.11%
Macro f1-score: 39.94%
Diagnosis acc on 90mins: 0.8
[0.99840987 0.92406464 0.99935883 0.04969681 0.72252017]
pred: 0.7388100638985634, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp019-nsrr

=== Test on chp020-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.269930, loss_ss: 1.532942, loss_d: 0.736988
0.2463 --- loss: 2.289476, loss_ss: 1.535298, loss_d: 0.754178
0.4926 --- loss: 2.177082, loss_ss: 1.475277, loss_d: 0.701805
0.7389 --- loss: 2.641512, loss_ss: 1.531909, loss_d: 1.109604
0.9852 --- loss: 2.114753, loss_ss: 1.477757, loss_d: 0.636995
Epoch finished! Loss: 2.1672656148672105
Starting epoch 2/10.
0.0000 --- loss: 1.793771, loss_ss: 1.436489, loss_d: 0.357282
0.2463 --- loss: 2.047886, loss_ss: 1.482092, loss_d: 0.565794
0.4926 --- loss: 2.095511, loss_ss: 1.476701, loss_d: 0.618810
0.7389 --- loss: 1.781904, loss_ss: 1.448726, loss_d: 0.333178
0.9852 --- loss: 2.150840, loss_ss: 1.358863, loss_d: 0.791978
Epoch finished! Loss: 1.9996152997016907
Starting epoch 3/10.
0.0000 --- loss: 1.813523, loss_ss: 1.306635, loss_d: 0.506887
0.2463 --- loss: 2.056211, loss_ss: 1.341296, loss_d: 0.714915
0.4926 --- loss: 1.600656, loss_ss: 1.281046, loss_d: 0.319610
0.7389 --- loss: 1.922356, loss_ss: 1.291205, loss_d: 0.631151
0.9852 --- loss: 1.639565, loss_ss: 1.255097, loss_d: 0.384468
Epoch finished! Loss: 1.9137212723493575
Starting epoch 4/10.
0.0000 --- loss: 1.689561, loss_ss: 1.328605, loss_d: 0.360955
0.2463 --- loss: 1.761486, loss_ss: 1.278240, loss_d: 0.483246
0.4926 --- loss: 1.601722, loss_ss: 1.292248, loss_d: 0.309474
0.7389 --- loss: 1.711704, loss_ss: 1.264860, loss_d: 0.446844
0.9852 --- loss: 1.821005, loss_ss: 1.268504, loss_d: 0.552501
Epoch finished! Loss: 1.8035304188728332
Starting epoch 5/10.
0.0000 --- loss: 1.818473, loss_ss: 1.188494, loss_d: 0.629979
0.2463 --- loss: 1.537909, loss_ss: 1.214186, loss_d: 0.323723
0.4926 --- loss: 1.587071, loss_ss: 1.185417, loss_d: 0.401654
0.7389 --- loss: 1.692402, loss_ss: 1.303362, loss_d: 0.389040
0.9852 --- loss: 1.589519, loss_ss: 1.147387, loss_d: 0.442132
Epoch finished! Loss: 1.7680521726608276
Starting epoch 6/10.
0.0000 --- loss: 1.732352, loss_ss: 1.382897, loss_d: 0.349455
0.2463 --- loss: 1.421001, loss_ss: 1.148146, loss_d: 0.272855
0.4926 --- loss: 1.667955, loss_ss: 1.094130, loss_d: 0.573825
0.7389 --- loss: 1.426435, loss_ss: 1.095379, loss_d: 0.331056
0.9852 --- loss: 1.717431, loss_ss: 1.285587, loss_d: 0.431844
Epoch finished! Loss: 1.6117774486541747
Starting epoch 7/10.
0.0000 --- loss: 1.411015, loss_ss: 1.237674, loss_d: 0.173341
0.2463 --- loss: 1.828768, loss_ss: 1.167175, loss_d: 0.661593
0.4926 --- loss: 1.135352, loss_ss: 1.068251, loss_d: 0.067101
0.7389 --- loss: 1.634052, loss_ss: 1.121762, loss_d: 0.512290
0.9852 --- loss: 1.271609, loss_ss: 1.094168, loss_d: 0.177441
Epoch finished! Loss: 1.5102139979600906
Starting epoch 8/10.
0.0000 --- loss: 1.381148, loss_ss: 1.187696, loss_d: 0.193452
0.2463 --- loss: 1.184627, loss_ss: 1.070395, loss_d: 0.114232
0.4926 --- loss: 1.438866, loss_ss: 1.308254, loss_d: 0.130612
0.7389 --- loss: 1.100352, loss_ss: 1.059422, loss_d: 0.040930
0.9852 --- loss: 1.348985, loss_ss: 1.050402, loss_d: 0.298583
Epoch finished! Loss: 1.3217201590538026
Starting epoch 9/10.
0.0000 --- loss: 1.254027, loss_ss: 1.169078, loss_d: 0.084948
0.2463 --- loss: 1.185148, loss_ss: 1.024426, loss_d: 0.160722
0.4926 --- loss: 1.290051, loss_ss: 1.066242, loss_d: 0.223808
0.7389 --- loss: 1.024724, loss_ss: 1.004236, loss_d: 0.020487
0.9852 --- loss: 1.488558, loss_ss: 1.020710, loss_d: 0.467849
Epoch finished! Loss: 1.3191606119275092
Starting epoch 10/10.
0.0000 --- loss: 1.903387, loss_ss: 0.964683, loss_d: 0.938705
0.2463 --- loss: 1.205348, loss_ss: 1.112723, loss_d: 0.092625
0.4926 --- loss: 1.165363, loss_ss: 1.056663, loss_d: 0.108700
0.7389 --- loss: 1.146960, loss_ss: 1.118933, loss_d: 0.028027
0.9852 --- loss: 1.113245, loss_ss: 0.945482, loss_d: 0.167763
Epoch finished! Loss: 1.2894382327795029
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5564814814814815
              precision    recall  f1-score   support

         0.0       0.84      0.46      0.59       237
         1.0       0.00      0.00      0.00       200
         2.0       0.44      0.95      0.61       354
         3.0       0.84      0.97      0.90       159
         4.0       0.12      0.01      0.01       130

    accuracy                           0.56      1080
   macro avg       0.45      0.48      0.42      1080
weighted avg       0.47      0.56      0.46      1080
 


====== chp020-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  86.20  45.57   97.63  84.38     59.18
1  81.48   0.00  100.00   0.00      0.00
2  59.26  95.20   41.74  44.34     60.50
3  96.94  97.48   96.85  84.24     90.38
4  87.41   0.77   99.26  12.50      1.45
Total accuracy: 55.65%
Average sen: 47.80%
Average spec: 87.10%
Macro f1-score: 42.30%
Diagnosis acc on 90mins: 1.0
[0.98995835 0.78475422 0.99976844 0.95713753 0.62264431 0.99577647]
pred: 0.8916732172171274, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp020-nsrr

=== Test on chp022-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.602530, loss_ss: 1.853582, loss_d: 0.748948
0.2469 --- loss: 2.177289, loss_ss: 1.513699, loss_d: 0.663590
0.4938 --- loss: 2.023318, loss_ss: 1.419992, loss_d: 0.603326
0.7407 --- loss: 1.940757, loss_ss: 1.529418, loss_d: 0.411338
0.9877 --- loss: 2.114196, loss_ss: 1.457823, loss_d: 0.656374
Epoch finished! Loss: 2.1975722670555116
Starting epoch 2/10.
0.0000 --- loss: 1.896866, loss_ss: 1.489779, loss_d: 0.407087
0.2469 --- loss: 1.901855, loss_ss: 1.308848, loss_d: 0.593007
0.4938 --- loss: 1.945083, loss_ss: 1.365225, loss_d: 0.579858
0.7407 --- loss: 1.770457, loss_ss: 1.324684, loss_d: 0.445772
0.9877 --- loss: 1.730817, loss_ss: 1.214646, loss_d: 0.516172
Epoch finished! Loss: 1.9793305963277816
Starting epoch 3/10.
0.0000 --- loss: 2.041459, loss_ss: 1.318946, loss_d: 0.722512
0.2469 --- loss: 1.972348, loss_ss: 1.425923, loss_d: 0.546426
0.4938 --- loss: 1.703140, loss_ss: 1.374815, loss_d: 0.328325
0.7407 --- loss: 1.967435, loss_ss: 1.226363, loss_d: 0.741072
0.9877 --- loss: 1.686780, loss_ss: 1.248475, loss_d: 0.438305
Epoch finished! Loss: 1.8540345162153244
Starting epoch 4/10.
0.0000 --- loss: 1.694052, loss_ss: 1.236184, loss_d: 0.457868
0.2469 --- loss: 1.653205, loss_ss: 1.210000, loss_d: 0.443204
0.4938 --- loss: 1.686833, loss_ss: 1.293075, loss_d: 0.393758
0.7407 --- loss: 1.379757, loss_ss: 1.063205, loss_d: 0.316553
0.9877 --- loss: 1.661816, loss_ss: 1.258827, loss_d: 0.402990
Epoch finished! Loss: 1.730236279964447
Starting epoch 5/10.
0.0000 --- loss: 1.510086, loss_ss: 1.187226, loss_d: 0.322860
0.2469 --- loss: 1.367300, loss_ss: 1.110158, loss_d: 0.257142
0.4938 --- loss: 1.631902, loss_ss: 1.374936, loss_d: 0.256966
0.7407 --- loss: 2.040806, loss_ss: 1.110819, loss_d: 0.929987
0.9877 --- loss: 1.712465, loss_ss: 1.299100, loss_d: 0.413365
Epoch finished! Loss: 1.6126123517751694
Starting epoch 6/10.
0.0000 --- loss: 1.666016, loss_ss: 1.178791, loss_d: 0.487225
0.2469 --- loss: 1.771037, loss_ss: 1.337679, loss_d: 0.433358
0.4938 --- loss: 1.434597, loss_ss: 1.125571, loss_d: 0.309026
0.7407 --- loss: 1.383888, loss_ss: 1.033556, loss_d: 0.350332
0.9877 --- loss: 2.655780, loss_ss: 1.022645, loss_d: 1.633135
Epoch finished! Loss: 1.543797367811203
Starting epoch 7/10.
0.0000 --- loss: 1.535087, loss_ss: 1.262676, loss_d: 0.272412
0.2469 --- loss: 1.498042, loss_ss: 1.109818, loss_d: 0.388224
0.4938 --- loss: 1.163502, loss_ss: 1.019512, loss_d: 0.143990
0.7407 --- loss: 1.454890, loss_ss: 1.365336, loss_d: 0.089555
0.9877 --- loss: 2.359931, loss_ss: 1.443111, loss_d: 0.916819
Epoch finished! Loss: 1.4171446800231933
Starting epoch 8/10.
0.0000 --- loss: 1.255875, loss_ss: 0.937129, loss_d: 0.318746
0.2469 --- loss: 1.124927, loss_ss: 1.014789, loss_d: 0.110138
0.4938 --- loss: 1.489870, loss_ss: 1.137295, loss_d: 0.352575
0.7407 --- loss: 1.304924, loss_ss: 1.086295, loss_d: 0.218629
0.9877 --- loss: 1.918738, loss_ss: 1.013369, loss_d: 0.905369
Epoch finished! Loss: 1.3954896330833435
Starting epoch 9/10.
0.0000 --- loss: 1.172452, loss_ss: 1.121718, loss_d: 0.050734
0.2469 --- loss: 1.357557, loss_ss: 1.257500, loss_d: 0.100057
0.4938 --- loss: 1.104591, loss_ss: 1.036143, loss_d: 0.068448
0.7407 --- loss: 1.021645, loss_ss: 0.971152, loss_d: 0.050492
0.9877 --- loss: 1.163220, loss_ss: 1.117271, loss_d: 0.045949
Epoch finished! Loss: 1.248021386563778
Starting epoch 10/10.
0.0000 --- loss: 0.970734, loss_ss: 0.913566, loss_d: 0.057168
0.2469 --- loss: 0.982695, loss_ss: 0.961993, loss_d: 0.020702
0.4938 --- loss: 1.144266, loss_ss: 1.134906, loss_d: 0.009361
0.7407 --- loss: 1.229111, loss_ss: 1.225056, loss_d: 0.004054
0.9877 --- loss: 0.885175, loss_ss: 0.869774, loss_d: 0.015402
Epoch finished! Loss: 1.0785303264856339
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5738095238095238
              precision    recall  f1-score   support

         0.0       0.80      0.67      0.73       253
         1.0       0.00      0.00      0.00       293
         2.0       0.78      0.68      0.73       468
         3.0       0.40      0.95      0.57       107
         4.0       0.34      0.96      0.51       139

    accuracy                           0.57      1260
   macro avg       0.47      0.65      0.51      1260
weighted avg       0.52      0.57      0.52      1260
 


====== chp022-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  90.00  66.80   95.83  80.09     72.84
1  76.75   0.00  100.00   0.00      0.00
2  80.95  67.95   88.64  77.94     72.60
3  87.70  95.33   86.99  40.48     56.82
4  79.37  96.40   77.25  34.45     50.76
Total accuracy: 57.38%
Average sen: 65.30%
Average spec: 89.74%
Macro f1-score: 50.61%
Diagnosis acc on 90mins: 0.8571428571428571
[1.         0.12595458 0.99759573 0.69031328 0.99967849 0.75480783
 0.99851745]
pred: 0.7952667666333062, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp022-nsrr

=== Test on chp024-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.534206, loss_ss: 1.788320, loss_d: 0.745885
0.2463 --- loss: 2.268812, loss_ss: 1.683132, loss_d: 0.585680
0.4926 --- loss: 2.238462, loss_ss: 1.581773, loss_d: 0.656689
0.7389 --- loss: 1.881727, loss_ss: 1.393049, loss_d: 0.488678
0.9852 --- loss: 2.009279, loss_ss: 1.531701, loss_d: 0.477578
Epoch finished! Loss: 2.1896411329507828
Starting epoch 2/10.
0.0000 --- loss: 2.100632, loss_ss: 1.524906, loss_d: 0.575725
0.2463 --- loss: 1.801669, loss_ss: 1.299585, loss_d: 0.502084
0.4926 --- loss: 2.075565, loss_ss: 1.378082, loss_d: 0.697483
0.7389 --- loss: 1.740423, loss_ss: 1.345137, loss_d: 0.395286
0.9852 --- loss: 1.793488, loss_ss: 1.327048, loss_d: 0.466440
Epoch finished! Loss: 1.9786261528730393
Starting epoch 3/10.
0.0000 --- loss: 1.650366, loss_ss: 1.204988, loss_d: 0.445377
0.2463 --- loss: 1.772635, loss_ss: 1.260766, loss_d: 0.511869
0.4926 --- loss: 1.826018, loss_ss: 1.384597, loss_d: 0.441421
0.7389 --- loss: 1.504483, loss_ss: 1.224477, loss_d: 0.280006
0.9852 --- loss: 2.109283, loss_ss: 1.160770, loss_d: 0.948513
Epoch finished! Loss: 1.8847301423549652
Starting epoch 4/10.
0.0000 --- loss: 1.576797, loss_ss: 1.267227, loss_d: 0.309570
0.2463 --- loss: 1.906476, loss_ss: 1.300963, loss_d: 0.605513
0.4926 --- loss: 1.681337, loss_ss: 1.222700, loss_d: 0.458637
0.7389 --- loss: 1.571923, loss_ss: 1.163438, loss_d: 0.408485
0.9852 --- loss: 1.880465, loss_ss: 1.328478, loss_d: 0.551986
Epoch finished! Loss: 1.7700567722320557
Starting epoch 5/10.
0.0000 --- loss: 1.392431, loss_ss: 1.122821, loss_d: 0.269611
0.2463 --- loss: 1.427589, loss_ss: 1.212361, loss_d: 0.215228
0.4926 --- loss: 1.449100, loss_ss: 1.105790, loss_d: 0.343310
0.7389 --- loss: 1.878214, loss_ss: 1.260026, loss_d: 0.618188
0.9852 --- loss: 1.641032, loss_ss: 1.156501, loss_d: 0.484531
Epoch finished! Loss: 1.6573116183280945
Starting epoch 6/10.
0.0000 --- loss: 1.634803, loss_ss: 1.170078, loss_d: 0.464724
0.2463 --- loss: 1.412803, loss_ss: 1.210032, loss_d: 0.202771
0.4926 --- loss: 1.395957, loss_ss: 1.178899, loss_d: 0.217058
0.7389 --- loss: 1.729463, loss_ss: 1.189487, loss_d: 0.539975
0.9852 --- loss: 1.689102, loss_ss: 1.052676, loss_d: 0.636425
Epoch finished! Loss: 1.5762122869491577
Starting epoch 7/10.
0.0000 --- loss: 1.278841, loss_ss: 1.104279, loss_d: 0.174562
0.2463 --- loss: 1.261536, loss_ss: 1.075086, loss_d: 0.186451
0.4926 --- loss: 1.176716, loss_ss: 1.130244, loss_d: 0.046473
0.7389 --- loss: 1.526950, loss_ss: 1.102382, loss_d: 0.424568
0.9852 --- loss: 1.148391, loss_ss: 1.103927, loss_d: 0.044464
Epoch finished! Loss: 1.3311805158853531
Starting epoch 8/10.
0.0000 --- loss: 1.081461, loss_ss: 1.012578, loss_d: 0.068883
0.2463 --- loss: 1.180763, loss_ss: 1.073533, loss_d: 0.107230
0.4926 --- loss: 1.051936, loss_ss: 1.028015, loss_d: 0.023921
0.7389 --- loss: 1.170805, loss_ss: 1.086520, loss_d: 0.084285
0.9852 --- loss: 1.009813, loss_ss: 0.994447, loss_d: 0.015366
Epoch finished! Loss: 1.2790961533784866
Starting epoch 9/10.
0.0000 --- loss: 1.012069, loss_ss: 0.995534, loss_d: 0.016534
0.2463 --- loss: 1.049070, loss_ss: 1.009268, loss_d: 0.039802
0.4926 --- loss: 1.189641, loss_ss: 1.086819, loss_d: 0.102821
0.7389 --- loss: 1.194842, loss_ss: 1.063055, loss_d: 0.131787
0.9852 --- loss: 1.660698, loss_ss: 0.996578, loss_d: 0.664120
Epoch finished! Loss: 1.347775122523308
Starting epoch 10/10.
0.0000 --- loss: 1.149318, loss_ss: 1.080666, loss_d: 0.068652
0.2463 --- loss: 1.261402, loss_ss: 1.003507, loss_d: 0.257895
0.4926 --- loss: 1.073315, loss_ss: 1.026078, loss_d: 0.047237
0.7389 --- loss: 1.070053, loss_ss: 1.039718, loss_d: 0.030334
0.9852 --- loss: 1.332299, loss_ss: 1.294638, loss_d: 0.037661
Epoch finished! Loss: 1.2129286229610443
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6166666666666667
              precision    recall  f1-score   support

         0.0       0.55      0.85      0.67       232
         1.0       0.00      0.00      0.00       179
         2.0       0.46      0.88      0.60       216
         3.0       0.94      0.79      0.86       339
         4.0       0.46      0.10      0.16       114

    accuracy                           0.62      1080
   macro avg       0.48      0.52      0.46      1080
weighted avg       0.55      0.62      0.55      1080
 


====== chp024-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  82.04  85.34   81.13  55.31     67.12
1  83.43   0.00  100.00   0.00      0.00
2  76.67  87.50   73.96  45.65     60.00
3  91.94  79.06   97.84  94.37     86.04
4  89.26   9.65   98.65  45.83     15.94
Total accuracy: 61.67%
Average sen: 52.31%
Average spec: 90.32%
Macro f1-score: 45.82%
Diagnosis acc on 90mins: 0.6666666666666666
[0.45931652 0.92447108 0.39013168 0.99102813 0.84265733 0.86770165]
pred: 0.7458843986193339, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp024-nsrr

=== Test on chp025-nsrr. train_data(410), test_data(2) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.372055, loss_ss: 1.677914, loss_d: 0.694142
0.2439 --- loss: 1.959401, loss_ss: 1.554349, loss_d: 0.405053
0.4878 --- loss: 2.479648, loss_ss: 1.555187, loss_d: 0.924461
0.7317 --- loss: 2.278506, loss_ss: 1.560282, loss_d: 0.718224
0.9756 --- loss: 2.093402, loss_ss: 1.573260, loss_d: 0.520142
Epoch finished! Loss: 2.304379531741142
Starting epoch 2/10.
0.0000 --- loss: 2.044983, loss_ss: 1.560080, loss_d: 0.484904
0.2439 --- loss: 2.082614, loss_ss: 1.529395, loss_d: 0.553218
0.4878 --- loss: 2.001025, loss_ss: 1.490283, loss_d: 0.510741
0.7317 --- loss: 1.838101, loss_ss: 1.476891, loss_d: 0.361210
0.9756 --- loss: 2.433394, loss_ss: 1.457958, loss_d: 0.975436
Epoch finished! Loss: 2.15607393682003
Starting epoch 3/10.
0.0000 --- loss: 1.996688, loss_ss: 1.481649, loss_d: 0.515039
0.2439 --- loss: 1.875050, loss_ss: 1.478865, loss_d: 0.396186
0.4878 --- loss: 1.818746, loss_ss: 1.364599, loss_d: 0.454147
0.7317 --- loss: 2.588063, loss_ss: 1.391299, loss_d: 1.196763
0.9756 --- loss: 1.909636, loss_ss: 1.465516, loss_d: 0.444120
Epoch finished! Loss: 2.0333320409059525
Starting epoch 4/10.
0.0000 --- loss: 1.884659, loss_ss: 1.349825, loss_d: 0.534834
0.2439 --- loss: 1.765358, loss_ss: 1.363808, loss_d: 0.401550
0.4878 --- loss: 1.736339, loss_ss: 1.366469, loss_d: 0.369869
0.7317 --- loss: 1.889723, loss_ss: 1.383941, loss_d: 0.505782
0.9756 --- loss: 1.626023, loss_ss: 1.285870, loss_d: 0.340153
Epoch finished! Loss: 1.8661545783281326
Starting epoch 5/10.
0.0000 --- loss: 1.628085, loss_ss: 1.298945, loss_d: 0.329141
0.2439 --- loss: 1.594556, loss_ss: 1.288191, loss_d: 0.306365
0.4878 --- loss: 1.643743, loss_ss: 1.252543, loss_d: 0.391200
0.7317 --- loss: 1.601817, loss_ss: 1.219468, loss_d: 0.382349
0.9756 --- loss: 1.870375, loss_ss: 1.228761, loss_d: 0.641614
Epoch finished! Loss: 1.7449785500764847
Starting epoch 6/10.
0.0000 --- loss: 1.782467, loss_ss: 1.136368, loss_d: 0.646100
0.2439 --- loss: 1.447986, loss_ss: 1.174560, loss_d: 0.273426
0.4878 --- loss: 1.914188, loss_ss: 1.160417, loss_d: 0.753771
0.7317 --- loss: 1.859592, loss_ss: 1.063747, loss_d: 0.795845
0.9756 --- loss: 1.479129, loss_ss: 1.112172, loss_d: 0.366957
Epoch finished! Loss: 1.6170218527317046
Starting epoch 7/10.
0.0000 --- loss: 1.647553, loss_ss: 1.134179, loss_d: 0.513375
0.2439 --- loss: 1.408182, loss_ss: 1.121107, loss_d: 0.287075
0.4878 --- loss: 1.324883, loss_ss: 1.111475, loss_d: 0.213408
0.7317 --- loss: 1.589511, loss_ss: 1.156508, loss_d: 0.433003
0.9756 --- loss: 1.341204, loss_ss: 1.100060, loss_d: 0.241144
Epoch finished! Loss: 1.5295809537172318
Starting epoch 8/10.
0.0000 --- loss: 1.324864, loss_ss: 1.039001, loss_d: 0.285863
0.2439 --- loss: 1.149694, loss_ss: 0.953579, loss_d: 0.196115
0.4878 --- loss: 1.179725, loss_ss: 1.049588, loss_d: 0.130138
0.7317 --- loss: 1.486785, loss_ss: 1.004283, loss_d: 0.482502
0.9756 --- loss: 1.165481, loss_ss: 0.981929, loss_d: 0.183552
Epoch finished! Loss: 1.3631415963172913
Starting epoch 9/10.
0.0000 --- loss: 1.313689, loss_ss: 1.104473, loss_d: 0.209216
0.2439 --- loss: 1.243915, loss_ss: 1.017122, loss_d: 0.226793
0.4878 --- loss: 1.087281, loss_ss: 1.021061, loss_d: 0.066220
0.7317 --- loss: 1.181450, loss_ss: 0.974273, loss_d: 0.207177
0.9756 --- loss: 1.360472, loss_ss: 0.928858, loss_d: 0.431614
Epoch finished! Loss: 1.1992748737335206
Starting epoch 10/10.
0.0000 --- loss: 1.076652, loss_ss: 0.965595, loss_d: 0.111057
0.2439 --- loss: 1.092770, loss_ss: 1.035105, loss_d: 0.057665
0.4878 --- loss: 0.887723, loss_ss: 0.856582, loss_d: 0.031141
0.7317 --- loss: 1.478433, loss_ss: 1.013785, loss_d: 0.464648
0.9756 --- loss: 0.944174, loss_ss: 0.854849, loss_d: 0.089325
Epoch finished! Loss: 1.2184637263417244
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5083333333333333
              precision    recall  f1-score   support

         0.0       0.86      0.41      0.56       249
         1.0       0.00      0.00      0.00        20
         2.0       0.61      0.66      0.63        29
         3.0       0.93      1.00      0.96        62
         4.0       0.00      0.00      0.00         0

    accuracy                           0.51       360
   macro avg       0.48      0.41      0.43       360
weighted avg       0.81      0.51      0.60       360
 


====== chp025-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  54.72   40.96   85.59  86.44     55.59
1  94.44    0.00  100.00   0.00      0.00
2  93.89   65.52   96.37  61.29     63.33
3  98.61  100.00   98.32  92.54     96.12
4  60.00     NaN   60.00   0.00       NaN
Total accuracy: 50.83%
Average sen: 51.62%
Average spec: 88.06%
Macro f1-score: 53.76%
Diagnosis acc on 90mins: 1.0
[0.99953914 0.99787617]
pred: 0.99870765209198, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp025-nsrr

=== Test on chp026-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.505665, loss_ss: 1.749425, loss_d: 0.756240
0.2457 --- loss: 2.187681, loss_ss: 1.754237, loss_d: 0.433444
0.4914 --- loss: 2.286391, loss_ss: 1.599348, loss_d: 0.687043
0.7371 --- loss: 2.462085, loss_ss: 1.619925, loss_d: 0.842160
0.9828 --- loss: 2.485975, loss_ss: 1.629651, loss_d: 0.856324
Epoch finished! Loss: 2.3243104964494705
Starting epoch 2/10.
0.0000 --- loss: 1.856237, loss_ss: 1.504062, loss_d: 0.352174
0.2457 --- loss: 2.056478, loss_ss: 1.468817, loss_d: 0.587661
0.4914 --- loss: 2.140125, loss_ss: 1.552568, loss_d: 0.587557
0.7371 --- loss: 1.978259, loss_ss: 1.567450, loss_d: 0.410809
0.9828 --- loss: 2.440986, loss_ss: 1.450104, loss_d: 0.990882
Epoch finished! Loss: 2.1441104233264925
Starting epoch 3/10.
0.0000 --- loss: 1.936908, loss_ss: 1.478674, loss_d: 0.458235
0.2457 --- loss: 2.023985, loss_ss: 1.498797, loss_d: 0.525187
0.4914 --- loss: 2.113698, loss_ss: 1.572622, loss_d: 0.541076
0.7371 --- loss: 2.007851, loss_ss: 1.428720, loss_d: 0.579131
0.9828 --- loss: 1.932602, loss_ss: 1.450967, loss_d: 0.481635
Epoch finished! Loss: 2.05252483189106
Starting epoch 4/10.
0.0000 --- loss: 1.878698, loss_ss: 1.394085, loss_d: 0.484612
0.2457 --- loss: 1.959542, loss_ss: 1.352286, loss_d: 0.607256
0.4914 --- loss: 1.785119, loss_ss: 1.306075, loss_d: 0.479044
0.7371 --- loss: 1.902556, loss_ss: 1.479525, loss_d: 0.423031
0.9828 --- loss: 2.208763, loss_ss: 1.417963, loss_d: 0.790799
Epoch finished! Loss: 1.9498179793357848
Starting epoch 5/10.
0.0000 --- loss: 1.742069, loss_ss: 1.369478, loss_d: 0.372590
0.2457 --- loss: 1.703077, loss_ss: 1.372000, loss_d: 0.331077
0.4914 --- loss: 1.491955, loss_ss: 1.331930, loss_d: 0.160025
0.7371 --- loss: 1.837603, loss_ss: 1.292384, loss_d: 0.545219
0.9828 --- loss: 1.649604, loss_ss: 1.311043, loss_d: 0.338561
Epoch finished! Loss: 1.7672323524951934
Starting epoch 6/10.
0.0000 --- loss: 1.554738, loss_ss: 1.293257, loss_d: 0.261480
0.2457 --- loss: 1.738963, loss_ss: 1.341317, loss_d: 0.397646
0.4914 --- loss: 1.736024, loss_ss: 1.259267, loss_d: 0.476757
0.7371 --- loss: 1.652577, loss_ss: 1.273244, loss_d: 0.379334
0.9828 --- loss: 1.367279, loss_ss: 1.157977, loss_d: 0.209302
Epoch finished! Loss: 1.6372907876968383
Starting epoch 7/10.
0.0000 --- loss: 1.530530, loss_ss: 1.317611, loss_d: 0.212919
0.2457 --- loss: 1.419539, loss_ss: 1.136375, loss_d: 0.283164
0.4914 --- loss: 1.172514, loss_ss: 1.129589, loss_d: 0.042926
0.7371 --- loss: 1.178095, loss_ss: 1.084344, loss_d: 0.093752
0.9828 --- loss: 1.813382, loss_ss: 1.218693, loss_d: 0.594688
Epoch finished! Loss: 1.3892625510692596
Starting epoch 8/10.
0.0000 --- loss: 1.199429, loss_ss: 1.145097, loss_d: 0.054332
0.2457 --- loss: 1.535805, loss_ss: 1.174318, loss_d: 0.361487
0.4914 --- loss: 1.437263, loss_ss: 1.111772, loss_d: 0.325491
0.7371 --- loss: 1.424792, loss_ss: 1.108933, loss_d: 0.315859
0.9828 --- loss: 1.192089, loss_ss: 0.890730, loss_d: 0.301359
Epoch finished! Loss: 1.3735364139080048
Starting epoch 9/10.
0.0000 --- loss: 1.357317, loss_ss: 0.990471, loss_d: 0.366845
0.2457 --- loss: 1.372263, loss_ss: 1.069517, loss_d: 0.302746
0.4914 --- loss: 1.647631, loss_ss: 1.166455, loss_d: 0.481177
0.7371 --- loss: 1.345880, loss_ss: 1.091283, loss_d: 0.254597
0.9828 --- loss: 1.393418, loss_ss: 1.016432, loss_d: 0.376986
Epoch finished! Loss: 1.2796786919236183
Starting epoch 10/10.
0.0000 --- loss: 0.985201, loss_ss: 0.920219, loss_d: 0.064982
0.2457 --- loss: 1.175868, loss_ss: 1.074625, loss_d: 0.101243
0.4914 --- loss: 1.004678, loss_ss: 0.990482, loss_d: 0.014196
0.7371 --- loss: 1.261393, loss_ss: 1.076991, loss_d: 0.184402
0.9828 --- loss: 1.145843, loss_ss: 1.063178, loss_d: 0.082665
Epoch finished! Loss: 1.1351385965943337
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7555555555555555
              precision    recall  f1-score   support

         0.0       0.78      0.74      0.76        58
         1.0       0.00      0.00      0.00        55
         2.0       0.73      0.79      0.76       386
         3.0       0.70      0.99      0.82       182
         4.0       0.88      0.70      0.78       219

    accuracy                           0.76       900
   macro avg       0.62      0.64      0.62       900
weighted avg       0.72      0.76      0.73       900
 


====== chp026-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  97.00  74.14   98.57  78.18     76.11
1  93.89   0.00  100.00   0.00      0.00
2  78.67  78.76   78.60  73.43     76.00
3  91.11  98.90   89.14  69.77     81.82
4  90.44  69.86   97.06  88.44     78.06
Total accuracy: 75.56%
Average sen: 64.33%
Average spec: 92.67%
Macro f1-score: 62.40%
Diagnosis acc on 90mins: 0.8
[0.7074858  1.         0.69963241 0.99635482 0.05748614]
pred: 0.6921918325126171, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp026-nsrr

=== Test on chp028-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.310073, loss_ss: 1.630013, loss_d: 0.680060
0.2457 --- loss: 1.928871, loss_ss: 1.424463, loss_d: 0.504408
0.4914 --- loss: 2.009078, loss_ss: 1.469847, loss_d: 0.539231
0.7371 --- loss: 1.749669, loss_ss: 1.359734, loss_d: 0.389935
0.9828 --- loss: 1.947393, loss_ss: 1.251530, loss_d: 0.695863
Epoch finished! Loss: 2.1305241137742996
Starting epoch 2/10.
0.0000 --- loss: 1.776708, loss_ss: 1.356399, loss_d: 0.420309
0.2457 --- loss: 2.628243, loss_ss: 1.411695, loss_d: 1.216548
0.4914 --- loss: 1.859114, loss_ss: 1.274171, loss_d: 0.584942
0.7371 --- loss: 1.738490, loss_ss: 1.137672, loss_d: 0.600819
0.9828 --- loss: 1.714065, loss_ss: 1.229337, loss_d: 0.484728
Epoch finished! Loss: 1.8948596686124801
Starting epoch 3/10.
0.0000 --- loss: 1.495120, loss_ss: 1.163706, loss_d: 0.331414
0.2457 --- loss: 2.102094, loss_ss: 1.211677, loss_d: 0.890417
0.4914 --- loss: 2.005701, loss_ss: 1.152751, loss_d: 0.852950
0.7371 --- loss: 1.698892, loss_ss: 1.154618, loss_d: 0.544274
0.9828 --- loss: 1.517264, loss_ss: 1.065092, loss_d: 0.452172
Epoch finished! Loss: 1.7685685992240905
Starting epoch 4/10.
0.0000 --- loss: 1.442099, loss_ss: 1.078415, loss_d: 0.363683
0.2457 --- loss: 1.476238, loss_ss: 1.154214, loss_d: 0.322024
0.4914 --- loss: 1.708302, loss_ss: 1.192231, loss_d: 0.516070
0.7371 --- loss: 1.410018, loss_ss: 1.106297, loss_d: 0.303721
0.9828 --- loss: 1.756412, loss_ss: 1.230294, loss_d: 0.526117
Epoch finished! Loss: 1.675645849108696
Starting epoch 5/10.
0.0000 --- loss: 1.524034, loss_ss: 1.073985, loss_d: 0.450050
0.2457 --- loss: 1.674546, loss_ss: 1.096119, loss_d: 0.578427
0.4914 --- loss: 1.360866, loss_ss: 0.989957, loss_d: 0.370909
0.7371 --- loss: 1.497634, loss_ss: 1.097737, loss_d: 0.399897
0.9828 --- loss: 1.322108, loss_ss: 0.995807, loss_d: 0.326300
Epoch finished! Loss: 1.627584883570671
Starting epoch 6/10.
0.0000 --- loss: 1.449283, loss_ss: 1.151238, loss_d: 0.298045
0.2457 --- loss: 1.353947, loss_ss: 0.971566, loss_d: 0.382381
0.4914 --- loss: 1.666519, loss_ss: 0.966199, loss_d: 0.700320
0.7371 --- loss: 1.375764, loss_ss: 0.992280, loss_d: 0.383484
0.9828 --- loss: 1.356528, loss_ss: 1.023110, loss_d: 0.333417
Epoch finished! Loss: 1.5717946887016296
Starting epoch 7/10.
0.0000 --- loss: 1.537718, loss_ss: 1.111104, loss_d: 0.426614
0.2457 --- loss: 1.243289, loss_ss: 1.124144, loss_d: 0.119146
0.4914 --- loss: 1.696344, loss_ss: 1.018285, loss_d: 0.678059
0.7371 --- loss: 1.489955, loss_ss: 1.050073, loss_d: 0.439882
0.9828 --- loss: 1.339646, loss_ss: 0.964279, loss_d: 0.375367
Epoch finished! Loss: 1.5104162126779557
Starting epoch 8/10.
0.0000 --- loss: 1.327924, loss_ss: 1.011425, loss_d: 0.316499
0.2457 --- loss: 1.265109, loss_ss: 0.886512, loss_d: 0.378598
0.4914 --- loss: 1.828039, loss_ss: 1.232426, loss_d: 0.595613
0.7371 --- loss: 1.301185, loss_ss: 0.954945, loss_d: 0.346240
0.9828 --- loss: 1.142395, loss_ss: 0.868826, loss_d: 0.273570
Epoch finished! Loss: 1.382647341489792
Starting epoch 9/10.
0.0000 --- loss: 1.115634, loss_ss: 0.855695, loss_d: 0.259939
0.2457 --- loss: 1.221762, loss_ss: 1.113576, loss_d: 0.108187
0.4914 --- loss: 1.230327, loss_ss: 1.067571, loss_d: 0.162756
0.7371 --- loss: 1.109996, loss_ss: 0.974355, loss_d: 0.135642
0.9828 --- loss: 1.592321, loss_ss: 1.397853, loss_d: 0.194468
Epoch finished! Loss: 1.282677710056305
Starting epoch 10/10.
0.0000 --- loss: 1.434213, loss_ss: 0.975197, loss_d: 0.459016
0.2457 --- loss: 0.952370, loss_ss: 0.904757, loss_d: 0.047613
0.4914 --- loss: 1.243529, loss_ss: 0.991138, loss_d: 0.252391
0.7371 --- loss: 1.322453, loss_ss: 1.134929, loss_d: 0.187524
0.9828 --- loss: 0.983068, loss_ss: 0.920467, loss_d: 0.062600
Epoch finished! Loss: 1.2394682839512825
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7708565072302559
              precision    recall  f1-score   support

         0.0       0.92      0.74      0.82        89
         1.0       0.00      0.00      0.00        53
         2.0       0.78      0.80      0.79       382
         3.0       0.61      0.77      0.68       191
         4.0       0.90      0.95      0.92       184

    accuracy                           0.77       899
   macro avg       0.64      0.65      0.64       899
weighted avg       0.74      0.77      0.75       899
 


====== chp028-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  96.77  74.16   99.26  91.67     81.99
1  94.10   0.00  100.00   0.00      0.00
2  81.76  79.58   83.37  77.95     78.76
3  84.76  77.49   86.72  61.16     68.36
4  96.77  95.11   97.20  89.74     92.35
Total accuracy: 77.09%
Average sen: 65.27%
Average spec: 93.31%
Macro f1-score: 64.29%
Diagnosis acc on 90mins: 1.0
[0.74108684 0.968404   0.99953663 0.98994946 0.9728846 ]
pred: 0.9343723058700562, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp028-nsrr

=== Test on chp029-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.475818, loss_ss: 1.807686, loss_d: 0.668131
0.2457 --- loss: 2.166430, loss_ss: 1.561986, loss_d: 0.604444
0.4914 --- loss: 1.878174, loss_ss: 1.618364, loss_d: 0.259810
0.7371 --- loss: 2.201238, loss_ss: 1.582641, loss_d: 0.618597
0.9828 --- loss: 2.141574, loss_ss: 1.634241, loss_d: 0.507334
Epoch finished! Loss: 2.2837227433919907
Starting epoch 2/10.
0.0000 --- loss: 2.178148, loss_ss: 1.395949, loss_d: 0.782199
0.2457 --- loss: 2.273479, loss_ss: 1.380928, loss_d: 0.892550
0.4914 --- loss: 1.967997, loss_ss: 1.554130, loss_d: 0.413866
0.7371 --- loss: 2.076129, loss_ss: 1.395001, loss_d: 0.681128
0.9828 --- loss: 2.024392, loss_ss: 1.616904, loss_d: 0.407488
Epoch finished! Loss: 2.0747936964035034
Starting epoch 3/10.
0.0000 --- loss: 2.052424, loss_ss: 1.375317, loss_d: 0.677108
0.2457 --- loss: 1.978125, loss_ss: 1.427407, loss_d: 0.550718
0.4914 --- loss: 1.940181, loss_ss: 1.330725, loss_d: 0.609456
0.7371 --- loss: 1.813270, loss_ss: 1.451220, loss_d: 0.362050
0.9828 --- loss: 1.927849, loss_ss: 1.548526, loss_d: 0.379323
Epoch finished! Loss: 1.9752515703439713
Starting epoch 4/10.
0.0000 --- loss: 1.761714, loss_ss: 1.425045, loss_d: 0.336669
0.2457 --- loss: 2.234481, loss_ss: 1.451557, loss_d: 0.782924
0.4914 --- loss: 1.828643, loss_ss: 1.361957, loss_d: 0.466686
0.7371 --- loss: 2.243091, loss_ss: 1.487009, loss_d: 0.756083
0.9828 --- loss: 1.776664, loss_ss: 1.516012, loss_d: 0.260652
Epoch finished! Loss: 1.9421187549829484
Starting epoch 5/10.
0.0000 --- loss: 1.709228, loss_ss: 1.355872, loss_d: 0.353356
0.2457 --- loss: 1.758458, loss_ss: 1.222808, loss_d: 0.535650
0.4914 --- loss: 1.690958, loss_ss: 1.197505, loss_d: 0.493453
0.7371 --- loss: 1.784773, loss_ss: 1.165319, loss_d: 0.619454
0.9828 --- loss: 1.445616, loss_ss: 1.192164, loss_d: 0.253453
Epoch finished! Loss: 1.7924653708934783
Starting epoch 6/10.
0.0000 --- loss: 1.846818, loss_ss: 1.266881, loss_d: 0.579937
0.2457 --- loss: 1.708547, loss_ss: 1.241896, loss_d: 0.466651
0.4914 --- loss: 1.708618, loss_ss: 1.229828, loss_d: 0.478791
0.7371 --- loss: 1.595395, loss_ss: 1.307683, loss_d: 0.287712
0.9828 --- loss: 1.559300, loss_ss: 1.178045, loss_d: 0.381254
Epoch finished! Loss: 1.689452338218689
Starting epoch 7/10.
0.0000 --- loss: 1.791887, loss_ss: 1.243732, loss_d: 0.548155
0.2457 --- loss: 1.588257, loss_ss: 1.264366, loss_d: 0.323891
0.4914 --- loss: 1.355292, loss_ss: 1.157923, loss_d: 0.197369
0.7371 --- loss: 1.480661, loss_ss: 1.106927, loss_d: 0.373734
0.9828 --- loss: 1.547050, loss_ss: 1.177375, loss_d: 0.369674
Epoch finished! Loss: 1.671908974647522
Starting epoch 8/10.
0.0000 --- loss: 1.471464, loss_ss: 1.171286, loss_d: 0.300177
0.2457 --- loss: 1.730688, loss_ss: 1.114096, loss_d: 0.616592
0.4914 --- loss: 1.424812, loss_ss: 1.201962, loss_d: 0.222850
0.7371 --- loss: 1.333476, loss_ss: 1.131927, loss_d: 0.201549
0.9828 --- loss: 1.452020, loss_ss: 1.175003, loss_d: 0.277018
Epoch finished! Loss: 1.5817719787359237
Starting epoch 9/10.
0.0000 --- loss: 1.457607, loss_ss: 1.153599, loss_d: 0.304008
0.2457 --- loss: 1.274267, loss_ss: 1.176407, loss_d: 0.097860
0.4914 --- loss: 1.746381, loss_ss: 1.325920, loss_d: 0.420461
0.7371 --- loss: 2.027687, loss_ss: 1.058663, loss_d: 0.969024
0.9828 --- loss: 1.263527, loss_ss: 1.210697, loss_d: 0.052830
Epoch finished! Loss: 1.5144268035888673
Starting epoch 10/10.
0.0000 --- loss: 1.796048, loss_ss: 1.011730, loss_d: 0.784318
0.2457 --- loss: 1.337602, loss_ss: 1.235876, loss_d: 0.101726
0.4914 --- loss: 1.321170, loss_ss: 1.108092, loss_d: 0.213078
0.7371 --- loss: 1.353237, loss_ss: 1.080274, loss_d: 0.272963
0.9828 --- loss: 1.303554, loss_ss: 1.214019, loss_d: 0.089535
Epoch finished! Loss: 1.408140555024147
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6622222222222223
              precision    recall  f1-score   support

         0.0       0.32      0.73      0.44        66
         1.0       0.00      0.00      0.00        44
         2.0       0.63      0.92      0.75       374
         3.0       1.00      0.65      0.79       311
         4.0       0.50      0.01      0.02       105

    accuracy                           0.66       900
   macro avg       0.49      0.46      0.40       900
weighted avg       0.69      0.66      0.62       900
 


====== chp029-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  86.67  72.73   87.77   32.00     44.44
1  95.11   0.00  100.00    0.00      0.00
2  74.33  91.98   61.79   63.12     74.86
3  88.00  65.27  100.00  100.00     78.99
4  88.33   0.95   99.87   50.00      1.87
Total accuracy: 66.22%
Average sen: 46.19%
Average spec: 89.89%
Macro f1-score: 40.03%
Diagnosis acc on 90mins: 0.4
[0.93352258 0.46434736 0.03171445 0.99892753 0.15406635]
pred: 0.5165156565606595, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp029-nsrr

=== Test on chp030-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.420147, loss_ss: 1.669698, loss_d: 0.750449
0.2463 --- loss: 2.180504, loss_ss: 1.557413, loss_d: 0.623091
0.4926 --- loss: 2.085191, loss_ss: 1.498036, loss_d: 0.587155
0.7389 --- loss: 2.068843, loss_ss: 1.386012, loss_d: 0.682832
0.9852 --- loss: 1.758701, loss_ss: 1.356904, loss_d: 0.401797
Epoch finished! Loss: 2.1288197547197343
Starting epoch 2/10.
0.0000 --- loss: 2.029892, loss_ss: 1.341560, loss_d: 0.688332
0.2463 --- loss: 1.624918, loss_ss: 1.346378, loss_d: 0.278540
0.4926 --- loss: 1.764369, loss_ss: 1.313745, loss_d: 0.450624
0.7389 --- loss: 1.997689, loss_ss: 1.384401, loss_d: 0.613289
0.9852 --- loss: 1.829748, loss_ss: 1.190384, loss_d: 0.639364
Epoch finished! Loss: 1.9092684149742127
Starting epoch 3/10.
0.0000 --- loss: 2.009275, loss_ss: 1.300762, loss_d: 0.708512
0.2463 --- loss: 1.831158, loss_ss: 1.184606, loss_d: 0.646552
0.4926 --- loss: 1.799331, loss_ss: 1.224855, loss_d: 0.574476
0.7389 --- loss: 1.947768, loss_ss: 1.147033, loss_d: 0.800735
0.9852 --- loss: 1.922819, loss_ss: 1.431390, loss_d: 0.491429
Epoch finished! Loss: 1.7930307894945146
Starting epoch 4/10.
0.0000 --- loss: 1.472347, loss_ss: 1.230502, loss_d: 0.241845
0.2463 --- loss: 1.611726, loss_ss: 1.304620, loss_d: 0.307106
0.4926 --- loss: 1.713320, loss_ss: 1.201421, loss_d: 0.511898
0.7389 --- loss: 1.368641, loss_ss: 1.160642, loss_d: 0.207999
0.9852 --- loss: 1.558322, loss_ss: 1.385385, loss_d: 0.172937
Epoch finished! Loss: 1.692799198627472
Starting epoch 5/10.
0.0000 --- loss: 1.510535, loss_ss: 1.154276, loss_d: 0.356259
0.2463 --- loss: 1.588273, loss_ss: 1.212147, loss_d: 0.376127
0.4926 --- loss: 1.932300, loss_ss: 0.993071, loss_d: 0.939229
0.7389 --- loss: 2.013071, loss_ss: 1.306865, loss_d: 0.706206
0.9852 --- loss: 1.794573, loss_ss: 1.329188, loss_d: 0.465385
Epoch finished! Loss: 1.610624113678932
Starting epoch 6/10.
0.0000 --- loss: 1.482703, loss_ss: 1.171545, loss_d: 0.311158
0.2463 --- loss: 1.263152, loss_ss: 1.069510, loss_d: 0.193642
0.4926 --- loss: 1.598183, loss_ss: 1.136668, loss_d: 0.461515
0.7389 --- loss: 1.273723, loss_ss: 1.107291, loss_d: 0.166432
0.9852 --- loss: 1.221440, loss_ss: 1.167465, loss_d: 0.053975
Epoch finished! Loss: 1.4800975233316422
Starting epoch 7/10.
0.0000 --- loss: 1.492800, loss_ss: 1.057801, loss_d: 0.435000
0.2463 --- loss: 1.336130, loss_ss: 1.112243, loss_d: 0.223887
0.4926 --- loss: 1.580736, loss_ss: 1.070245, loss_d: 0.510491
0.7389 --- loss: 1.468210, loss_ss: 1.024986, loss_d: 0.443224
0.9852 --- loss: 2.571493, loss_ss: 1.052228, loss_d: 1.519265
Epoch finished! Loss: 1.3812256425619125
Starting epoch 8/10.
0.0000 --- loss: 1.258023, loss_ss: 1.104864, loss_d: 0.153159
0.2463 --- loss: 1.113084, loss_ss: 1.038207, loss_d: 0.074877
0.4926 --- loss: 1.337724, loss_ss: 1.104454, loss_d: 0.233270
0.7389 --- loss: 1.201793, loss_ss: 1.033201, loss_d: 0.168593
0.9852 --- loss: 1.343296, loss_ss: 0.941890, loss_d: 0.401405
Epoch finished! Loss: 1.3360085755586624
Starting epoch 9/10.
0.0000 --- loss: 1.194585, loss_ss: 1.178036, loss_d: 0.016548
0.2463 --- loss: 0.972315, loss_ss: 0.939607, loss_d: 0.032708
0.4926 --- loss: 1.076122, loss_ss: 0.966469, loss_d: 0.109652
0.7389 --- loss: 0.994282, loss_ss: 0.905850, loss_d: 0.088432
0.9852 --- loss: 1.055624, loss_ss: 1.053604, loss_d: 0.002020
Epoch finished! Loss: 1.1056043714284898
Starting epoch 10/10.
0.0000 --- loss: 1.110659, loss_ss: 1.087600, loss_d: 0.023059
0.2463 --- loss: 1.064734, loss_ss: 1.060862, loss_d: 0.003873
0.4926 --- loss: 0.860237, loss_ss: 0.852858, loss_d: 0.007379
0.7389 --- loss: 1.002470, loss_ss: 0.941102, loss_d: 0.061368
0.9852 --- loss: 0.990522, loss_ss: 0.981386, loss_d: 0.009136
Epoch finished! Loss: 1.0509894445538521
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.3493975903614458
              precision    recall  f1-score   support

         0.0       0.85      0.30      0.44       335
         1.0       0.00      0.00      0.00       200
         2.0       0.33      0.65      0.44       270
         3.0       0.00      0.00      0.00       154
         4.0       0.28      0.83      0.41       120

    accuracy                           0.35      1079
   macro avg       0.29      0.36      0.26      1079
weighted avg       0.38      0.35      0.29      1079
 


====== chp030-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  76.65  30.15   97.58  84.87     44.49
1  81.46   0.00  100.00   0.00      0.00
2  58.76  65.19   56.61  33.40     44.17
3  79.15   0.00   92.32   0.00      0.00
4  73.86  83.33   72.68  27.62     41.49
Total accuracy: 34.94%
Average sen: 35.73%
Average spec: 83.84%
Macro f1-score: 26.03%
Diagnosis acc on 90mins: 1.0
[0.96229702 0.75195092 0.89010191 0.59054691 0.99025601 0.90950644]
pred: 0.8491098682085673, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp030-nsrr

=== Test on chp031-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.335092, loss_ss: 1.685702, loss_d: 0.649390
0.2463 --- loss: 1.991699, loss_ss: 1.539424, loss_d: 0.452275
0.4926 --- loss: 2.203791, loss_ss: 1.547966, loss_d: 0.655825
0.7389 --- loss: 2.184130, loss_ss: 1.541180, loss_d: 0.642949
0.9852 --- loss: 2.174829, loss_ss: 1.629646, loss_d: 0.545184
Epoch finished! Loss: 2.249272158741951
Starting epoch 2/10.
0.0000 --- loss: 2.071187, loss_ss: 1.554042, loss_d: 0.517145
0.2463 --- loss: 2.274122, loss_ss: 1.520577, loss_d: 0.753546
0.4926 --- loss: 1.954116, loss_ss: 1.524387, loss_d: 0.429729
0.7389 --- loss: 2.005325, loss_ss: 1.506692, loss_d: 0.498633
0.9852 --- loss: 2.078483, loss_ss: 1.382106, loss_d: 0.696377
Epoch finished! Loss: 2.09493944644928
Starting epoch 3/10.
0.0000 --- loss: 1.717137, loss_ss: 1.383144, loss_d: 0.333994
0.2463 --- loss: 1.982644, loss_ss: 1.415284, loss_d: 0.567360
0.4926 --- loss: 2.038477, loss_ss: 1.294128, loss_d: 0.744349
0.7389 --- loss: 1.853117, loss_ss: 1.322368, loss_d: 0.530750
0.9852 --- loss: 2.569514, loss_ss: 1.263983, loss_d: 1.305532
Epoch finished! Loss: 1.9810158133506774
Starting epoch 4/10.
0.0000 --- loss: 2.195301, loss_ss: 1.296293, loss_d: 0.899008
0.2463 --- loss: 1.591788, loss_ss: 1.252203, loss_d: 0.339585
0.4926 --- loss: 1.761600, loss_ss: 1.201766, loss_d: 0.559833
0.7389 --- loss: 2.098599, loss_ss: 1.247961, loss_d: 0.850638
0.9852 --- loss: 1.637072, loss_ss: 1.264868, loss_d: 0.372204
Epoch finished! Loss: 1.825387531518936
Starting epoch 5/10.
0.0000 --- loss: 1.721760, loss_ss: 1.235435, loss_d: 0.486325
0.2463 --- loss: 1.509312, loss_ss: 1.206448, loss_d: 0.302864
0.4926 --- loss: 1.842660, loss_ss: 1.169428, loss_d: 0.673233
0.7389 --- loss: 1.875005, loss_ss: 1.174620, loss_d: 0.700385
0.9852 --- loss: 1.536701, loss_ss: 1.241542, loss_d: 0.295159
Epoch finished! Loss: 1.7865150988101959
Starting epoch 6/10.
0.0000 --- loss: 1.465739, loss_ss: 1.116430, loss_d: 0.349310
0.2463 --- loss: 1.597163, loss_ss: 1.172765, loss_d: 0.424398
0.4926 --- loss: 1.532173, loss_ss: 1.105012, loss_d: 0.427161
0.7389 --- loss: 1.560662, loss_ss: 1.260127, loss_d: 0.300535
0.9852 --- loss: 1.616395, loss_ss: 1.214616, loss_d: 0.401779
Epoch finished! Loss: 1.643598347902298
Starting epoch 7/10.
0.0000 --- loss: 1.358736, loss_ss: 1.018224, loss_d: 0.340511
0.2463 --- loss: 1.602627, loss_ss: 1.069156, loss_d: 0.533471
0.4926 --- loss: 1.684973, loss_ss: 1.277440, loss_d: 0.407532
0.7389 --- loss: 1.233329, loss_ss: 1.103631, loss_d: 0.129698
0.9852 --- loss: 1.460187, loss_ss: 1.149219, loss_d: 0.310968
Epoch finished! Loss: 1.54405617415905
Starting epoch 8/10.
0.0000 --- loss: 1.866342, loss_ss: 1.251131, loss_d: 0.615211
0.2463 --- loss: 1.287921, loss_ss: 1.089692, loss_d: 0.198228
0.4926 --- loss: 1.307841, loss_ss: 1.149671, loss_d: 0.158171
0.7389 --- loss: 1.206812, loss_ss: 1.022790, loss_d: 0.184022
0.9852 --- loss: 1.698293, loss_ss: 0.929185, loss_d: 0.769108
Epoch finished! Loss: 1.4565674602985381
Starting epoch 9/10.
0.0000 --- loss: 1.347190, loss_ss: 1.163295, loss_d: 0.183895
0.2463 --- loss: 1.487607, loss_ss: 1.057861, loss_d: 0.429746
0.4926 --- loss: 1.286807, loss_ss: 1.115100, loss_d: 0.171706
0.7389 --- loss: 1.127252, loss_ss: 0.981128, loss_d: 0.146124
0.9852 --- loss: 1.592675, loss_ss: 0.926194, loss_d: 0.666480
Epoch finished! Loss: 1.303707903623581
Starting epoch 10/10.
0.0000 --- loss: 1.094264, loss_ss: 0.897198, loss_d: 0.197065
0.2463 --- loss: 1.561773, loss_ss: 0.989436, loss_d: 0.572336
0.4926 --- loss: 1.344876, loss_ss: 1.073878, loss_d: 0.270997
0.7389 --- loss: 1.723830, loss_ss: 1.175632, loss_d: 0.548198
0.9852 --- loss: 1.295081, loss_ss: 1.187347, loss_d: 0.107733
Epoch finished! Loss: 1.2448316246271134
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6351851851851852
              precision    recall  f1-score   support

         0.0       0.13      0.43      0.20        51
         1.0       0.00      0.00      0.00        48
         2.0       0.60      0.82      0.69       309
         3.0       0.78      0.90      0.84       229
         4.0       0.88      0.46      0.61       443

    accuracy                           0.64      1080
   macro avg       0.48      0.52      0.47      1080
weighted avg       0.71      0.64      0.63      1080
 


====== chp031-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  84.17  43.14   86.20  13.41     20.47
1  95.56   0.00  100.00   0.00      0.00
2  79.35  81.55   78.47  60.29     69.33
3  92.59  90.39   93.18  78.11     83.81
4  75.37  46.28   95.60  87.98     60.65
Total accuracy: 63.52%
Average sen: 52.27%
Average spec: 90.69%
Macro f1-score: 46.85%
Diagnosis acc on 90mins: 0.8333333333333334
[0.28383958 0.88439649 0.99451125 0.97006029 0.9517315  0.98530513]
pred: 0.8449740409851074, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp031-nsrr

=== Test on chp032-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.494232, loss_ss: 1.786873, loss_d: 0.707359
0.2457 --- loss: 2.288229, loss_ss: 1.586101, loss_d: 0.702128
0.4914 --- loss: 2.204403, loss_ss: 1.619579, loss_d: 0.584825
0.7371 --- loss: 1.910275, loss_ss: 1.419652, loss_d: 0.490623
0.9828 --- loss: 2.138776, loss_ss: 1.502639, loss_d: 0.636137
Epoch finished! Loss: 2.220612493157387
Starting epoch 2/10.
0.0000 --- loss: 2.053104, loss_ss: 1.491657, loss_d: 0.561447
0.2457 --- loss: 1.897756, loss_ss: 1.432146, loss_d: 0.465610
0.4914 --- loss: 2.539682, loss_ss: 1.438416, loss_d: 1.101265
0.7371 --- loss: 2.004135, loss_ss: 1.361522, loss_d: 0.642612
0.9828 --- loss: 2.051432, loss_ss: 1.398693, loss_d: 0.652739
Epoch finished! Loss: 2.0739713996648788
Starting epoch 3/10.
0.0000 --- loss: 1.929490, loss_ss: 1.272138, loss_d: 0.657352
0.2457 --- loss: 1.706325, loss_ss: 1.291763, loss_d: 0.414562
0.4914 --- loss: 1.679019, loss_ss: 1.250403, loss_d: 0.428617
0.7371 --- loss: 1.770945, loss_ss: 1.172888, loss_d: 0.598057
0.9828 --- loss: 2.174771, loss_ss: 1.191250, loss_d: 0.983521
Epoch finished! Loss: 1.8558185607194901
Starting epoch 4/10.
0.0000 --- loss: 1.448725, loss_ss: 1.180008, loss_d: 0.268717
0.2457 --- loss: 1.878681, loss_ss: 1.139379, loss_d: 0.739302
0.4914 --- loss: 1.519838, loss_ss: 1.071258, loss_d: 0.448581
0.7371 --- loss: 1.789775, loss_ss: 1.166252, loss_d: 0.623523
0.9828 --- loss: 1.642142, loss_ss: 1.278753, loss_d: 0.363389
Epoch finished! Loss: 1.7748900443315505
Starting epoch 5/10.
0.0000 --- loss: 1.464749, loss_ss: 1.127662, loss_d: 0.337086
0.2457 --- loss: 1.933263, loss_ss: 1.161455, loss_d: 0.771808
0.4914 --- loss: 1.486215, loss_ss: 1.162670, loss_d: 0.323545
0.7371 --- loss: 1.514789, loss_ss: 1.142525, loss_d: 0.372264
0.9828 --- loss: 1.631741, loss_ss: 1.040084, loss_d: 0.591657
Epoch finished! Loss: 1.6651663154363632
Starting epoch 6/10.
0.0000 --- loss: 1.568291, loss_ss: 0.994618, loss_d: 0.573673
0.2457 --- loss: 1.587205, loss_ss: 1.021300, loss_d: 0.565905
0.4914 --- loss: 1.391834, loss_ss: 1.061685, loss_d: 0.330149
0.7371 --- loss: 1.778301, loss_ss: 1.074211, loss_d: 0.704090
0.9828 --- loss: 1.467890, loss_ss: 1.120419, loss_d: 0.347471
Epoch finished! Loss: 1.5930625826120377
Starting epoch 7/10.
0.0000 --- loss: 1.303369, loss_ss: 1.018686, loss_d: 0.284683
0.2457 --- loss: 1.302422, loss_ss: 1.027074, loss_d: 0.275348
0.4914 --- loss: 1.446172, loss_ss: 1.041028, loss_d: 0.405144
0.7371 --- loss: 1.272180, loss_ss: 1.046764, loss_d: 0.225415
0.9828 --- loss: 1.337209, loss_ss: 1.027828, loss_d: 0.309381
Epoch finished! Loss: 1.4907839894294739
Starting epoch 8/10.
0.0000 --- loss: 1.337652, loss_ss: 1.105216, loss_d: 0.232436
0.2457 --- loss: 1.194903, loss_ss: 1.002293, loss_d: 0.192609
0.4914 --- loss: 1.187923, loss_ss: 0.927282, loss_d: 0.260641
0.7371 --- loss: 1.101083, loss_ss: 0.909208, loss_d: 0.191875
0.9828 --- loss: 1.483214, loss_ss: 1.155096, loss_d: 0.328118
Epoch finished! Loss: 1.3636220186948775
Starting epoch 9/10.
0.0000 --- loss: 1.227124, loss_ss: 0.854251, loss_d: 0.372874
0.2457 --- loss: 1.223132, loss_ss: 1.048746, loss_d: 0.174386
0.4914 --- loss: 1.148010, loss_ss: 0.868029, loss_d: 0.279981
0.7371 --- loss: 1.226057, loss_ss: 0.934939, loss_d: 0.291118
0.9828 --- loss: 1.452899, loss_ss: 1.282234, loss_d: 0.170664
Epoch finished! Loss: 1.265941572189331
Starting epoch 10/10.
0.0000 --- loss: 1.101678, loss_ss: 1.013484, loss_d: 0.088195
0.2457 --- loss: 1.066505, loss_ss: 0.987576, loss_d: 0.078929
0.4914 --- loss: 1.390743, loss_ss: 1.137716, loss_d: 0.253027
0.7371 --- loss: 0.833575, loss_ss: 0.792107, loss_d: 0.041467
0.9828 --- loss: 0.915220, loss_ss: 0.840075, loss_d: 0.075145
Epoch finished! Loss: 1.2030785977840424
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6311111111111111
              precision    recall  f1-score   support

         0.0       0.17      0.64      0.27        14
         1.0       0.00      0.00      0.00        92
         2.0       0.86      0.61      0.71       486
         3.0       1.00      0.76      0.86       150
         4.0       0.39      0.94      0.55       158

    accuracy                           0.63       900
   macro avg       0.48      0.59      0.48       900
weighted avg       0.70      0.63      0.63       900
 


====== chp032-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  94.56  64.29   95.03   16.98     26.87
1  89.33   0.00   99.50    0.00      0.00
2  73.44  61.11   87.92   85.59     71.31
3  96.00  76.00  100.00  100.00     86.36
4  72.89  93.67   68.46   38.74     54.81
Total accuracy: 63.11%
Average sen: 59.01%
Average spec: 90.19%
Macro f1-score: 47.87%
Diagnosis acc on 90mins: 1.0
[0.92465371 1.         0.97188222 0.99982953 0.87424451]
pred: 0.954121994972229, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp032-nsrr

=== Test on chp033-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.430730, loss_ss: 1.758847, loss_d: 0.671883
0.2457 --- loss: 2.140506, loss_ss: 1.651736, loss_d: 0.488770
0.4914 --- loss: 2.163357, loss_ss: 1.527039, loss_d: 0.636318
0.7371 --- loss: 2.009740, loss_ss: 1.427579, loss_d: 0.582161
0.9828 --- loss: 1.921989, loss_ss: 1.531776, loss_d: 0.390213
Epoch finished! Loss: 2.284751018881798
Starting epoch 2/10.
0.0000 --- loss: 1.710706, loss_ss: 1.419591, loss_d: 0.291115
0.2457 --- loss: 1.870616, loss_ss: 1.567047, loss_d: 0.303569
0.4914 --- loss: 2.500587, loss_ss: 1.617711, loss_d: 0.882876
0.7371 --- loss: 1.825448, loss_ss: 1.286096, loss_d: 0.539352
0.9828 --- loss: 1.877132, loss_ss: 1.436014, loss_d: 0.441118
Epoch finished! Loss: 2.0675271093845367
Starting epoch 3/10.
0.0000 --- loss: 2.139938, loss_ss: 1.415009, loss_d: 0.724930
0.2457 --- loss: 1.872841, loss_ss: 1.443289, loss_d: 0.429551
0.4914 --- loss: 1.983829, loss_ss: 1.424009, loss_d: 0.559820
0.7371 --- loss: 1.967656, loss_ss: 1.271180, loss_d: 0.696476
0.9828 --- loss: 1.678467, loss_ss: 1.333467, loss_d: 0.345000
Epoch finished! Loss: 1.9306226521730423
Starting epoch 4/10.
0.0000 --- loss: 1.924098, loss_ss: 1.388856, loss_d: 0.535242
0.2457 --- loss: 2.179085, loss_ss: 1.288523, loss_d: 0.890562
0.4914 --- loss: 1.726204, loss_ss: 1.342748, loss_d: 0.383456
0.7371 --- loss: 1.820394, loss_ss: 1.261506, loss_d: 0.558888
0.9828 --- loss: 1.903573, loss_ss: 1.365982, loss_d: 0.537591
Epoch finished! Loss: 1.8420894414186477
Starting epoch 5/10.
0.0000 --- loss: 1.664593, loss_ss: 1.266030, loss_d: 0.398563
0.2457 --- loss: 1.611995, loss_ss: 1.156054, loss_d: 0.455942
0.4914 --- loss: 1.649582, loss_ss: 1.179276, loss_d: 0.470306
0.7371 --- loss: 2.089139, loss_ss: 1.321748, loss_d: 0.767391
0.9828 --- loss: 1.995941, loss_ss: 1.168684, loss_d: 0.827258
Epoch finished! Loss: 1.6614736944437027
Starting epoch 6/10.
0.0000 --- loss: 1.508323, loss_ss: 1.245027, loss_d: 0.263296
0.2457 --- loss: 1.386214, loss_ss: 1.244533, loss_d: 0.141680
0.4914 --- loss: 1.580091, loss_ss: 1.162515, loss_d: 0.417576
0.7371 --- loss: 1.516225, loss_ss: 1.115886, loss_d: 0.400340
0.9828 --- loss: 1.584111, loss_ss: 1.205937, loss_d: 0.378174
Epoch finished! Loss: 1.6171694993972778
Starting epoch 7/10.
0.0000 --- loss: 1.218725, loss_ss: 1.040821, loss_d: 0.177904
0.2457 --- loss: 1.426193, loss_ss: 1.171888, loss_d: 0.254305
0.4914 --- loss: 1.226886, loss_ss: 0.959398, loss_d: 0.267487
0.7371 --- loss: 1.305668, loss_ss: 1.047893, loss_d: 0.257775
0.9828 --- loss: 1.846037, loss_ss: 1.080151, loss_d: 0.765885
Epoch finished! Loss: 1.4042864948511125
Starting epoch 8/10.
0.0000 --- loss: 1.187611, loss_ss: 1.101321, loss_d: 0.086289
0.2457 --- loss: 1.338727, loss_ss: 1.049266, loss_d: 0.289461
0.4914 --- loss: 1.011050, loss_ss: 0.917213, loss_d: 0.093837
0.7371 --- loss: 1.347575, loss_ss: 1.029938, loss_d: 0.317638
0.9828 --- loss: 1.130483, loss_ss: 1.067487, loss_d: 0.062997
Epoch finished! Loss: 1.2033284187316895
Starting epoch 9/10.
0.0000 --- loss: 1.070290, loss_ss: 0.997541, loss_d: 0.072748
0.2457 --- loss: 1.066853, loss_ss: 1.032526, loss_d: 0.034327
0.4914 --- loss: 1.098710, loss_ss: 1.080784, loss_d: 0.017926
0.7371 --- loss: 1.052772, loss_ss: 1.030409, loss_d: 0.022364
0.9828 --- loss: 0.969901, loss_ss: 0.798862, loss_d: 0.171039
Epoch finished! Loss: 1.127787134051323
Starting epoch 10/10.
0.0000 --- loss: 0.999052, loss_ss: 0.930380, loss_d: 0.068671
0.2457 --- loss: 1.116281, loss_ss: 0.922299, loss_d: 0.193981
0.4914 --- loss: 1.061045, loss_ss: 0.949571, loss_d: 0.111474
0.7371 --- loss: 1.524572, loss_ss: 1.031074, loss_d: 0.493498
0.9828 --- loss: 1.370600, loss_ss: 1.159300, loss_d: 0.211300
Epoch finished! Loss: 1.153155605494976
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5855555555555556
              precision    recall  f1-score   support

         0.0       0.17      0.97      0.29        32
         1.0       0.00      0.00      0.00       248
         2.0       0.58      0.89      0.70       208
         3.0       0.95      0.97      0.96       254
         4.0       0.45      0.41      0.43       158

    accuracy                           0.59       900
   macro avg       0.43      0.65      0.48       900
weighted avg       0.49      0.59      0.52       900
 


====== chp033-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  83.44  96.88   82.95  17.32     29.38
1  72.44   0.00  100.00   0.00      0.00
2  82.44  88.94   80.49  57.81     70.08
3  97.78  97.24   97.99  95.00     96.11
4  81.00  40.51   89.62  45.39     42.81
Total accuracy: 58.56%
Average sen: 64.71%
Average spec: 90.21%
Macro f1-score: 47.68%
Diagnosis acc on 90mins: 0.8
[9.99937534e-01 9.97919142e-01 6.67215288e-01 9.97358620e-01
 1.74799497e-04]
pred: 0.7325210767856334, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp033-nsrr

=== Test on chp034-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.458822, loss_ss: 1.719915, loss_d: 0.738907
0.2457 --- loss: 2.134412, loss_ss: 1.459111, loss_d: 0.675301
0.4914 --- loss: 1.789556, loss_ss: 1.382599, loss_d: 0.406957
0.7371 --- loss: 2.145625, loss_ss: 1.320048, loss_d: 0.825576
0.9828 --- loss: 1.871934, loss_ss: 1.292081, loss_d: 0.579853
Epoch finished! Loss: 2.0741449266672136
Starting epoch 2/10.
0.0000 --- loss: 1.711045, loss_ss: 1.322769, loss_d: 0.388276
0.2457 --- loss: 1.836881, loss_ss: 1.373997, loss_d: 0.462884
0.4914 --- loss: 1.746532, loss_ss: 1.308821, loss_d: 0.437711
0.7371 --- loss: 1.685016, loss_ss: 1.354168, loss_d: 0.330848
0.9828 --- loss: 1.729724, loss_ss: 1.216087, loss_d: 0.513637
Epoch finished! Loss: 1.8968973726034164
Starting epoch 3/10.
0.0000 --- loss: 1.572217, loss_ss: 1.204743, loss_d: 0.367474
0.2457 --- loss: 1.660266, loss_ss: 1.305514, loss_d: 0.354752
0.4914 --- loss: 1.759250, loss_ss: 1.321422, loss_d: 0.437828
0.7371 --- loss: 1.529373, loss_ss: 1.164489, loss_d: 0.364884
0.9828 --- loss: 2.005388, loss_ss: 1.198884, loss_d: 0.806503
Epoch finished! Loss: 1.7736201286315918
Starting epoch 4/10.
0.0000 --- loss: 1.408050, loss_ss: 1.130306, loss_d: 0.277744
0.2457 --- loss: 1.648771, loss_ss: 1.251881, loss_d: 0.396890
0.4914 --- loss: 1.613589, loss_ss: 1.140952, loss_d: 0.472637
0.7371 --- loss: 1.790977, loss_ss: 1.164091, loss_d: 0.626886
0.9828 --- loss: 1.656197, loss_ss: 1.116459, loss_d: 0.539738
Epoch finished! Loss: 1.679489681124687
Starting epoch 5/10.
0.0000 --- loss: 1.447734, loss_ss: 1.113485, loss_d: 0.334248
0.2457 --- loss: 1.485838, loss_ss: 1.288934, loss_d: 0.196904
0.4914 --- loss: 1.363130, loss_ss: 1.184364, loss_d: 0.178767
0.7371 --- loss: 1.460412, loss_ss: 1.137338, loss_d: 0.323074
0.9828 --- loss: 1.165602, loss_ss: 1.048625, loss_d: 0.116977
Epoch finished! Loss: 1.5619197815656662
Starting epoch 6/10.
0.0000 --- loss: 1.312906, loss_ss: 1.032508, loss_d: 0.280398
0.2457 --- loss: 1.261010, loss_ss: 1.070422, loss_d: 0.190588
0.4914 --- loss: 1.381269, loss_ss: 0.950558, loss_d: 0.430710
0.7371 --- loss: 1.202921, loss_ss: 1.014907, loss_d: 0.188014
0.9828 --- loss: 1.534975, loss_ss: 1.071396, loss_d: 0.463579
Epoch finished! Loss: 1.4426663279533387
Starting epoch 7/10.
0.0000 --- loss: 1.081853, loss_ss: 0.959919, loss_d: 0.121933
0.2457 --- loss: 1.646653, loss_ss: 0.997268, loss_d: 0.649386
0.4914 --- loss: 1.213122, loss_ss: 1.013640, loss_d: 0.199481
0.7371 --- loss: 1.321655, loss_ss: 1.013811, loss_d: 0.307844
0.9828 --- loss: 1.692968, loss_ss: 1.026416, loss_d: 0.666552
Epoch finished! Loss: 1.3985819429159165
Starting epoch 8/10.
0.0000 --- loss: 1.240187, loss_ss: 1.030559, loss_d: 0.209628
0.2457 --- loss: 1.881682, loss_ss: 1.107525, loss_d: 0.774157
0.4914 --- loss: 0.986058, loss_ss: 0.912863, loss_d: 0.073195
0.7371 --- loss: 1.067574, loss_ss: 1.012971, loss_d: 0.054604
0.9828 --- loss: 1.161719, loss_ss: 1.081527, loss_d: 0.080192
Epoch finished! Loss: 1.3241968676447868
Starting epoch 9/10.
0.0000 --- loss: 1.121286, loss_ss: 1.008720, loss_d: 0.112566
0.2457 --- loss: 1.028417, loss_ss: 0.945085, loss_d: 0.083332
0.4914 --- loss: 1.097745, loss_ss: 0.984842, loss_d: 0.112903
0.7371 --- loss: 1.087929, loss_ss: 0.879404, loss_d: 0.208525
0.9828 --- loss: 1.040806, loss_ss: 1.025085, loss_d: 0.015721
Epoch finished! Loss: 1.1363552063703537
Starting epoch 10/10.
0.0000 --- loss: 0.961550, loss_ss: 0.923614, loss_d: 0.037936
0.2457 --- loss: 0.888010, loss_ss: 0.872574, loss_d: 0.015436
0.4914 --- loss: 1.127951, loss_ss: 0.885873, loss_d: 0.242078
0.7371 --- loss: 1.002608, loss_ss: 0.909598, loss_d: 0.093010
0.9828 --- loss: 0.928606, loss_ss: 0.889733, loss_d: 0.038873
Epoch finished! Loss: 1.0705900996923448
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7444444444444445
              precision    recall  f1-score   support

         0.0       0.13      0.41      0.20        17
         1.0       0.00      0.00      0.00        62
         2.0       0.72      0.81      0.76       325
         3.0       0.88      0.84      0.86       316
         4.0       0.76      0.76      0.76       180

    accuracy                           0.74       900
   macro avg       0.50      0.56      0.51       900
weighted avg       0.72      0.74      0.73       900
 


====== chp034-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  93.67  41.18   94.68  12.96     19.72
1  93.11   0.00  100.00   0.00      0.00
2  81.67  80.62   82.26  71.98     76.05
3  90.11  83.54   93.66  87.71     85.58
4  90.33  76.11   93.89  75.69     75.90
Total accuracy: 74.44%
Average sen: 56.29%
Average spec: 92.90%
Macro f1-score: 51.45%
Diagnosis acc on 90mins: 0.8
[0.79186368 0.9997192  0.16875903 0.98240572 0.69168764]
pred: 0.7268870562314987, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp034-nsrr

=== Test on chp036-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.440186, loss_ss: 1.661152, loss_d: 0.779033
0.2469 --- loss: 2.441739, loss_ss: 1.607283, loss_d: 0.834456
0.4938 --- loss: 2.106224, loss_ss: 1.546931, loss_d: 0.559293
0.7407 --- loss: 2.165145, loss_ss: 1.475758, loss_d: 0.689388
0.9877 --- loss: 2.078838, loss_ss: 1.463945, loss_d: 0.614893
Epoch finished! Loss: 2.2377087771892548
Starting epoch 2/10.
0.0000 --- loss: 2.039445, loss_ss: 1.438584, loss_d: 0.600861
0.2469 --- loss: 1.909472, loss_ss: 1.389413, loss_d: 0.520059
0.4938 --- loss: 1.976280, loss_ss: 1.425686, loss_d: 0.550594
0.7407 --- loss: 1.913387, loss_ss: 1.353801, loss_d: 0.559586
0.9877 --- loss: 1.691186, loss_ss: 1.322130, loss_d: 0.369055
Epoch finished! Loss: 1.9874781847000123
Starting epoch 3/10.
0.0000 --- loss: 1.732964, loss_ss: 1.305941, loss_d: 0.427023
0.2469 --- loss: 1.988620, loss_ss: 1.230165, loss_d: 0.758454
0.4938 --- loss: 1.602530, loss_ss: 1.217395, loss_d: 0.385135
0.7407 --- loss: 1.802919, loss_ss: 1.331303, loss_d: 0.471616
0.9877 --- loss: 1.704356, loss_ss: 1.149056, loss_d: 0.555300
Epoch finished! Loss: 1.8637631505727768
Starting epoch 4/10.
0.0000 --- loss: 1.658597, loss_ss: 1.221358, loss_d: 0.437239
0.2469 --- loss: 1.739017, loss_ss: 1.333706, loss_d: 0.405311
0.4938 --- loss: 1.642098, loss_ss: 1.192936, loss_d: 0.449162
0.7407 --- loss: 1.719108, loss_ss: 1.249329, loss_d: 0.469779
0.9877 --- loss: 1.511095, loss_ss: 1.170704, loss_d: 0.340391
Epoch finished! Loss: 1.7393534988164903
Starting epoch 5/10.
0.0000 --- loss: 1.647990, loss_ss: 1.096714, loss_d: 0.551276
0.2469 --- loss: 1.667901, loss_ss: 1.269257, loss_d: 0.398645
0.4938 --- loss: 1.551608, loss_ss: 0.990570, loss_d: 0.561038
0.7407 --- loss: 1.397261, loss_ss: 1.066242, loss_d: 0.331019
0.9877 --- loss: 1.321429, loss_ss: 1.106443, loss_d: 0.214986
Epoch finished! Loss: 1.5780554205179214
Starting epoch 6/10.
0.0000 --- loss: 1.299724, loss_ss: 1.040499, loss_d: 0.259225
0.2469 --- loss: 1.620072, loss_ss: 1.084256, loss_d: 0.535816
0.4938 --- loss: 1.189743, loss_ss: 0.992694, loss_d: 0.197049
0.7407 --- loss: 1.197652, loss_ss: 1.044855, loss_d: 0.152797
0.9877 --- loss: 1.988592, loss_ss: 0.998298, loss_d: 0.990293
Epoch finished! Loss: 1.4963492274284362
Starting epoch 7/10.
0.0000 --- loss: 1.553840, loss_ss: 1.111807, loss_d: 0.442034
0.2469 --- loss: 1.587787, loss_ss: 1.056617, loss_d: 0.531170
0.4938 --- loss: 1.835992, loss_ss: 1.178601, loss_d: 0.657391
0.7407 --- loss: 1.445800, loss_ss: 1.057975, loss_d: 0.387826
0.9877 --- loss: 1.828206, loss_ss: 1.508819, loss_d: 0.319388
Epoch finished! Loss: 1.5632820308208466
Starting epoch 8/10.
0.0000 --- loss: 1.343852, loss_ss: 1.088662, loss_d: 0.255190
0.2469 --- loss: 1.315671, loss_ss: 0.958381, loss_d: 0.357291
0.4938 --- loss: 1.237569, loss_ss: 1.025274, loss_d: 0.212294
0.7407 --- loss: 1.337085, loss_ss: 1.057883, loss_d: 0.279201
0.9877 --- loss: 1.295138, loss_ss: 0.984716, loss_d: 0.310423
Epoch finished! Loss: 1.2377202078700065
Starting epoch 9/10.
0.0000 --- loss: 0.997876, loss_ss: 0.970268, loss_d: 0.027608
0.2469 --- loss: 1.066789, loss_ss: 1.042466, loss_d: 0.024322
0.4938 --- loss: 1.382758, loss_ss: 0.951287, loss_d: 0.431471
0.7407 --- loss: 0.979463, loss_ss: 0.953479, loss_d: 0.025984
0.9877 --- loss: 1.128866, loss_ss: 1.117955, loss_d: 0.010912
Epoch finished! Loss: 1.1352358415722847
Starting epoch 10/10.
0.0000 --- loss: 1.055180, loss_ss: 1.036458, loss_d: 0.018722
0.2469 --- loss: 0.983517, loss_ss: 0.896573, loss_d: 0.086944
0.4938 --- loss: 1.150707, loss_ss: 1.005506, loss_d: 0.145201
0.7407 --- loss: 0.945718, loss_ss: 0.913808, loss_d: 0.031910
0.9877 --- loss: 0.979400, loss_ss: 0.940506, loss_d: 0.038894
Epoch finished! Loss: 1.0852968662977218
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6698412698412698
              precision    recall  f1-score   support

         0.0       0.79      0.39      0.53       237
         1.0       0.00      0.00      0.00       167
         2.0       0.85      0.84      0.84       563
         3.0       0.09      0.88      0.16         8
         4.0       0.54      0.95      0.69       285

    accuracy                           0.67      1260
   macro avg       0.45      0.61      0.44      1260
weighted avg       0.65      0.67      0.63      1260
 


====== chp036-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  86.67  39.24   97.65  79.49     52.54
1  86.75   0.00  100.00   0.00      0.00
2  86.03  84.01   87.66  84.62     84.31
3  93.97  87.50   94.01   8.54     15.56
4  80.56  95.09   76.31  53.98     68.87
Total accuracy: 66.98%
Average sen: 61.17%
Average spec: 91.13%
Macro f1-score: 44.26%
Diagnosis acc on 90mins: 0.7142857142857143
[0.07297861 0.95836753 0.85429251 0.18404289 0.97336483 0.80212414
 0.99999928]
pred: 0.6921671128698758, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp036-nsrr

=== Test on chp037-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.639540, loss_ss: 1.852784, loss_d: 0.786756
0.2457 --- loss: 2.319844, loss_ss: 1.517468, loss_d: 0.802376
0.4914 --- loss: 2.128725, loss_ss: 1.514513, loss_d: 0.614212
0.7371 --- loss: 2.251130, loss_ss: 1.542576, loss_d: 0.708553
0.9828 --- loss: 2.281128, loss_ss: 1.517396, loss_d: 0.763732
Epoch finished! Loss: 2.249345788359642
Starting epoch 2/10.
0.0000 --- loss: 2.121053, loss_ss: 1.476087, loss_d: 0.644966
0.2457 --- loss: 2.039377, loss_ss: 1.463227, loss_d: 0.576150
0.4914 --- loss: 1.935327, loss_ss: 1.406439, loss_d: 0.528888
0.7371 --- loss: 1.696453, loss_ss: 1.275435, loss_d: 0.421018
0.9828 --- loss: 1.906392, loss_ss: 1.299893, loss_d: 0.606499
Epoch finished! Loss: 2.0401151895523073
Starting epoch 3/10.
0.0000 --- loss: 1.896440, loss_ss: 1.391771, loss_d: 0.504668
0.2457 --- loss: 1.698080, loss_ss: 1.400265, loss_d: 0.297815
0.4914 --- loss: 2.437355, loss_ss: 1.355394, loss_d: 1.081960
0.7371 --- loss: 1.804228, loss_ss: 1.312799, loss_d: 0.491429
0.9828 --- loss: 2.208627, loss_ss: 1.265769, loss_d: 0.942859
Epoch finished! Loss: 1.9172460556030273
Starting epoch 4/10.
0.0000 --- loss: 1.833978, loss_ss: 1.432601, loss_d: 0.401377
0.2457 --- loss: 1.771887, loss_ss: 1.331051, loss_d: 0.440836
0.4914 --- loss: 1.771354, loss_ss: 1.286608, loss_d: 0.484746
0.7371 --- loss: 1.626932, loss_ss: 1.244453, loss_d: 0.382479
0.9828 --- loss: 1.952476, loss_ss: 1.158424, loss_d: 0.794052
Epoch finished! Loss: 1.8083486527204513
Starting epoch 5/10.
0.0000 --- loss: 1.784869, loss_ss: 1.215895, loss_d: 0.568974
0.2457 --- loss: 1.518445, loss_ss: 1.162131, loss_d: 0.356315
0.4914 --- loss: 1.867927, loss_ss: 1.227231, loss_d: 0.640696
0.7371 --- loss: 1.415509, loss_ss: 1.165638, loss_d: 0.249871
0.9828 --- loss: 1.862484, loss_ss: 1.092250, loss_d: 0.770234
Epoch finished! Loss: 1.6637012183666229
Starting epoch 6/10.
0.0000 --- loss: 1.585121, loss_ss: 1.314993, loss_d: 0.270128
0.2457 --- loss: 2.064344, loss_ss: 1.073392, loss_d: 0.990952
0.4914 --- loss: 1.632707, loss_ss: 1.103093, loss_d: 0.529613
0.7371 --- loss: 1.490757, loss_ss: 1.049268, loss_d: 0.441489
0.9828 --- loss: 1.312550, loss_ss: 1.090853, loss_d: 0.221697
Epoch finished! Loss: 1.617378470301628
Starting epoch 7/10.
0.0000 --- loss: 1.448951, loss_ss: 1.141489, loss_d: 0.307462
0.2457 --- loss: 1.501697, loss_ss: 1.090022, loss_d: 0.411675
0.4914 --- loss: 1.335203, loss_ss: 1.226041, loss_d: 0.109162
0.7371 --- loss: 1.112194, loss_ss: 1.030508, loss_d: 0.081686
0.9828 --- loss: 1.415842, loss_ss: 1.130253, loss_d: 0.285588
Epoch finished! Loss: 1.4231238305568694
Starting epoch 8/10.
0.0000 --- loss: 1.277347, loss_ss: 1.122777, loss_d: 0.154570
0.2457 --- loss: 1.127852, loss_ss: 0.963015, loss_d: 0.164836
0.4914 --- loss: 1.672182, loss_ss: 1.222299, loss_d: 0.449883
0.7371 --- loss: 1.200715, loss_ss: 1.054891, loss_d: 0.145824
0.9828 --- loss: 1.214290, loss_ss: 1.150582, loss_d: 0.063708
Epoch finished! Loss: 1.3949149578809739
Starting epoch 9/10.
0.0000 --- loss: 1.019193, loss_ss: 0.983688, loss_d: 0.035504
0.2457 --- loss: 1.229139, loss_ss: 0.977553, loss_d: 0.251586
0.4914 --- loss: 1.133739, loss_ss: 1.015089, loss_d: 0.118649
0.7371 --- loss: 1.171517, loss_ss: 1.113386, loss_d: 0.058131
0.9828 --- loss: 1.300340, loss_ss: 1.101550, loss_d: 0.198791
Epoch finished! Loss: 1.1977651357650756
Starting epoch 10/10.
0.0000 --- loss: 1.382435, loss_ss: 1.032712, loss_d: 0.349723
0.2457 --- loss: 1.158810, loss_ss: 0.949276, loss_d: 0.209534
0.4914 --- loss: 1.292527, loss_ss: 1.044782, loss_d: 0.247745
0.7371 --- loss: 1.134572, loss_ss: 1.093161, loss_d: 0.041411
0.9828 --- loss: 1.432370, loss_ss: 1.053620, loss_d: 0.378750
Epoch finished! Loss: 1.2771169617772102
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5933333333333334
              precision    recall  f1-score   support

         0.0       0.57      0.26      0.36       191
         1.0       0.00      0.00      0.00       143
         2.0       0.63      0.88      0.73       274
         3.0       0.83      0.95      0.89       208
         4.0       0.24      0.54      0.33        84

    accuracy                           0.59       900
   macro avg       0.45      0.53      0.46       900
weighted avg       0.53      0.59      0.53       900
 


====== chp037-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  80.22  26.18   94.78  57.47     35.97
1  84.11   0.00  100.00   0.00      0.00
2  80.56  87.96   77.32  62.92     73.36
3  94.33  95.19   94.08  82.85     88.59
4  79.44  53.57   82.11  23.56     32.73
Total accuracy: 59.33%
Average sen: 52.58%
Average spec: 89.66%
Macro f1-score: 46.13%
Diagnosis acc on 90mins: 1.0
[0.99584132 0.5153836  0.99870145 0.99598783 0.99154848]
pred: 0.8994925379753113, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp037-nsrr

=== Test on chp038-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.320366, loss_ss: 1.640473, loss_d: 0.679893
0.2457 --- loss: 2.014845, loss_ss: 1.493516, loss_d: 0.521329
0.4914 --- loss: 2.282753, loss_ss: 1.386614, loss_d: 0.896138
0.7371 --- loss: 1.945724, loss_ss: 1.394765, loss_d: 0.550958
0.9828 --- loss: 2.190765, loss_ss: 1.423196, loss_d: 0.767569
Epoch finished! Loss: 2.1622177988290785
Starting epoch 2/10.
0.0000 --- loss: 1.873136, loss_ss: 1.431810, loss_d: 0.441326
0.2457 --- loss: 1.929741, loss_ss: 1.355815, loss_d: 0.573926
0.4914 --- loss: 1.742577, loss_ss: 1.403536, loss_d: 0.339041
0.7371 --- loss: 1.752412, loss_ss: 1.314273, loss_d: 0.438139
0.9828 --- loss: 2.046919, loss_ss: 1.310472, loss_d: 0.736447
Epoch finished! Loss: 2.0133721083402634
Starting epoch 3/10.
0.0000 --- loss: 1.940703, loss_ss: 1.345717, loss_d: 0.594986
0.2457 --- loss: 1.890210, loss_ss: 1.341200, loss_d: 0.549010
0.4914 --- loss: 1.654628, loss_ss: 1.269734, loss_d: 0.384894
0.7371 --- loss: 1.946192, loss_ss: 1.205693, loss_d: 0.740499
0.9828 --- loss: 1.824178, loss_ss: 1.146544, loss_d: 0.677634
Epoch finished! Loss: 1.9013231933116912
Starting epoch 4/10.
0.0000 --- loss: 1.881171, loss_ss: 1.290961, loss_d: 0.590210
0.2457 --- loss: 1.685948, loss_ss: 1.308051, loss_d: 0.377897
0.4914 --- loss: 1.626403, loss_ss: 1.307403, loss_d: 0.319000
0.7371 --- loss: 1.577181, loss_ss: 1.189043, loss_d: 0.388139
0.9828 --- loss: 1.596128, loss_ss: 1.172076, loss_d: 0.424052
Epoch finished! Loss: 1.813433077931404
Starting epoch 5/10.
0.0000 --- loss: 1.793113, loss_ss: 1.173223, loss_d: 0.619890
0.2457 --- loss: 1.780339, loss_ss: 1.175020, loss_d: 0.605319
0.4914 --- loss: 1.566519, loss_ss: 1.156940, loss_d: 0.409580
0.7371 --- loss: 1.891031, loss_ss: 1.137427, loss_d: 0.753604
0.9828 --- loss: 1.927569, loss_ss: 1.142222, loss_d: 0.785347
Epoch finished! Loss: 1.7357194513082503
Starting epoch 6/10.
0.0000 --- loss: 1.547236, loss_ss: 1.128736, loss_d: 0.418500
0.2457 --- loss: 1.655371, loss_ss: 1.086062, loss_d: 0.569309
0.4914 --- loss: 1.502647, loss_ss: 1.081138, loss_d: 0.421509
0.7371 --- loss: 1.415211, loss_ss: 1.023663, loss_d: 0.391548
0.9828 --- loss: 1.745356, loss_ss: 1.191355, loss_d: 0.554001
Epoch finished! Loss: 1.6290316700935363
Starting epoch 7/10.
0.0000 --- loss: 1.361613, loss_ss: 1.029995, loss_d: 0.331618
0.2457 --- loss: 1.458206, loss_ss: 1.111889, loss_d: 0.346317
0.4914 --- loss: 1.472961, loss_ss: 1.060222, loss_d: 0.412739
0.7371 --- loss: 1.365597, loss_ss: 1.009402, loss_d: 0.356194
0.9828 --- loss: 1.092321, loss_ss: 0.915453, loss_d: 0.176868
Epoch finished! Loss: 1.488428220152855
Starting epoch 8/10.
0.0000 --- loss: 1.314384, loss_ss: 0.927060, loss_d: 0.387323
0.2457 --- loss: 1.494136, loss_ss: 1.030092, loss_d: 0.464045
0.4914 --- loss: 1.492973, loss_ss: 0.994466, loss_d: 0.498507
0.7371 --- loss: 1.840587, loss_ss: 1.005223, loss_d: 0.835364
0.9828 --- loss: 1.550624, loss_ss: 1.118670, loss_d: 0.431954
Epoch finished! Loss: 1.447846269607544
Starting epoch 9/10.
0.0000 --- loss: 1.534732, loss_ss: 1.033885, loss_d: 0.500847
0.2457 --- loss: 1.165500, loss_ss: 1.070064, loss_d: 0.095435
0.4914 --- loss: 1.190461, loss_ss: 1.035877, loss_d: 0.154584
0.7371 --- loss: 1.371637, loss_ss: 0.961061, loss_d: 0.410576
0.9828 --- loss: 1.190411, loss_ss: 1.109707, loss_d: 0.080703
Epoch finished! Loss: 1.2823466628789901
Starting epoch 10/10.
0.0000 --- loss: 0.989019, loss_ss: 0.839832, loss_d: 0.149187
0.2457 --- loss: 1.064100, loss_ss: 0.963255, loss_d: 0.100845
0.4914 --- loss: 1.217692, loss_ss: 1.078781, loss_d: 0.138911
0.7371 --- loss: 1.028150, loss_ss: 0.901101, loss_d: 0.127049
0.9828 --- loss: 2.199801, loss_ss: 0.858903, loss_d: 1.340898
Epoch finished! Loss: 1.1848632514476776
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6066666666666667
              precision    recall  f1-score   support

         0.0       0.39      0.92      0.55        61
         1.0       0.00      0.00      0.00       153
         2.0       0.64      0.70      0.67       373
         3.0       0.48      0.99      0.65       102
         4.0       0.89      0.60      0.72       211

    accuracy                           0.61       900
   macro avg       0.48      0.64      0.52       900
weighted avg       0.56      0.61      0.56       900
 


====== chp038-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  89.89  91.80   89.75  39.44     55.17
1  83.00   0.00  100.00   0.00      0.00
2  71.56  70.24   72.49  64.37     67.18
3  87.89  99.02   86.47  48.33     64.95
4  89.00  60.19   97.82  89.44     71.95
Total accuracy: 60.67%
Average sen: 64.25%
Average spec: 89.30%
Macro f1-score: 51.85%
Diagnosis acc on 90mins: 1.0
[0.97806066 0.77597219 0.62907845 0.62674582 0.6549837 ]
pred: 0.7329681634902954, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp038-nsrr

=== Test on chp039-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.380967, loss_ss: 1.726370, loss_d: 0.654597
0.2463 --- loss: 2.331766, loss_ss: 1.594579, loss_d: 0.737186
0.4926 --- loss: 2.069536, loss_ss: 1.526318, loss_d: 0.543218
0.7389 --- loss: 2.059497, loss_ss: 1.435799, loss_d: 0.623698
0.9852 --- loss: 2.216216, loss_ss: 1.480185, loss_d: 0.736031
Epoch finished! Loss: 2.2792846351861953
Starting epoch 2/10.
0.0000 --- loss: 2.008018, loss_ss: 1.522330, loss_d: 0.485688
0.2463 --- loss: 2.024613, loss_ss: 1.498570, loss_d: 0.526042
0.4926 --- loss: 2.396646, loss_ss: 1.541391, loss_d: 0.855255
0.7389 --- loss: 1.847013, loss_ss: 1.406992, loss_d: 0.440020
0.9852 --- loss: 2.216284, loss_ss: 1.475026, loss_d: 0.741257
Epoch finished! Loss: 2.1016170978546143
Starting epoch 3/10.
0.0000 --- loss: 1.925895, loss_ss: 1.377383, loss_d: 0.548512
0.2463 --- loss: 1.906730, loss_ss: 1.364846, loss_d: 0.541884
0.4926 --- loss: 2.000787, loss_ss: 1.384229, loss_d: 0.616558
0.7389 --- loss: 2.105552, loss_ss: 1.335560, loss_d: 0.769992
0.9852 --- loss: 1.731406, loss_ss: 1.300902, loss_d: 0.430505
Epoch finished! Loss: 1.9835904747247697
Starting epoch 4/10.
0.0000 --- loss: 1.740135, loss_ss: 1.348797, loss_d: 0.391338
0.2463 --- loss: 1.672795, loss_ss: 1.297949, loss_d: 0.374846
0.4926 --- loss: 1.959206, loss_ss: 1.303685, loss_d: 0.655520
0.7389 --- loss: 1.850499, loss_ss: 1.256850, loss_d: 0.593649
0.9852 --- loss: 1.597913, loss_ss: 1.177522, loss_d: 0.420391
Epoch finished! Loss: 1.8765973836183547
Starting epoch 5/10.
0.0000 --- loss: 1.703380, loss_ss: 1.289358, loss_d: 0.414022
0.2463 --- loss: 1.542102, loss_ss: 1.202510, loss_d: 0.339591
0.4926 --- loss: 1.880245, loss_ss: 1.285103, loss_d: 0.595143
0.7389 --- loss: 1.747333, loss_ss: 1.263998, loss_d: 0.483335
0.9852 --- loss: 1.688343, loss_ss: 1.334247, loss_d: 0.354097
Epoch finished! Loss: 1.7048640310764314
Starting epoch 6/10.
0.0000 --- loss: 1.904578, loss_ss: 1.269823, loss_d: 0.634755
0.2463 --- loss: 1.625191, loss_ss: 1.313739, loss_d: 0.311452
0.4926 --- loss: 2.149167, loss_ss: 1.131926, loss_d: 1.017241
0.7389 --- loss: 1.358648, loss_ss: 1.180803, loss_d: 0.177846
0.9852 --- loss: 1.528024, loss_ss: 1.228989, loss_d: 0.299036
Epoch finished! Loss: 1.6202086836099625
Starting epoch 7/10.
0.0000 --- loss: 1.518509, loss_ss: 1.095990, loss_d: 0.422520
0.2463 --- loss: 1.359017, loss_ss: 1.031177, loss_d: 0.327840
0.4926 --- loss: 1.440370, loss_ss: 1.184931, loss_d: 0.255438
0.7389 --- loss: 1.212840, loss_ss: 1.044816, loss_d: 0.168024
0.9852 --- loss: 1.163872, loss_ss: 1.018804, loss_d: 0.145068
Epoch finished! Loss: 1.4364650070667266
Starting epoch 8/10.
0.0000 --- loss: 1.351541, loss_ss: 1.056152, loss_d: 0.295389
0.2463 --- loss: 1.187011, loss_ss: 1.029987, loss_d: 0.157024
0.4926 --- loss: 1.273219, loss_ss: 0.958809, loss_d: 0.314410
0.7389 --- loss: 1.429486, loss_ss: 1.015688, loss_d: 0.413798
0.9852 --- loss: 1.237765, loss_ss: 1.112220, loss_d: 0.125545
Epoch finished! Loss: 1.3745842397212982
Starting epoch 9/10.
0.0000 --- loss: 1.214997, loss_ss: 1.021881, loss_d: 0.193116
0.2463 --- loss: 1.129561, loss_ss: 1.012317, loss_d: 0.117244
0.4926 --- loss: 0.990697, loss_ss: 0.926965, loss_d: 0.063732
0.7389 --- loss: 1.032786, loss_ss: 0.987948, loss_d: 0.044838
0.9852 --- loss: 1.286318, loss_ss: 1.236833, loss_d: 0.049485
Epoch finished! Loss: 1.1898577377200126
Starting epoch 10/10.
0.0000 --- loss: 1.102574, loss_ss: 1.061270, loss_d: 0.041304
0.2463 --- loss: 0.996969, loss_ss: 0.936554, loss_d: 0.060415
0.4926 --- loss: 0.955554, loss_ss: 0.929601, loss_d: 0.025953
0.7389 --- loss: 1.251601, loss_ss: 0.891232, loss_d: 0.360369
0.9852 --- loss: 1.350277, loss_ss: 0.992755, loss_d: 0.357521
Epoch finished! Loss: 1.1417520567774773
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.37592592592592594
              precision    recall  f1-score   support

         0.0       0.04      0.95      0.07        19
         1.0       0.00      0.00      0.00       325
         2.0       0.74      0.55      0.63       376
         3.0       0.95      0.77      0.85       199
         4.0       0.22      0.18      0.20       161

    accuracy                           0.38      1080
   macro avg       0.39      0.49      0.35      1080
weighted avg       0.47      0.38      0.41      1080
 


====== chp039-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  54.35  94.74   53.63   3.53      6.81
1  69.91   0.00  100.00   0.00      0.00
2  77.41  54.79   89.49  73.57     62.80
3  95.00  76.88   99.09  95.03     85.00
4  78.52  18.01   89.12  22.48     20.00
Total accuracy: 37.59%
Average sen: 48.88%
Average spec: 86.27%
Macro f1-score: 34.92%
Diagnosis acc on 90mins: 1.0
[0.99003321 0.97595495 0.99624747 0.99998677 0.99761105 0.9998877 ]
pred: 0.9932868580023447, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp039-nsrr

=== Test on chp040-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.396987, loss_ss: 1.695209, loss_d: 0.701778
0.2457 --- loss: 3.155638, loss_ss: 1.608156, loss_d: 1.547482
0.4914 --- loss: 2.100087, loss_ss: 1.528570, loss_d: 0.571517
0.7371 --- loss: 2.202756, loss_ss: 1.475945, loss_d: 0.726812
0.9828 --- loss: 2.089507, loss_ss: 1.476033, loss_d: 0.613474
Epoch finished! Loss: 2.2434139251708984
Starting epoch 2/10.
0.0000 --- loss: 1.857786, loss_ss: 1.353538, loss_d: 0.504248
0.2457 --- loss: 1.992638, loss_ss: 1.407430, loss_d: 0.585209
0.4914 --- loss: 1.970308, loss_ss: 1.401985, loss_d: 0.568322
0.7371 --- loss: 1.706539, loss_ss: 1.344326, loss_d: 0.362214
0.9828 --- loss: 2.411211, loss_ss: 1.398417, loss_d: 1.012794
Epoch finished! Loss: 1.97876338660717
Starting epoch 3/10.
0.0000 --- loss: 1.592235, loss_ss: 1.318951, loss_d: 0.273283
0.2457 --- loss: 2.170583, loss_ss: 1.354528, loss_d: 0.816054
0.4914 --- loss: 1.879644, loss_ss: 1.223579, loss_d: 0.656066
0.7371 --- loss: 1.670563, loss_ss: 1.190287, loss_d: 0.480277
0.9828 --- loss: 1.686113, loss_ss: 1.246759, loss_d: 0.439354
Epoch finished! Loss: 1.8688330799341202
Starting epoch 4/10.
0.0000 --- loss: 1.779580, loss_ss: 1.260620, loss_d: 0.518961
0.2457 --- loss: 1.575480, loss_ss: 1.283949, loss_d: 0.291531
0.4914 --- loss: 1.698176, loss_ss: 1.373379, loss_d: 0.324797
0.7371 --- loss: 1.913483, loss_ss: 1.396613, loss_d: 0.516870
0.9828 --- loss: 1.595137, loss_ss: 1.264634, loss_d: 0.330503
Epoch finished! Loss: 1.7462564617395402
Starting epoch 5/10.
0.0000 --- loss: 1.610522, loss_ss: 1.183626, loss_d: 0.426896
0.2457 --- loss: 1.651206, loss_ss: 1.206338, loss_d: 0.444868
0.4914 --- loss: 1.532280, loss_ss: 1.101740, loss_d: 0.430540
0.7371 --- loss: 1.459283, loss_ss: 1.069050, loss_d: 0.390233
0.9828 --- loss: 1.497745, loss_ss: 1.306891, loss_d: 0.190854
Epoch finished! Loss: 1.5989433228969574
Starting epoch 6/10.
0.0000 --- loss: 1.287807, loss_ss: 1.149941, loss_d: 0.137866
0.2457 --- loss: 1.099535, loss_ss: 0.985318, loss_d: 0.114217
0.4914 --- loss: 1.564651, loss_ss: 1.103297, loss_d: 0.461355
0.7371 --- loss: 1.330032, loss_ss: 1.029210, loss_d: 0.300822
0.9828 --- loss: 1.018897, loss_ss: 0.914137, loss_d: 0.104760
Epoch finished! Loss: 1.3932541459798813
Starting epoch 7/10.
0.0000 --- loss: 1.137441, loss_ss: 1.033720, loss_d: 0.103721
0.2457 --- loss: 1.371191, loss_ss: 1.141533, loss_d: 0.229658
0.4914 --- loss: 1.057481, loss_ss: 0.975374, loss_d: 0.082107
0.7371 --- loss: 1.208303, loss_ss: 0.978143, loss_d: 0.230160
0.9828 --- loss: 1.203348, loss_ss: 1.043782, loss_d: 0.159567
Epoch finished! Loss: 1.4193502128124238
Starting epoch 8/10.
0.0000 --- loss: 1.158338, loss_ss: 1.037466, loss_d: 0.120872
0.2457 --- loss: 1.248125, loss_ss: 1.129448, loss_d: 0.118677
0.4914 --- loss: 1.065379, loss_ss: 0.961525, loss_d: 0.103854
0.7371 --- loss: 1.144491, loss_ss: 1.105647, loss_d: 0.038844
0.9828 --- loss: 1.031626, loss_ss: 0.996526, loss_d: 0.035100
Epoch finished! Loss: 1.1710922777652741
Starting epoch 9/10.
0.0000 --- loss: 1.055116, loss_ss: 1.047687, loss_d: 0.007429
0.2457 --- loss: 1.298383, loss_ss: 1.044862, loss_d: 0.253522
0.4914 --- loss: 1.094356, loss_ss: 1.043136, loss_d: 0.051221
0.7371 --- loss: 0.944058, loss_ss: 0.859488, loss_d: 0.084570
0.9828 --- loss: 0.806212, loss_ss: 0.803755, loss_d: 0.002456
Epoch finished! Loss: 1.0812366306781769
Starting epoch 10/10.
0.0000 --- loss: 0.910357, loss_ss: 0.879544, loss_d: 0.030812
0.2457 --- loss: 1.084654, loss_ss: 0.956787, loss_d: 0.127868
0.4914 --- loss: 1.644865, loss_ss: 0.870709, loss_d: 0.774155
0.7371 --- loss: 0.977419, loss_ss: 0.946197, loss_d: 0.031222
0.9828 --- loss: 1.409809, loss_ss: 0.919478, loss_d: 0.490330
Epoch finished! Loss: 1.0873810648918152
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6333333333333333
              precision    recall  f1-score   support

         0.0       0.93      0.61      0.73       157
         1.0       0.00      0.00      0.00       124
         2.0       0.52      0.63      0.57       264
         3.0       0.65      0.98      0.79       192
         4.0       0.63      0.73      0.67       163

    accuracy                           0.63       900
   macro avg       0.55      0.59      0.55       900
weighted avg       0.57      0.63      0.59       900
 


====== chp040-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  92.33  60.51   99.06  93.14     73.36
1  86.22   0.00  100.00   0.00      0.00
2  72.33  63.26   76.10  52.35     57.29
3  88.56  98.44   85.88  65.40     78.59
4  87.22  73.01   90.37  62.63     67.42
Total accuracy: 63.33%
Average sen: 59.04%
Average spec: 90.28%
Macro f1-score: 55.33%
Diagnosis acc on 90mins: 0.6
[0.19891286 0.99110281 0.99987459 0.98468542 0.12488057]
pred: 0.6598912522196769, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp040-nsrr

=== Test on chp041-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.301798, loss_ss: 1.644428, loss_d: 0.657370
0.2463 --- loss: 2.010142, loss_ss: 1.535269, loss_d: 0.474873
0.4926 --- loss: 2.072144, loss_ss: 1.507694, loss_d: 0.564449
0.7389 --- loss: 2.055848, loss_ss: 1.513427, loss_d: 0.542421
0.9852 --- loss: 2.148277, loss_ss: 1.446443, loss_d: 0.701834
Epoch finished! Loss: 2.1803693532943726
Starting epoch 2/10.
0.0000 --- loss: 1.672981, loss_ss: 1.416255, loss_d: 0.256727
0.2463 --- loss: 2.072577, loss_ss: 1.315853, loss_d: 0.756725
0.4926 --- loss: 1.864242, loss_ss: 1.428519, loss_d: 0.435722
0.7389 --- loss: 1.793261, loss_ss: 1.317984, loss_d: 0.475277
0.9852 --- loss: 1.738514, loss_ss: 1.310556, loss_d: 0.427958
Epoch finished! Loss: 1.9932574093341828
Starting epoch 3/10.
0.0000 --- loss: 1.923893, loss_ss: 1.295792, loss_d: 0.628102
0.2463 --- loss: 1.616633, loss_ss: 1.310135, loss_d: 0.306498
0.4926 --- loss: 1.518845, loss_ss: 1.191351, loss_d: 0.327494
0.7389 --- loss: 2.033007, loss_ss: 1.309184, loss_d: 0.723823
0.9852 --- loss: 1.799701, loss_ss: 1.299531, loss_d: 0.500170
Epoch finished! Loss: 1.8731845557689666
Starting epoch 4/10.
0.0000 --- loss: 1.768030, loss_ss: 1.268798, loss_d: 0.499232
0.2463 --- loss: 1.670217, loss_ss: 1.176697, loss_d: 0.493520
0.4926 --- loss: 1.586249, loss_ss: 1.241377, loss_d: 0.344872
0.7389 --- loss: 2.043362, loss_ss: 1.250835, loss_d: 0.792527
0.9852 --- loss: 1.548725, loss_ss: 1.188512, loss_d: 0.360212
Epoch finished! Loss: 1.7822470873594285
Starting epoch 5/10.
0.0000 --- loss: 1.941563, loss_ss: 1.357064, loss_d: 0.584500
0.2463 --- loss: 2.049581, loss_ss: 1.285060, loss_d: 0.764521
0.4926 --- loss: 1.629991, loss_ss: 1.133815, loss_d: 0.496177
0.7389 --- loss: 1.398614, loss_ss: 1.110702, loss_d: 0.287912
0.9852 --- loss: 2.103961, loss_ss: 1.231631, loss_d: 0.872330
Epoch finished! Loss: 1.6695212811231612
Starting epoch 6/10.
0.0000 --- loss: 1.494896, loss_ss: 1.052736, loss_d: 0.442160
0.2463 --- loss: 1.651114, loss_ss: 1.198181, loss_d: 0.452933
0.4926 --- loss: 1.282403, loss_ss: 1.014530, loss_d: 0.267873
0.7389 --- loss: 1.234968, loss_ss: 1.120839, loss_d: 0.114128
0.9852 --- loss: 1.529032, loss_ss: 1.270004, loss_d: 0.259028
Epoch finished! Loss: 1.6105089902877807
Starting epoch 7/10.
0.0000 --- loss: 1.405351, loss_ss: 1.072286, loss_d: 0.333064
0.2463 --- loss: 1.172220, loss_ss: 1.086278, loss_d: 0.085942
0.4926 --- loss: 1.399664, loss_ss: 1.102303, loss_d: 0.297361
0.7389 --- loss: 2.419133, loss_ss: 1.161259, loss_d: 1.257874
0.9852 --- loss: 1.619633, loss_ss: 1.008757, loss_d: 0.610876
Epoch finished! Loss: 1.4714171975851058
Starting epoch 8/10.
0.0000 --- loss: 1.516074, loss_ss: 1.137003, loss_d: 0.379071
0.2463 --- loss: 1.192913, loss_ss: 1.040311, loss_d: 0.152602
0.4926 --- loss: 1.125667, loss_ss: 1.007803, loss_d: 0.117865
0.7389 --- loss: 1.582101, loss_ss: 1.233411, loss_d: 0.348690
0.9852 --- loss: 1.400497, loss_ss: 1.182930, loss_d: 0.217567
Epoch finished! Loss: 1.3770691514015199
Starting epoch 9/10.
0.0000 --- loss: 1.148185, loss_ss: 0.995678, loss_d: 0.152508
0.2463 --- loss: 1.169629, loss_ss: 1.090668, loss_d: 0.078961
0.4926 --- loss: 1.189216, loss_ss: 1.054353, loss_d: 0.134863
0.7389 --- loss: 1.068193, loss_ss: 0.974141, loss_d: 0.094052
0.9852 --- loss: 1.323982, loss_ss: 1.269538, loss_d: 0.054444
Epoch finished! Loss: 1.2145283788442611
Starting epoch 10/10.
0.0000 --- loss: 1.136027, loss_ss: 1.060774, loss_d: 0.075253
0.2463 --- loss: 1.127496, loss_ss: 1.106140, loss_d: 0.021356
0.4926 --- loss: 1.130815, loss_ss: 1.022881, loss_d: 0.107934
0.7389 --- loss: 1.020121, loss_ss: 0.955015, loss_d: 0.065106
0.9852 --- loss: 1.294568, loss_ss: 1.240013, loss_d: 0.054555
Epoch finished! Loss: 1.2299090713262557
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.4287037037037037
              precision    recall  f1-score   support

         0.0       0.51      0.82      0.63       196
         1.0       0.00      0.00      0.00        58
         2.0       0.52      0.48      0.50       527
         3.0       0.12      1.00      0.22        33
         4.0       0.84      0.06      0.11       266

    accuracy                           0.43      1080
   macro avg       0.40      0.47      0.29      1080
weighted avg       0.56      0.43      0.39      1080
 


====== chp041-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  82.59   81.63   82.81  51.28     62.99
1  94.63    0.00  100.00   0.00      0.00
2  53.33   48.20   58.23  52.37     50.20
3  78.61  100.00   77.94  12.50     22.22
4  76.57    6.02   99.63  84.21     11.23
Total accuracy: 42.87%
Average sen: 47.17%
Average spec: 83.72%
Macro f1-score: 29.33%
Diagnosis acc on 90mins: 0.8333333333333334
[0.99999774 0.99996424 0.99993587 0.96447599 0.12063821 0.99914849]
pred: 0.8473600881795088, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp041-nsrr

=== Test on chp042-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.417218, loss_ss: 1.707418, loss_d: 0.709801
0.2463 --- loss: 1.912892, loss_ss: 1.442495, loss_d: 0.470397
0.4926 --- loss: 2.021228, loss_ss: 1.447166, loss_d: 0.574062
0.7389 --- loss: 1.951405, loss_ss: 1.451157, loss_d: 0.500247
0.9852 --- loss: 2.364954, loss_ss: 1.254748, loss_d: 1.110205
Epoch finished! Loss: 2.118946519494057
Starting epoch 2/10.
0.0000 --- loss: 1.828117, loss_ss: 1.334921, loss_d: 0.493196
0.2463 --- loss: 1.894199, loss_ss: 1.437664, loss_d: 0.456535
0.4926 --- loss: 1.660551, loss_ss: 1.341544, loss_d: 0.319007
0.7389 --- loss: 1.609558, loss_ss: 1.276727, loss_d: 0.332831
0.9852 --- loss: 1.868659, loss_ss: 1.209394, loss_d: 0.659266
Epoch finished! Loss: 1.86513751745224
Starting epoch 3/10.
0.0000 --- loss: 1.643916, loss_ss: 1.293558, loss_d: 0.350358
0.2463 --- loss: 1.658185, loss_ss: 1.337797, loss_d: 0.320389
0.4926 --- loss: 2.051046, loss_ss: 1.235190, loss_d: 0.815856
0.7389 --- loss: 1.675692, loss_ss: 1.201624, loss_d: 0.474069
0.9852 --- loss: 1.759755, loss_ss: 1.175641, loss_d: 0.584114
Epoch finished! Loss: 1.7021211415529252
Starting epoch 4/10.
0.0000 --- loss: 1.425718, loss_ss: 1.135232, loss_d: 0.290486
0.2463 --- loss: 1.719201, loss_ss: 1.232132, loss_d: 0.487069
0.4926 --- loss: 1.446565, loss_ss: 1.213073, loss_d: 0.233492
0.7389 --- loss: 1.518669, loss_ss: 1.091058, loss_d: 0.427610
0.9852 --- loss: 1.621787, loss_ss: 1.067699, loss_d: 0.554088
Epoch finished! Loss: 1.6517795085906983
Starting epoch 5/10.
0.0000 --- loss: 1.517838, loss_ss: 1.073626, loss_d: 0.444211
0.2463 --- loss: 1.069533, loss_ss: 1.004568, loss_d: 0.064965
0.4926 --- loss: 1.135183, loss_ss: 1.042122, loss_d: 0.093061
0.7389 --- loss: 1.112905, loss_ss: 1.058029, loss_d: 0.054875
0.9852 --- loss: 1.051026, loss_ss: 1.011819, loss_d: 0.039207
Epoch finished! Loss: 1.3258175939321517
Starting epoch 6/10.
0.0000 --- loss: 1.129049, loss_ss: 1.040810, loss_d: 0.088239
0.2463 --- loss: 1.155690, loss_ss: 1.128746, loss_d: 0.026943
0.4926 --- loss: 1.116870, loss_ss: 1.078925, loss_d: 0.037945
0.7389 --- loss: 1.262117, loss_ss: 0.972865, loss_d: 0.289251
0.9852 --- loss: 1.331519, loss_ss: 1.246827, loss_d: 0.084692
Epoch finished! Loss: 1.3045555040240289
Starting epoch 7/10.
0.0000 --- loss: 1.164346, loss_ss: 1.024969, loss_d: 0.139377
0.2463 --- loss: 1.923138, loss_ss: 1.159523, loss_d: 0.763615
0.4926 --- loss: 1.326692, loss_ss: 0.950063, loss_d: 0.376629
0.7389 --- loss: 1.299650, loss_ss: 0.996482, loss_d: 0.303168
0.9852 --- loss: 0.965112, loss_ss: 0.913190, loss_d: 0.051922
Epoch finished! Loss: 1.311466097831726
Starting epoch 8/10.
0.0000 --- loss: 1.238986, loss_ss: 1.141660, loss_d: 0.097326
0.2463 --- loss: 1.070592, loss_ss: 0.950991, loss_d: 0.119601
0.4926 --- loss: 1.084133, loss_ss: 1.044913, loss_d: 0.039220
0.7389 --- loss: 1.092051, loss_ss: 0.975103, loss_d: 0.116947
0.9852 --- loss: 1.581986, loss_ss: 0.866073, loss_d: 0.715913
Epoch finished! Loss: 1.1139851272106172
Starting epoch 9/10.
0.0000 --- loss: 0.948336, loss_ss: 0.934751, loss_d: 0.013585
0.2463 --- loss: 1.067524, loss_ss: 1.062683, loss_d: 0.004841
0.4926 --- loss: 1.015138, loss_ss: 0.994517, loss_d: 0.020622
0.7389 --- loss: 0.932217, loss_ss: 0.919214, loss_d: 0.013003
0.9852 --- loss: 0.970875, loss_ss: 0.969701, loss_d: 0.001174
Epoch finished! Loss: 1.033758246898651
Starting epoch 10/10.
0.0000 --- loss: 0.983832, loss_ss: 0.980569, loss_d: 0.003263
0.2463 --- loss: 0.965189, loss_ss: 0.954642, loss_d: 0.010546
0.4926 --- loss: 0.890665, loss_ss: 0.886054, loss_d: 0.004611
0.7389 --- loss: 1.025688, loss_ss: 1.021537, loss_d: 0.004151
0.9852 --- loss: 0.935942, loss_ss: 0.898342, loss_d: 0.037599
Epoch finished! Loss: 0.9842313572764396
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5916666666666667
              precision    recall  f1-score   support

         0.0       0.87      0.44      0.59       152
         1.0       0.00      0.00      0.00       230
         2.0       0.49      0.98      0.65       414
         3.0       0.94      0.84      0.89        93
         4.0       0.99      0.47      0.63       191

    accuracy                           0.59      1080
   macro avg       0.66      0.54      0.55      1080
weighted avg       0.57      0.59      0.52      1080
 


====== chp042-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  91.20  44.08   98.92  87.01     58.52
1  78.70   0.00  100.00   0.00      0.00
2  59.81  97.83   36.19  48.80     65.11
3  98.15  83.87   99.49  93.98     88.64
4  90.46  46.60   99.89  98.89     63.35
Total accuracy: 59.17%
Average sen: 54.47%
Average spec: 86.90%
Macro f1-score: 55.12%
Diagnosis acc on 90mins: 1.0
[0.9760142  0.99840087 0.99942786 0.99865675 1.         0.93696558]
pred: 0.9849108755588531, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp042-nsrr

=== Test on chp043-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.338133, loss_ss: 1.615938, loss_d: 0.722196
0.2463 --- loss: 2.159803, loss_ss: 1.524901, loss_d: 0.634903
0.4926 --- loss: 1.982886, loss_ss: 1.413052, loss_d: 0.569834
0.7389 --- loss: 2.025256, loss_ss: 1.401437, loss_d: 0.623819
0.9852 --- loss: 1.671144, loss_ss: 1.435450, loss_d: 0.235694
Epoch finished! Loss: 2.210415631532669
Starting epoch 2/10.
0.0000 --- loss: 1.795131, loss_ss: 1.373283, loss_d: 0.421848
0.2463 --- loss: 2.163794, loss_ss: 1.416490, loss_d: 0.747304
0.4926 --- loss: 1.802902, loss_ss: 1.402368, loss_d: 0.400534
0.7389 --- loss: 2.013144, loss_ss: 1.299271, loss_d: 0.713874
0.9852 --- loss: 2.339981, loss_ss: 1.292337, loss_d: 1.047643
Epoch finished! Loss: 1.9436821788549423
Starting epoch 3/10.
0.0000 --- loss: 1.781674, loss_ss: 1.260044, loss_d: 0.521629
0.2463 --- loss: 1.708525, loss_ss: 1.221115, loss_d: 0.487410
0.4926 --- loss: 1.590591, loss_ss: 1.263576, loss_d: 0.327015
0.7389 --- loss: 1.560407, loss_ss: 1.148948, loss_d: 0.411459
0.9852 --- loss: 1.469727, loss_ss: 1.174968, loss_d: 0.294759
Epoch finished! Loss: 1.8206082671880721
Starting epoch 4/10.
0.0000 --- loss: 1.724965, loss_ss: 1.144935, loss_d: 0.580030
0.2463 --- loss: 1.673294, loss_ss: 1.217360, loss_d: 0.455934
0.4926 --- loss: 1.516483, loss_ss: 1.182300, loss_d: 0.334183
0.7389 --- loss: 1.544768, loss_ss: 1.191894, loss_d: 0.352874
0.9852 --- loss: 1.395120, loss_ss: 1.033219, loss_d: 0.361901
Epoch finished! Loss: 1.70480178296566
Starting epoch 5/10.
0.0000 --- loss: 1.496328, loss_ss: 1.139281, loss_d: 0.357047
0.2463 --- loss: 1.331579, loss_ss: 1.077153, loss_d: 0.254426
0.4926 --- loss: 1.743733, loss_ss: 1.109687, loss_d: 0.634046
0.7389 --- loss: 1.767038, loss_ss: 1.261387, loss_d: 0.505651
0.9852 --- loss: 1.473874, loss_ss: 1.117414, loss_d: 0.356460
Epoch finished! Loss: 1.55528926551342
Starting epoch 6/10.
0.0000 --- loss: 1.261571, loss_ss: 1.049892, loss_d: 0.211679
0.2463 --- loss: 1.131922, loss_ss: 0.984789, loss_d: 0.147132
0.4926 --- loss: 1.351279, loss_ss: 1.020606, loss_d: 0.330673
0.7389 --- loss: 1.372959, loss_ss: 1.072423, loss_d: 0.300536
0.9852 --- loss: 1.254474, loss_ss: 0.950301, loss_d: 0.304173
Epoch finished! Loss: 1.4321709603071213
Starting epoch 7/10.
0.0000 --- loss: 1.160336, loss_ss: 1.038328, loss_d: 0.122009
0.2463 --- loss: 1.189713, loss_ss: 1.037193, loss_d: 0.152520
0.4926 --- loss: 1.821728, loss_ss: 1.103444, loss_d: 0.718284
0.7389 --- loss: 1.572705, loss_ss: 1.207842, loss_d: 0.364864
0.9852 --- loss: 1.183241, loss_ss: 1.018094, loss_d: 0.165148
Epoch finished! Loss: 1.3406817734241485
Starting epoch 8/10.
0.0000 --- loss: 1.153774, loss_ss: 0.965242, loss_d: 0.188532
0.2463 --- loss: 1.607445, loss_ss: 1.051349, loss_d: 0.556096
0.4926 --- loss: 1.087397, loss_ss: 0.986469, loss_d: 0.100928
0.7389 --- loss: 1.411981, loss_ss: 1.205324, loss_d: 0.206657
0.9852 --- loss: 1.269203, loss_ss: 1.141297, loss_d: 0.127906
Epoch finished! Loss: 1.2360921874642372
Starting epoch 9/10.
0.0000 --- loss: 1.476282, loss_ss: 0.894974, loss_d: 0.581308
0.2463 --- loss: 1.051282, loss_ss: 1.028089, loss_d: 0.023193
0.4926 --- loss: 0.930134, loss_ss: 0.915730, loss_d: 0.014404
0.7389 --- loss: 1.041075, loss_ss: 0.986327, loss_d: 0.054747
0.9852 --- loss: 1.257080, loss_ss: 1.197035, loss_d: 0.060045
Epoch finished! Loss: 1.1185810565948486
Starting epoch 10/10.
0.0000 --- loss: 1.108905, loss_ss: 0.989270, loss_d: 0.119634
0.2463 --- loss: 0.907824, loss_ss: 0.902219, loss_d: 0.005605
0.4926 --- loss: 1.069611, loss_ss: 1.028397, loss_d: 0.041214
0.7389 --- loss: 0.832209, loss_ss: 0.750616, loss_d: 0.081593
0.9852 --- loss: 2.547718, loss_ss: 0.966745, loss_d: 1.580972
Epoch finished! Loss: 1.1531139120459557
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6259259259259259
              precision    recall  f1-score   support

         0.0       1.00      0.32      0.48       136
         1.0       0.00      0.00      0.00       184
         2.0       0.85      0.76      0.80       489
         3.0       0.77      0.85      0.80        39
         4.0       0.41      0.98      0.58       232

    accuracy                           0.63      1080
   macro avg       0.61      0.58      0.53      1080
weighted avg       0.63      0.63      0.58      1080
 


====== chp043-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %   ppr %  f1-score
0  91.39  31.62  100.00  100.00     48.04
1  82.87   0.00   99.89    0.00      0.00
2  82.87  76.07   88.49   84.55     80.09
3  98.52  84.62   99.04   76.74     80.49
4  69.54  98.28   61.67   41.23     58.09
Total accuracy: 62.59%
Average sen: 58.12%
Average spec: 89.82%
Macro f1-score: 53.34%
Diagnosis acc on 90mins: 0.5
[0.00250286 0.61823279 0.00556793 0.93634844 0.00698589 0.94413233]
pred: 0.4189617062608401, label: 1
Wrong!!! Real Diagnosis: NT1
Save 90mins of subject chp043-nsrr

=== Test on chp044-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.352524, loss_ss: 1.677522, loss_d: 0.675002
0.2457 --- loss: 2.145380, loss_ss: 1.741739, loss_d: 0.403641
0.4914 --- loss: 2.217562, loss_ss: 1.440196, loss_d: 0.777366
0.7371 --- loss: 1.958527, loss_ss: 1.681378, loss_d: 0.277149
0.9828 --- loss: 2.357106, loss_ss: 1.499660, loss_d: 0.857446
Epoch finished! Loss: 2.231868603825569
Starting epoch 2/10.
0.0000 --- loss: 1.770574, loss_ss: 1.400661, loss_d: 0.369913
0.2457 --- loss: 2.172079, loss_ss: 1.438273, loss_d: 0.733806
0.4914 --- loss: 1.773455, loss_ss: 1.260040, loss_d: 0.513415
0.7371 --- loss: 1.714123, loss_ss: 1.293988, loss_d: 0.420135
0.9828 --- loss: 1.642707, loss_ss: 1.387563, loss_d: 0.255145
Epoch finished! Loss: 1.982028952240944
Starting epoch 3/10.
0.0000 --- loss: 2.045716, loss_ss: 1.423119, loss_d: 0.622597
0.2457 --- loss: 1.764880, loss_ss: 1.278388, loss_d: 0.486492
0.4914 --- loss: 2.205616, loss_ss: 1.180431, loss_d: 1.025185
0.7371 --- loss: 1.780239, loss_ss: 1.266923, loss_d: 0.513315
0.9828 --- loss: 1.675829, loss_ss: 1.189121, loss_d: 0.486708
Epoch finished! Loss: 1.8556524097919465
Starting epoch 4/10.
0.0000 --- loss: 1.676978, loss_ss: 1.192215, loss_d: 0.484763
0.2457 --- loss: 1.499306, loss_ss: 1.140419, loss_d: 0.358887
0.4914 --- loss: 1.379713, loss_ss: 1.229964, loss_d: 0.149748
0.7371 --- loss: 1.794930, loss_ss: 1.203367, loss_d: 0.591563
0.9828 --- loss: 1.705773, loss_ss: 1.281708, loss_d: 0.424064
Epoch finished! Loss: 1.664548897743225
Starting epoch 5/10.
0.0000 --- loss: 1.540038, loss_ss: 1.266063, loss_d: 0.273976
0.2457 --- loss: 1.455507, loss_ss: 1.167127, loss_d: 0.288379
0.4914 --- loss: 1.582215, loss_ss: 1.197823, loss_d: 0.384391
0.7371 --- loss: 1.563109, loss_ss: 1.100468, loss_d: 0.462641
0.9828 --- loss: 2.070290, loss_ss: 1.160248, loss_d: 0.910043
Epoch finished! Loss: 1.4892275840044022
Starting epoch 6/10.
0.0000 --- loss: 1.166488, loss_ss: 1.021540, loss_d: 0.144948
0.2457 --- loss: 1.331038, loss_ss: 1.137108, loss_d: 0.193930
0.4914 --- loss: 1.348168, loss_ss: 1.192400, loss_d: 0.155767
0.7371 --- loss: 1.114845, loss_ss: 1.083139, loss_d: 0.031706
0.9828 --- loss: 1.811086, loss_ss: 1.299553, loss_d: 0.511534
Epoch finished! Loss: 1.4042626202106476
Starting epoch 7/10.
0.0000 --- loss: 1.216393, loss_ss: 1.031865, loss_d: 0.184529
0.2457 --- loss: 1.179530, loss_ss: 1.124128, loss_d: 0.055402
0.4914 --- loss: 1.043030, loss_ss: 0.994627, loss_d: 0.048403
0.7371 --- loss: 1.185375, loss_ss: 1.167653, loss_d: 0.017723
0.9828 --- loss: 1.267831, loss_ss: 1.083951, loss_d: 0.183880
Epoch finished! Loss: 1.271679863333702
Starting epoch 8/10.
0.0000 --- loss: 1.095644, loss_ss: 1.077126, loss_d: 0.018518
0.2457 --- loss: 1.132212, loss_ss: 1.096897, loss_d: 0.035315
0.4914 --- loss: 1.055743, loss_ss: 1.019556, loss_d: 0.036187
0.7371 --- loss: 1.205292, loss_ss: 1.144014, loss_d: 0.061278
0.9828 --- loss: 1.222379, loss_ss: 1.161051, loss_d: 0.061328
Epoch finished! Loss: 1.1724400043487548
Starting epoch 9/10.
0.0000 --- loss: 1.093246, loss_ss: 1.063681, loss_d: 0.029565
0.2457 --- loss: 1.064103, loss_ss: 1.062622, loss_d: 0.001481
0.4914 --- loss: 0.986714, loss_ss: 0.982045, loss_d: 0.004669
0.7371 --- loss: 0.890236, loss_ss: 0.886863, loss_d: 0.003374
0.9828 --- loss: 1.138974, loss_ss: 0.986799, loss_d: 0.152175
Epoch finished! Loss: 1.0772950172424316
Starting epoch 10/10.
0.0000 --- loss: 0.978934, loss_ss: 0.977062, loss_d: 0.001872
0.2457 --- loss: 1.042861, loss_ss: 1.023632, loss_d: 0.019230
0.4914 --- loss: 1.078049, loss_ss: 1.066172, loss_d: 0.011877
0.7371 --- loss: 1.170388, loss_ss: 0.856978, loss_d: 0.313411
0.9828 --- loss: 1.076303, loss_ss: 1.011513, loss_d: 0.064790
Epoch finished! Loss: 1.0656416311860084
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6955555555555556
              precision    recall  f1-score   support

         0.0       0.24      0.93      0.38        15
         1.0       0.20      0.03      0.04        80
         2.0       0.57      0.83      0.67       286
         3.0       0.95      0.75      0.84       417
         4.0       0.70      0.61      0.65       102

    accuracy                           0.70       900
   macro avg       0.53      0.63      0.52       900
weighted avg       0.72      0.70      0.69       900
 


====== chp044-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  95.00  93.33   95.03  24.14     38.36
1  90.44   2.50   99.02  20.00      4.44
2  74.67  82.52   71.01  57.00     67.43
3  86.44  74.82   96.48  94.83     83.65
4  92.56  60.78   96.62  69.66     64.92
Total accuracy: 69.56%
Average sen: 62.79%
Average spec: 91.63%
Macro f1-score: 51.76%
Diagnosis acc on 90mins: 0.8
[0.99996161 0.99641329 0.99966908 0.04601604 0.99960047]
pred: 0.8083320990204811, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp044-nsrr

=== Test on chp045-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.402708, loss_ss: 1.651520, loss_d: 0.751188
0.2463 --- loss: 2.421271, loss_ss: 1.533148, loss_d: 0.888124
0.4926 --- loss: 2.075605, loss_ss: 1.486392, loss_d: 0.589213
0.7389 --- loss: 1.992419, loss_ss: 1.483613, loss_d: 0.508806
0.9852 --- loss: 2.670174, loss_ss: 1.415435, loss_d: 1.254739
Epoch finished! Loss: 2.206504172086716
Starting epoch 2/10.
0.0000 --- loss: 2.210812, loss_ss: 1.457075, loss_d: 0.753738
0.2463 --- loss: 2.068092, loss_ss: 1.580130, loss_d: 0.487962
0.4926 --- loss: 1.737602, loss_ss: 1.316817, loss_d: 0.420784
0.7389 --- loss: 1.918108, loss_ss: 1.397545, loss_d: 0.520563
0.9852 --- loss: 1.769366, loss_ss: 1.241817, loss_d: 0.527549
Epoch finished! Loss: 2.0014812529087065
Starting epoch 3/10.
0.0000 --- loss: 1.813242, loss_ss: 1.297042, loss_d: 0.516200
0.2463 --- loss: 1.793176, loss_ss: 1.159845, loss_d: 0.633331
0.4926 --- loss: 2.059546, loss_ss: 1.466113, loss_d: 0.593433
0.7389 --- loss: 1.533549, loss_ss: 1.275688, loss_d: 0.257861
0.9852 --- loss: 1.660163, loss_ss: 1.279275, loss_d: 0.380888
Epoch finished! Loss: 1.859569501876831
Starting epoch 4/10.
0.0000 --- loss: 1.615726, loss_ss: 1.209669, loss_d: 0.406057
0.2463 --- loss: 1.823255, loss_ss: 1.227777, loss_d: 0.595478
0.4926 --- loss: 1.517956, loss_ss: 1.168457, loss_d: 0.349499
0.7389 --- loss: 1.607691, loss_ss: 1.253617, loss_d: 0.354073
0.9852 --- loss: 1.631168, loss_ss: 1.349935, loss_d: 0.281232
Epoch finished! Loss: 1.7832194209098815
Starting epoch 5/10.
0.0000 --- loss: 1.724750, loss_ss: 1.238812, loss_d: 0.485938
0.2463 --- loss: 1.598208, loss_ss: 1.095368, loss_d: 0.502840
0.4926 --- loss: 1.713412, loss_ss: 1.243456, loss_d: 0.469955
0.7389 --- loss: 1.350247, loss_ss: 1.227923, loss_d: 0.122324
0.9852 --- loss: 1.419464, loss_ss: 1.169569, loss_d: 0.249895
Epoch finished! Loss: 1.644962078332901
Starting epoch 6/10.
0.0000 --- loss: 1.461330, loss_ss: 1.081336, loss_d: 0.379994
0.2463 --- loss: 1.428467, loss_ss: 1.097745, loss_d: 0.330723
0.4926 --- loss: 1.710763, loss_ss: 1.175248, loss_d: 0.535514
0.7389 --- loss: 1.473939, loss_ss: 1.061999, loss_d: 0.411939
0.9852 --- loss: 1.476912, loss_ss: 1.059422, loss_d: 0.417490
Epoch finished! Loss: 1.5399278074502945
Starting epoch 7/10.
0.0000 --- loss: 1.532062, loss_ss: 1.129993, loss_d: 0.402069
0.2463 --- loss: 1.497360, loss_ss: 1.154745, loss_d: 0.342616
0.4926 --- loss: 1.334768, loss_ss: 1.047555, loss_d: 0.287212
0.7389 --- loss: 1.300481, loss_ss: 1.053818, loss_d: 0.246662
0.9852 --- loss: 1.475187, loss_ss: 1.146616, loss_d: 0.328572
Epoch finished! Loss: 1.5464990317821503
Starting epoch 8/10.
0.0000 --- loss: 1.418531, loss_ss: 1.068005, loss_d: 0.350525
0.2463 --- loss: 1.279179, loss_ss: 1.172007, loss_d: 0.107173
0.4926 --- loss: 1.319579, loss_ss: 1.027911, loss_d: 0.291668
0.7389 --- loss: 1.553234, loss_ss: 1.206659, loss_d: 0.346575
0.9852 --- loss: 1.112668, loss_ss: 1.047397, loss_d: 0.065271
Epoch finished! Loss: 1.3482421845197679
Starting epoch 9/10.
0.0000 --- loss: 1.177782, loss_ss: 1.161261, loss_d: 0.016522
0.2463 --- loss: 1.327518, loss_ss: 1.278491, loss_d: 0.049027
0.4926 --- loss: 1.061108, loss_ss: 1.022479, loss_d: 0.038629
0.7389 --- loss: 1.179175, loss_ss: 1.138727, loss_d: 0.040449
0.9852 --- loss: 1.195243, loss_ss: 1.060815, loss_d: 0.134429
Epoch finished! Loss: 1.2990986764431
Starting epoch 10/10.
0.0000 --- loss: 1.220702, loss_ss: 1.184726, loss_d: 0.035975
0.2463 --- loss: 1.179745, loss_ss: 1.152384, loss_d: 0.027361
0.4926 --- loss: 1.529430, loss_ss: 1.206389, loss_d: 0.323041
0.7389 --- loss: 1.355992, loss_ss: 1.013980, loss_d: 0.342012
0.9852 --- loss: 1.304649, loss_ss: 1.020850, loss_d: 0.283799
Epoch finished! Loss: 1.2342194408178329
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.535681186283596
              precision    recall  f1-score   support

         0.0       0.50      0.01      0.03       138
         1.0       0.00      0.00      0.00       120
         2.0       0.56      0.89      0.69       410
         3.0       0.54      0.37      0.44       212
         4.0       0.47      0.68      0.56       199

    accuracy                           0.54      1079
   macro avg       0.42      0.39      0.34      1079
weighted avg       0.47      0.54      0.45      1079
 


====== chp045-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  87.21   1.45   99.79  50.00      2.82
1  88.88   0.00  100.00   0.00      0.00
2  69.60  88.54   58.00  56.37     68.88
3  81.46  36.79   92.39  54.17     43.82
4  79.98  67.84   82.73  47.04     55.56
Total accuracy: 53.57%
Average sen: 38.92%
Average spec: 86.58%
Macro f1-score: 34.21%
Diagnosis acc on 90mins: 0.6666666666666666
[0.99947339 0.02953774 0.05222825 0.52225888 0.99939489 0.9845525 ]
pred: 0.597907608995835, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp045-nsrr

=== Test on chp046-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.357024, loss_ss: 1.647781, loss_d: 0.709243
0.2463 --- loss: 3.217548, loss_ss: 1.530648, loss_d: 1.686900
0.4926 --- loss: 2.018023, loss_ss: 1.487505, loss_d: 0.530519
0.7389 --- loss: 1.896700, loss_ss: 1.388476, loss_d: 0.508224
0.9852 --- loss: 2.165968, loss_ss: 1.355693, loss_d: 0.810275
Epoch finished! Loss: 2.2037910908460616
Starting epoch 2/10.
0.0000 --- loss: 1.822364, loss_ss: 1.384541, loss_d: 0.437823
0.2463 --- loss: 1.945935, loss_ss: 1.332211, loss_d: 0.613725
0.4926 --- loss: 1.891811, loss_ss: 1.279207, loss_d: 0.612604
0.7389 --- loss: 1.953315, loss_ss: 1.340815, loss_d: 0.612500
0.9852 --- loss: 1.788432, loss_ss: 1.272065, loss_d: 0.516367
Epoch finished! Loss: 1.9325528353452683
Starting epoch 3/10.
0.0000 --- loss: 1.750452, loss_ss: 1.286375, loss_d: 0.464077
0.2463 --- loss: 1.754407, loss_ss: 1.294780, loss_d: 0.459627
0.4926 --- loss: 1.634482, loss_ss: 1.187569, loss_d: 0.446913
0.7389 --- loss: 1.753276, loss_ss: 1.289479, loss_d: 0.463797
0.9852 --- loss: 1.869426, loss_ss: 1.218994, loss_d: 0.650431
Epoch finished! Loss: 1.8459911406040193
Starting epoch 4/10.
0.0000 --- loss: 1.769662, loss_ss: 1.221385, loss_d: 0.548277
0.2463 --- loss: 1.794261, loss_ss: 1.191557, loss_d: 0.602704
0.4926 --- loss: 2.073081, loss_ss: 1.106650, loss_d: 0.966432
0.7389 --- loss: 1.531549, loss_ss: 1.186755, loss_d: 0.344795
0.9852 --- loss: 1.839489, loss_ss: 1.077646, loss_d: 0.761844
Epoch finished! Loss: 1.7510288625955581
Starting epoch 5/10.
0.0000 --- loss: 1.618221, loss_ss: 1.069912, loss_d: 0.548309
0.2463 --- loss: 1.715149, loss_ss: 1.078745, loss_d: 0.636404
0.4926 --- loss: 1.436254, loss_ss: 1.070318, loss_d: 0.365936
0.7389 --- loss: 1.577004, loss_ss: 1.112273, loss_d: 0.464731
0.9852 --- loss: 1.383517, loss_ss: 1.032046, loss_d: 0.351471
Epoch finished! Loss: 1.6117864966392517
Starting epoch 6/10.
0.0000 --- loss: 1.589801, loss_ss: 1.011064, loss_d: 0.578738
0.2463 --- loss: 1.441406, loss_ss: 1.127064, loss_d: 0.314342
0.4926 --- loss: 1.267705, loss_ss: 0.972100, loss_d: 0.295605
0.7389 --- loss: 1.271603, loss_ss: 1.117633, loss_d: 0.153970
0.9852 --- loss: 1.397614, loss_ss: 1.080538, loss_d: 0.317076
Epoch finished! Loss: 1.5061650604009629
Starting epoch 7/10.
0.0000 --- loss: 1.351485, loss_ss: 1.007395, loss_d: 0.344090
0.2463 --- loss: 1.533973, loss_ss: 1.023631, loss_d: 0.510342
0.4926 --- loss: 1.003509, loss_ss: 0.916355, loss_d: 0.087154
0.7389 --- loss: 1.225489, loss_ss: 1.141772, loss_d: 0.083717
0.9852 --- loss: 1.154439, loss_ss: 1.076628, loss_d: 0.077811
Epoch finished! Loss: 1.3188763022422791
Starting epoch 8/10.
0.0000 --- loss: 1.589030, loss_ss: 0.999583, loss_d: 0.589447
0.2463 --- loss: 1.154818, loss_ss: 1.042729, loss_d: 0.112089
0.4926 --- loss: 1.195186, loss_ss: 0.960216, loss_d: 0.234969
0.7389 --- loss: 1.455375, loss_ss: 0.857278, loss_d: 0.598097
0.9852 --- loss: 1.046034, loss_ss: 0.968812, loss_d: 0.077222
Epoch finished! Loss: 1.277103455364704
Starting epoch 9/10.
0.0000 --- loss: 1.443452, loss_ss: 1.043359, loss_d: 0.400093
0.2463 --- loss: 1.004824, loss_ss: 0.971984, loss_d: 0.032841
0.4926 --- loss: 1.660996, loss_ss: 1.004068, loss_d: 0.656928
0.7389 --- loss: 1.114945, loss_ss: 0.980946, loss_d: 0.133999
0.9852 --- loss: 1.483817, loss_ss: 0.968919, loss_d: 0.514898
Epoch finished! Loss: 1.1594747617840766
Starting epoch 10/10.
0.0000 --- loss: 0.939881, loss_ss: 0.906938, loss_d: 0.032943
0.2463 --- loss: 1.047618, loss_ss: 1.000585, loss_d: 0.047033
0.4926 --- loss: 0.955153, loss_ss: 0.951757, loss_d: 0.003396
0.7389 --- loss: 1.334423, loss_ss: 0.822381, loss_d: 0.512042
0.9852 --- loss: 1.026081, loss_ss: 0.994324, loss_d: 0.031757
Epoch finished! Loss: 1.0543194085359573
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.3527777777777778
              precision    recall  f1-score   support

         0.0       0.80      0.69      0.74       226
         1.0       0.00      0.00      0.00       357
         2.0       0.14      0.43      0.21       192
         3.0       0.02      1.00      0.03         2
         4.0       0.91      0.46      0.61       303

    accuracy                           0.35      1080
   macro avg       0.37      0.52      0.32      1080
weighted avg       0.45      0.35      0.36      1080
 


====== chp046-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  90.00   69.47   95.43  80.10     74.41
1  66.94    0.00  100.00   0.00      0.00
2  41.30   43.23   40.88  13.65     20.75
3  88.70  100.00   88.68   1.61      3.17
4  83.61   45.87   98.33  91.45     61.10
Total accuracy: 35.28%
Average sen: 51.71%
Average spec: 84.66%
Macro f1-score: 31.89%
Diagnosis acc on 90mins: 0.8333333333333334
[0.97606122 0.9661147  0.03932063 0.96220243 0.97105038 0.98991781]
pred: 0.8174445300052563, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp046-nsrr

=== Test on chp047-nsrr. train_data(408), test_data(4) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.460089, loss_ss: 1.746603, loss_d: 0.713486
0.2451 --- loss: 2.408829, loss_ss: 1.586664, loss_d: 0.822166
0.4902 --- loss: 2.173870, loss_ss: 1.505896, loss_d: 0.667974
0.7353 --- loss: 2.186306, loss_ss: 1.481935, loss_d: 0.704371
0.9804 --- loss: 2.118684, loss_ss: 1.534190, loss_d: 0.584494
Epoch finished! Loss: 2.2492550671100617
Starting epoch 2/10.
0.0000 --- loss: 1.994928, loss_ss: 1.396746, loss_d: 0.598182
0.2451 --- loss: 1.872393, loss_ss: 1.414312, loss_d: 0.458081
0.4902 --- loss: 1.794055, loss_ss: 1.391116, loss_d: 0.402939
0.7353 --- loss: 1.692034, loss_ss: 1.310423, loss_d: 0.381612
0.9804 --- loss: 2.142352, loss_ss: 1.302572, loss_d: 0.839779
Epoch finished! Loss: 1.9697830021381377
Starting epoch 3/10.
0.0000 --- loss: 1.868846, loss_ss: 1.324239, loss_d: 0.544608
0.2451 --- loss: 1.716167, loss_ss: 1.342143, loss_d: 0.374025
0.4902 --- loss: 1.604443, loss_ss: 1.231585, loss_d: 0.372858
0.7353 --- loss: 1.612432, loss_ss: 1.243223, loss_d: 0.369209
0.9804 --- loss: 1.684529, loss_ss: 1.237251, loss_d: 0.447278
Epoch finished! Loss: 1.8183493882417678
Starting epoch 4/10.
0.0000 --- loss: 1.876130, loss_ss: 1.176190, loss_d: 0.699940
0.2451 --- loss: 1.556807, loss_ss: 1.144117, loss_d: 0.412691
0.4902 --- loss: 1.618899, loss_ss: 1.207610, loss_d: 0.411289
0.7353 --- loss: 1.735349, loss_ss: 1.281470, loss_d: 0.453879
0.9804 --- loss: 1.774832, loss_ss: 1.115909, loss_d: 0.658924
Epoch finished! Loss: 1.7110092252492906
Starting epoch 5/10.
0.0000 --- loss: 1.534315, loss_ss: 1.176530, loss_d: 0.357786
0.2451 --- loss: 1.506050, loss_ss: 1.131510, loss_d: 0.374540
0.4902 --- loss: 1.599897, loss_ss: 1.071236, loss_d: 0.528661
0.7353 --- loss: 1.571047, loss_ss: 1.182582, loss_d: 0.388464
0.9804 --- loss: 1.791031, loss_ss: 0.976850, loss_d: 0.814181
Epoch finished! Loss: 1.6269011110067368
Starting epoch 6/10.
0.0000 --- loss: 1.375620, loss_ss: 1.091216, loss_d: 0.284404
0.2451 --- loss: 1.545727, loss_ss: 1.141415, loss_d: 0.404312
0.4902 --- loss: 1.643908, loss_ss: 1.113739, loss_d: 0.530169
0.7353 --- loss: 1.453154, loss_ss: 1.038189, loss_d: 0.414966
0.9804 --- loss: 1.546024, loss_ss: 1.143921, loss_d: 0.402103
Epoch finished! Loss: 1.529794031381607
Starting epoch 7/10.
0.0000 --- loss: 1.399919, loss_ss: 1.103583, loss_d: 0.296336
0.2451 --- loss: 1.169864, loss_ss: 0.974495, loss_d: 0.195368
0.4902 --- loss: 1.175104, loss_ss: 1.065619, loss_d: 0.109485
0.7353 --- loss: 1.123902, loss_ss: 1.052690, loss_d: 0.071211
0.9804 --- loss: 1.046469, loss_ss: 1.019771, loss_d: 0.026698
Epoch finished! Loss: 1.2923223614692687
Starting epoch 8/10.
0.0000 --- loss: 1.083062, loss_ss: 0.965685, loss_d: 0.117377
0.2451 --- loss: 1.229114, loss_ss: 1.121854, loss_d: 0.107260
0.4902 --- loss: 1.308092, loss_ss: 1.194707, loss_d: 0.113385
0.7353 --- loss: 1.265536, loss_ss: 1.177064, loss_d: 0.088472
0.9804 --- loss: 1.331776, loss_ss: 0.978463, loss_d: 0.353313
Epoch finished! Loss: 1.257509395480156
Starting epoch 9/10.
0.0000 --- loss: 1.016907, loss_ss: 0.961482, loss_d: 0.055425
0.2451 --- loss: 1.024458, loss_ss: 0.990856, loss_d: 0.033602
0.4902 --- loss: 1.164058, loss_ss: 0.986713, loss_d: 0.177345
0.7353 --- loss: 1.105644, loss_ss: 0.998760, loss_d: 0.106884
0.9804 --- loss: 0.912479, loss_ss: 0.899049, loss_d: 0.013430
Epoch finished! Loss: 1.170306396484375
Starting epoch 10/10.
0.0000 --- loss: 1.050817, loss_ss: 1.033752, loss_d: 0.017064
0.2451 --- loss: 0.928354, loss_ss: 0.919387, loss_d: 0.008967
0.4902 --- loss: 0.971095, loss_ss: 0.955722, loss_d: 0.015373
0.7353 --- loss: 1.077118, loss_ss: 0.932430, loss_d: 0.144688
0.9804 --- loss: 1.134813, loss_ss: 0.952293, loss_d: 0.182521
Epoch finished! Loss: 1.105512648820877
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.41388888888888886
              precision    recall  f1-score   support

         0.0       0.55      0.48      0.52       224
         1.0       0.00      0.00      0.00       172
         2.0       0.58      0.61      0.60       233
         3.0       0.00      0.00      0.00        25
         4.0       0.18      0.71      0.29        66

    accuracy                           0.41       720
   macro avg       0.26      0.36      0.28       720
weighted avg       0.38      0.41      0.38       720
 


====== chp047-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  71.81  48.21   82.46  55.38     51.55
1  76.11   0.00  100.00   0.00      0.00
2  73.19  61.37   78.85  58.13     59.71
3  93.89   0.00   97.27   0.00      0.00
4  67.78  71.21   67.43  18.08     28.83
Total accuracy: 41.39%
Average sen: 36.16%
Average spec: 85.20%
Macro f1-score: 28.02%
Diagnosis acc on 90mins: 1.0
[0.99951422 0.99818355 0.98639351 0.98677176]
pred: 0.9927157610654831, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp047-nsrr

=== Test on chp048-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.394481, loss_ss: 1.708811, loss_d: 0.685670
0.2457 --- loss: 2.156093, loss_ss: 1.589454, loss_d: 0.566639
0.4914 --- loss: 2.070873, loss_ss: 1.371387, loss_d: 0.699485
0.7371 --- loss: 2.224407, loss_ss: 1.337641, loss_d: 0.886765
0.9828 --- loss: 1.982740, loss_ss: 1.332462, loss_d: 0.650279
Epoch finished! Loss: 2.200755628943443
Starting epoch 2/10.
0.0000 --- loss: 1.807209, loss_ss: 1.445130, loss_d: 0.362079
0.2457 --- loss: 1.799194, loss_ss: 1.253744, loss_d: 0.545451
0.4914 --- loss: 1.723434, loss_ss: 1.246026, loss_d: 0.477408
0.7371 --- loss: 2.163946, loss_ss: 1.446126, loss_d: 0.717820
0.9828 --- loss: 1.855078, loss_ss: 1.300433, loss_d: 0.554645
Epoch finished! Loss: 2.01038818359375
Starting epoch 3/10.
0.0000 --- loss: 2.014505, loss_ss: 1.332924, loss_d: 0.681581
0.2457 --- loss: 1.799028, loss_ss: 1.384788, loss_d: 0.414240
0.4914 --- loss: 1.604110, loss_ss: 1.284482, loss_d: 0.319629
0.7371 --- loss: 2.066473, loss_ss: 1.420089, loss_d: 0.646385
0.9828 --- loss: 1.655261, loss_ss: 1.291418, loss_d: 0.363843
Epoch finished! Loss: 1.9152529865503312
Starting epoch 4/10.
0.0000 --- loss: 1.829351, loss_ss: 1.310014, loss_d: 0.519337
0.2457 --- loss: 1.840791, loss_ss: 1.289366, loss_d: 0.551425
0.4914 --- loss: 1.593044, loss_ss: 1.287727, loss_d: 0.305317
0.7371 --- loss: 1.959069, loss_ss: 1.615826, loss_d: 0.343242
0.9828 --- loss: 1.827204, loss_ss: 1.195535, loss_d: 0.631669
Epoch finished! Loss: 1.8013362348079682
Starting epoch 5/10.
0.0000 --- loss: 1.591453, loss_ss: 1.232016, loss_d: 0.359437
0.2457 --- loss: 1.731447, loss_ss: 1.165716, loss_d: 0.565731
0.4914 --- loss: 1.609712, loss_ss: 1.230931, loss_d: 0.378780
0.7371 --- loss: 1.431258, loss_ss: 1.169724, loss_d: 0.261533
0.9828 --- loss: 1.528010, loss_ss: 1.237300, loss_d: 0.290710
Epoch finished! Loss: 1.6732596546411513
Starting epoch 6/10.
0.0000 --- loss: 1.665867, loss_ss: 1.285998, loss_d: 0.379869
0.2457 --- loss: 1.464391, loss_ss: 1.185649, loss_d: 0.278742
0.4914 --- loss: 1.554002, loss_ss: 1.113073, loss_d: 0.440929
0.7371 --- loss: 1.325466, loss_ss: 1.151686, loss_d: 0.173780
0.9828 --- loss: 1.544214, loss_ss: 1.152404, loss_d: 0.391810
Epoch finished! Loss: 1.5528901398181916
Starting epoch 7/10.
0.0000 --- loss: 1.444339, loss_ss: 1.267876, loss_d: 0.176463
0.2457 --- loss: 1.406067, loss_ss: 1.292700, loss_d: 0.113367
0.4914 --- loss: 1.278952, loss_ss: 1.129043, loss_d: 0.149910
0.7371 --- loss: 1.124089, loss_ss: 1.043755, loss_d: 0.080334
0.9828 --- loss: 1.695585, loss_ss: 1.172208, loss_d: 0.523377
Epoch finished! Loss: 1.478084260225296
Starting epoch 8/10.
0.0000 --- loss: 1.280282, loss_ss: 1.141680, loss_d: 0.138602
0.2457 --- loss: 1.349083, loss_ss: 1.037477, loss_d: 0.311607
0.4914 --- loss: 1.411557, loss_ss: 1.202463, loss_d: 0.209094
0.7371 --- loss: 1.169893, loss_ss: 1.145988, loss_d: 0.023905
0.9828 --- loss: 1.209223, loss_ss: 1.163747, loss_d: 0.045477
Epoch finished! Loss: 1.4341308563947677
Starting epoch 9/10.
0.0000 --- loss: 1.211515, loss_ss: 1.162532, loss_d: 0.048983
0.2457 --- loss: 1.079858, loss_ss: 0.989062, loss_d: 0.090796
0.4914 --- loss: 1.184545, loss_ss: 1.170538, loss_d: 0.014007
0.7371 --- loss: 0.985841, loss_ss: 0.923202, loss_d: 0.062639
0.9828 --- loss: 1.214349, loss_ss: 1.148395, loss_d: 0.065954
Epoch finished! Loss: 1.247087773680687
Starting epoch 10/10.
0.0000 --- loss: 1.347834, loss_ss: 1.313728, loss_d: 0.034106
0.2457 --- loss: 0.930026, loss_ss: 0.916251, loss_d: 0.013775
0.4914 --- loss: 1.081890, loss_ss: 1.054905, loss_d: 0.026984
0.7371 --- loss: 1.078507, loss_ss: 1.064467, loss_d: 0.014040
0.9828 --- loss: 1.083816, loss_ss: 0.973527, loss_d: 0.110289
Epoch finished! Loss: 1.185415895283222
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5244444444444445
              precision    recall  f1-score   support

         0.0       0.19      0.81      0.31        37
         1.0       0.00      0.00      0.00       126
         2.0       0.58      0.91      0.71       441
         3.0       0.78      0.34      0.47       107
         4.0       0.44      0.02      0.04       189

    accuracy                           0.52       900
   macro avg       0.40      0.42      0.31       900
weighted avg       0.48      0.52      0.43       900
 


====== chp048-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  85.22  81.08   85.40  19.23     31.09
1  86.00   0.00  100.00   0.00      0.00
2  63.78  91.16   37.47  58.35     71.15
3  91.00  33.64   98.74  78.26     47.06
4  78.89   2.12   99.30  44.44      4.04
Total accuracy: 52.44%
Average sen: 41.60%
Average spec: 84.18%
Macro f1-score: 30.67%
Diagnosis acc on 90mins: 0.8
[0.99924719 0.99835497 0.99992347 0.0099254  0.99999249]
pred: 0.8014887036755681, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp048-nsrr

=== Test on chp049-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.326765, loss_ss: 1.645737, loss_d: 0.681028
0.2463 --- loss: 2.030280, loss_ss: 1.430817, loss_d: 0.599464
0.4926 --- loss: 1.731485, loss_ss: 1.460726, loss_d: 0.270759
0.7389 --- loss: 1.802360, loss_ss: 1.366454, loss_d: 0.435906
0.9852 --- loss: 2.005585, loss_ss: 1.292085, loss_d: 0.713499
Epoch finished! Loss: 2.1178755193948744
Starting epoch 2/10.
0.0000 --- loss: 2.005533, loss_ss: 1.356017, loss_d: 0.649515
0.2463 --- loss: 1.803023, loss_ss: 1.332458, loss_d: 0.470565
0.4926 --- loss: 1.905596, loss_ss: 1.295683, loss_d: 0.609913
0.7389 --- loss: 1.881808, loss_ss: 1.327828, loss_d: 0.553980
0.9852 --- loss: 1.660754, loss_ss: 1.213141, loss_d: 0.447613
Epoch finished! Loss: 1.9276670068502426
Starting epoch 3/10.
0.0000 --- loss: 1.681961, loss_ss: 1.219525, loss_d: 0.462436
0.2463 --- loss: 1.769401, loss_ss: 1.297962, loss_d: 0.471439
0.4926 --- loss: 1.844260, loss_ss: 1.305490, loss_d: 0.538770
0.7389 --- loss: 1.632719, loss_ss: 1.177832, loss_d: 0.454887
0.9852 --- loss: 2.433211, loss_ss: 1.233108, loss_d: 1.200103
Epoch finished! Loss: 1.8247634828090669
Starting epoch 4/10.
0.0000 --- loss: 1.476121, loss_ss: 1.154187, loss_d: 0.321933
0.2463 --- loss: 1.663793, loss_ss: 1.293175, loss_d: 0.370619
0.4926 --- loss: 1.562675, loss_ss: 1.196559, loss_d: 0.366116
0.7389 --- loss: 1.660088, loss_ss: 1.120333, loss_d: 0.539755
0.9852 --- loss: 1.652232, loss_ss: 1.053328, loss_d: 0.598904
Epoch finished! Loss: 1.6838528513908386
Starting epoch 5/10.
0.0000 --- loss: 1.610058, loss_ss: 1.154822, loss_d: 0.455237
0.2463 --- loss: 1.556704, loss_ss: 1.093101, loss_d: 0.463603
0.4926 --- loss: 1.313426, loss_ss: 1.074741, loss_d: 0.238685
0.7389 --- loss: 1.670362, loss_ss: 1.230342, loss_d: 0.440019
0.9852 --- loss: 1.627868, loss_ss: 0.966647, loss_d: 0.661221
Epoch finished! Loss: 1.559511235356331
Starting epoch 6/10.
0.0000 --- loss: 1.188555, loss_ss: 1.031306, loss_d: 0.157249
0.2463 --- loss: 1.452896, loss_ss: 1.018811, loss_d: 0.434085
0.4926 --- loss: 1.313663, loss_ss: 1.060089, loss_d: 0.253574
0.7389 --- loss: 1.813864, loss_ss: 1.006550, loss_d: 0.807314
0.9852 --- loss: 1.255959, loss_ss: 1.109178, loss_d: 0.146781
Epoch finished! Loss: 1.4005729526281356
Starting epoch 7/10.
0.0000 --- loss: 1.205093, loss_ss: 1.046286, loss_d: 0.158806
0.2463 --- loss: 1.233857, loss_ss: 0.964460, loss_d: 0.269397
0.4926 --- loss: 1.381385, loss_ss: 0.980661, loss_d: 0.400724
0.7389 --- loss: 1.268441, loss_ss: 1.000614, loss_d: 0.267827
0.9852 --- loss: 1.003449, loss_ss: 0.771196, loss_d: 0.232253
Epoch finished! Loss: 1.3096034303307533
Starting epoch 8/10.
0.0000 --- loss: 1.367025, loss_ss: 1.224257, loss_d: 0.142768
0.2463 --- loss: 1.096249, loss_ss: 0.928183, loss_d: 0.168066
0.4926 --- loss: 1.044559, loss_ss: 0.914371, loss_d: 0.130188
0.7389 --- loss: 1.010685, loss_ss: 0.925040, loss_d: 0.085645
0.9852 --- loss: 0.976336, loss_ss: 0.824634, loss_d: 0.151702
Epoch finished! Loss: 1.2063526898622512
Starting epoch 9/10.
0.0000 --- loss: 0.975662, loss_ss: 0.905931, loss_d: 0.069731
0.2463 --- loss: 1.216992, loss_ss: 0.821758, loss_d: 0.395234
0.4926 --- loss: 1.369145, loss_ss: 0.906393, loss_d: 0.462752
0.7389 --- loss: 0.844498, loss_ss: 0.809432, loss_d: 0.035066
0.9852 --- loss: 1.584765, loss_ss: 1.151513, loss_d: 0.433252
Epoch finished! Loss: 1.1088578656315804
Starting epoch 10/10.
0.0000 --- loss: 0.923394, loss_ss: 0.903328, loss_d: 0.020066
0.2463 --- loss: 1.070690, loss_ss: 1.057411, loss_d: 0.013278
0.4926 --- loss: 1.059001, loss_ss: 0.944200, loss_d: 0.114801
0.7389 --- loss: 0.956451, loss_ss: 0.926276, loss_d: 0.030175
0.9852 --- loss: 1.123277, loss_ss: 1.005992, loss_d: 0.117285
Epoch finished! Loss: 1.0503768563270568
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.48518518518518516
              precision    recall  f1-score   support

         0.0       0.35      0.64      0.45       108
         1.0       0.00      0.00      0.00       387
         2.0       0.48      0.85      0.62       360
         3.0       0.57      0.99      0.73        95
         4.0       0.64      0.42      0.50       130

    accuracy                           0.49      1080
   macro avg       0.41      0.58      0.46      1080
weighted avg       0.32      0.49      0.38      1080
 


====== chp049-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  84.35  63.89   86.63  34.67     44.95
1  64.17   0.00  100.00   0.00      0.00
2  64.91  85.28   54.72  48.50     61.83
3  93.43  98.95   92.89  57.32     72.59
4  90.19  41.54   96.84  64.29     50.47
Total accuracy: 48.52%
Average sen: 57.93%
Average spec: 86.22%
Macro f1-score: 45.97%
Diagnosis acc on 90mins: 1.0
[0.96026444 0.99216533 0.98969334 0.9999547  0.70300633 0.99278271]
pred: 0.939644475777944, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp049-nsrr

=== Test on chp051-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.480576, loss_ss: 1.802101, loss_d: 0.678475
0.2463 --- loss: 2.174443, loss_ss: 1.634046, loss_d: 0.540396
0.4926 --- loss: 2.304837, loss_ss: 1.577015, loss_d: 0.727822
0.7389 --- loss: 2.074250, loss_ss: 1.488647, loss_d: 0.585602
0.9852 --- loss: 2.209811, loss_ss: 1.445696, loss_d: 0.764116
Epoch finished! Loss: 2.2805900305509565
Starting epoch 2/10.
0.0000 --- loss: 2.034009, loss_ss: 1.470578, loss_d: 0.563432
0.2463 --- loss: 2.261265, loss_ss: 1.595659, loss_d: 0.665607
0.4926 --- loss: 2.054641, loss_ss: 1.354395, loss_d: 0.700247
0.7389 --- loss: 1.895704, loss_ss: 1.344218, loss_d: 0.551485
0.9852 --- loss: 2.099580, loss_ss: 1.287431, loss_d: 0.812150
Epoch finished! Loss: 2.0315107673406603
Starting epoch 3/10.
0.0000 --- loss: 1.595625, loss_ss: 1.228372, loss_d: 0.367253
0.2463 --- loss: 1.859968, loss_ss: 1.268982, loss_d: 0.590986
0.4926 --- loss: 1.845514, loss_ss: 1.444778, loss_d: 0.400736
0.7389 --- loss: 1.775224, loss_ss: 1.159464, loss_d: 0.615760
0.9852 --- loss: 1.698921, loss_ss: 1.242715, loss_d: 0.456205
Epoch finished! Loss: 1.8820214688777923
Starting epoch 4/10.
0.0000 --- loss: 1.635012, loss_ss: 1.146373, loss_d: 0.488639
0.2463 --- loss: 1.709569, loss_ss: 1.210229, loss_d: 0.499339
0.4926 --- loss: 1.781940, loss_ss: 1.239476, loss_d: 0.542464
0.7389 --- loss: 1.653960, loss_ss: 1.260299, loss_d: 0.393662
0.9852 --- loss: 1.803049, loss_ss: 1.338461, loss_d: 0.464588
Epoch finished! Loss: 1.8046432435512543
Starting epoch 5/10.
0.0000 --- loss: 1.525198, loss_ss: 1.191189, loss_d: 0.334009
0.2463 --- loss: 1.514636, loss_ss: 1.081265, loss_d: 0.433372
0.4926 --- loss: 1.428532, loss_ss: 1.128710, loss_d: 0.299822
0.7389 --- loss: 1.661272, loss_ss: 1.153255, loss_d: 0.508017
0.9852 --- loss: 1.590700, loss_ss: 1.342281, loss_d: 0.248419
Epoch finished! Loss: 1.6752901732921601
Starting epoch 6/10.
0.0000 --- loss: 1.743037, loss_ss: 1.106713, loss_d: 0.636324
0.2463 --- loss: 1.867233, loss_ss: 1.177008, loss_d: 0.690225
0.4926 --- loss: 1.795518, loss_ss: 1.198162, loss_d: 0.597356
0.7389 --- loss: 1.457560, loss_ss: 1.160697, loss_d: 0.296863
0.9852 --- loss: 1.244384, loss_ss: 1.072968, loss_d: 0.171415
Epoch finished! Loss: 1.5663336992263794
Starting epoch 7/10.
0.0000 --- loss: 1.351248, loss_ss: 1.085307, loss_d: 0.265941
0.2463 --- loss: 1.166478, loss_ss: 0.924241, loss_d: 0.242237
0.4926 --- loss: 1.359145, loss_ss: 1.171804, loss_d: 0.187341
0.7389 --- loss: 1.287058, loss_ss: 1.049244, loss_d: 0.237814
0.9852 --- loss: 1.232027, loss_ss: 1.031432, loss_d: 0.200594
Epoch finished! Loss: 1.4754418402910232
Starting epoch 8/10.
0.0000 --- loss: 1.511925, loss_ss: 1.118069, loss_d: 0.393855
0.2463 --- loss: 1.716256, loss_ss: 1.183447, loss_d: 0.532809
0.4926 --- loss: 1.180170, loss_ss: 0.999274, loss_d: 0.180897
0.7389 --- loss: 1.260608, loss_ss: 0.929353, loss_d: 0.331255
0.9852 --- loss: 1.430218, loss_ss: 0.946003, loss_d: 0.484215
Epoch finished! Loss: 1.3563951075077056
Starting epoch 9/10.
0.0000 --- loss: 1.050847, loss_ss: 0.998842, loss_d: 0.052005
0.2463 --- loss: 1.039694, loss_ss: 0.989757, loss_d: 0.049937
0.4926 --- loss: 1.145345, loss_ss: 1.081878, loss_d: 0.063467
0.7389 --- loss: 1.388869, loss_ss: 1.132867, loss_d: 0.256002
0.9852 --- loss: 1.174329, loss_ss: 0.941064, loss_d: 0.233265
Epoch finished! Loss: 1.257379749417305
Starting epoch 10/10.
0.0000 --- loss: 1.162246, loss_ss: 1.095447, loss_d: 0.066799
0.2463 --- loss: 0.976313, loss_ss: 0.921052, loss_d: 0.055260
0.4926 --- loss: 1.216689, loss_ss: 1.006166, loss_d: 0.210522
0.7389 --- loss: 1.135422, loss_ss: 1.057243, loss_d: 0.078179
0.9852 --- loss: 1.178958, loss_ss: 1.018570, loss_d: 0.160389
Epoch finished! Loss: 1.1901636496186256
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5888888888888889
              precision    recall  f1-score   support

         0.0       0.18      1.00      0.31        30
         1.0       0.00      0.00      0.00       136
         2.0       0.58      0.72      0.64       404
         3.0       0.89      0.81      0.85       239
         4.0       0.61      0.45      0.52       271

    accuracy                           0.59      1080
   macro avg       0.45      0.60      0.46      1080
weighted avg       0.57      0.59      0.57      1080
 


====== chp051-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %   sen %  spec %  ppr %  f1-score
0  87.69  100.00   87.33  18.40     31.09
1  87.41    0.00  100.00   0.00      0.00
2  70.19   72.03   69.08  58.20     64.38
3  93.52   80.75   97.15  88.94     84.65
4  78.98   45.02   90.36  61.00     51.80
Total accuracy: 58.89%
Average sen: 59.56%
Average spec: 88.78%
Macro f1-score: 46.38%
Diagnosis acc on 90mins: 1.0
[0.99989605 0.99861014 0.90099013 0.9891215  0.99604648 0.97787046]
pred: 0.9770891269048055, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp051-nsrr

=== Test on chp052-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.368756, loss_ss: 1.700941, loss_d: 0.667815
0.2457 --- loss: 1.987881, loss_ss: 1.415594, loss_d: 0.572287
0.4914 --- loss: 1.900474, loss_ss: 1.365474, loss_d: 0.535000
0.7371 --- loss: 2.169882, loss_ss: 1.440102, loss_d: 0.729780
0.9828 --- loss: 2.110407, loss_ss: 1.511023, loss_d: 0.599384
Epoch finished! Loss: 2.148350274562836
Starting epoch 2/10.
0.0000 --- loss: 1.735213, loss_ss: 1.300743, loss_d: 0.434470
0.2457 --- loss: 2.066833, loss_ss: 1.360852, loss_d: 0.705981
0.4914 --- loss: 1.696996, loss_ss: 1.286453, loss_d: 0.410543
0.7371 --- loss: 1.827380, loss_ss: 1.283844, loss_d: 0.543536
0.9828 --- loss: 1.752707, loss_ss: 1.333813, loss_d: 0.418894
Epoch finished! Loss: 1.9762411087751388
Starting epoch 3/10.
0.0000 --- loss: 2.035212, loss_ss: 1.394786, loss_d: 0.640426
0.2457 --- loss: 1.507036, loss_ss: 1.293451, loss_d: 0.213586
0.4914 --- loss: 1.756919, loss_ss: 1.262547, loss_d: 0.494372
0.7371 --- loss: 1.880851, loss_ss: 1.335639, loss_d: 0.545212
0.9828 --- loss: 2.030649, loss_ss: 1.267155, loss_d: 0.763494
Epoch finished! Loss: 1.8986161589622497
Starting epoch 4/10.
0.0000 --- loss: 1.636005, loss_ss: 1.232937, loss_d: 0.403068
0.2457 --- loss: 1.851022, loss_ss: 1.273575, loss_d: 0.577448
0.4914 --- loss: 1.721903, loss_ss: 1.350508, loss_d: 0.371395
0.7371 --- loss: 1.715249, loss_ss: 1.161772, loss_d: 0.553477
0.9828 --- loss: 1.550322, loss_ss: 1.250479, loss_d: 0.299844
Epoch finished! Loss: 1.7909060031175614
Starting epoch 5/10.
0.0000 --- loss: 1.502176, loss_ss: 1.164564, loss_d: 0.337611
0.2457 --- loss: 1.872045, loss_ss: 1.275900, loss_d: 0.596144
0.4914 --- loss: 1.844033, loss_ss: 1.288555, loss_d: 0.555478
0.7371 --- loss: 1.648029, loss_ss: 1.223195, loss_d: 0.424834
0.9828 --- loss: 1.361771, loss_ss: 1.146082, loss_d: 0.215689
Epoch finished! Loss: 1.6593583941459655
Starting epoch 6/10.
0.0000 --- loss: 1.678175, loss_ss: 1.143018, loss_d: 0.535157
0.2457 --- loss: 1.586692, loss_ss: 1.156539, loss_d: 0.430152
0.4914 --- loss: 1.387762, loss_ss: 1.178681, loss_d: 0.209081
0.7371 --- loss: 1.532006, loss_ss: 1.118370, loss_d: 0.413636
0.9828 --- loss: 1.478779, loss_ss: 1.064478, loss_d: 0.414301
Epoch finished! Loss: 1.6358309656381607
Starting epoch 7/10.
0.0000 --- loss: 1.322725, loss_ss: 1.147454, loss_d: 0.175271
0.2457 --- loss: 2.130424, loss_ss: 1.168360, loss_d: 0.962063
0.4914 --- loss: 1.367071, loss_ss: 0.996349, loss_d: 0.370723
0.7371 --- loss: 1.194971, loss_ss: 1.042725, loss_d: 0.152246
0.9828 --- loss: 2.068683, loss_ss: 1.409154, loss_d: 0.659529
Epoch finished! Loss: 1.462445828318596
Starting epoch 8/10.
0.0000 --- loss: 1.127255, loss_ss: 1.011205, loss_d: 0.116050
0.2457 --- loss: 1.465744, loss_ss: 1.184168, loss_d: 0.281576
0.4914 --- loss: 1.381244, loss_ss: 1.179530, loss_d: 0.201714
0.7371 --- loss: 2.283218, loss_ss: 1.103663, loss_d: 1.179556
0.9828 --- loss: 1.315628, loss_ss: 1.138766, loss_d: 0.176862
Epoch finished! Loss: 1.3194869488477707
Starting epoch 9/10.
0.0000 --- loss: 1.033973, loss_ss: 0.999501, loss_d: 0.034471
0.2457 --- loss: 1.108594, loss_ss: 0.969416, loss_d: 0.139178
0.4914 --- loss: 1.191935, loss_ss: 0.971505, loss_d: 0.220430
0.7371 --- loss: 1.095487, loss_ss: 0.951551, loss_d: 0.143936
0.9828 --- loss: 1.329584, loss_ss: 1.101650, loss_d: 0.227934
Epoch finished! Loss: 1.2844973862171174
Starting epoch 10/10.
0.0000 --- loss: 1.135240, loss_ss: 0.973426, loss_d: 0.161814
0.2457 --- loss: 1.250873, loss_ss: 1.044157, loss_d: 0.206716
0.4914 --- loss: 1.010781, loss_ss: 0.975676, loss_d: 0.035105
0.7371 --- loss: 1.007858, loss_ss: 0.922465, loss_d: 0.085393
0.9828 --- loss: 0.969637, loss_ss: 0.956684, loss_d: 0.012953
Epoch finished! Loss: 1.1610078319907189
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7666666666666667
              precision    recall  f1-score   support

         0.0       0.84      0.85      0.84       156
         1.0       0.56      0.13      0.21        76
         2.0       0.89      0.74      0.81       397
         3.0       0.50      0.98      0.66        66
         4.0       0.71      0.92      0.80       205

    accuracy                           0.77       900
   macro avg       0.70      0.72      0.67       900
weighted avg       0.78      0.77      0.75       900
 


====== chp052-nsrr ======
   acc %  sen %  spec %  ppr %  f1-score
0  94.56  84.62   96.64  84.08     84.35
1  91.78  13.16   99.03  55.56     21.28
2  84.67  74.31   92.84  89.12     81.04
3  92.67  98.48   92.21  50.00     66.33
4  89.67  91.71   89.06  71.21     80.17
Total accuracy: 76.67%
Average sen: 72.45%
Average spec: 93.96%
Macro f1-score: 66.63%
Diagnosis acc on 90mins: 0.8
[0.99769884 0.99706727 0.29720393 0.94990003 1.        ]
pred: 0.8483740150928497, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp052-nsrr

=== Test on chp053-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.387017, loss_ss: 1.669012, loss_d: 0.718005
0.2463 --- loss: 2.316047, loss_ss: 1.594639, loss_d: 0.721409
0.4926 --- loss: 2.043477, loss_ss: 1.524358, loss_d: 0.519119
0.7389 --- loss: 2.508765, loss_ss: 1.514868, loss_d: 0.993896
0.9852 --- loss: 2.064728, loss_ss: 1.463012, loss_d: 0.601716
Epoch finished! Loss: 2.2451686382293703
Starting epoch 2/10.
0.0000 --- loss: 1.901738, loss_ss: 1.416951, loss_d: 0.484787
0.2463 --- loss: 2.002882, loss_ss: 1.537595, loss_d: 0.465287
0.4926 --- loss: 2.056847, loss_ss: 1.398812, loss_d: 0.658035
0.7389 --- loss: 1.951511, loss_ss: 1.462029, loss_d: 0.489482
0.9852 --- loss: 1.826014, loss_ss: 1.415811, loss_d: 0.410203
Epoch finished! Loss: 2.0573733270168306
Starting epoch 3/10.
0.0000 --- loss: 1.816152, loss_ss: 1.357299, loss_d: 0.458853
0.2463 --- loss: 1.965728, loss_ss: 1.269773, loss_d: 0.695955
0.4926 --- loss: 1.657560, loss_ss: 1.355876, loss_d: 0.301684
0.7389 --- loss: 1.919571, loss_ss: 1.360365, loss_d: 0.559206
0.9852 --- loss: 1.724919, loss_ss: 1.279139, loss_d: 0.445780
Epoch finished! Loss: 1.9013155221939086
Starting epoch 4/10.
0.0000 --- loss: 1.686364, loss_ss: 1.282821, loss_d: 0.403543
0.2463 --- loss: 1.537822, loss_ss: 1.271607, loss_d: 0.266215
0.4926 --- loss: 1.781273, loss_ss: 1.273215, loss_d: 0.508058
0.7389 --- loss: 1.656993, loss_ss: 1.139838, loss_d: 0.517155
0.9852 --- loss: 1.815977, loss_ss: 1.274330, loss_d: 0.541647
Epoch finished! Loss: 1.798169779777527
Starting epoch 5/10.
0.0000 --- loss: 1.598976, loss_ss: 1.254128, loss_d: 0.344848
0.2463 --- loss: 1.897379, loss_ss: 1.330993, loss_d: 0.566386
0.4926 --- loss: 1.462827, loss_ss: 1.275761, loss_d: 0.187065
0.7389 --- loss: 1.569440, loss_ss: 1.114034, loss_d: 0.455406
0.9852 --- loss: 1.470608, loss_ss: 1.135923, loss_d: 0.334685
Epoch finished! Loss: 1.6425953775644302
Starting epoch 6/10.
0.0000 --- loss: 1.282736, loss_ss: 1.079645, loss_d: 0.203092
0.2463 --- loss: 1.355214, loss_ss: 1.113588, loss_d: 0.241626
0.4926 --- loss: 1.500784, loss_ss: 1.042776, loss_d: 0.458009
0.7389 --- loss: 1.197784, loss_ss: 1.156972, loss_d: 0.040812
0.9852 --- loss: 1.305129, loss_ss: 1.179831, loss_d: 0.125298
Epoch finished! Loss: 1.4303320556879044
Starting epoch 7/10.
0.0000 --- loss: 1.387932, loss_ss: 1.199246, loss_d: 0.188686
0.2463 --- loss: 1.223220, loss_ss: 1.099347, loss_d: 0.123873
0.4926 --- loss: 1.231043, loss_ss: 1.185585, loss_d: 0.045457
0.7389 --- loss: 1.197950, loss_ss: 1.101563, loss_d: 0.096386
0.9852 --- loss: 1.239416, loss_ss: 0.988255, loss_d: 0.251161
Epoch finished! Loss: 1.2820956140756607
Starting epoch 8/10.
0.0000 --- loss: 1.176066, loss_ss: 1.148947, loss_d: 0.027119
0.2463 --- loss: 1.125138, loss_ss: 1.113211, loss_d: 0.011928
0.4926 --- loss: 1.323895, loss_ss: 1.075998, loss_d: 0.247898
0.7389 --- loss: 1.177800, loss_ss: 1.148864, loss_d: 0.028936
0.9852 --- loss: 1.237740, loss_ss: 1.190567, loss_d: 0.047173
Epoch finished! Loss: 1.2871321588754654
Starting epoch 9/10.
0.0000 --- loss: 1.756859, loss_ss: 1.035978, loss_d: 0.720881
0.2463 --- loss: 1.056026, loss_ss: 1.006706, loss_d: 0.049320
0.4926 --- loss: 1.168877, loss_ss: 0.916639, loss_d: 0.252237
0.7389 --- loss: 1.014766, loss_ss: 0.987972, loss_d: 0.026794
0.9852 --- loss: 0.988164, loss_ss: 0.953945, loss_d: 0.034219
Epoch finished! Loss: 1.2137289881706237
Starting epoch 10/10.
0.0000 --- loss: 1.107216, loss_ss: 1.070107, loss_d: 0.037109
0.2463 --- loss: 1.027951, loss_ss: 1.022517, loss_d: 0.005434
0.4926 --- loss: 1.189894, loss_ss: 1.170074, loss_d: 0.019821
0.7389 --- loss: 1.045104, loss_ss: 1.033392, loss_d: 0.011712
0.9852 --- loss: 0.884015, loss_ss: 0.866208, loss_d: 0.017807
Epoch finished! Loss: 1.123891432583332
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6203703703703703
              precision    recall  f1-score   support

         0.0       0.75      0.49      0.59       251
         1.0       0.00      0.00      0.00       147
         2.0       0.65      0.84      0.73       305
         3.0       0.85      0.77      0.81       250
         4.0       0.34      0.77      0.47       127

    accuracy                           0.62      1080
   macro avg       0.52      0.57      0.52      1080
weighted avg       0.59      0.62      0.59      1080
 


====== chp053-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  84.26  48.61   95.05  74.85     58.94
1  86.39   0.00  100.00   0.00      0.00
2  82.50  84.26   81.81  64.57     73.12
3  91.48  77.20   95.78  84.65     80.75
4  79.44  77.17   79.75  33.68     46.89
Total accuracy: 62.04%
Average sen: 57.45%
Average spec: 90.48%
Macro f1-score: 51.94%
Diagnosis acc on 90mins: 1.0
[0.99703324 0.99997914 0.63805556 0.97183007 0.50732529 0.82055503]
pred: 0.8224630554517111, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp053-nsrr

=== Test on chp054-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.400435, loss_ss: 1.763232, loss_d: 0.637203
0.2463 --- loss: 2.511037, loss_ss: 1.625053, loss_d: 0.885984
0.4926 --- loss: 2.096004, loss_ss: 1.503570, loss_d: 0.592434
0.7389 --- loss: 2.276355, loss_ss: 1.433054, loss_d: 0.843301
0.9852 --- loss: 2.610954, loss_ss: 1.423769, loss_d: 1.187185
Epoch finished! Loss: 2.242661479115486
Starting epoch 2/10.
0.0000 --- loss: 2.007185, loss_ss: 1.476945, loss_d: 0.530240
0.2463 --- loss: 1.965634, loss_ss: 1.400053, loss_d: 0.565581
0.4926 --- loss: 1.753235, loss_ss: 1.403410, loss_d: 0.349826
0.7389 --- loss: 1.886596, loss_ss: 1.407101, loss_d: 0.479494
0.9852 --- loss: 1.629332, loss_ss: 1.368423, loss_d: 0.260909
Epoch finished! Loss: 2.0464560359716417
Starting epoch 3/10.
0.0000 --- loss: 1.838633, loss_ss: 1.309582, loss_d: 0.529051
0.2463 --- loss: 1.761754, loss_ss: 1.276050, loss_d: 0.485703
0.4926 --- loss: 2.891624, loss_ss: 1.277730, loss_d: 1.613895
0.7389 --- loss: 1.990004, loss_ss: 1.227520, loss_d: 0.762484
0.9852 --- loss: 2.016756, loss_ss: 1.332332, loss_d: 0.684424
Epoch finished! Loss: 1.9221054136753082
Starting epoch 4/10.
0.0000 --- loss: 1.902098, loss_ss: 1.385506, loss_d: 0.516592
0.2463 --- loss: 1.956969, loss_ss: 1.289919, loss_d: 0.667049
0.4926 --- loss: 1.896039, loss_ss: 1.263041, loss_d: 0.632998
0.7389 --- loss: 1.691016, loss_ss: 1.219662, loss_d: 0.471354
0.9852 --- loss: 1.674692, loss_ss: 1.402705, loss_d: 0.271987
Epoch finished! Loss: 1.8068436890840531
Starting epoch 5/10.
0.0000 --- loss: 1.630613, loss_ss: 1.185562, loss_d: 0.445051
0.2463 --- loss: 1.485383, loss_ss: 1.136225, loss_d: 0.349158
0.4926 --- loss: 1.428217, loss_ss: 1.167720, loss_d: 0.260497
0.7389 --- loss: 1.550931, loss_ss: 1.214593, loss_d: 0.336338
0.9852 --- loss: 1.988082, loss_ss: 1.127431, loss_d: 0.860651
Epoch finished! Loss: 1.684743994474411
Starting epoch 6/10.
0.0000 --- loss: 1.748698, loss_ss: 1.101951, loss_d: 0.646748
0.2463 --- loss: 1.666592, loss_ss: 1.366042, loss_d: 0.300550
0.4926 --- loss: 1.599750, loss_ss: 1.168086, loss_d: 0.431664
0.7389 --- loss: 1.746827, loss_ss: 1.236838, loss_d: 0.509989
0.9852 --- loss: 1.408729, loss_ss: 1.133272, loss_d: 0.275457
Epoch finished! Loss: 1.609853780269623
Starting epoch 7/10.
0.0000 --- loss: 1.428012, loss_ss: 1.070313, loss_d: 0.357698
0.2463 --- loss: 1.459532, loss_ss: 1.290180, loss_d: 0.169352
0.4926 --- loss: 1.375868, loss_ss: 1.167665, loss_d: 0.208203
0.7389 --- loss: 1.730643, loss_ss: 1.141429, loss_d: 0.589213
0.9852 --- loss: 1.460095, loss_ss: 1.210478, loss_d: 0.249616
Epoch finished! Loss: 1.4998239010572434
Starting epoch 8/10.
0.0000 --- loss: 1.168553, loss_ss: 1.046105, loss_d: 0.122448
0.2463 --- loss: 1.505960, loss_ss: 1.092278, loss_d: 0.413682
0.4926 --- loss: 1.088551, loss_ss: 0.942467, loss_d: 0.146084
0.7389 --- loss: 1.282935, loss_ss: 1.101416, loss_d: 0.181520
0.9852 --- loss: 1.359443, loss_ss: 1.309214, loss_d: 0.050229
Epoch finished! Loss: 1.3379258692264557
Starting epoch 9/10.
0.0000 --- loss: 1.035833, loss_ss: 0.990546, loss_d: 0.045288
0.2463 --- loss: 1.194172, loss_ss: 1.063036, loss_d: 0.131135
0.4926 --- loss: 1.112906, loss_ss: 1.097362, loss_d: 0.015545
0.7389 --- loss: 1.325289, loss_ss: 1.008276, loss_d: 0.317013
0.9852 --- loss: 1.041395, loss_ss: 0.976535, loss_d: 0.064860
Epoch finished! Loss: 1.2141514420509338
Starting epoch 10/10.
0.0000 --- loss: 1.043355, loss_ss: 1.007787, loss_d: 0.035568
0.2463 --- loss: 1.153230, loss_ss: 1.148377, loss_d: 0.004854
0.4926 --- loss: 1.016924, loss_ss: 1.012709, loss_d: 0.004215
0.7389 --- loss: 1.280732, loss_ss: 1.053274, loss_d: 0.227458
0.9852 --- loss: 1.205749, loss_ss: 1.192021, loss_d: 0.013728
Epoch finished! Loss: 1.234489281475544
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.7694444444444445
              precision    recall  f1-score   support

         0.0       0.76      0.79      0.77       228
         1.0       0.00      0.00      0.00        86
         2.0       0.71      0.91      0.80       451
         3.0       0.97      0.89      0.93        99
         4.0       0.88      0.71      0.79       216

    accuracy                           0.77      1080
   macro avg       0.66      0.66      0.66      1080
weighted avg       0.72      0.77      0.74      1080
 


====== chp054-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  90.28  78.51   93.43  76.17     77.32
1  92.04   0.00  100.00   0.00      0.00
2  80.65  90.91   73.29  70.93     79.69
3  98.70  88.89   99.69  96.70     92.63
4  92.22  71.30   97.45  87.50     78.57
Total accuracy: 76.94%
Average sen: 65.92%
Average spec: 92.77%
Macro f1-score: 65.64%
Diagnosis acc on 90mins: 0.6666666666666666
[9.99697328e-01 9.99753296e-01 1.54303268e-01 1.93423693e-04
 6.24723911e-01 9.87552404e-01]
pred: 0.6277039384949603, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp054-nsrr

=== Test on chp055-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.311760, loss_ss: 1.604953, loss_d: 0.706807
0.2463 --- loss: 2.017263, loss_ss: 1.451577, loss_d: 0.565686
0.4926 --- loss: 1.846161, loss_ss: 1.453711, loss_d: 0.392450
0.7389 --- loss: 2.200092, loss_ss: 1.304746, loss_d: 0.895346
0.9852 --- loss: 2.007053, loss_ss: 1.346966, loss_d: 0.660088
Epoch finished! Loss: 2.0988573104143144
Starting epoch 2/10.
0.0000 --- loss: 1.677804, loss_ss: 1.303898, loss_d: 0.373906
0.2463 --- loss: 1.657172, loss_ss: 1.312589, loss_d: 0.344583
0.4926 --- loss: 1.938483, loss_ss: 1.459639, loss_d: 0.478844
0.7389 --- loss: 1.858378, loss_ss: 1.214807, loss_d: 0.643571
0.9852 --- loss: 1.819382, loss_ss: 1.216474, loss_d: 0.602908
Epoch finished! Loss: 1.9375047236680984
Starting epoch 3/10.
0.0000 --- loss: 1.940868, loss_ss: 1.207509, loss_d: 0.733359
0.2463 --- loss: 1.617372, loss_ss: 1.186846, loss_d: 0.430525
0.4926 --- loss: 1.692950, loss_ss: 1.204996, loss_d: 0.487955
0.7389 --- loss: 1.479900, loss_ss: 1.202306, loss_d: 0.277594
0.9852 --- loss: 1.756558, loss_ss: 1.240384, loss_d: 0.516174
Epoch finished! Loss: 1.7625817567110063
Starting epoch 4/10.
0.0000 --- loss: 1.624853, loss_ss: 1.312439, loss_d: 0.312414
0.2463 --- loss: 1.457967, loss_ss: 1.215211, loss_d: 0.242756
0.4926 --- loss: 1.657374, loss_ss: 1.207100, loss_d: 0.450274
0.7389 --- loss: 1.647295, loss_ss: 1.227733, loss_d: 0.419563
0.9852 --- loss: 1.786137, loss_ss: 1.333992, loss_d: 0.452144
Epoch finished! Loss: 1.6777665585279464
Starting epoch 5/10.
0.0000 --- loss: 1.562381, loss_ss: 1.341078, loss_d: 0.221304
0.2463 --- loss: 1.347923, loss_ss: 1.161334, loss_d: 0.186589
0.4926 --- loss: 1.341273, loss_ss: 1.156797, loss_d: 0.184476
0.7389 --- loss: 1.525893, loss_ss: 1.256353, loss_d: 0.269540
0.9852 --- loss: 1.595217, loss_ss: 1.168673, loss_d: 0.426544
Epoch finished! Loss: 1.6132614195346833
Starting epoch 6/10.
0.0000 --- loss: 1.542816, loss_ss: 1.130252, loss_d: 0.412564
0.2463 --- loss: 1.227159, loss_ss: 1.077959, loss_d: 0.149200
0.4926 --- loss: 1.466355, loss_ss: 1.237023, loss_d: 0.229332
0.7389 --- loss: 1.148567, loss_ss: 1.044029, loss_d: 0.104538
0.9852 --- loss: 1.238730, loss_ss: 1.103602, loss_d: 0.135129
Epoch finished! Loss: 1.4539811581373214
Starting epoch 7/10.
0.0000 --- loss: 1.192649, loss_ss: 1.101561, loss_d: 0.091088
0.2463 --- loss: 1.097105, loss_ss: 1.083786, loss_d: 0.013319
0.4926 --- loss: 1.049267, loss_ss: 0.960057, loss_d: 0.089209
0.7389 --- loss: 1.285195, loss_ss: 1.141049, loss_d: 0.144146
0.9852 --- loss: 1.139232, loss_ss: 1.122622, loss_d: 0.016609
Epoch finished! Loss: 1.2429262846708298
Starting epoch 8/10.
0.0000 --- loss: 1.052326, loss_ss: 1.026064, loss_d: 0.026262
0.2463 --- loss: 1.317056, loss_ss: 1.161955, loss_d: 0.155101
0.4926 --- loss: 1.098369, loss_ss: 1.094624, loss_d: 0.003746
0.7389 --- loss: 1.076253, loss_ss: 1.014866, loss_d: 0.061387
0.9852 --- loss: 1.138023, loss_ss: 1.123324, loss_d: 0.014699
Epoch finished! Loss: 1.215745137631893
Starting epoch 9/10.
0.0000 --- loss: 1.090370, loss_ss: 1.003988, loss_d: 0.086382
0.2463 --- loss: 1.499743, loss_ss: 1.149548, loss_d: 0.350195
0.4926 --- loss: 1.062419, loss_ss: 1.026421, loss_d: 0.035998
0.7389 --- loss: 1.099773, loss_ss: 1.090177, loss_d: 0.009596
0.9852 --- loss: 1.013631, loss_ss: 1.011721, loss_d: 0.001910
Epoch finished! Loss: 1.1294404819607735
Starting epoch 10/10.
0.0000 --- loss: 0.984737, loss_ss: 0.979942, loss_d: 0.004795
0.2463 --- loss: 0.903726, loss_ss: 0.894690, loss_d: 0.009036
0.4926 --- loss: 0.999047, loss_ss: 0.972774, loss_d: 0.026273
0.7389 --- loss: 1.027244, loss_ss: 1.022877, loss_d: 0.004367
0.9852 --- loss: 1.145917, loss_ss: 1.122849, loss_d: 0.023067
Epoch finished! Loss: 1.0520381137728692
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5444444444444444
              precision    recall  f1-score   support

         0.0       0.81      0.45      0.58       211
         1.0       1.00      0.01      0.01       154
         2.0       0.65      0.67      0.66       408
         3.0       0.35      0.92      0.50       130
         4.0       0.51      0.56      0.54       177

    accuracy                           0.54      1080
   macro avg       0.66      0.52      0.46      1080
weighted avg       0.67      0.54      0.51      1080
 


====== chp055-nsrr ======
   acc %  sen %  spec %   ppr %  f1-score
0  87.22  45.02   97.47   81.20     57.93
1  85.83   0.65  100.00  100.00      1.29
2  73.80  66.67   78.12   64.92     65.78
3  78.06  92.31   76.11   34.58     50.31
4  83.98  56.50   89.37   51.02     53.62
Total accuracy: 54.44%
Average sen: 52.23%
Average spec: 88.21%
Macro f1-score: 45.79%
Diagnosis acc on 90mins: 0.5
[0.27705553 0.31684881 0.81005239 0.99999964 0.34488618 0.99985385]
pred: 0.6247827361027399, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp055-nsrr

=== Test on chp056-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.206603, loss_ss: 1.532653, loss_d: 0.673950
0.2463 --- loss: 1.853656, loss_ss: 1.487240, loss_d: 0.366415
0.4926 --- loss: 1.917421, loss_ss: 1.294462, loss_d: 0.622959
0.7389 --- loss: 1.977669, loss_ss: 1.365481, loss_d: 0.612188
0.9852 --- loss: 1.634897, loss_ss: 1.266723, loss_d: 0.368175
Epoch finished! Loss: 2.0561373621225356
Starting epoch 2/10.
0.0000 --- loss: 1.631588, loss_ss: 1.279969, loss_d: 0.351618
0.2463 --- loss: 1.862273, loss_ss: 1.193769, loss_d: 0.668504
0.4926 --- loss: 1.923139, loss_ss: 1.270097, loss_d: 0.653041
0.7389 --- loss: 1.754451, loss_ss: 1.191822, loss_d: 0.562628
0.9852 --- loss: 1.849897, loss_ss: 1.092129, loss_d: 0.757767
Epoch finished! Loss: 1.892889592051506
Starting epoch 3/10.
0.0000 --- loss: 1.778400, loss_ss: 1.245792, loss_d: 0.532608
0.2463 --- loss: 1.848451, loss_ss: 1.306701, loss_d: 0.541750
0.4926 --- loss: 1.683348, loss_ss: 1.171035, loss_d: 0.512313
0.7389 --- loss: 1.640943, loss_ss: 1.179998, loss_d: 0.460945
0.9852 --- loss: 1.645121, loss_ss: 1.141921, loss_d: 0.503200
Epoch finished! Loss: 1.7706794530153274
Starting epoch 4/10.
0.0000 --- loss: 1.658632, loss_ss: 1.166465, loss_d: 0.492167
0.2463 --- loss: 1.352734, loss_ss: 1.067355, loss_d: 0.285379
0.4926 --- loss: 1.777747, loss_ss: 1.104549, loss_d: 0.673198
0.7389 --- loss: 1.634372, loss_ss: 1.106501, loss_d: 0.527871
0.9852 --- loss: 1.648829, loss_ss: 1.227380, loss_d: 0.421448
Epoch finished! Loss: 1.7007061332464217
Starting epoch 5/10.
0.0000 --- loss: 1.431444, loss_ss: 1.067894, loss_d: 0.363550
0.2463 --- loss: 1.357148, loss_ss: 1.028497, loss_d: 0.328651
0.4926 --- loss: 1.568987, loss_ss: 1.059607, loss_d: 0.509380
0.7389 --- loss: 1.714545, loss_ss: 1.026236, loss_d: 0.688309
0.9852 --- loss: 1.315840, loss_ss: 0.898156, loss_d: 0.417684
Epoch finished! Loss: 1.5964443534612656
Starting epoch 6/10.
0.0000 --- loss: 1.356959, loss_ss: 1.018263, loss_d: 0.338697
0.2463 --- loss: 1.335913, loss_ss: 1.011433, loss_d: 0.324480
0.4926 --- loss: 1.403446, loss_ss: 1.155580, loss_d: 0.247866
0.7389 --- loss: 1.558878, loss_ss: 1.156297, loss_d: 0.402580
0.9852 --- loss: 1.560672, loss_ss: 1.123401, loss_d: 0.437271
Epoch finished! Loss: 1.5152138620615005
Starting epoch 7/10.
0.0000 --- loss: 1.725626, loss_ss: 1.207541, loss_d: 0.518085
0.2463 --- loss: 1.584696, loss_ss: 0.990800, loss_d: 0.593895
0.4926 --- loss: 1.516572, loss_ss: 0.984171, loss_d: 0.532401
0.7389 --- loss: 1.707790, loss_ss: 1.125064, loss_d: 0.582725
0.9852 --- loss: 1.405863, loss_ss: 1.090843, loss_d: 0.315020
Epoch finished! Loss: 1.4674649685621262
Starting epoch 8/10.
0.0000 --- loss: 1.215787, loss_ss: 1.002896, loss_d: 0.212891
0.2463 --- loss: 1.630721, loss_ss: 1.148821, loss_d: 0.481900
0.4926 --- loss: 1.056484, loss_ss: 0.877632, loss_d: 0.178851
0.7389 --- loss: 2.245902, loss_ss: 0.922197, loss_d: 1.323706
0.9852 --- loss: 1.003368, loss_ss: 0.900185, loss_d: 0.103183
Epoch finished! Loss: 1.3203905194997787
Starting epoch 9/10.
0.0000 --- loss: 1.062421, loss_ss: 0.937403, loss_d: 0.125018
0.2463 --- loss: 1.097013, loss_ss: 1.060971, loss_d: 0.036042
0.4926 --- loss: 1.116770, loss_ss: 0.819709, loss_d: 0.297060
0.7389 --- loss: 1.565107, loss_ss: 1.129645, loss_d: 0.435461
0.9852 --- loss: 1.149688, loss_ss: 1.089921, loss_d: 0.059768
Epoch finished! Loss: 1.1607168108224868
Starting epoch 10/10.
0.0000 --- loss: 0.968807, loss_ss: 0.929157, loss_d: 0.039650
0.2463 --- loss: 1.114289, loss_ss: 0.845945, loss_d: 0.268344
0.4926 --- loss: 1.151412, loss_ss: 0.980670, loss_d: 0.170743
0.7389 --- loss: 0.881371, loss_ss: 0.833440, loss_d: 0.047932
0.9852 --- loss: 1.120651, loss_ss: 0.984427, loss_d: 0.136224
Epoch finished! Loss: 1.0998572632670403
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5425925925925926
              precision    recall  f1-score   support

         0.0       0.22      0.72      0.34        78
         1.0       0.00      0.00      0.00       284
         2.0       0.52      0.72      0.61       258
         3.0       0.78      0.99      0.87       185
         4.0       0.67      0.58      0.62       275

    accuracy                           0.54      1080
   macro avg       0.44      0.60      0.49      1080
weighted avg       0.45      0.54      0.48      1080
 


====== chp056-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  80.09  71.79   80.74  22.49     34.25
1  73.70   0.00  100.00   0.00      0.00
2  77.59  72.09   79.32  52.25     60.59
3  95.09  99.46   94.19  77.97     87.41
4  82.04  58.18   90.19  66.95     62.26
Total accuracy: 54.26%
Average sen: 60.31%
Average spec: 88.89%
Macro f1-score: 48.90%
Diagnosis acc on 90mins: 1.0
[0.88876092 0.98362029 0.98468    0.99615306 0.99999154 0.99990618]
pred: 0.9755186637242635, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp056-nsrr

=== Test on chp057-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.294739, loss_ss: 1.624967, loss_d: 0.669772
0.2463 --- loss: 2.066880, loss_ss: 1.483593, loss_d: 0.583287
0.4926 --- loss: 2.325943, loss_ss: 1.377134, loss_d: 0.948809
0.7389 --- loss: 1.932388, loss_ss: 1.375442, loss_d: 0.556947
0.9852 --- loss: 1.821918, loss_ss: 1.293859, loss_d: 0.528059
Epoch finished! Loss: 2.124498265981674
Starting epoch 2/10.
0.0000 --- loss: 1.958018, loss_ss: 1.254709, loss_d: 0.703309
0.2463 --- loss: 1.844726, loss_ss: 1.381289, loss_d: 0.463437
0.4926 --- loss: 2.115571, loss_ss: 1.241318, loss_d: 0.874252
0.7389 --- loss: 1.717692, loss_ss: 1.203048, loss_d: 0.514643
0.9852 --- loss: 2.202179, loss_ss: 1.221925, loss_d: 0.980254
Epoch finished! Loss: 1.8806312322616576
Starting epoch 3/10.
0.0000 --- loss: 1.673735, loss_ss: 1.217270, loss_d: 0.456464
0.2463 --- loss: 1.784241, loss_ss: 1.237665, loss_d: 0.546576
0.4926 --- loss: 1.750375, loss_ss: 1.132730, loss_d: 0.617646
0.7389 --- loss: 1.817133, loss_ss: 1.200266, loss_d: 0.616867
0.9852 --- loss: 2.169624, loss_ss: 1.406002, loss_d: 0.763622
Epoch finished! Loss: 1.794667336344719
Starting epoch 4/10.
0.0000 --- loss: 1.782738, loss_ss: 1.285119, loss_d: 0.497619
0.2463 --- loss: 1.684516, loss_ss: 1.204591, loss_d: 0.479925
0.4926 --- loss: 1.653659, loss_ss: 1.251693, loss_d: 0.401966
0.7389 --- loss: 1.547267, loss_ss: 1.202768, loss_d: 0.344499
0.9852 --- loss: 1.826398, loss_ss: 1.162830, loss_d: 0.663569
Epoch finished! Loss: 1.7365490227937699
Starting epoch 5/10.
0.0000 --- loss: 1.902791, loss_ss: 0.992114, loss_d: 0.910677
0.2463 --- loss: 1.708417, loss_ss: 1.093799, loss_d: 0.614619
0.4926 --- loss: 1.835514, loss_ss: 1.089422, loss_d: 0.746091
0.7389 --- loss: 1.373919, loss_ss: 1.069064, loss_d: 0.304855
0.9852 --- loss: 1.341478, loss_ss: 0.923402, loss_d: 0.418075
Epoch finished! Loss: 1.646336030960083
Starting epoch 6/10.
0.0000 --- loss: 1.544513, loss_ss: 1.224706, loss_d: 0.319807
0.2463 --- loss: 1.387793, loss_ss: 1.087934, loss_d: 0.299859
0.4926 --- loss: 1.623503, loss_ss: 1.116274, loss_d: 0.507229
0.7389 --- loss: 1.302041, loss_ss: 1.020953, loss_d: 0.281088
0.9852 --- loss: 1.775545, loss_ss: 0.901570, loss_d: 0.873975
Epoch finished! Loss: 1.513020423054695
Starting epoch 7/10.
0.0000 --- loss: 1.431545, loss_ss: 1.243961, loss_d: 0.187584
0.2463 --- loss: 1.836249, loss_ss: 1.273104, loss_d: 0.563145
0.4926 --- loss: 1.311368, loss_ss: 0.984275, loss_d: 0.327093
0.7389 --- loss: 1.364445, loss_ss: 1.079737, loss_d: 0.284709
0.9852 --- loss: 1.345567, loss_ss: 1.150201, loss_d: 0.195366
Epoch finished! Loss: 1.4330996870994568
Starting epoch 8/10.
0.0000 --- loss: 1.086854, loss_ss: 1.008779, loss_d: 0.078074
0.2463 --- loss: 1.361811, loss_ss: 1.046688, loss_d: 0.315123
0.4926 --- loss: 1.067718, loss_ss: 0.954417, loss_d: 0.113301
0.7389 --- loss: 1.144113, loss_ss: 1.068206, loss_d: 0.075907
0.9852 --- loss: 1.215191, loss_ss: 1.048725, loss_d: 0.166466
Epoch finished! Loss: 1.3461310118436813
Starting epoch 9/10.
0.0000 --- loss: 1.243824, loss_ss: 1.109372, loss_d: 0.134452
0.2463 --- loss: 0.960694, loss_ss: 0.870309, loss_d: 0.090385
0.4926 --- loss: 1.264329, loss_ss: 0.862300, loss_d: 0.402029
0.7389 --- loss: 1.281386, loss_ss: 1.054884, loss_d: 0.226502
0.9852 --- loss: 1.063657, loss_ss: 0.863158, loss_d: 0.200499
Epoch finished! Loss: 1.219985942542553
Starting epoch 10/10.
0.0000 --- loss: 1.220045, loss_ss: 1.097505, loss_d: 0.122540
0.2463 --- loss: 0.995899, loss_ss: 0.960935, loss_d: 0.034964
0.4926 --- loss: 1.164511, loss_ss: 1.081092, loss_d: 0.083419
0.7389 --- loss: 1.023380, loss_ss: 0.978626, loss_d: 0.044754
0.9852 --- loss: 1.287084, loss_ss: 1.280489, loss_d: 0.006595
Epoch finished! Loss: 1.1285562485456466
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6311399443929564
              precision    recall  f1-score   support

         0.0       0.68      0.65      0.66       260
         1.0       0.00      0.00      0.00       142
         2.0       0.57      0.99      0.72       423
         3.0       0.97      0.77      0.86        74
         4.0       0.95      0.20      0.33       180

    accuracy                           0.63      1079
   macro avg       0.63      0.52      0.52      1079
weighted avg       0.61      0.63      0.56      1079
 


====== chp057-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  84.24  64.62   90.48  68.29     66.40
1  86.84   0.00  100.00   0.00      0.00
2  70.44  99.29   51.83  57.07     72.48
3  98.24  77.03   99.80  96.61     85.71
4  86.47  20.00   99.78  94.74     33.03
Total accuracy: 63.11%
Average sen: 52.19%
Average spec: 88.38%
Macro f1-score: 51.52%
Diagnosis acc on 90mins: 1.0
[0.92493129 0.94551039 0.99965191 0.84596145 0.86000645 0.77833903]
pred: 0.8924000859260559, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp057-nsrr

=== Test on chp058-nsrr. train_data(407), test_data(5) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.603001, loss_ss: 1.819473, loss_d: 0.783528
0.2457 --- loss: 2.246133, loss_ss: 1.602954, loss_d: 0.643179
0.4914 --- loss: 1.787856, loss_ss: 1.514574, loss_d: 0.273282
0.7371 --- loss: 2.355783, loss_ss: 1.499587, loss_d: 0.856196
0.9828 --- loss: 2.054499, loss_ss: 1.499384, loss_d: 0.555115
Epoch finished! Loss: 2.2759348928928373
Starting epoch 2/10.
0.0000 --- loss: 1.998991, loss_ss: 1.473590, loss_d: 0.525401
0.2457 --- loss: 1.971776, loss_ss: 1.576573, loss_d: 0.395202
0.4914 --- loss: 2.240970, loss_ss: 1.430135, loss_d: 0.810835
0.7371 --- loss: 2.092989, loss_ss: 1.432834, loss_d: 0.660156
0.9828 --- loss: 1.927458, loss_ss: 1.350385, loss_d: 0.577073
Epoch finished! Loss: 2.067229574918747
Starting epoch 3/10.
0.0000 --- loss: 1.998660, loss_ss: 1.445202, loss_d: 0.553458
0.2457 --- loss: 1.975936, loss_ss: 1.375269, loss_d: 0.600667
0.4914 --- loss: 1.901060, loss_ss: 1.350331, loss_d: 0.550729
0.7371 --- loss: 1.753985, loss_ss: 1.339892, loss_d: 0.414093
0.9828 --- loss: 1.940898, loss_ss: 1.418482, loss_d: 0.522416
Epoch finished! Loss: 1.930502897500992
Starting epoch 4/10.
0.0000 --- loss: 1.708737, loss_ss: 1.406561, loss_d: 0.302176
0.2457 --- loss: 1.756936, loss_ss: 1.250577, loss_d: 0.506359
0.4914 --- loss: 1.726633, loss_ss: 1.243899, loss_d: 0.482734
0.7371 --- loss: 1.553579, loss_ss: 1.220219, loss_d: 0.333360
0.9828 --- loss: 1.460177, loss_ss: 1.341219, loss_d: 0.118958
Epoch finished! Loss: 1.805115082859993
Starting epoch 5/10.
0.0000 --- loss: 1.773381, loss_ss: 1.331075, loss_d: 0.442307
0.2457 --- loss: 1.604182, loss_ss: 1.290941, loss_d: 0.313240
0.4914 --- loss: 1.494883, loss_ss: 1.154419, loss_d: 0.340464
0.7371 --- loss: 1.758898, loss_ss: 1.152693, loss_d: 0.606205
0.9828 --- loss: 1.898772, loss_ss: 1.253204, loss_d: 0.645568
Epoch finished! Loss: 1.7424281895160676
Starting epoch 6/10.
0.0000 --- loss: 1.481626, loss_ss: 1.114880, loss_d: 0.366746
0.2457 --- loss: 1.666355, loss_ss: 1.345181, loss_d: 0.321175
0.4914 --- loss: 1.759169, loss_ss: 1.023502, loss_d: 0.735667
0.7371 --- loss: 1.429278, loss_ss: 1.210042, loss_d: 0.219236
0.9828 --- loss: 1.595399, loss_ss: 1.153649, loss_d: 0.441751
Epoch finished! Loss: 1.6172500014305116
Starting epoch 7/10.
0.0000 --- loss: 1.222827, loss_ss: 1.131109, loss_d: 0.091718
0.2457 --- loss: 1.433932, loss_ss: 1.271972, loss_d: 0.161960
0.4914 --- loss: 1.218106, loss_ss: 1.085830, loss_d: 0.132276
0.7371 --- loss: 1.357434, loss_ss: 1.112044, loss_d: 0.245390
0.9828 --- loss: 1.465172, loss_ss: 1.131652, loss_d: 0.333520
Epoch finished! Loss: 1.4356202811002732
Starting epoch 8/10.
0.0000 --- loss: 1.305426, loss_ss: 1.180226, loss_d: 0.125200
0.2457 --- loss: 1.264309, loss_ss: 1.163350, loss_d: 0.100959
0.4914 --- loss: 1.415155, loss_ss: 0.944656, loss_d: 0.470499
0.7371 --- loss: 0.996894, loss_ss: 0.975524, loss_d: 0.021370
0.9828 --- loss: 1.236912, loss_ss: 1.062084, loss_d: 0.174828
Epoch finished! Loss: 1.2503063321113586
Starting epoch 9/10.
0.0000 --- loss: 1.065042, loss_ss: 1.050196, loss_d: 0.014846
0.2457 --- loss: 1.163412, loss_ss: 1.127779, loss_d: 0.035632
0.4914 --- loss: 1.244094, loss_ss: 1.107266, loss_d: 0.136828
0.7371 --- loss: 1.221748, loss_ss: 1.077653, loss_d: 0.144095
0.9828 --- loss: 0.994970, loss_ss: 0.990789, loss_d: 0.004181
Epoch finished! Loss: 1.134362319111824
Starting epoch 10/10.
0.0000 --- loss: 1.025422, loss_ss: 1.016867, loss_d: 0.008555
0.2457 --- loss: 1.260606, loss_ss: 1.056006, loss_d: 0.204600
0.4914 --- loss: 1.119475, loss_ss: 1.107623, loss_d: 0.011852
0.7371 --- loss: 0.920615, loss_ss: 0.907334, loss_d: 0.013282
0.9828 --- loss: 1.168988, loss_ss: 1.018453, loss_d: 0.150534
Epoch finished! Loss: 1.1918888792395592
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.6222222222222222
              precision    recall  f1-score   support

         0.0       0.55      0.16      0.25       105
         1.0       0.00      0.00      0.00        44
         2.0       0.66      0.58      0.62       290
         3.0       0.96      0.67      0.79       228
         4.0       0.49      0.96      0.65       233

    accuracy                           0.62       900
   macro avg       0.53      0.47      0.46       900
weighted avg       0.65      0.62      0.60       900
 


====== chp058-nsrr ======

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  88.67  16.19   98.24  54.84     25.00
1  94.56   0.00   99.42   0.00      0.00
2  76.89  57.59   86.07  66.27     61.62
3  90.78  66.67   98.96  95.60     78.55
4  73.56  96.14   65.67  49.45     65.31
Total accuracy: 62.22%
Average sen: 47.32%
Average spec: 89.67%
Macro f1-score: 46.10%
Diagnosis acc on 90mins: 0.8
[0.89198333 1.         0.99997318 0.42351785 1.        ]
pred: 0.8630948722362518, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp058-nsrr

=== Test on chp059-nsrr. train_data(406), test_data(6) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.353535, loss_ss: 1.701710, loss_d: 0.651825
0.2463 --- loss: 1.829425, loss_ss: 1.455337, loss_d: 0.374088
0.4926 --- loss: 2.014824, loss_ss: 1.477052, loss_d: 0.537773
0.7389 --- loss: 2.197461, loss_ss: 1.383097, loss_d: 0.814363
0.9852 --- loss: 1.770879, loss_ss: 1.394800, loss_d: 0.376079
Epoch finished! Loss: 2.20644069314003
Starting epoch 2/10.
0.0000 --- loss: 1.930474, loss_ss: 1.350848, loss_d: 0.579626
0.2463 --- loss: 2.011339, loss_ss: 1.378975, loss_d: 0.632363
0.4926 --- loss: 1.998024, loss_ss: 1.456253, loss_d: 0.541771
0.7389 --- loss: 1.759380, loss_ss: 1.287757, loss_d: 0.471623
0.9852 --- loss: 1.921048, loss_ss: 1.367602, loss_d: 0.553446
Epoch finished! Loss: 1.97163567841053
Starting epoch 3/10.
0.0000 --- loss: 1.739069, loss_ss: 1.217304, loss_d: 0.521765
0.2463 --- loss: 2.018447, loss_ss: 1.322743, loss_d: 0.695705
0.4926 --- loss: 1.779828, loss_ss: 1.355904, loss_d: 0.423924
0.7389 --- loss: 1.562249, loss_ss: 1.260805, loss_d: 0.301444
0.9852 --- loss: 1.578506, loss_ss: 1.146614, loss_d: 0.431892
Epoch finished! Loss: 1.8655466377735137
Starting epoch 4/10.
0.0000 --- loss: 1.781236, loss_ss: 1.253914, loss_d: 0.527322
0.2463 --- loss: 2.054889, loss_ss: 1.226675, loss_d: 0.828214
0.4926 --- loss: 1.820292, loss_ss: 1.144701, loss_d: 0.675591
0.7389 --- loss: 1.752501, loss_ss: 1.195707, loss_d: 0.556794
0.9852 --- loss: 1.518528, loss_ss: 1.016875, loss_d: 0.501653
Epoch finished! Loss: 1.7546423137187959
Starting epoch 5/10.
0.0000 --- loss: 1.732522, loss_ss: 1.105849, loss_d: 0.626673
0.2463 --- loss: 1.424393, loss_ss: 1.144708, loss_d: 0.279685
0.4926 --- loss: 1.941384, loss_ss: 1.211328, loss_d: 0.730055
0.7389 --- loss: 1.553471, loss_ss: 1.139171, loss_d: 0.414300
0.9852 --- loss: 1.567195, loss_ss: 1.238460, loss_d: 0.328735
Epoch finished! Loss: 1.6587450921535491
Starting epoch 6/10.
0.0000 --- loss: 1.453025, loss_ss: 1.117749, loss_d: 0.335276
0.2463 --- loss: 1.291520, loss_ss: 1.009792, loss_d: 0.281728
0.4926 --- loss: 1.699525, loss_ss: 1.103158, loss_d: 0.596366
0.7389 --- loss: 1.323333, loss_ss: 1.070055, loss_d: 0.253278
0.9852 --- loss: 1.720010, loss_ss: 1.062292, loss_d: 0.657717
Epoch finished! Loss: 1.5314112722873687
Starting epoch 7/10.
0.0000 --- loss: 1.348745, loss_ss: 0.970725, loss_d: 0.378020
0.2463 --- loss: 1.254094, loss_ss: 1.050670, loss_d: 0.203424
0.4926 --- loss: 1.318443, loss_ss: 0.978711, loss_d: 0.339732
0.7389 --- loss: 1.319289, loss_ss: 0.978075, loss_d: 0.341214
0.9852 --- loss: 1.494302, loss_ss: 1.059887, loss_d: 0.434414
Epoch finished! Loss: 1.475385144352913
Starting epoch 8/10.
0.0000 --- loss: 1.287285, loss_ss: 1.126249, loss_d: 0.161036
0.2463 --- loss: 1.504503, loss_ss: 0.947573, loss_d: 0.556930
0.4926 --- loss: 1.278153, loss_ss: 0.970953, loss_d: 0.307200
0.7389 --- loss: 1.219721, loss_ss: 0.990162, loss_d: 0.229559
0.9852 --- loss: 1.531480, loss_ss: 0.992986, loss_d: 0.538495
Epoch finished! Loss: 1.2872263252735139
Starting epoch 9/10.
0.0000 --- loss: 1.170026, loss_ss: 1.043404, loss_d: 0.126622
0.2463 --- loss: 1.362142, loss_ss: 1.181674, loss_d: 0.180468
0.4926 --- loss: 1.285317, loss_ss: 1.016222, loss_d: 0.269095
0.7389 --- loss: 1.421612, loss_ss: 0.942139, loss_d: 0.479472
0.9852 --- loss: 1.020924, loss_ss: 0.889611, loss_d: 0.131313
Epoch finished! Loss: 1.1820902571082115
Starting epoch 10/10.
0.0000 --- loss: 0.990243, loss_ss: 0.939268, loss_d: 0.050975
0.2463 --- loss: 1.019794, loss_ss: 0.992164, loss_d: 0.027630
0.4926 --- loss: 0.925278, loss_ss: 0.914782, loss_d: 0.010496
0.7389 --- loss: 1.140078, loss_ss: 1.054611, loss_d: 0.085467
0.9852 --- loss: 1.102529, loss_ss: 0.953351, loss_d: 0.149178
Epoch finished! Loss: 1.139307163655758
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.649074074074074
              precision    recall  f1-score   support

         0.0       0.85      0.75      0.80       233
         1.0       0.59      0.38      0.46       238
         2.0       0.63      0.86      0.73       355
         3.0       0.00      0.00      0.00        87
         4.0       0.55      0.79      0.65       167

    accuracy                           0.65      1080
   macro avg       0.52      0.56      0.53      1080
weighted avg       0.61      0.65      0.61      1080
 


====== chp059-nsrr ======

The ppr of  3  has ZeroDivisionError.

The f1-score of  3  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  91.67  75.11   96.22  84.54     79.55
1  80.46  37.82   92.52  58.82     46.04
2  78.89  85.63   75.59  63.20     72.73
3  91.94   0.00  100.00   0.00      0.00
4  86.85  79.04   88.28  55.23     65.02
Total accuracy: 64.91%
Average sen: 55.52%
Average spec: 90.52%
Macro f1-score: 52.67%
Diagnosis acc on 90mins: 0.3333333333333333
[0.21954474 0.10792732 0.5781188  0.99786735 0.08529449 0.43333146]
pred: 0.4036806921164195, label: 1
Wrong!!! Real Diagnosis: NT1
Save 90mins of subject chp059-nsrr

=== Test on chp060-nsrr. train_data(405), test_data(7) ===
Define dataloader
==== START TRAINING ====
load model to cuda:1
Starting epoch 1/10.
0.0000 --- loss: 2.379714, loss_ss: 1.658324, loss_d: 0.721390
0.2469 --- loss: 1.878919, loss_ss: 1.395252, loss_d: 0.483667
0.4938 --- loss: 1.911597, loss_ss: 1.317024, loss_d: 0.594574
0.7407 --- loss: 1.703937, loss_ss: 1.244296, loss_d: 0.459641
0.9877 --- loss: 1.700552, loss_ss: 1.432699, loss_d: 0.267853
Epoch finished! Loss: 2.0273996740579605
Starting epoch 2/10.
0.0000 --- loss: 1.946409, loss_ss: 1.235863, loss_d: 0.710546
0.2469 --- loss: 1.579402, loss_ss: 1.233255, loss_d: 0.346147
0.4938 --- loss: 2.058836, loss_ss: 1.096100, loss_d: 0.962735
0.7407 --- loss: 1.693518, loss_ss: 1.204852, loss_d: 0.488666
0.9877 --- loss: 2.146465, loss_ss: 1.330096, loss_d: 0.816369
Epoch finished! Loss: 1.8094638288021088
Starting epoch 3/10.
0.0000 --- loss: 1.849824, loss_ss: 1.242146, loss_d: 0.607678
0.2469 --- loss: 1.673975, loss_ss: 1.112962, loss_d: 0.561014
0.4938 --- loss: 1.591205, loss_ss: 1.155339, loss_d: 0.435866
0.7407 --- loss: 1.674294, loss_ss: 1.191103, loss_d: 0.483191
0.9877 --- loss: 1.463388, loss_ss: 1.068273, loss_d: 0.395115
Epoch finished! Loss: 1.711400443315506
Starting epoch 4/10.
0.0000 --- loss: 1.506070, loss_ss: 1.047697, loss_d: 0.458373
0.2469 --- loss: 1.611342, loss_ss: 1.005512, loss_d: 0.605831
0.4938 --- loss: 1.556266, loss_ss: 1.024077, loss_d: 0.532189
0.7407 --- loss: 1.598531, loss_ss: 1.201404, loss_d: 0.397128
0.9877 --- loss: 1.595114, loss_ss: 1.110360, loss_d: 0.484754
Epoch finished! Loss: 1.589623361825943
Starting epoch 5/10.
0.0000 --- loss: 1.477314, loss_ss: 1.154557, loss_d: 0.322757
0.2469 --- loss: 1.442983, loss_ss: 1.156018, loss_d: 0.286964
0.4938 --- loss: 1.374968, loss_ss: 1.163154, loss_d: 0.211814
0.7407 --- loss: 1.693245, loss_ss: 1.184780, loss_d: 0.508464
0.9877 --- loss: 1.433936, loss_ss: 1.175118, loss_d: 0.258817
Epoch finished! Loss: 1.5078790456056594
Starting epoch 6/10.
0.0000 --- loss: 1.318878, loss_ss: 1.022393, loss_d: 0.296485
0.2469 --- loss: 1.280703, loss_ss: 0.984585, loss_d: 0.296119
0.4938 --- loss: 1.123120, loss_ss: 1.007088, loss_d: 0.116032
0.7407 --- loss: 1.146001, loss_ss: 0.906965, loss_d: 0.239037
0.9877 --- loss: 1.386333, loss_ss: 1.224119, loss_d: 0.162213
Epoch finished! Loss: 1.3707620322704315
Starting epoch 7/10.
0.0000 --- loss: 1.114853, loss_ss: 0.943304, loss_d: 0.171548
0.2469 --- loss: 1.085902, loss_ss: 0.890281, loss_d: 0.195621
0.4938 --- loss: 1.089929, loss_ss: 0.932502, loss_d: 0.157426
0.7407 --- loss: 1.163868, loss_ss: 1.122477, loss_d: 0.041392
0.9877 --- loss: 1.314429, loss_ss: 1.276513, loss_d: 0.037916
Epoch finished! Loss: 1.2446455478668212
Starting epoch 8/10.
0.0000 --- loss: 0.926634, loss_ss: 0.912336, loss_d: 0.014298
0.2469 --- loss: 1.188737, loss_ss: 0.883416, loss_d: 0.305321
0.4938 --- loss: 1.095205, loss_ss: 0.882745, loss_d: 0.212461
0.7407 --- loss: 1.252178, loss_ss: 0.919705, loss_d: 0.332473
0.9877 --- loss: 1.033769, loss_ss: 1.019067, loss_d: 0.014701
Epoch finished! Loss: 1.172648911178112
Starting epoch 9/10.
0.0000 --- loss: 1.012604, loss_ss: 0.926431, loss_d: 0.086174
0.2469 --- loss: 1.492375, loss_ss: 0.978494, loss_d: 0.513881
0.4938 --- loss: 1.032903, loss_ss: 0.992057, loss_d: 0.040846
0.7407 --- loss: 1.050226, loss_ss: 1.020737, loss_d: 0.029489
0.9877 --- loss: 1.023926, loss_ss: 0.996478, loss_d: 0.027447
Epoch finished! Loss: 1.147520750761032
Starting epoch 10/10.
0.0000 --- loss: 0.991742, loss_ss: 0.976163, loss_d: 0.015579
0.2469 --- loss: 1.208584, loss_ss: 1.084368, loss_d: 0.124216
0.4938 --- loss: 0.918355, loss_ss: 0.886953, loss_d: 0.031403
0.7407 --- loss: 0.939996, loss_ss: 0.908687, loss_d: 0.031309
0.9877 --- loss: 1.346847, loss_ss: 1.021962, loss_d: 0.324885
Epoch finished! Loss: 1.0603850066661835
Model saved !

==== START TESTING ====
hello
Sleep stage: acc = 0.5753968253968254
              precision    recall  f1-score   support

         0.0       0.81      0.56      0.67       519
         1.0       0.00      0.00      0.00       201
         2.0       0.44      0.86      0.58       228
         3.0       0.80      0.95      0.87       158
         4.0       0.32      0.56      0.41       154

    accuracy                           0.58      1260
   macro avg       0.48      0.59      0.51      1260
weighted avg       0.55      0.58      0.54      1260
 


====== chp060-nsrr ======

The ppr of  1  has ZeroDivisionError.

The f1-score of  1  has ZeroDivisionError.
   acc %  sen %  spec %  ppr %  f1-score
0  76.67  56.45   90.82  81.16     66.59
1  84.05   0.00  100.00   0.00      0.00
2  77.62  85.53   75.87  43.92     58.04
3  96.43  94.94   96.64  80.21     86.96
4  80.32  56.49   83.63  32.46     41.23
Total accuracy: 57.54%
Average sen: 58.68%
Average spec: 89.39%
Macro f1-score: 50.56%
Diagnosis acc on 90mins: 1.0
[0.99951863 0.99968946 0.99332952 0.9996413  0.99915767 0.99998415
 0.99999797]
pred: 0.9987598146711077, label: 1
Right! Diagnosis: NT1
Save 90mins of subject chp060-nsrr

====== all ======
   acc %  sen %  spec %  ppr %  f1-score
0  87.71  56.58   92.73  55.66     56.11
1  87.11   1.74   99.58  37.61      3.32
2  75.34  80.76   72.01  63.93     71.37
3  91.51  76.16   94.89  76.69     76.43
4  83.94  59.34   89.07  53.09     56.04
Total accuracy: 62.81%
Average sen: 54.92%
Average spec: 89.66%
Macro f1-score: 52.65%
Diagnosis acc on patients: 0.7051282051282052

====== all ======
   acc %  sen %  spec %  ppr %  f1-score
0  70.51   8.70   96.36  50.00     14.81
1  70.51  96.36    8.70  71.62     82.17
Total accuracy: 70.51%
Average sen: 52.53%
Average spec: 52.53%
Macro f1-score: 48.49%
fpr: 0.0, tpr: 0.0, threshold: 1.9987598146711076, 
fpr: 0.0, tpr: 0.01818181818181818, threshold: 0.9987598146711077, 
fpr: 0.0, tpr: 0.23636363636363636, threshold: 0.954121994972229, 
fpr: 0.043478260869565216, tpr: 0.23636363636363636, threshold: 0.950802993774414, 
fpr: 0.043478260869565216, tpr: 0.2545454545454545, threshold: 0.939644475777944, 
fpr: 0.08695652173913043, tpr: 0.2545454545454545, threshold: 0.9376125633716583, 
fpr: 0.08695652173913043, tpr: 0.2727272727272727, threshold: 0.9343723058700562, 
fpr: 0.17391304347826086, tpr: 0.2727272727272727, threshold: 0.9217842578887939, 
fpr: 0.17391304347826086, tpr: 0.2909090909090909, threshold: 0.9197148442268371, 
fpr: 0.21739130434782608, tpr: 0.2909090909090909, threshold: 0.917529284954071, 
fpr: 0.21739130434782608, tpr: 0.4909090909090909, threshold: 0.8449740409851074, 
fpr: 0.30434782608695654, tpr: 0.4909090909090909, threshold: 0.8297281265258789, 
fpr: 0.30434782608695654, tpr: 0.5272727272727272, threshold: 0.8224630554517111, 
fpr: 0.34782608695652173, tpr: 0.5272727272727272, threshold: 0.8181647235566439, 
fpr: 0.34782608695652173, tpr: 0.5454545454545454, threshold: 0.8174445300052563, 
fpr: 0.391304347826087, tpr: 0.5454545454545454, threshold: 0.8172914385795593, 
fpr: 0.391304347826087, tpr: 0.6181818181818182, threshold: 0.7952667666333062, 
fpr: 0.43478260869565216, tpr: 0.6181818181818182, threshold: 0.7749576580710709, 
fpr: 0.43478260869565216, tpr: 0.6363636363636364, threshold: 0.7574407219265898, 
fpr: 0.4782608695652174, tpr: 0.6363636363636364, threshold: 0.7510815113782883, 
fpr: 0.4782608695652174, tpr: 0.6727272727272727, threshold: 0.7388100638985634, 
fpr: 0.5217391304347826, tpr: 0.6727272727272727, threshold: 0.7387440458405763, 
fpr: 0.5217391304347826, tpr: 0.7090909090909091, threshold: 0.7325210767856334, 
fpr: 0.5652173913043478, tpr: 0.7090909090909091, threshold: 0.729091489315033, 
fpr: 0.5652173913043478, tpr: 0.7272727272727273, threshold: 0.7268870562314987, 
fpr: 0.6086956521739131, tpr: 0.7272727272727273, threshold: 0.7032286124303937, 
fpr: 0.6086956521739131, tpr: 0.8, threshold: 0.6772236277659734, 
fpr: 0.6521739130434783, tpr: 0.8, threshold: 0.6687420886009932, 
fpr: 0.6521739130434783, tpr: 0.8545454545454545, threshold: 0.6598912522196769, 
fpr: 0.6956521739130435, tpr: 0.8545454545454545, threshold: 0.6393452227115631, 
fpr: 0.6956521739130435, tpr: 0.9272727272727272, threshold: 0.6135733008384705, 
fpr: 0.7391304347826086, tpr: 0.9272727272727272, threshold: 0.605251919478178, 
fpr: 0.7391304347826086, tpr: 0.9454545454545454, threshold: 0.597907608995835, 
fpr: 0.9130434782608695, tpr: 0.9454545454545454, threshold: 0.5551316186785697, 
fpr: 0.9130434782608695, tpr: 1.0, threshold: 0.4036806921164195, 
fpr: 1.0, tpr: 1.0, threshold: 0.35499224066734314, 

=== best_threshold: 0.8449740409851074, best_fpr: 0.21739130434782608, best_tpr: 0.4909090909090909 ===
fpr: 0.0, tpr: 0.0, threshold: 2.0, 
fpr: 0.009433962264150943, tpr: 0.026143790849673203, threshold: 1.0, 
fpr: 0.009433962264150943, tpr: 0.032679738562091505, threshold: 0.9999998807907104, 
fpr: 0.009433962264150943, tpr: 0.05228758169934641, threshold: 0.9999967813491821, 
fpr: 0.018867924528301886, tpr: 0.05228758169934641, threshold: 0.9999939203262329, 
fpr: 0.018867924528301886, tpr: 0.05555555555555555, threshold: 0.9999924898147583, 
fpr: 0.02830188679245283, tpr: 0.05555555555555555, threshold: 0.9999923706054688, 
fpr: 0.02830188679245283, tpr: 0.07516339869281045, threshold: 0.9999731779098511, 
fpr: 0.03773584905660377, tpr: 0.07516339869281045, threshold: 0.9999722242355347, 
fpr: 0.03773584905660377, tpr: 0.1111111111111111, threshold: 0.9999234676361084, 
fpr: 0.04716981132075472, tpr: 0.1111111111111111, threshold: 0.9999086856842041, 
fpr: 0.04716981132075472, tpr: 0.11437908496732026, threshold: 0.9999061822891235, 
fpr: 0.05660377358490566, tpr: 0.11437908496732026, threshold: 0.9998977184295654, 
fpr: 0.05660377358490566, tpr: 0.12418300653594772, threshold: 0.9998745918273926, 
fpr: 0.0660377358490566, tpr: 0.12418300653594772, threshold: 0.9998664855957031, 
fpr: 0.0660377358490566, tpr: 0.14052287581699346, threshold: 0.9998157620429993, 
fpr: 0.07547169811320754, tpr: 0.14052287581699346, threshold: 0.99980229139328, 
fpr: 0.07547169811320754, tpr: 0.14705882352941177, threshold: 0.9997532963752747, 
fpr: 0.08490566037735849, tpr: 0.14705882352941177, threshold: 0.9997311234474182, 
fpr: 0.08490566037735849, tpr: 0.17320261437908496, threshold: 0.9996412992477417, 
fpr: 0.09433962264150944, tpr: 0.17320261437908496, threshold: 0.9996167421340942, 
fpr: 0.09433962264150944, tpr: 0.20261437908496732, threshold: 0.9993588328361511, 
fpr: 0.12264150943396226, tpr: 0.20261437908496732, threshold: 0.9992597699165344, 
fpr: 0.12264150943396226, tpr: 0.22875816993464052, threshold: 0.9990218877792358, 
fpr: 0.1320754716981132, tpr: 0.22875816993464052, threshold: 0.9989302754402161, 
fpr: 0.1320754716981132, tpr: 0.23202614379084968, threshold: 0.9989275336265564, 
fpr: 0.1509433962264151, tpr: 0.23202614379084968, threshold: 0.9987180233001709, 
fpr: 0.1509433962264151, tpr: 0.2777777777777778, threshold: 0.9978673458099365, 
fpr: 0.16981132075471697, tpr: 0.2777777777777778, threshold: 0.9978111386299133, 
fpr: 0.16981132075471697, tpr: 0.30392156862745096, threshold: 0.9969155788421631, 
fpr: 0.19811320754716982, tpr: 0.30392156862745096, threshold: 0.996440589427948, 
fpr: 0.19811320754716982, tpr: 0.3366013071895425, threshold: 0.9953728318214417, 
fpr: 0.20754716981132076, tpr: 0.3366013071895425, threshold: 0.9952124357223511, 
fpr: 0.20754716981132076, tpr: 0.34967320261437906, threshold: 0.9944646954536438, 
fpr: 0.2169811320754717, tpr: 0.34967320261437906, threshold: 0.9943090677261353, 
fpr: 0.2169811320754717, tpr: 0.35294117647058826, threshold: 0.9941313862800598, 
fpr: 0.22641509433962265, tpr: 0.35294117647058826, threshold: 0.9934718608856201, 
fpr: 0.22641509433962265, tpr: 0.3562091503267974, threshold: 0.9933295249938965, 
fpr: 0.24528301886792453, tpr: 0.3562091503267974, threshold: 0.993190348148346, 
fpr: 0.24528301886792453, tpr: 0.3790849673202614, threshold: 0.9921653270721436, 
fpr: 0.25471698113207547, tpr: 0.3790849673202614, threshold: 0.9920642971992493, 
fpr: 0.25471698113207547, tpr: 0.38235294117647056, threshold: 0.9919968247413635, 
fpr: 0.2641509433962264, tpr: 0.38235294117647056, threshold: 0.9917742609977722, 
fpr: 0.2641509433962264, tpr: 0.38562091503267976, threshold: 0.991548478603363, 
fpr: 0.27358490566037735, tpr: 0.38562091503267976, threshold: 0.9914304614067078, 
fpr: 0.27358490566037735, tpr: 0.4084967320261438, threshold: 0.9899178147315979, 
fpr: 0.2830188679245283, tpr: 0.4084967320261438, threshold: 0.9898813366889954, 
fpr: 0.2830188679245283, tpr: 0.4117647058823529, threshold: 0.9896933436393738, 
fpr: 0.29245283018867924, tpr: 0.4117647058823529, threshold: 0.9894266128540039, 
fpr: 0.29245283018867924, tpr: 0.41830065359477125, threshold: 0.9891214966773987, 
fpr: 0.3018867924528302, tpr: 0.41830065359477125, threshold: 0.9889059066772461, 
fpr: 0.3018867924528302, tpr: 0.42483660130718953, threshold: 0.9884268641471863, 
fpr: 0.3113207547169811, tpr: 0.42483660130718953, threshold: 0.9879586696624756, 
fpr: 0.3113207547169811, tpr: 0.46405228758169936, threshold: 0.983620285987854, 
fpr: 0.330188679245283, tpr: 0.46405228758169936, threshold: 0.9829476475715637, 
fpr: 0.330188679245283, tpr: 0.4738562091503268, threshold: 0.9824057221412659, 
fpr: 0.3490566037735849, tpr: 0.4738562091503268, threshold: 0.9813341498374939, 
fpr: 0.3490566037735849, tpr: 0.4934640522875817, threshold: 0.9772387742996216, 
fpr: 0.3584905660377358, tpr: 0.4934640522875817, threshold: 0.9760629534721375, 
fpr: 0.3584905660377358, tpr: 0.5196078431372549, threshold: 0.9718300700187683, 
fpr: 0.36792452830188677, tpr: 0.5196078431372549, threshold: 0.9716759920120239, 
fpr: 0.36792452830188677, tpr: 0.5228758169934641, threshold: 0.9710503816604614, 
fpr: 0.3867924528301887, tpr: 0.5228758169934641, threshold: 0.9701952338218689, 
fpr: 0.3867924528301887, tpr: 0.5261437908496732, threshold: 0.9700602889060974, 
fpr: 0.39622641509433965, tpr: 0.5261437908496732, threshold: 0.9690796136856079, 
fpr: 0.39622641509433965, tpr: 0.5326797385620915, threshold: 0.9684039950370789, 
fpr: 0.4056603773584906, tpr: 0.5326797385620915, threshold: 0.9670818448066711, 
fpr: 0.4056603773584906, tpr: 0.5555555555555556, threshold: 0.9622024297714233, 
fpr: 0.41509433962264153, tpr: 0.5555555555555556, threshold: 0.9606946706771851, 
fpr: 0.41509433962264153, tpr: 0.5686274509803921, threshold: 0.9571375250816345, 
fpr: 0.42452830188679247, tpr: 0.5686274509803921, threshold: 0.9561477303504944, 
fpr: 0.42452830188679247, tpr: 0.5718954248366013, threshold: 0.9550842642784119, 
fpr: 0.4339622641509434, tpr: 0.5718954248366013, threshold: 0.9541155695915222, 
fpr: 0.4339622641509434, tpr: 0.6078431372549019, threshold: 0.9363484382629395, 
fpr: 0.44339622641509435, tpr: 0.6078431372549019, threshold: 0.9341772198677063, 
fpr: 0.44339622641509435, tpr: 0.6111111111111112, threshold: 0.9335225820541382, 
fpr: 0.46226415094339623, tpr: 0.6111111111111112, threshold: 0.929487943649292, 
fpr: 0.46226415094339623, tpr: 0.6274509803921569, threshold: 0.9244710803031921, 
fpr: 0.4716981132075472, tpr: 0.6274509803921569, threshold: 0.9242214560508728, 
fpr: 0.4716981132075472, tpr: 0.6339869281045751, threshold: 0.9161523580551147, 
fpr: 0.4811320754716981, tpr: 0.6339869281045751, threshold: 0.9119038581848145, 
fpr: 0.4811320754716981, tpr: 0.6405228758169934, threshold: 0.9095064401626587, 
fpr: 0.5, tpr: 0.6405228758169934, threshold: 0.9042444825172424, 
fpr: 0.5, tpr: 0.6437908496732027, threshold: 0.9033909440040588, 
fpr: 0.5094339622641509, tpr: 0.6437908496732027, threshold: 0.9023159146308899, 
fpr: 0.5094339622641509, tpr: 0.6470588235294118, threshold: 0.9009901285171509, 
fpr: 0.5188679245283019, tpr: 0.6470588235294118, threshold: 0.8928219676017761, 
fpr: 0.5188679245283019, tpr: 0.6503267973856209, threshold: 0.8919833302497864, 
fpr: 0.5283018867924528, tpr: 0.6503267973856209, threshold: 0.8912078738212585, 
fpr: 0.5283018867924528, tpr: 0.6666666666666666, threshold: 0.8831123113632202, 
fpr: 0.5471698113207547, tpr: 0.6666666666666666, threshold: 0.8742551803588867, 
fpr: 0.5471698113207547, tpr: 0.6764705882352942, threshold: 0.8677016496658325, 
fpr: 0.5566037735849056, tpr: 0.6764705882352942, threshold: 0.8633224368095398, 
fpr: 0.5566037735849056, tpr: 0.6797385620915033, threshold: 0.8600064516067505, 
fpr: 0.5660377358490566, tpr: 0.6797385620915033, threshold: 0.8578475117683411, 
fpr: 0.5660377358490566, tpr: 0.6830065359477124, threshold: 0.8542925119400024, 
fpr: 0.5754716981132075, tpr: 0.6830065359477124, threshold: 0.854068398475647, 
fpr: 0.5754716981132075, tpr: 0.6928104575163399, threshold: 0.8295936584472656, 
fpr: 0.5849056603773585, tpr: 0.6928104575163399, threshold: 0.8218798637390137, 
fpr: 0.5849056603773585, tpr: 0.7026143790849673, threshold: 0.8100523948669434, 
fpr: 0.5943396226415094, tpr: 0.7026143790849673, threshold: 0.8051603436470032, 
fpr: 0.5943396226415094, tpr: 0.7058823529411765, threshold: 0.8021241426467896, 
fpr: 0.6037735849056604, tpr: 0.7058823529411765, threshold: 0.802056610584259, 
fpr: 0.6037735849056604, tpr: 0.7156862745098039, threshold: 0.7843996286392212, 
fpr: 0.6132075471698113, tpr: 0.7156862745098039, threshold: 0.7822588086128235, 
fpr: 0.6132075471698113, tpr: 0.7222222222222222, threshold: 0.7759721875190735, 
fpr: 0.6415094339622641, tpr: 0.7222222222222222, threshold: 0.7602809071540833, 
fpr: 0.6415094339622641, tpr: 0.7320261437908496, threshold: 0.7519509196281433, 
fpr: 0.6509433962264151, tpr: 0.7320261437908496, threshold: 0.7492084503173828, 
fpr: 0.6509433962264151, tpr: 0.7352941176470589, threshold: 0.7410868406295776, 
fpr: 0.6698113207547169, tpr: 0.7352941176470589, threshold: 0.7229868769645691, 
fpr: 0.6698113207547169, tpr: 0.7516339869281046, threshold: 0.7074857950210571, 
fpr: 0.6792452830188679, tpr: 0.7516339869281046, threshold: 0.7033924460411072, 
fpr: 0.6792452830188679, tpr: 0.761437908496732, threshold: 0.6952915787696838, 
fpr: 0.6886792452830188, tpr: 0.761437908496732, threshold: 0.6924359202384949, 
fpr: 0.6886792452830188, tpr: 0.7679738562091504, threshold: 0.6903132796287537, 
fpr: 0.6981132075471698, tpr: 0.7679738562091504, threshold: 0.6872503161430359, 
fpr: 0.6981132075471698, tpr: 0.7777777777777778, threshold: 0.6672152876853943, 
fpr: 0.7075471698113207, tpr: 0.7777777777777778, threshold: 0.6624259352684021, 
fpr: 0.7075471698113207, tpr: 0.8169934640522876, threshold: 0.5874484181404114, 
fpr: 0.7264150943396226, tpr: 0.8169934640522876, threshold: 0.5817517638206482, 
fpr: 0.7264150943396226, tpr: 0.8202614379084967, threshold: 0.5781188011169434, 
fpr: 0.7547169811320755, tpr: 0.8202614379084967, threshold: 0.5389577746391296, 
fpr: 0.7547169811320755, tpr: 0.8300653594771242, threshold: 0.507325291633606, 
fpr: 0.7641509433962265, tpr: 0.8300653594771242, threshold: 0.4825100898742676, 
fpr: 0.7641509433962265, tpr: 0.8627450980392157, threshold: 0.39455363154411316, 
fpr: 0.7735849056603774, tpr: 0.8627450980392157, threshold: 0.3916069567203522, 
fpr: 0.7735849056603774, tpr: 0.869281045751634, threshold: 0.38206058740615845, 
fpr: 0.7830188679245284, tpr: 0.869281045751634, threshold: 0.3798055946826935, 
fpr: 0.7830188679245284, tpr: 0.8725490196078431, threshold: 0.3769890367984772, 
fpr: 0.8018867924528302, tpr: 0.8725490196078431, threshold: 0.34902024269104004, 
fpr: 0.8018867924528302, tpr: 0.8823529411764706, threshold: 0.3179667592048645, 
fpr: 0.8113207547169812, tpr: 0.8823529411764706, threshold: 0.3174050450325012, 
fpr: 0.8113207547169812, tpr: 0.8856209150326797, threshold: 0.3168488144874573, 
fpr: 0.8207547169811321, tpr: 0.8856209150326797, threshold: 0.31158098578453064, 
fpr: 0.8207547169811321, tpr: 0.8921568627450981, threshold: 0.297203928232193, 
fpr: 0.8301886792452831, tpr: 0.8921568627450981, threshold: 0.28683966398239136, 
fpr: 0.8301886792452831, tpr: 0.8986928104575164, threshold: 0.2770555317401886, 
fpr: 0.8490566037735849, tpr: 0.8986928104575164, threshold: 0.250129371881485, 
fpr: 0.8490566037735849, tpr: 0.9019607843137255, threshold: 0.24238628149032593, 
fpr: 0.8584905660377359, tpr: 0.9019607843137255, threshold: 0.23329155147075653, 
fpr: 0.8584905660377359, tpr: 0.9052287581699346, threshold: 0.21954473853111267, 
fpr: 0.8679245283018868, tpr: 0.9052287581699346, threshold: 0.20311607420444489, 
fpr: 0.8679245283018868, tpr: 0.9150326797385621, threshold: 0.1687590330839157, 
fpr: 0.8773584905660378, tpr: 0.9150326797385621, threshold: 0.16524741053581238, 
fpr: 0.8773584905660378, tpr: 0.9248366013071896, threshold: 0.15406635403633118, 
fpr: 0.8867924528301887, tpr: 0.9248366013071896, threshold: 0.14759239554405212, 
fpr: 0.8867924528301887, tpr: 0.934640522875817, threshold: 0.12063821405172348, 
fpr: 0.8962264150943396, tpr: 0.934640522875817, threshold: 0.11014419049024582, 
fpr: 0.8962264150943396, tpr: 0.9411764705882353, threshold: 0.08529448509216309, 
fpr: 0.9245283018867925, tpr: 0.9411764705882353, threshold: 0.07511460781097412, 
fpr: 0.9245283018867925, tpr: 0.9477124183006536, threshold: 0.057486142963171005, 
fpr: 0.9339622641509434, tpr: 0.9477124183006536, threshold: 0.05355914309620857, 
fpr: 0.9339622641509434, tpr: 0.9771241830065359, threshold: 0.029537737369537354, 
fpr: 0.9433962264150944, tpr: 0.9771241830065359, threshold: 0.029247203841805458, 
fpr: 0.9433962264150944, tpr: 0.9836601307189542, threshold: 0.00992539618164301, 
fpr: 0.9716981132075472, tpr: 0.9836601307189542, threshold: 0.008286518044769764, 
fpr: 0.9716981132075472, tpr: 0.9901960784313726, threshold: 0.005567931570112705, 
fpr: 0.9811320754716981, tpr: 0.9901960784313726, threshold: 0.00471270689740777, 
fpr: 0.9811320754716981, tpr: 0.9934640522875817, threshold: 0.0025028595700860023, 
fpr: 1.0, tpr: 0.9934640522875817, threshold: 0.0011371949221938848, 
fpr: 1.0, tpr: 1.0, threshold: 0.0001747994974721223, 

=== best_threshold: 0.9363484382629395, best_fpr: 0.4339622641509434, best_tpr: 0.6078431372549019 ===
