nohup: ignoring input
cuda:0
Subjects num: 78

2.5min inputs: chc001-nsrr (160)
2.5min inputs: chc004-nsrr (213)
2.5min inputs: chc005-nsrr (190)
2.5min inputs: chc006-nsrr (165)
2.5min inputs: chc008-nsrr (192)
2.5min inputs: chc009-nsrr (178)
2.5min inputs: chc010-nsrr (172)
2.5min inputs: chc012-nsrr (184)
2.5min inputs: chc013-nsrr (188)
2.5min inputs: chc014-nsrr (191)
2.5min inputs: chc015-nsrr (187)
2.5min inputs: chc016-nsrr (191)
2.5min inputs: chc022-nsrr (162)
2.5min inputs: chc025-nsrr (166)
2.5min inputs: chc027-nsrr (180)
2.5min inputs: chc028-nsrr (177)
2.5min inputs: chc033-nsrr (174)
2.5min inputs: chc035-nsrr (180)
2.5min inputs: chc037-nsrr (177)
2.5min inputs: chc040-nsrr (216)
2.5min inputs: chc041-nsrr (171)
2.5min inputs: chc052-nsrr (183)
2.5min inputs: chc056-nsrr (184)
2.5min inputs: chp001-nsrr (232)
2.5min inputs: chp002-nsrr (216)
2.5min inputs: chp003-nsrr (200)
2.5min inputs: chp004-nsrr (197)
2.5min inputs: chp005-nsrr (261)
2.5min inputs: chp006-nsrr (220)
2.5min inputs: chp007-nsrr (231)
2.5min inputs: chp008-nsrr (191)
2.5min inputs: chp009-nsrr (206)
2.5min inputs: chp010-nsrr (194)
2.5min inputs: chp011-nsrr (202)
2.5min inputs: chp012-nsrr (223)
2.5min inputs: chp013-nsrr (200)
2.5min inputs: chp014-nsrr (201)
2.5min inputs: chp015-nsrr (231)
2.5min inputs: chp016-nsrr (254)
2.5min inputs: chp017-nsrr (202)
2.5min inputs: chp018-nsrr (225)
2.5min inputs: chp019-nsrr (188)
2.5min inputs: chp020-nsrr (230)
2.5min inputs: chp022-nsrr (253)
2.5min inputs: chp024-nsrr (225)
2.5min inputs: chp025-nsrr (89)
2.5min inputs: chp026-nsrr (188)
2.5min inputs: chp028-nsrr (206)
2.5min inputs: chp029-nsrr (209)
2.5min inputs: chp030-nsrr (240)
2.5min inputs: chp031-nsrr (222)
2.5min inputs: chp032-nsrr (213)
2.5min inputs: chp033-nsrr (202)
2.5min inputs: chp034-nsrr (208)
2.5min inputs: chp036-nsrr (252)
2.5min inputs: chp037-nsrr (207)
2.5min inputs: chp038-nsrr (205)
2.5min inputs: chp039-nsrr (222)
2.5min inputs: chp040-nsrr (214)
2.5min inputs: chp041-nsrr (221)
2.5min inputs: chp042-nsrr (223)
2.5min inputs: chp043-nsrr (241)
2.5min inputs: chp044-nsrr (210)
2.5min inputs: chp045-nsrr (241)
2.5min inputs: chp046-nsrr (219)
2.5min inputs: chp047-nsrr (178)
2.5min inputs: chp048-nsrr (206)
2.5min inputs: chp049-nsrr (216)
2.5min inputs: chp051-nsrr (218)
2.5min inputs: chp052-nsrr (200)
2.5min inputs: chp053-nsrr (217)
2.5min inputs: chp054-nsrr (224)
2.5min inputs: chp055-nsrr (222)
2.5min inputs: chp056-nsrr (220)
2.5min inputs: chp057-nsrr (239)
2.5min inputs: chp058-nsrr (206)
2.5min inputs: chp059-nsrr (227)
2.5min inputs: chp060-nsrr (252)
/home/shenning/classifier.py:225: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  conf_mats = np.zeros((5,5), dtype=np.int)

=== Test on chc001-nsrr. train_data(15860), test_data(160) ===
Define dataloader
==== START TRAINING ====
MultiCNNC2CM(
  (multicnn_se): MultiCNN_SE(
    (multicnn): MultiScalerCNN(
      (cnnblock1): CNNBlock(
        (cnnblock): Sequential(
          (0): SingleConv(
            (conv): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 50), stride=(1, 2))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (1): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)
          (2): Dropout(p=0.5, inplace=False)
          (3): SingleConv(
            (conv): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1))
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (4): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)
          (5): SingleConv(
            (conv): Sequential(
              (0): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1))
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (6): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)
        )
      )
      (cnnblock2): CNNBlock(
        (cnnblock): Sequential(
          (0): SingleConv(
            (conv): Sequential(
              (0): Conv2d(3, 64, kernel_size=(1, 20), stride=(1, 2))
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (1): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)
          (2): Dropout(p=0.5, inplace=False)
          (3): SingleConv(
            (conv): Sequential(
              (0): Conv2d(64, 128, kernel_size=(1, 3), stride=(1, 1))
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (4): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)
          (5): SingleConv(
            (conv): Sequential(
              (0): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1))
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (6): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
    )
    (se): SELayer(
      (avg_pool): AdaptiveAvgPool2d(output_size=1)
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=8, bias=False)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=8, out_features=128, bias=False)
        (3): Sigmoid()
      )
    )
  )
  (conv1): SingleConv(
    (conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 3))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (conv2): SingleConv(
    (conv): Sequential(
      (0): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 3))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (conv2_ss1): SingleConv(
    (conv): Sequential(
      (0): Conv2d(128, 5, kernel_size=(1, 4), stride=(1, 1))
      (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (out_ss): OutSleepStage(
    (outsleepstage): Conv2d(5, 5, kernel_size=(1, 1), stride=(1, 1))
  )
  (conv3): SingleConv(
    (conv): Sequential(
      (0): Conv2d(128, 256, kernel_size=(5, 1), stride=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (out_d): OutDiagnosis(
    (fc): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=1024, out_features=256, bias=True)
      (2): ReLU(inplace=True)
      (3): Linear(in_features=256, out_features=1, bias=True)
    )
  )
)
nohup: ignoring input
cuda:0
Subjects num: 78

2.5min inputs: chc001-nsrr (160)
2.5min inputs: chc004-nsrr (213)
2.5min inputs: chc005-nsrr (190)
2.5min inputs: chc006-nsrr (165)
2.5min inputs: chc008-nsrr (192)
2.5min inputs: chc009-nsrr (178)
2.5min inputs: chc010-nsrr (172)
2.5min inputs: chc012-nsrr (184)
2.5min inputs: chc013-nsrr (188)
2.5min inputs: chc014-nsrr (191)
2.5min inputs: chc015-nsrr (187)
2.5min inputs: chc016-nsrr (191)
2.5min inputs: chc022-nsrr (162)
2.5min inputs: chc025-nsrr (166)
2.5min inputs: chc027-nsrr (180)
2.5min inputs: chc028-nsrr (177)
2.5min inputs: chc033-nsrr (174)
2.5min inputs: chc035-nsrr (180)
2.5min inputs: chc037-nsrr (177)
2.5min inputs: chc040-nsrr (216)
2.5min inputs: chc041-nsrr (171)
2.5min inputs: chc052-nsrr (183)
2.5min inputs: chc056-nsrr (184)
2.5min inputs: chp001-nsrr (232)
2.5min inputs: chp002-nsrr (216)
2.5min inputs: chp003-nsrr (200)
2.5min inputs: chp004-nsrr (197)
2.5min inputs: chp005-nsrr (261)
2.5min inputs: chp006-nsrr (220)
2.5min inputs: chp007-nsrr (231)
2.5min inputs: chp008-nsrr (191)
2.5min inputs: chp009-nsrr (206)
2.5min inputs: chp010-nsrr (194)
2.5min inputs: chp011-nsrr (202)
2.5min inputs: chp012-nsrr (223)
2.5min inputs: chp013-nsrr (200)
2.5min inputs: chp014-nsrr (201)
2.5min inputs: chp015-nsrr (231)
2.5min inputs: chp016-nsrr (254)
2.5min inputs: chp017-nsrr (202)
2.5min inputs: chp018-nsrr (225)
2.5min inputs: chp019-nsrr (188)
2.5min inputs: chp020-nsrr (230)
2.5min inputs: chp022-nsrr (253)
2.5min inputs: chp024-nsrr (225)
2.5min inputs: chp025-nsrr (89)
2.5min inputs: chp026-nsrr (188)
2.5min inputs: chp028-nsrr (206)
2.5min inputs: chp029-nsrr (209)
2.5min inputs: chp030-nsrr (240)
2.5min inputs: chp031-nsrr (222)
2.5min inputs: chp032-nsrr (213)
2.5min inputs: chp033-nsrr (202)
2.5min inputs: chp034-nsrr (208)
2.5min inputs: chp036-nsrr (252)
2.5min inputs: chp037-nsrr (207)
2.5min inputs: chp038-nsrr (205)
2.5min inputs: chp039-nsrr (222)
2.5min inputs: chp040-nsrr (214)
2.5min inputs: chp041-nsrr (221)
2.5min inputs: chp042-nsrr (223)
2.5min inputs: chp043-nsrr (241)
2.5min inputs: chp044-nsrr (210)
2.5min inputs: chp045-nsrr (241)
2.5min inputs: chp046-nsrr (219)
2.5min inputs: chp047-nsrr (178)
2.5min inputs: chp048-nsrr (206)
2.5min inputs: chp049-nsrr (216)
2.5min inputs: chp051-nsrr (218)
2.5min inputs: chp052-nsrr (200)
2.5min inputs: chp053-nsrr (217)
2.5min inputs: chp054-nsrr (224)
2.5min inputs: chp055-nsrr (222)
2.5min inputs: chp056-nsrr (220)
2.5min inputs: chp057-nsrr (239)
2.5min inputs: chp058-nsrr (206)
2.5min inputs: chp059-nsrr (227)
2.5min inputs: chp060-nsrr (252)
/home/shenning/classifier.py:226: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  conf_mats = np.zeros((5,5), dtype=np.int)

=== Test on chc001-nsrr. train_data(15860), test_data(160) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
Traceback (most recent call last):
  File "/home/shenning/classifier.py", line 452, in <module>
    LeaveOneSubjectOut_loadmodel(base)
  File "/home/shenning/classifier.py", line 263, in LeaveOneSubjectOut_loadmodel
    conv3_feature = model.featuremap.cpu()
  File "/home/shenning/anaconda3/envs/narcolepsy_torch_new/lib/python3.9/site-packages/torch/nn/modules/module.py", line 947, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'MultiCNNC2CM' object has no attribute 'featuremap'
nohup: ignoring input
cuda:0
Subjects num: 78

2.5min inputs: chc001-nsrr (160)
2.5min inputs: chc004-nsrr (213)
2.5min inputs: chc005-nsrr (190)
2.5min inputs: chc006-nsrr (165)
2.5min inputs: chc008-nsrr (192)
2.5min inputs: chc009-nsrr (178)
2.5min inputs: chc010-nsrr (172)
2.5min inputs: chc012-nsrr (184)
2.5min inputs: chc013-nsrr (188)
2.5min inputs: chc014-nsrr (191)
2.5min inputs: chc015-nsrr (187)
2.5min inputs: chc016-nsrr (191)
2.5min inputs: chc022-nsrr (162)
2.5min inputs: chc025-nsrr (166)
2.5min inputs: chc027-nsrr (180)
2.5min inputs: chc028-nsrr (177)
2.5min inputs: chc033-nsrr (174)
2.5min inputs: chc035-nsrr (180)
2.5min inputs: chc037-nsrr (177)
2.5min inputs: chc040-nsrr (216)
2.5min inputs: chc041-nsrr (171)
2.5min inputs: chc052-nsrr (183)
2.5min inputs: chc056-nsrr (184)
2.5min inputs: chp001-nsrr (232)
2.5min inputs: chp002-nsrr (216)
2.5min inputs: chp003-nsrr (200)
2.5min inputs: chp004-nsrr (197)
2.5min inputs: chp005-nsrr (261)
2.5min inputs: chp006-nsrr (220)
2.5min inputs: chp007-nsrr (231)
2.5min inputs: chp008-nsrr (191)
2.5min inputs: chp009-nsrr (206)
2.5min inputs: chp010-nsrr (194)
2.5min inputs: chp011-nsrr (202)
2.5min inputs: chp012-nsrr (223)
2.5min inputs: chp013-nsrr (200)
2.5min inputs: chp014-nsrr (201)
2.5min inputs: chp015-nsrr (231)
2.5min inputs: chp016-nsrr (254)
2.5min inputs: chp017-nsrr (202)
2.5min inputs: chp018-nsrr (225)
2.5min inputs: chp019-nsrr (188)
2.5min inputs: chp020-nsrr (230)
2.5min inputs: chp022-nsrr (253)
2.5min inputs: chp024-nsrr (225)
2.5min inputs: chp025-nsrr (89)
2.5min inputs: chp026-nsrr (188)
2.5min inputs: chp028-nsrr (206)
2.5min inputs: chp029-nsrr (209)
2.5min inputs: chp030-nsrr (240)
2.5min inputs: chp031-nsrr (222)
2.5min inputs: chp032-nsrr (213)
2.5min inputs: chp033-nsrr (202)
2.5min inputs: chp034-nsrr (208)
2.5min inputs: chp036-nsrr (252)
2.5min inputs: chp037-nsrr (207)
2.5min inputs: chp038-nsrr (205)
2.5min inputs: chp039-nsrr (222)
2.5min inputs: chp040-nsrr (214)
2.5min inputs: chp041-nsrr (221)
2.5min inputs: chp042-nsrr (223)
2.5min inputs: chp043-nsrr (241)
2.5min inputs: chp044-nsrr (210)
2.5min inputs: chp045-nsrr (241)
2.5min inputs: chp046-nsrr (219)
2.5min inputs: chp047-nsrr (178)
2.5min inputs: chp048-nsrr (206)
2.5min inputs: chp049-nsrr (216)
2.5min inputs: chp051-nsrr (218)
2.5min inputs: chp052-nsrr (200)
2.5min inputs: chp053-nsrr (217)
2.5min inputs: chp054-nsrr (224)
2.5min inputs: chp055-nsrr (222)
2.5min inputs: chp056-nsrr (220)
2.5min inputs: chp057-nsrr (239)
2.5min inputs: chp058-nsrr (206)
2.5min inputs: chp059-nsrr (227)
2.5min inputs: chp060-nsrr (252)
/home/shenning/classifier.py:226: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  conf_mats = np.zeros((5,5), dtype=np.int)

=== Test on chc001-nsrr. train_data(15860), test_data(160) ===
Define dataloader
==== START TRAINING ====
load model to cuda:0
==== START TESTING ====
torch.Size([10, 256, 1, 4])
Shape of inp: torch.Size([256, 8, 50])
Traceback (most recent call last):
  File "/home/shenning/classifier.py", line 453, in <module>
    LeaveOneSubjectOut_loadmodel(base)
  File "/home/shenning/classifier.py", line 269, in LeaveOneSubjectOut_loadmodel
    sss, conf_mat, d_pred, d_label, ds_15min_subject = test_on_subject(model, test_dataloader, ntest, subject)
  File "/home/shenning/classifier.py", line 391, in test_on_subject
    feature_imshow(conv3_out)
  File "/home/shenning/classifier.py", line 442, in feature_imshow
    inp = std*inp + mean
ValueError: operands could not be broadcast together with shapes (3,) (8,50,256) 
